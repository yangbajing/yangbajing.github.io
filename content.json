{"meta":{"title":"羊八井花园","subtitle":"羊八井花园 -> 杨景","description":"羊八井/杨景的个人站点，Scala/Java/Pulsar/Akka/Elasticsearch/BigData/Cassandra","author":"杨景","url":"https://yangbajing.github.io","root":"/"},"pages":[],"posts":[{"title":"数据的相等性比较引发的 BUG","slug":"数据的相等性比较引发的bug","date":"2023-04-29T02:40:54.000Z","updated":"2023-04-28T03:18:55.989Z","comments":true,"path":"2023/04/29/数据的相等性比较引发的bug/","link":"","permalink":"https://yangbajing.github.io/2023/04/29/%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%B8%E7%AD%89%E6%80%A7%E6%AF%94%E8%BE%83%E5%BC%95%E5%8F%91%E7%9A%84bug/","excerpt":"","text":"问题相同的代码逻辑，在不同的环境得出了不同的结果。在业务系统里是正确的，但是数据系统里却计算出了不同的结果。给一个示例： 12345Integer x = 1234567;Long y = 1234567L;if (x.equals(y))) &#123; // 处理业务逻辑&#125; 我们预期if语句判断能够成功并进入进行处理业务逻辑，但实际上这里会始终返回 false。这是因为java.lang.Integer和java.lang.Long的equals方法实现均会先判断类型，类型相同才会进行实际的相等性比较。Integer#equals方法实现如下： 123456public boolean equals(Object obj) &#123; if (obj instanceof Integer) &#123; return value == ((Integer)obj).intValue(); &#125; return false;&#125; 怎样避免此类问题？配置 IDEA 提升对于不兼容类型进行相等性比较时的检查级别 1234567&lt;component name&#x3D;&quot;InspectionProjectProfileManager&quot;&gt; &lt;profile version&#x3D;&quot;1.0&quot;&gt; &lt;option name&#x3D;&quot;myName&quot; value&#x3D;&quot;Project Default&quot; &#x2F;&gt; &lt;inspection_tool class&#x3D;&quot;EqualsBetweenInconvertibleTypes&quot; enabled&#x3D;&quot;true&quot; level&#x3D;&quot;ERROR&quot; enabled_by_default&#x3D;&quot;true&quot; editorAttributes&#x3D;&quot;ERRORS_ATTRIBUTES&quot; &#x2F;&gt; &lt;&#x2F;profile&gt;&lt;&#x2F;component&gt; Java 17123456789101112131415161718192021222324252627282930313233| Welcome to JShell -- Version 17.0.6| For an introduction type: /help introjshell&gt; var i = new Integer(12345678)| Warning:| Integer(int) in java.lang.Integer has been deprecated and marked for removal| var i = new Integer(12345678);| ^-------------------^i ==&gt; 12345678jshell&gt; Integer i = 12345678;i ==&gt; 12345678jshell&gt; Long l = 12345678L;l ==&gt; 12345678jshell&gt; i.equals(i, l)| Error:| method equals in class java.lang.Integer cannot be applied to given types;| required: java.lang.Object| found: java.lang.Integer,java.lang.Long| reason: actual and formal argument lists differ in length| i.equals(i, l)| ^------^jshell&gt; Objects.equals(i, l)$4 ==&gt; falsejshell&gt; i == l| Error:| incomparable types: java.lang.Integer and java.lang.Long| i == l| ^----^ 其它语言Scala12345678910111213141516171819202122(base) ➜ spring3-template git:(main) ✗ scalaWelcome to Scala 3.2.1 (17.0.6, Java OpenJDK 64-Bit Server VM).Type in expressions for evaluation. Or try :help.scala&gt; val i = new java.lang.Integer(12345678)there was 1 deprecation warning; re-run with -deprecation for details1 warning foundval i: Integer = 12345678scala&gt; val l = new java.lang.Long(12345678)there was 1 deprecation warning; re-run with -deprecation for details1 warning foundval l: Long = 12345678scala&gt; i.equals(l)val res0: Boolean = falsescala&gt; java.util.Objects.equals(i, l)val res1: Boolean = falsescala&gt; i == lval res2: Boolean = true Rust总结TODO","categories":[],"tags":[]},{"title":"使用 Pulsar CDC 同步 PostgreSQL","slug":"使用-Pulsar-CDC-同步-PostgreSQL","date":"2021-09-30T11:50:31.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2021/09/30/使用-Pulsar-CDC-同步-PostgreSQL/","link":"","permalink":"https://yangbajing.github.io/2021/09/30/%E4%BD%BF%E7%94%A8-Pulsar-CDC-%E5%90%8C%E6%AD%A5-PostgreSQL/","excerpt":"","text":"问题监控发现 PostgreSQL 的 pg_wal 日志文件一直在持续增长，设置的 max_wal_size = 2GB 参数值未起作用。 12-bash-4.2$ du -sh $PGDATA&#x2F;pg_wal61G &#x2F;data&#x2F;pgsql&#x2F;12&#x2F;data&#x2F;pg_wal 12345postgres=# select pg_walfile_name(&#x27;0/14CB2278&#x27;); pg_walfile_name -------------------------- 000000010000000000000014(1 行记录) 进一步查询文件发现其创建时间为 9 月 1 号： 12-bash-4.2$ ls -l $PGDATA&#x2F;pg_wal&#x2F;000000010000000000000014-rw------- 1 postgres postgres 16777216 9月 1 12:31 000000010000000000000014 查询指定日志文件与单前最新日志文件的大小也于磁盘空间战胜一致 12345postgres=# select pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), &#x27;0/14CB2278&#x27;)); pg_size_pretty ---------------- 61 GB(1 行记录)","categories":[],"tags":[]},{"title":"微服务：代码分层","slug":"微服务：代码分层","date":"2021-07-30T01:00:29.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2021/07/30/微服务：代码分层/","link":"","permalink":"https://yangbajing.github.io/2021/07/30/%E5%BE%AE%E6%9C%8D%E5%8A%A1%EF%BC%9A%E4%BB%A3%E7%A0%81%E5%88%86%E5%B1%82/","excerpt":"","text":"本篇是微服务系统的第一篇，我将基于自身的经验和在公司项目中的实践来记录我们施行微服务的过程和方式。","categories":[{"name":"essay","slug":"essay","permalink":"https://yangbajing.github.io/categories/essay/"}],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://yangbajing.github.io/tags/micro-service/"},{"name":"DDD","slug":"DDD","permalink":"https://yangbajing.github.io/tags/DDD/"}]},{"title":"Pulsar 2.7：集群，认证、授权，函数计算，CDC","slug":"pulsar-2.7：集群，认证、授权，函数计算，CDC","date":"2021-04-13T14:45:52.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2021/04/13/pulsar-2.7：集群，认证、授权，函数计算，CDC/","link":"","permalink":"https://yangbajing.github.io/2021/04/13/pulsar-2.7%EF%BC%9A%E9%9B%86%E7%BE%A4%EF%BC%8C%E8%AE%A4%E8%AF%81%E3%80%81%E6%8E%88%E6%9D%83%EF%BC%8C%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97%EF%BC%8CCDC/","excerpt":"","text":"一些问题 Apache Pulsar 2.7.1 当 Functions Worker 独立运行时，客户端需要直接 Worker，现在的 Pulsar 还不能通过 broker 找到 Worker 地址。社区已有相应的 PR #6425 修复 当配置了 Pulsar 集群配置了认证/授权，且 connector 使用进程模式运行时，现在 connector 未继承 Functions Worker 的认证配置，造成 connector 将以匿名用户的方式连接 broker。解决方案有（现在社区也有相应的 PR #8668 修复此问题）： 禁用 Pulsar 集群的认证/授权 设置 broker 的 anonymousUserRole= 为配置的某个用户。 debezium MySQL 1.4.2 for Apache Pulsar CDC 默认的 debezium 为 1.0 版本，对 MySQL 8 新的密码认证方式支持不好，会报： Caused by: java.sql.SQLNonTransientConnectionException: Public Key Retrival is not allowed 异常。我们可以通过从代码自行编译的方式来升级 debezium 为更高版本解决此问题。 Pulsar 集群安装按官网文档安装即可： https://pulsar.apache.org/docs/en/deploy-bare-metal/ 。 对于 Functions Woker，采用独立运行的方式，安装文档见：https://pulsar.apache.org/docs/en/functions-worker/#run-functions-worker-separately 。 认证/授权Broker 的认证/授权Pulsar 支持多种认证/授权机制，本文采用 JWT Token 的方式，设置文档见： https://pulsar.apache.org/docs/en/security-jwt/ 。 JWT Token 支持两种签名模式：对称与非对称，非对称相对来说更安全。默认的非对称加密使用的 RS256 加密方式，相对 ES256 来说，ES256 生成的 token 在想同安全强度下生成的字符串更短，同时计算速度也更快。同过如下命令可生成 ES256 密钥对： 1234bin&#x2F;pulsar tokens create-key-pair \\ --signature-algorithm ES256 \\ --output-private-key conf&#x2F;fruits-private.key \\ --output-public-key conf&#x2F;fruits-public.key 不过，官网没有说明采用 ES256 加密算法时 broker 端的配置方式，需要在 conf/broker.conf 里添加如下配置，不然 broker 默认使用 RS256 算法解析密钥文件。相应的，若使用其它算法也应将其配置对应算法。 1tokenPublicAlg=ES256 Functions Worker 的认证/授权独立运行的 Functions WorkerFunctions Worker 独立运行时，它有两种角色： 当做一个独立的 Broker 加入 Pulsar 集群 做为一个客户端访问 broker 所以，在 conf/functions_worker.conf 配置文件里要用配置认证、授权和客户端，相应配置如下： 123456789101112131415# As broker clientbrokerClientAuthenticationEnabled: truebrokerClientAuthenticationPlugin: org.apache.pulsar.client.impl.auth.AuthenticationTokenbrokerClientAuthenticationParameters: file:///data/local/pulsar/conf/token-fruits.jwt# As brokerauthenticationEnabled: trueauthorizationEnabled: trueauthenticationProviders: [ &quot;org.apache.pulsar.broker.authentication.AuthenticationProviderToken&quot; ]authorizationProvider: org.apache.pulsar.broker.authorization.PulsarAuthorizationProvidersuperUserRoles: - fruitsproperties: tokenPublicKey: file:///data/local/pulsar/conf/fruits-public.key tokenPublicAlg: ES256 因为 Functions Worker 作为一个 Broker 独立运行，同时使用了 ES256 算法进行 JWT 签名，所以也需要配置 tokenPublicAlg 选项。 客户端访问对于独立运行的 Functions Worker，客户端需要直连 Worker，当前 Pulsar 还不能通过 broker 获取 functions worker 的地址，所以与函数计算相关的功能都需要直连 Functions Worker。如： 1bin&#x2F;pulsar-admin --admin-url http:&#x2F;&#x2F;node1:6750 functions list 端口 6750 是 conf/functions_worker.conf 里配置的 Functions Worker 监听地址。与函数计算相关的功能有：functions、sources、sinks。 小结Apache Pulsar 是一个功能很强大的消息、函数计算、流处理系统，整体功能还在不断发展中。但还是有些小细节的问题，还不够完善……这些对于新人来说会耽误不少时间，这里记录在此，希望能让遇到类似问题的朋友可以少走些弯路、节约点时间。以后再多分享些在实际业务中应用 Pulsar 的经验。","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"pulsar","slug":"bigdata/pulsar","permalink":"https://yangbajing.github.io/categories/bigdata/pulsar/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://yangbajing.github.io/tags/mysql/"},{"name":"pulsar","slug":"pulsar","permalink":"https://yangbajing.github.io/tags/pulsar/"},{"name":"cdc","slug":"cdc","permalink":"https://yangbajing.github.io/tags/cdc/"},{"name":"functions","slug":"functions","permalink":"https://yangbajing.github.io/tags/functions/"},{"name":"debezium","slug":"debezium","permalink":"https://yangbajing.github.io/tags/debezium/"}]},{"title":"使用 gRPC 设计 API 的优势","slug":"使用-grpc-设计-api-的优势","date":"2021-04-08T12:09:51.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2021/04/08/使用-grpc-设计-api-的优势/","link":"","permalink":"https://yangbajing.github.io/2021/04/08/%E4%BD%BF%E7%94%A8-grpc-%E8%AE%BE%E8%AE%A1-api-%E7%9A%84%E4%BC%98%E5%8A%BF/","excerpt":"","text":"现阶段 API 设计的问题在开发过程中，有一些很困扰前、后端团队交互的问题： 谁来设计 API？ 提供什么形式的 API？ 什么时候可以提供 API？ 对于第一个问题，通常情况下都是由后端人员来设计 API，这就造成前端人员会在开发初期的一段时间内没法作数据模型和服务端交互方面的工作。这时，一些独立的 API 管理工具就派上用场了，比如：类似 yapi 这样的 API 管理/Mock 工具。前端人员可以不用等后端设计 API，直接在 yapi 上设计接口并可以提供一些“无用”的模拟数据。但是，这又会引入些其它问题，在 yapi 上设计的接口，后端人员需要在后端代码里重新实现一次，而且很容易出现 yapi 上设计的接口和后端代码实现的接口不一致的情况，如：字段缺失、数据类型不一致等等。有没有方法可以通过 API 文档自动生成代码呢？前端有很多工具可以从 swagger API 文档自动生成代码，但生成后端的工具暂未发现（或不实用），从后端代码生成 swagger 的但是有很多（比如：springfox）。所以，传统模式下通常是这种情况： 前端等着后端设计 API。或者通过独立的 API 管理工具来设计接口，然后后端再参照实现； 前端根据 API 管理工具/或后端生成的 swagger 文档手工编写交互 model 和 service，或者通过自动化 codegen 工具从 swagger 自动生成； 如果有变更，继续重复上述两个步骤。 理想的 API 设计从上面可以看出，无论是等后端设计还是通过 API 管理工具来设计都会有某一方或两方都需要参照 API 文档来手工实现代码逻辑的问题，都会存在 API 与代码实现脱节的问题。理想情况下，我们希望 API 设计/生成方式具备如下特性： 利于前/后端协作，API 定义文件既是 活文档 ； API 设计独立于代码实现，可以通过设计好的 API 文档自动生成前/后端代码； API 设计好了，前/后端即可分别开发，不需要等着某一方提供后才能着手开发； API 有修改时，前/后端都可以自动化的响应变更，而不需要通过手动编码的方式去查找哪些字段、哪些接口有变化； 通过 API 文档生成的接口代码应该是易用地、性能优化的； API 应该具备一定的向后兼容性； Mock 真的需要吗？ 基于以上几点，笔者觉得 gRPC（或者其它类似的工具）是现阶段很合适的（以后可能会有更好的技术） API 设计工具。 gRPCgRPC 是 Google 推出的一款 RPC 工具，本文不会对 RPC 原理做过多介绍，也不会详细的讲解 gRPC 本身，将专注于介绍用 gRPC 来设计 API 的好处上。对于 RPC 以及 gRPC 本身，后续文章再对其作进一步介绍。 gRPC 是通过 .proto 文件来设计的，也就是说它可以独立于前/后端设计、管理。这样，在开发早期，前/后端人员都可以对其进行设计，而且因为 .proto 文件只是纯文本文件，可以使用源代码管理工具（如：Git、SVN等）对其进行管理。这从 API 版本的管理上比使用类似 yapi 这样独立的 API 管理工具来说更好，也不需要为此单独部署一套软件。这就解决了在 API 设计/管理层面上前/后端协作的问题。 gRPC 的设计是独立于代码实现的，它有一套自己的语法规则（非常简单，很快就能上手），而且官方和社区提供了大部分编程语言/框架的代码生成。这就解决了代码实现与 API 文档不一致的问题，一但 API 有调整，通过工具即可自动生成最新的代码，后端服务及数据模型，前端访问接口服务及数据模型。 gRPC 是通过二进制数据传输的，而且提供了数据压缩等特性，相比传统的 JSON 格式，它有着更快的 CPU （序列化/反序列化）性能以及更小的网络数据传输流量（二进制、数据压缩）。 gRPC 的向后兼容性通过 Protobuf 体现，Protobuf Message 有两个特点：默认值和字段序号，可以较好地解决兼容性问题。这体现在： 默认值：从设计层面还在纠结字段 null 的情况，所有字段若不设置都会有默认值（除了 String 的默认值为空字符串外和集合类型的默认值为不可变空集合外，其它对像类型字段的默认值均为 null） 字段序号：字段名字的改变，只要保证对应的序号不变或不起冲突，那接口就是兼容的，不需要前/后端的 .proto Message 设计完全一致 12345message User &#123; int64 id = 1; string username = 2; int64 create_time = 3;&#125; 真的需要 Mock 吗？Mock，准确地说是类似于 yapi 这样的 API 管理工具提供的数据 Mock，真的需要吗？首先来聊聊 Mock 想要解决和实际解决得怎样的问题：Mock 想解决后端还未实现接口时，前端可以访问后端服务的问题。 但实际上，它解决得并不好；而且，通常情况下我们也不需要它。Mock 生成的数据通常都是一些无意义的字符串或一些随机的数值、日期，当然，有些工具提供 js 脚本可以自定义设计 mock 生成规则……但这些都更像是掩耳盗铃，前端需要的是真实的、能向前走通业务流程的接口数据，而 Mock 是做不到的！若做到了，那就不需要 Mock，因为你已经在实现真实的业务逻辑。所以，正确的做法应该是后端通过 gRPC 自动生成服务接口，并在接口层返回一些固定的模拟数据即可，前端在做 UI 组件和 前端侧业务逻辑 时只要保证调用后端接口不报错就行，这并不需要太多的时间。 从另一个角度来说，gRPC 可以生成完整的前端代码，配以类似 Typescript 等静态类型语言。在开发早期（后端还未提供任何一个返回真实业务数据接口的时候），前端是可以直接写业务逻辑的，因为这时前端已经拥有了完整的业务数据 model 和 API 接口访问请求代码。在这一阶段，前/后端是可以独立、并行的进行代码开发的。待后端提供了任何一个可用的服务 API，即可进行前/后端联调。 GraphQLGraphQL 也是一套很好地用来设计 API 的工具，当然也可以选择使用 GraphQL。在某些业务上它具备 gRPC 没有的灵活性。不过，gRPC 可以统一前/后端交互与后端服务内部 RPC 的完整技术栈，从这一点看它可以减少学习成本。 小结本文阐述了笔者对使用 gRPC 来设计 API 的一些思考，它可以解决传统 RESTful 及使用单独的 API 管理工具来设计 API 的缺陷。同时，通过在 gRPC 所使用 .proto 文件里添加注释，本身就是（活）文档，不需要再额外管理 API 文档。 使用 gRPC 也会有一些问题，比如生态还不够丰富、相关学习资料偏少。以及缺少强大的测试工具，不过这可以通过开发些小的工具软件来解决。 之后会写系列文章来介绍怎样具体使用 gRPC 设计 API。敬请期待！","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"grpc","slug":"grpc","permalink":"https://yangbajing.github.io/tags/grpc/"},{"name":"api-design","slug":"api-design","permalink":"https://yangbajing.github.io/tags/api-design/"},{"name":"api","slug":"api","permalink":"https://yangbajing.github.io/tags/api/"},{"name":"protobuf","slug":"protobuf","permalink":"https://yangbajing.github.io/tags/protobuf/"}]},{"title":"Greenplum 6.x 安装注意事项","slug":"greenplum-6-x-安装注意事项","date":"2020-11-19T07:06:59.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2020/11/19/greenplum-6-x-安装注意事项/","link":"","permalink":"https://yangbajing.github.io/2020/11/19/greenplum-6-x-%E5%AE%89%E8%A3%85%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"/etc/sysctl.conf 设置注意12kernel.shmall=echo $(expr $(getconf _PHYS_PAGES) / 2)kernel.shmmax=echo $(expr $(getconf _PHYS_PAGES) / 2 \\* $(getconf PAGESIZE))","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"greenplum","slug":"bigdata/greenplum","permalink":"https://yangbajing.github.io/categories/bigdata/greenplum/"}],"tags":[{"name":"postgres","slug":"postgres","permalink":"https://yangbajing.github.io/tags/postgres/"},{"name":"greenplum","slug":"greenplum","permalink":"https://yangbajing.github.io/tags/greenplum/"},{"name":"centos","slug":"centos","permalink":"https://yangbajing.github.io/tags/centos/"}]},{"title":"DolphinScheduler","slug":"dolphinscheduler","date":"2020-09-21T08:17:04.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2020/09/21/dolphinscheduler/","link":"","permalink":"https://yangbajing.github.io/2020/09/21/dolphinscheduler/","excerpt":"","text":"系统配置操作系统环境 1234567891011121314151617systemctl stop firewalldsystemctl disable firewalld# Install softwaresyum -y install epel-releaseyum -y install java-11-openjdk-devel tree htop vim sshpass wget curl# Add useruseradd dolphinschedulerecho dolphinscheduler | passwd --stdin dolphinschedulerecho &#39;dolphinscheduler ALL&#x3D;(ALL) NOPASSWD: NOPASSWD: ALL&#39; &gt;&gt; &#x2F;etc&#x2F;sudoerssed -i &#39;s&#x2F;Defaults requirett&#x2F;#Defaults requirett&#x2F;g&#39; &#x2F;etc&#x2F;sudoers# Create directorymkdir &#x2F;opt&#x2F;dolphinschedulerchown -R dolphinscheduler:dolphinscheduler &#x2F;opt&#x2F;dolphinscheduler 免密登录su dolphinscheduler 12345678ssh-keygen -t rsa -P &#39;&#39; -f ~&#x2F;.ssh&#x2F;id_rsacat ~&#x2F;.ssh&#x2F;id_rsa.pub &gt;&gt; ~&#x2F;.ssh&#x2F;authorized_keyschmod 600 ~&#x2F;.ssh&#x2F;authorized_keysfor ip in ds2 ds3; #请将此处ds2 ds3替换为自己要部署的机器的hostnamedo ssh-copy-id $ip #该操作执行过程中需要手动输入dolphinscheduler用户的密码done 安装 PostgreSQL12345sudo yum -y install https:&#x2F;&#x2F;yum.postgresql.org&#x2F;12&#x2F;redhat&#x2F;rhel-7-x86_64&#x2F;pgdg-redhat-repo-latest.noarch.rpmsudo yum -y install postgresql12 postgresql12-serversudo &#x2F;usr&#x2F;pgsql-12&#x2F;bin&#x2F;postgresql-12-setup initdbsudo systemctl enable postgresql-12sudo systemctl start postgresql-12 12sudo -u postgres psql -c &quot;create user dolphinscheduler nosuperuser replication encrypted password &#39;dolphinscheduler&#39;;&quot;sudo -u postgres psql -c &quot;create database dolphinscheduler owner&#x3D;dolphinscheduler;&quot;","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"scheduler","slug":"scheduler","permalink":"https://yangbajing.github.io/tags/scheduler/"}]},{"title":"实时数据处理探索：接收、处理、访问","slug":"实时数据处理探索-receive-process-access","date":"2020-09-03T12:58:43.000Z","updated":"2022-02-16T02:50:45.203Z","comments":true,"path":"2020/09/03/实时数据处理探索-receive-process-access/","link":"","permalink":"https://yangbajing.github.io/2020/09/03/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8E%A2%E7%B4%A2-receive-process-access/","excerpt":"","text":"ETL（也包括ELT）是数据处理工作里必不可少的步骤，一直以来通常都是以天或小时为单位采用批处理来对大量的数据进行 ETL 操作。随着业务的增长及需求的变化，用户/客户希望能更快的看到各类数据操作的结果，这就催生了实时 ETL 的诉求。 传统上，批量 ETL 会在数据仓库上进行。比如按 天 为单位从一个库同步原始数据到 ODS 层，再通过编写存储过程来对 ODS 层的数据进行加工后将明细数据存储到 DWS 层，然后再对 DWS 层数据作进一步加工形成业务可直接使用的数据。整个处理过程本身非常缓慢，通常需要持续几个小时…… 而实时 ETL 通常要求从收到 原始数据 -&gt; 数据清洗、加工 -&gt; 业务可用 在 秒 级时间来完成，且通常为来一条记录既处理一条记录，实现业务数据的实时更新。 本文将将实时 ETL 抽像成 数据接收、数据处理、数据访问 三个部分，并依据此3部分来讨论实时 ETL 的一种建设方案。 数据接收数据接收是实时 ETL 的第一步，对于数据接收方式我将期抽像为两类： 主动拉取：数据源提供用于数据同步的数据库、FTP/sFTP等，ETL 系统登录上去获取数据接收（常用于传统的批量 ETL） 被动接收：提供一个 API（HTTP接口或消息系统），由数据源主动将数据提交上来（实时 ETL 更多使用此种方式） 主动拉取对于通过数据库同步的方式，传统的批量 ETL 有很多工具可用于数据同步，在此不再做更多的介绍。这里，介绍下实时 ETL 的一种数据拉取方式。 实时 ETL 从数据库拉取数据，可以通过 Kafka Connect JDBC 来拉取表记录并将数据写入 Kafka 主题，这样我们就可以使用各种大数据处理工具（Kafka Streams、Flink、Spark Streaming等）来消费 Kafka 主题的数据并对其进行数据清洗工作。 被动接收被动接收通常有3种方式 提供一个 API（HTTP）接口，数据源调用 API 将数据推送上来 提供一个数据步同的消息系统（如：Kafka），数据源向消息系统写入数据 通过 CDC 监听业务系统数据库表数据变更 通过 Debezium 监听数据库表数据的变更，可实时响应业务系统数据的变化并对其进行加工、分析处理 对于基于 HTTP 的 API 接口，可以考虑使用 JSON Schema 来定义数据校验格式，在数据验证正确后再将数据写入 Kafka。JSON 作为现在最通用的数据格式，可以降低数据对接的技术难度，而因为 JSON 的动态特性，对数据进行格式校验是必不可少的，JSON Schema因其标准化、可扩展性很适合承担此任务。 这里，可以看到各种数据接收方式最终都是把数据写入了 Kafka 消息系统，那我们可以把数据写入其它消息系统或存储系统吗？答案是可以的，但这里建议还是将数据写入 Kafka 进行暂存，因为 Kafka 本身具备数据持久化、高可用/高性能等特性，且与各类数据处理工具都有适配，可以说是现在实事上的大数据处理消息系统标准。当然，也有其它很不错的消息系统（RocketMQ、Pulsar）和存储系统（Pravega）可胜任此任务，但综合技术难度、生态和已有案例，从 Kafka 开始是一个不错的选择。 数据处理实时数据处理与传统的批量数据处理（ETL）有个显著的不同，通过消息系统与流数据处理系统的结合，可以流水线的形式来对数据进行加工。在数据处理过程中可以做到不 落盘（这里指不像存储的批处理模式那样需要每个步骤处理后需要将数据批量写入各个层里，比如：ODS、DWD、DWS等）。 数据处理是一个很灵活的部分，但也有“规则”可循。在这一部分，数据处理抽像为从 Kafka 读取数据，处理完后将数据写入数据存储（通常为 Database）或 Kafka。该一过程可能会有几轮循环，这通常取决于业务复杂程度。 在接收数据我们将数据统一暂存到 Kafka 中，这样在数据处理部分就统一了数据来源。数据处理后的结果存储到数据库中都很容易理解，这是可以直接供业务系统调用的数据（以数据仓库的概念，通常会存储到 APP 层）。 而将处理后的数据再存到 Kafka 是做什么用呢？因为对于实时 ETL，速度为第一要务，处理后的结果需要及时通知业务系统，这就可以通过 Kafka 这样的消息系统来 “推送” 给业务系统（实质上是将结果写入一个 Kafka topic，业务系统监听该 topic）。 实时数据处理，可以运用多种技术来实现，比如：Kafka Streams、Flink/Spark Streaming 等。对于比较简单的实时处理或比较小的技术团队，可以使用 Kafka Streams，相对来说对技术、运维和资源的要求更低。而对于较复杂的实时处理，或团队比较完善，有专门的大数据团队，则可以选择 Flink 或者 Spark Streaming 这样的专而全的实时处理大数据工具。 实时数据处理是一个很大课题，对于怎样进行实时数据处理及技术本身本文不作更多介绍……也许之后我会单独写文章介绍实时数据处理相关知识。 数据访问实时数据处理，处理后的 结果 数据需要及时推送到业务系统，这可以通过消息系统来实现，Kafka 是一个很好的选择（RocketMQ、Pulsar和RabbitMQ等也可以）。这样从数据接收、数据处理到数据访问既形成了一个完整的 实时 闭环。 在消息推送之外，也需要将结果数据持久化存储下来供业务系统访问。这可以通过两种方式来实现： 在流处理中直接将结果写入持久化存储（如数据库） 消费推送到 Kafka topic 里的实时结果数据，将其存储到持久化存储 对于存储在持久化存储里的结果数据，可能使用一个统一的 data-access 微服务来像其它业务系统提供服务。通过 RESTful、RPC 等方式将数据接口暴露出去。 总结本文简单的介绍了实时数据处理可用到的技术与业务分层探索。在大的方面可对实时数据处理分为数据接收、数据处理和数据访问3部分，对每一部分可用到的技术进行了初步的介绍。 实时数据处理还有更多可能等待探索，目的只有一个：天下武功，唯快不破！","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://yangbajing.github.io/tags/kafka/"},{"name":"etl","slug":"etl","permalink":"https://yangbajing.github.io/tags/etl/"},{"name":"flink","slug":"flink","permalink":"https://yangbajing.github.io/tags/flink/"},{"name":"realtime-etl","slug":"realtime-etl","permalink":"https://yangbajing.github.io/tags/realtime-etl/"}]},{"title":"CRUDer 的自我修养：PostgreSQL、JDBC、MyBatis、R2DBC","slug":"cruder-的自我修养：postgresql、jdbc、mybatis、r2dbc","date":"2020-08-09T09:02:00.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/08/09/cruder-的自我修养：postgresql、jdbc、mybatis、r2dbc/","link":"","permalink":"https://yangbajing.github.io/2020/08/09/cruder-%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%EF%BC%9Apostgresql%E3%80%81jdbc%E3%80%81mybatis%E3%80%81r2dbc/","excerpt":"","text":"这是一系列文章的目录，对于一个合格的 CRUD 程序猿/媛、码农、IT民工，更高效的进行 CRUD 是我们孜孜不倦的追求！本文是系列文章的序文，首先介绍各技术的亮点，再在之后的单独文章里详细介绍各技术的功能、优势、技巧等……通过对这 4 个主题的介绍，增进我们更好的进行 CRUD 开发。 PostgreSQL本系列文章以 PostgreSQL（以下简称：PG）为例讲解 SQL，对于 CRUDer ，SQL 是基础中的基础！我们应逃出 ORM 的束缚，在 SQL 的海洋里乘风破浪。这里首先介绍 PG 的其中 4 个亮点技术： 数组其实 JDBC 标准本身是支持数组的，而且大部分数据库也支持数组类型，但日常开发中这个特性使用得还是比较少。在业务建模中应用数组是很常见的需求，比如一篇文章的 TAG 标签列表、组织的管理员（用户ID）列表等很多对于事实表需要存储少量列表数据的情况。而对于列表数据很多的情况使用数组存储就不大合适，继续使用一张关系表是个有效的解决方案，比如组织内的成员列表，因为一个组织内的成员可能很多，可能成千上万；这么大的一个数组是不必要的，而且通常业务上也不会一次性对这么大的一个数组进行查询或处理。 在了解了数组类型的适用范围后，我们来看看 PG 中具体怎样定义和使用数组。PG 的数组类型是一个完备的类型，支持几乎所有的类型的数组，如：int[]、text[]、numeric[]、timestamp[] 等。可以看到，要声明一个列为数组类型，只需要在普通的类型后面加个中括号 [] 即可。我们可以 通过中括号并由 array 修饰 的方式来定义一个数组： 12insert into t_test(topic, tags, user_ids, create_time)values (&#x27;topic-002&#x27;, array [&#x27;Java&#x27;,&#x27;Scala&#x27;,&#x27;Javascript&#x27;,&#x27;SQL&#x27;], array [2,3,4], now()); JSON现在，越来越多的关系型数据库支持 JSON 了，这使关系型数据库在某种程度上具备了 NoSQL 的特性（灵活性），同时还拥有 NoSQL 不具备的关联查询、事物等易用的特性。可以说，在 PG 中使用 JSON（jsonb）类型会是一个比使用 MongoDB 更好的一个选择！因为 PG 的 JSON 融合了 NoSQL 数据库的模式灵活性，同时还具备关系型数据库的关系查询、事物、索引等能力，MongoDB 实际上在创建二级索引后性能非常的差，至于 K/V ，有很多比 MongoDB 更好的选择…… PG 中有两种 JSON ： jsonb：将解析后的 JSON 结构以二进制的方式存储，类型 MongoDB 的 BSON 那样，有查询优化，同时可以为某些字段创建索引； json：按字符串存储，在每次使用时再转换成 JSON，写入速度更快，占用存储空间相对 jsonb 更少，但查询速度更慢，且不能创建索引。 12insert into t_test(metadata)values (&#x27;&#123;&quot;title&quot;:&quot;CRUDer 的自我修养&quot;,&quot;author&quot;:&quot;杨景&quot;&#125;&#x27;::jsonb); returning通常情况下，除了 select 语句外 update、delete、insert 都只能返回一个代表此操作影响了的记录行数。如果你想在 修改 操作后紧接着马上获得操作的那条记录，那你得再进行一次 select 查询。使用 returning 语句，你可以在 update、delete、insert 语句执行后马上将受影响记录的数据返回，这可以在语句后紧接使用 returning * 实现；甚至你还可以指定要返回的例，而不用将所有列都返回 returning id, create_time 。 123insert into t_test(metadata)values (&#x27;&#123;&quot;title&quot;:&quot;CRUDer 的自我修养&quot;,&quot;author&quot;:&quot;杨景&quot;&#125;&#x27;::jsonb)returning id; 此条语句在插入成功后返回插入记录的自增主键值。 batch insertPG 在 SQL 语法层面支持批量插入（虽然 COPY 更快，但它非 SQL 标准），类似的 MySQL 也支持 SQL 层面的批量插入特性： 123insert into t(name) values(&#x27;羊八井&#x27;),(&#x27;杨景&#x27;); Insert on conflictinsert on conflict 就是 PG 中的一个 杀手级 功能，真的是太好用了。它可以在你插入数据起冲突时（主键、唯一键、唯一索引）由你选择是原地更新数据还是什么也不做（忽略）。这可以简化 查询-判断-写入/更新 逻辑，而且因为少一次数据库访问，在性能上也会有提升。另外，若你选择了 do update set，在更新时你还可以精确的控制更新方式，如：更新某几个字符，甚至在更新语句时执行各种计算（update_count = update_count + 1）…… 这里有一个示例： 12345insert into t_test(topic, tags, user_ids, create_time, update_time)values (?, ?, ?, ?, ?)on conflict (topic) do update set tags = excluded.tags, user_ids = excluded.user_ids, update_time = coalesce(excluded.update_time, excluded.create_time); 这里有一个技巧 coalesce(excluded.update_time, excluded.create_time)，coalesce 函数在第一个参数为 null 的时候取第二个参数值，并依此类推直到最后个参数。这样，当 update_time 未设置值的时候就使用 create_time 的值，理论上说，create_time 应该是有设置值的。 MySQL 也有一个类似的语法 insert on duplicate key，从语法上就能看出它的功能比 PG 要弱一点，它限制为 主键 冲突时更新，而且更新时还不能选择更新的字段。 递归查询递归查询应用了 PG 的 CTE （common table expressions，通用表表达式）特性。在很多业务场景中很有用，比如：生成树形菜单、组织结构…… 12345with recursive org_tree as ( select id, name, parent from ig_org where id = ? union all select ig_org.id, ig_org.name, ig_org.parent from ig_org, org_tree where org_tree.parent is not null and ig_org.id = org_tree.parent) select id, name from org_tree 这是一个通过组织 ID 返回组织的完整路径的 SQL 查询语句，通过 PG 的递归查询，查找它的父级组织（父级的低级，一直递归向上找）。 with org_tree as (....) 就是通用表表达式，小括号内的查询结果将缓存在 org_tree 临时表里。recursive 关键字表明这个通用表查询允许递归查询，union all 前面是非递归部分，后面是递归部分。首先通过组织 ID 找到指定的组织，再由找到的组织的 parent（父组织 ID）与 ig_org 表关联查询更新 org_tree，并递归查找直到 org_tree.parent 为 null 为止。 使用 union 将对整个结果集进行去重，union all 不进行去重返回所有记录。 JDBCJava 提供了标准的数据库访问接口： JDBC，我们通过它可以操作各种数据库。PG 的 JDBC 驱动实现了 JDBC 4.1 规范，同时还提供了一些很有用的特性。 batch insertPG 有一个连接参数可以对 batch insert 进行优化，将多条 SQL 语句转换成单条语句 insert into test(name), values (&#39;..&#39;), (&#39;...&#39;) 的形式，这可以有 2到3 倍的性能提升。只需要将以下参数加到连接字符串上即可： 1?reWriteBatchedInserts&#x3D;true 时区、字符集有时候可能需要指定 JDBC 连接的时区和字符集，可以在 connection 连接时设置。在 Spring Boot 可以通过如下配置进行设置： 1234spring: datasource: hikari: connection-init-sql: &quot;SET TIME ZONE &#x27;Asia/Chongqing&#x27;;SET CLIENT_ENCODING TO &#x27;UTF-8&#x27;;&quot; MybatisJava 生态下 ORM 工具有很多，常用的有：JPA（Hibernate、Eclipse TopLink）、Mybatis、JOOQ等。国内 Mybatis 用得比较多，是因为它灵活、高效，在搭配 mybatis-plus 类似的增强工具后，以能实现类似 JPA 的 自动 查询能力，同时还不失其强大的自定义和控制能力。若你受过 JPQL 的折磨，你能够理解到这一点的…… &lt;select&gt; 不只查询PG 支持 returning 语句，但是 Mybatis 的 &lt;insert&gt;、&lt;update&gt;、&lt;delete&gt; 标签只能返回 int 值，这时你可以在 &lt;select&gt; 标签里执行 修改 语句。如： 12345&lt;select id=&quot;insert&quot; resultMap=&quot;TestDO&quot;&gt;insert into t_test(metadata)values (&#x27;&#123;&quot;title&quot;:&quot;CRUDer 的自我修养&quot;,&quot;author&quot;:&quot;杨景&quot;&#125;&#x27;::jsonb)returning id;&lt;/select&gt; Mybatis-plus使用原生 Mybatis，你所有的语句都得自己手工写 SQL（使用 XML 或 注解）；然后要执行分页查询还得自己实现一个 Intercepter ，对于一个懒人，能否靠在别人的肩膀上呢？mybatis-plus 就是可以依靠的肩膀（NB）。 枚举枚举是一个很好的工具，但 JDBC 默认不支持，或者大部分 ORM 库都将枚举序列化成字符串，可实际上我们希望它能够被当成 Integer 来进行序列化。（对于枚举应用还比较少的同学，可以先看看我的另一篇文章：Java 枚举：有效应用）。 Mybatis-plus 提供了对枚举的更好的支持，文档在此：https://mp.baomidou.com/guide/enum.html 。 jsonb在 Mybatis-plus 里使用 JSONB 类型，可以使用 Mybatis-plus 提供的 字段类型处理器 https://mp.baomidou.com/guide/typehandler.html 。 而对于直接使用 mybatis 的用户，也可以直接自定义 TypeHandler。在此可以找到自定义 TypeHandler 的代码：https://github.com/yangbajing/spring-example/tree/develop/example-common/src/main/java/me/yangbajing/springreactive/mybatis/handlers 。 实现自定义 JsonNodeTypeHandler 后，可通过 mybatis-plus 的配置参数全局加载： 12mybatis-plus: type-handlers-package: me.yangbajing.springreactive.mybatis.handlers 这样，就可以像使用 String、LocalDateTime 等类型一样在 Mybatis 里使用 Jackson（支持JsonNode、ObjectNode、ArrayNode）了。 数组Mybatis 默认有提供数组类型的 TypeHandler，但并未启用，需要在使用时使用 typehandler=org.apache.ibatis.type.ArrayTypeHandler 手工指定。但是，可以像前面的 JsonNodeTypeHandler 一样，定义自己的各类数组 TypeHandler，并通过 type-handlers-package 配置全局启用： 12345678910111213141516@MappedTypes(Double[].class)@MappedJdbcTypes(JdbcType.ARRAY)public class DoubleArrayTypeHandler extends ArrayTypeHandler &#123;&#125;@MappedTypes(Integer[].class)@MappedJdbcTypes(JdbcType.ARRAY)public class IntegerArrayTypeHandler extends org.apache.ibatis.type.ArrayTypeHandler &#123;&#125;@MappedTypes(String[].class)@MappedJdbcTypes(JdbcType.ARRAY)public class StringArrayTypeHandler extends ArrayTypeHandler &#123;&#125;// .... R2DBC拥抱反应式 R2DBC 是由 Spring 社区推动的，为 reactor 提供了一套异步、反应式流的关系数据库访问驱动。它可以更好的适配 Spring Webflux 编程模型。对于 反应式，也许你可以读一读 《反应式宣言》 。 遍历全表数据R2DBC 返回结果是 Publisher&lt;T&gt; ，spring-data-r2dbc 将其包装成了 Flux&lt;T&gt;。它在需要遍历数据的时候非常好用，你不在需要自己手动分页来查询，也不需要通过设置 JDBC 的游标来通过游标查询，就按照普通的数据流一条一条的读取记录就可，非常简单。 1234567dataSchemaRepository .findAll() .subscribe( data -&gt; log.info(&quot;处理数据为：&#123;&#125;&quot;, data), error -&gt; log.error(&quot;处理异常：&#123;&#125;&quot;, error.getMessage(), error), () -&gt; log.info(&quot;数据流已完成！&quot;) ); 总结本文简略的介绍了 SQL（PostgreSQL）、JDBC、Mybatis 和 R2DBC 的使用和一些技巧，灵活运行这些特性和功能可以显著提升我们的开发效率，让我们成为一个更有价值的 CRUDer。远离 996，拥抱 965 ！","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"r2dbc","slug":"r2dbc","permalink":"https://yangbajing.github.io/tags/r2dbc/"},{"name":"postgresql","slug":"postgresql","permalink":"https://yangbajing.github.io/tags/postgresql/"},{"name":"jdbc","slug":"jdbc","permalink":"https://yangbajing.github.io/tags/jdbc/"},{"name":"jackson","slug":"jackson","permalink":"https://yangbajing.github.io/tags/jackson/"},{"name":"enum","slug":"enum","permalink":"https://yangbajing.github.io/tags/enum/"},{"name":"mybatis-plus","slug":"mybatis-plus","permalink":"https://yangbajing.github.io/tags/mybatis-plus/"},{"name":"mybatis","slug":"mybatis","permalink":"https://yangbajing.github.io/tags/mybatis/"}]},{"title":"Java 枚举：有效应用","slug":"java-枚举：有效应用","date":"2020-08-08T06:58:35.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/08/08/java-枚举：有效应用/","link":"","permalink":"https://yangbajing.github.io/2020/08/08/java-%E6%9E%9A%E4%B8%BE%EF%BC%9A%E6%9C%89%E6%95%88%E5%BA%94%E7%94%A8/","excerpt":"","text":"Java 枚举本身的介绍本文就不多说，相关资料很多，本文将讲述些 Java 枚举使用的技巧和注意事项。 枚举属性Java 枚举除了可以定义常量以外，还可以定义属性。比如很常见的一个星期枚举 123public enum WeekEnum &#123; MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY;&#125; 以英文定义了从周一到周日的7个枚举常量值，通常情况下大部分序列化工具都会以常量名的字符串形式对其进行序列化。WeekEnum.MONDAY 的常量名字符就是字符串&quot;MONDAY&quot;，可以通过 MONDAY.name() 函数访问。 这样定义的枚举除了英文常量外，没有附带其它信息。但是，我们可以通过在枚举内自定义属性，为枚举添加有意义的附加信息： 1234567891011121314151617public enum WeekEnum &#123; MONDAY(1, &quot;周一&quot;), TUESDAY(2, &quot;周二&quot;), WEDNESDAY(3, &quot;周三&quot;), THURSDAY(4, &quot;周四&quot;), FRIDAY(5, &quot;周五&quot;), SATURDAY(6, &quot;周六&quot;), SUNDAY(7, &quot;周日&quot;); WeekEnum(int value, String label) &#123; this.value = value; this.label = label; &#125; public final int value; public final String label;&#125; 通过添加一个 int 类型的 value 属性来说明枚举的值（序列化的字段），一个 String 类型的 label 属性来说明枚举的描述。如果需要，你可以添加多个描述属性，如： 1234567891011121314public enum WeekEnum &#123; MONDAY(1, &quot;周一&quot;, &quot;工作日&quot;), // .... SUNDAY(7, &quot;周日&quot;, &quot;休息日&quot;); WeekEnum(int value, String label, String desc) &#123; this.value = value; this.label = label; this.desc = desc; &#125; public final int value; public final String label; public final String desc;&#125; 枚举常量名 name枚举常量名：WeekEnum.MONDAY 它的常量名就是 name，字符串表现形式为 &quot;MONDAY&quot;。属性 name 是 private的，可以通过 name() 方法访问。 这里的一个 坑 在于，name() 方法带有 final 修饰符，意味着你不能重写它，因为 Java 的机制，你可以定义一个 name 属性字段来覆盖枚举默认的 name，比如这样： 12345678public enum SexEnum &#123; MALE(&quot;MAN&quot;), FEMALE(&quot;WOMAN&quot;); SexEnum(String name) &#123; this.name = name; &#125; private String name;&#125; 这时候可能会给你造成一个假象，以为 name() 方法将返回你定义的的 this.name 的值，如：MALE.name() 将返回 &quot;MAN&quot;，但实际上它将返回 &quot;MALE&quot;。因为枚举常量名（name()）是不能重写的，同时在 Enum 里定义的 name 是 private的，它将始终带初始化为常量名的字符串表形形式。 记住，这一点很重要！因为大多数序列化工具都调用枚举的 .name() 方法获得字符串来进行序列化，如：Jackson、Dubbo…… 所以为了避免不必要的理解岐义，建议自定义属性时不要使用 name 作为属性名字。 枚举属性命名 用于序列化的枚举属性只应使用 int 或 String 类型 用于序列化的枚举属性建议命名为 value 用于描述枚举的字段建议命名为：label、desc、title 等 自定义枚举属性不要命名为 name，这会覆盖枚举自身的常量名。 枚举序列化以 Jackson 为例，若恰好你的枚举使用常量名进行序列化已经满足业务要求，那你不需要作任何设置。 若你想以某个自定义属性的值来作为序列化，那你在属性名上添加 @JsonValue 注解即可，在序列化时 Jackson 将会使用它的值来进行序列化。比如前面定义的 WeekEnum#value 属性，在添加了 @JsonValue 注解后，Jackson 将会把 WeekEnum.MONDAY 序列化成数字 1 。 不建议使用枚举索引来序列化Jackson 对枚举提供了 4 种序列化方式： 全局配置调用 .name() 序列化为字符串（默认） 全局配置调用 .toString() 序列化为字符串 全局配置调用 .ordinal() 序列化为数字 通过注解自定义序列化，如：@JsonValue 指定序列化的属性 通过 .ordinal() 获得枚举常量索引进行序列化是最不推荐的方式，因为它是按照常量在枚举里定义的顺序从上到下从 0 开始计数的，在代码重构及演进过程中，很可能不小心改变了顺序，这样会造成序列化值的错乱并失去兼容性！ 枚举反序列化当你使用 Jackson 的全局配置调用 .name()、.toString()、.ordinal() 序列化枚举，再想将其反序列化时会一切正常。但是，使用 @JsonValue 注解序列化，在反序列化时，Jackson 仍将使用默认配置的方式进行反序列化，也就是说并不会将使用 @JsonValue 注解指定的属性用来进行反序列化。若要通过用 @JsonValue 指定的属性来进行反序列化，需要自定义一个 Deserializer ，并通过 Jackson 的模块机制注册它。这很简单： 虽然嘴上说很简单，但代码还是不少的。这里就不贴代码了，完整代码可访问： https://github.com/yangbajing/spring-example/tree/develop/example-common/src/main/java/com/fasterxml/jackson/module/yangbajing https://github.com/yangbajing/spring-example/blob/develop/example-common/src/main/resources/META-INF/services/com.fasterxml.jackson.databind.Module 有关 Jackson 更多内容可以阅读我的另一篇文章：《JSON 之 Jackson》 。 总结 自定义属性时建议用于序列化的属性命名为 value，并只使用 int 或 String 作为数据类型。枚举作为常量，使用 Integer 包装类型是没有意义的 用于描述的字段建议使用 label、title、desc 等字段，可使用任意类型 Jackson 的 @JsonValue 注解默认只在序列化时起效，反序列化需要自定义 Jackson Deserializer 不用使用枚举的 .ordinal() 来进行序列化！ 请确保枚举常量名稳定！通常大部分序列化框架都通过 .name() 方法获取枚举常量名的字符串表现形式并用于序列化/反序列化。比如：Dubbo 对于数据库访问层怎样使用 Java 枚举，比如：Mybatis，之后的文章我将对其进行介绍。你可以先收藏我的一个系列文章 《CRUDer 的自我修养：PostgreSQL、JDBC、MyBatis、R2DBC》 。","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"jackson","slug":"jackson","permalink":"https://yangbajing.github.io/tags/jackson/"},{"name":"enum","slug":"enum","permalink":"https://yangbajing.github.io/tags/enum/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"}]},{"title":"JSON 之 Jackson","slug":"json-之-jackson","date":"2020-07-04T04:59:19.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/07/04/json-之-jackson/","link":"","permalink":"https://yangbajing.github.io/2020/07/04/json-%E4%B9%8B-jackson/","excerpt":"","text":"Jackson 是 Java 生态下的一款 JSON （返）序列化工具，具有高效、强大、安全（没有 Fastjson 那么多的安全漏洞）等特性。同时应用广泛，Spring Boot/Cloud、Akka、Spark 等众多框架都将其作为默认 JSON 处理工具。 依赖要使用 Jackson，需要在项目中添加如下依赖（注：使用 Spring Boot 时不需要手动添加，Spring 框架已经默认包含）： Maven 12345678910&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jdk8&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt;&lt;/dependency&gt; Sbt 1234libraryDependencies ++&#x3D; Seq( &quot;com.fasterxml.jackson.datatype&quot; % &quot;jackson-datatype-jsr310&quot; % &quot;2.11.1&quot;, &quot;com.fasterxml.jackson.datatype&quot; % &quot;jackson-datatype-jdk8&quot; % &quot;2.11.1&quot;) jsr310：Java 8 新加日期、时间类型支持（java.time.*）支持 jdk8：Java 8 新加数据类型支持（Optional等） 简明使用获取 JacksonJackson 在使用之前需要实例化一个 ObjectMapper 对像（它不直接提供全局的默认静态方法）。通常我们会将 objectMapper 定义成一个静态成员，或通过 DI 框架注入使用。 Java 1public static final ObjectMapper objectMapper = new ObjectMapper().findAndRegisterModules() Spring 12@Autowiredprivate ObjectMapper objectMapper; 注：Spring 默认不会自动加载 classpath 路径的所有 Jackson Module。需要在 objectMapper 上调用 registerModule 方法手动注册。 Scala 1val objectMapper = new ObjectMapper().findAndRegisterModules() 建议的 Jackson 配置编码配置 1234567891011121314151617ObjectMapper objectMapper = new ObjectMapper() // 自动加载 classpath 中所有 Jackson Module .findAndRegisterModules() // 时区序列化为 +08:00 形式 .configure(SerializationFeature.WRITE_DATES_WITH_ZONE_ID, false) // 日期、时间序列化为字符串 .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false) // 持续时间序列化为字符串 .configure(SerializationFeature.WRITE_DURATIONS_AS_TIMESTAMPS, false) // 当出现 Java 类中未知的属性时不报错，而是忽略此 JSON 字段 .configure(SerializationFeature.FAIL_ON_UNWRAPPED_TYPE_IDENTIFIERS, false) // 枚举类型调用 `toString` 方法进行序列化 .configure(SerializationFeature.WRITE_ENUMS_USING_TO_STRING, true) // 设置 java.util.Date 类型序列化格式 .setDateFormat(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;)) // 设置 Jackson 使用的时区 .setTimeZone(SimpleTimeZone.getTimeZone(&quot;GMT+8&quot;)); 创建 JSON 对像Jackson 的 ArrayNode 和 ObjectNode 对象均不能直接创建，需要通过 objectMapper 来创建。同时，两个 Node 对像都 JsonNode 的子类。 12345ArrayNode jsonArray &#x3D; objectMapper.createArrayNode();jsonArray.add(&quot;Jackson&quot;).add(&quot;JSON&quot;);ObjectNode jsonObject &#x3D; objectMapper.createObjectNode() .put(&quot;title&quot;, &quot;Json 之 Jackson&quot;) .put(&quot;readCount&quot;, 1024); 反序列化12345678910String jsonText = ....;// json text -&gt; Jackson json nodeJsonNode javaTimeNode = objectMapper.readTree(jsonText);// json text -&gt; java classJavaTime javaTime1 = objectMapper.readValue(jsonText, JavaTime.class);// Jackson json node -&gt; java classJavaTime javaTime2 = objectMapper.treeToValue(javaTimeNode, JavaTime.class); 序列化12345678910111213ZonedDateTime zdt = ZonedDateTime.parse(&quot;2020-07-02T14:31:28.822+08:00[Asia/Shanghai]&quot;);JavaTime javaTime = new JavaTime() .setLocalDateTime(zdt.toLocalDateTime()) .setZonedDateTime(zdt) .setOffsetDateTime(zdt.toOffsetDateTime()) .setLocalDate(zdt.toLocalDate()) .setLocalTime(zdt.toLocalTime()) .setDuration(Duration.parse(&quot;P1DT1H1M1.1S&quot;)) .setDate(Date.from(zdt.toInstant())) .setTimestamp(Timestamp.from(zdt.toInstant()));out.println(objectMapper.writeValueAsString(javaTime));out.println(objectMapper.writeValueAsString(jsonObject));out.println(objectMapper.writeValueAsString(jsonArray)); 输出： 123&#123;&quot;localDateTime&quot;:&quot;2020-07-02T14:31:28.822&quot;,&quot;zonedDateTime&quot;:&quot;2020-07-02T14:31:28.822+08:00&quot;,&quot;offsetDateTime&quot;:&quot;2020-07-02T14:31:28.822+08:00&quot;,&quot;localDate&quot;:&quot;2020-07-02&quot;,&quot;localTime&quot;:&quot;14:31:28.822&quot;,&quot;duration&quot;:&quot;PT25H1M1.1S&quot;,&quot;date&quot;:&quot;2020-07-02 14:31:28&quot;,&quot;timestamp&quot;:&quot;2020-07-02 14:31:28&quot;&#125;&#123;&quot;title&quot;:&quot;Json 之 Jackson&quot;,&quot;readCount&quot;:1024&#125;[&quot;Jackson&quot;,&quot;JSON&quot;] Java 类转换成 Jackson JsonNode 1JsonNode jsonNode = objectMapper.valueToTree(javaTime); 美化输出 1objectMapper.writerWithDefaultPrettyPrinter().writeValueAsString(javaTime) 12345678910&#123; &quot;localDateTime&quot; : &quot;2020-07-02T14:31:28.822&quot;, &quot;zonedDateTime&quot; : &quot;2020-07-02T14:31:28.822+08:00&quot;, &quot;offsetDateTime&quot; : &quot;2020-07-02T14:31:28.822+08:00&quot;, &quot;localDate&quot; : &quot;2020-07-02&quot;, &quot;localTime&quot; : &quot;14:31:28.822&quot;, &quot;duration&quot; : &quot;PT25H1M1.1S&quot;, &quot;date&quot; : &quot;2020-07-02 14:31:28&quot;, &quot;timestamp&quot; : &quot;2020-07-02 14:31:28&quot;&#125; 序列化时忽略某些字段@JsonIgnore 12@JsonIgnoreprivate Long _version; @JsonIgnore 注解也可以添加在 getter 函数上。 @JsonIgnoreProperties 123@JsonIgnoreProperties(&#123;&quot;_version&quot;, &quot;timestamp&quot;&#125;)public class JavaTime &#123;&#125; 自定义序列化、反序列化器对于某些自定义类型或 Jackson 不支持的类型，可以实现自己的序列化、反序列化器。 POJO 在类型上使用 @JsonSerialize 和 @JsonDeserialize 注解来分别指定序列化和反序列化器。 12345678@Datapublic class User &#123; private String id; @JsonSerialize(using = PgJsonSerializer.class) @JsonDeserialize(using = PgJsonDeserializer.class) private io.r2dbc.postgresql.codec.Json metadata;&#125; 先将 R2DBC PostgreSQL 的 JSON 转化为 JsonNode 对象，再调用 gen.writeTree 对其进行序列化。这样才能保证序列化出来的字段值是一个 JSON 对象或 JSON 数组。 123456789101112131415import io.r2dbc.postgresql.codec.Json;public class PgJsonSerializer extends StdSerializer&lt;Json&gt; &#123; public PgJsonSerializer() &#123; super(Json.class); &#125; @Override public void serialize(Json value, JsonGenerator gen, SerializerProvider provider) throws IOException &#123; JsonParser parser = gen.getCodec().getFactory().createParser(value.asArray()); JsonNode node = gen.getCodec().readTree(parser); gen.writeTree(node); &#125;&#125; 通过 ObjectCodec#readTree 将 JsonParse 读取为一个 TreeNode 对像，再将其序列化为 JSON 格式（JSON 字符串的字符数组形式）后传给 Json.of 函数。 12345678910111213141516import io.r2dbc.postgresql.codec.Json;public class PgJsonDeserializer extends StdDeserializer&lt;Json&gt; &#123; public PgJsonDeserializer() &#123; super(Json.class); &#125; @Override public Json deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException &#123; TreeNode node = p.getCodec().readTree(p); ObjectMapper objectMapper = (ObjectMapper) p.getCodec(); byte[] value = objectMapper.writeValueAsBytes(node); return Json.of(value); &#125;&#125; Jackson Module当自定义（反）序列化变多时，在每个类上通过注解手工指定（反）序列化器就变得很繁琐。我们可以通过定义一个 Jackson Module 并使用 .findAndRegisterModules() 通过 Java 的 Service 机制自动注册到 ObjectMapper。通过 Module 机制注册了类型的序列化、反序列化器后，不在需要在属性或方法上定义 @JsonSerialize 和 @JsonDeserialize 注解。 1. 定义 Serializers 和 Deserializers 12345678910111213141516171819202122232425262728public class ExampleSerializers extends Serializers.Base implements java.io.Serializable &#123; private static final long serialVersionUID = 1L; @Override public JsonSerializer&lt;?&gt; findSerializer( SerializationConfig config, JavaType type, BeanDescription beanDesc) &#123; final Class&lt;?&gt; raw = type.getRawClass(); if (Json.class.isAssignableFrom(raw)) &#123; return new PgJsonSerializer(); &#125; return super.findSerializer(config, type, beanDesc); &#125;&#125;public class ExampleDeserializers extends Deserializers.Base implements java.io.Serializable &#123; private static final long serialVersionUID = 1L; @Override public JsonDeserializer&lt;?&gt; findBeanDeserializer( JavaType type, DeserializationConfig config, BeanDescription beanDesc) throws JsonMappingException &#123; if (type.hasRawClass(Optional.class)) &#123; return new PgJsonDeserializer(); &#125; return super.findBeanDeserializer(type, config, beanDesc); &#125;&#125; 2. 实现 Module 1234567891011121314151617public class ExampleModule extends com.fasterxml.jackson.databind.Module &#123; @Override public void setupModule(SetupContext context) &#123; context.addSerializers(new ExampleSerializers()); context.addDeserializers(new ExampleDeserializers()); &#125; @Override public String getModuleName() &#123; return &quot;ExampleModule&quot;; &#125; @Override public Version version() &#123; return Version.unknownVersion(); &#125;&#125; 3. 定义 META-INF.services 文件（可选） 通过 Java ServiceLoader 机制，Jackson 可以自动注册配置的 Module。在 com.fasterxml.jackson.databind.Module 配置文件里指定需要自动注册 Module 的全路径，多个 Module 可以写在多行。注意：services 配置文件必须为 com.fasterxml.jackson.databind.Module。 1234src&#x2F;main&#x2F;resources&#x2F;├── META-INF│ └── services│ └── com.fasterxml.jackson.databind.Module 若没有配置 services 文件，则在调用 objectMapper.findAndRegisterModules() 时不能自动加载，需要通过 objectMapper.registerModule 方法手动注册，如： 1objectMapper.registerModule(new ExampleModule()); SpringSpring Boot 配置文件 1234567891011spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 locale: zh_CN serialization: WRITE_DATES_WITH_ZONE_ID: false WRITE_DURATIONS_AS_TIMESTAMPS: false WRITE_DATES_AS_TIMESTAMPS: false FAIL_ON_UNWRAPPED_TYPE_IDENTIFIERS: false WRITE_ENUMS_USING_TO_STRING: true WebFlux 加载 jackson-module-scala 添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt; &lt;artifactId&gt;jackson-module-scala_2.12&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt;&lt;/dependency&gt; 在 configureHttpMessageCodecs 中配置 JsonDecoder 和 JsonEncoder。 123456789101112131415@EnableWebFlux@Configurationpublic class CoreWebConfiguration implements WebFluxConfigurer &#123; @Autowired private ObjectMapper objectMapper; @Override public void configureHttpMessageCodecs(ServerCodecConfigurer configurer) &#123; ServerCodecConfigurer.ServerDefaultCodecs defaultCodecs = configurer.defaultCodecs(); defaultCodecs.enableLoggingRequestDetails(true); objectMapper.registerModule(new DefaultScalaModule()); defaultCodecs.jackson2JsonDecoder(new Jackson2JsonDecoder(objectMapper, MediaType.APPLICATION_JSON, MediaType.APPLICATION_STREAM_JSON)); defaultCodecs.jackson2JsonEncoder(new Jackson2JsonEncoder(objectMapper, MediaType.APPLICATION_JSON, MediaType.APPLICATION_STREAM_JSON)); &#125;&#125; 小结为 Java 世界里众多 JSON 库选择烦恼？Jackson、Gson、Fastjson……不要犹豫，使用 Jackson！除了在 Spring 生态里开箱既用，在 Java 世界里也是最流行的。Jackson 除了支持 Scala 数据类型，还支持 Kotlin，对于 JVM 多语言开发，还有更好的选择吗？","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://yangbajing.github.io/tags/spring-boot/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"jackson","slug":"jackson","permalink":"https://yangbajing.github.io/tags/jackson/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"json","slug":"json","permalink":"https://yangbajing.github.io/tags/json/"},{"name":"jackson-module-scala","slug":"jackson-module-scala","permalink":"https://yangbajing.github.io/tags/jackson-module-scala/"}]},{"title":"JDBC 批量插入：MyBatis、PostgreSQL","slug":"jdbc-批量插入：mybatis、postgresql","date":"2020-06-27T09:07:20.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/06/27/jdbc-批量插入：mybatis、postgresql/","link":"","permalink":"https://yangbajing.github.io/2020/06/27/jdbc-%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%EF%BC%9Amybatis%E3%80%81postgresql/","excerpt":"","text":"当一次插入数据很多时，使用批量插入可以显著提升性能，在此以 PostgreSQL 为例介绍几种批量插入的方式。 JDBC batch execute使用 JDBC 时，可以使用 Statement#addBatch(String sql) 或 PreparedStatement#addBatch 方法来将SQL语句加入批量列表，然后再通过 executeBatch 方法来批量执行。 reWriteBatchedInserts=truePostgreSQL JDBC 驱动支持 reWriteBatchedInserts=true 连接参数，可以将多条插入/更新语句修改成单条语句执行，如：insert into test(name) values (&#39;n&#39;); insert into test(name) values (&#39;m&#39;); 修改为 insert into test(name) values (&#39;n&#39;), (&#39;m&#39;); 。这可提供2到3倍的性能提升。 注意：executeBatch 返回值***使用 reWriteBatchedInserts=true 参数后， executeBatch 执行后返回的 int[] 元素值将为 -2。这是因为 executeBatch 的返回值将被重写为 Statement#SUCCESS_NO_INFO，这个参数值表示 JDBC 批量语句执行成功，但受其影响的行数计数不可用。 123456789@Testpublic void batchInsert() &#123; int[] rets = jdbcTemplate.batchUpdate(&quot;insert into test(id, name) values (?, ?)&quot;, Arrays.asList( new Object[]&#123;1, &quot;羊八井&quot;&#125;, new Object[]&#123;2, &quot;杨景&quot;&#125;, new Object[]&#123;3, &quot;yangbajing&quot;&#125; )); System.out.println(Arrays.toString(rets));&#125; Mybatis使用 123456&lt;insert id=&quot;batchInsert&quot;&gt; INSERT INTO test (name, content) VALUES &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;,&quot;&gt; (#&#123;item.name&#125;, $&#123;item.content&#125;) &lt;/foreach&gt;&lt;/insert&gt; 使用 mybatis-plus 的 IService通过 IService 的 saveBatch 方法可实现批量插入功能，默认将按每 1000 条记录进行提交执行（非事物提交，如：3700 条记录将分 4 次执行 executeBatch，但仍在一个事物里）。 自定义 insertBatch，获得批处理影响的行数mybatis-plus 的 IService#saveBatch 默认返回 boolean ，可以自定义实现一个 insertBatch 函数返回批量执行影响的行数（注：实际上因为 saveBatch 函数使用了事物，根据参数是否执行成功，批量数据要么全部执行成功，要么全部执行失败，事实上并不需要一个返回影响行数的方法。此处可是演示下怎样自定义批量执行函数）。 DataIService 123456789101112import com.baomidou.mybatisplus.extension.service.IService;import java.util.List;public interface DataIService&lt;T&gt; extends IService&lt;T&gt; &#123; int insertBatch(List&lt;T&gt; entityList, int batchSize); default boolean insert(T entity) &#123; return save(entity); &#125;&#125; DataIServiceImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import com.baomidou.mybatisplus.core.enums.SqlMethod;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.baomidou.mybatisplus.core.toolkit.Assert;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import org.apache.commons.collections4.CollectionUtils;import org.apache.ibatis.executor.BatchResult;import org.apache.ibatis.session.SqlSession;import java.sql.Statement;import java.util.*;import java.util.function.BiConsumer;public class DataIServiceImpl&lt;M extends BaseMapper&lt;T&gt;, T&gt; extends ServiceImpl&lt;M, T&gt; implements DataIService&lt;T&gt; &#123; @Override public int insertBatch(List&lt;T&gt; entityList, int batchSize) &#123; if (CollectionUtils.isEmpty(entityList)) &#123; return 0; &#125; String sqlStatement = sqlStatement(SqlMethod.INSERT_ONE); List&lt;BatchResult&gt; rets = batchExecute(entityList, batchSize, (sqlSession, entity) -&gt; sqlSession.insert(sqlStatement, entity)); return rets.stream() .mapToInt(result -&gt; Arrays.stream(result.getUpdateCounts()) .map(n -&gt; n == Statement.SUCCESS_NO_INFO ? 1 : n).sum()) .sum(); &#125; protected &lt;E&gt; List&lt;BatchResult&gt; batchExecute(Collection&lt;E&gt; list, int batchSize, BiConsumer&lt;SqlSession, E&gt; consumer) &#123; Assert.isFalse(batchSize &lt; 1, &quot;batchSize must not be less than one&quot;); if (list.isEmpty()) &#123; return Collections.emptyList(); &#125; final List&lt;BatchResult&gt; results = new LinkedList&lt;&gt;(); executeBatch(sqlSession -&gt; &#123; int size = list.size(); int i = 1; for (E element : list) &#123; consumer.accept(sqlSession, element); if ((i % batchSize == 0) || i == size) &#123; List&lt;BatchResult&gt; rets = sqlSession.flushStatements(); results.addAll(rets); &#125; i++; &#125; &#125;); return results; &#125;&#125; 对 List&lt;BatchResult&gt; rets 进行聚合计数获得受影响的行数时需要注意判断 BatchResult#getUpdateCounts 返回的 int[] 元素值是否为 Statement.SUCCESS_NO_INFO 。","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://yangbajing.github.io/tags/postgresql/"},{"name":"jdbc","slug":"jdbc","permalink":"https://yangbajing.github.io/tags/jdbc/"},{"name":"mybatis","slug":"mybatis","permalink":"https://yangbajing.github.io/tags/mybatis/"},{"name":"batch-insert","slug":"batch-insert","permalink":"https://yangbajing.github.io/tags/batch-insert/"}]},{"title":"Flink Kafka 确定一次消费与写入","slug":"flink-kafka-确定一次消费与写入","date":"2020-06-04T08:04:33.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/06/04/flink-kafka-确定一次消费与写入/","link":"","permalink":"https://yangbajing.github.io/2020/06/04/flink-kafka-%E7%A1%AE%E5%AE%9A%E4%B8%80%E6%AC%A1%E6%B6%88%E8%B4%B9%E4%B8%8E%E5%86%99%E5%85%A5/","excerpt":"","text":"Flink Kafka Exactly Once，确定一次消费/写入。示例代码：https://github.com/yangbajing/learn-bigdata/tree/develop/learn-flink/src/main/scala/connector/kafka 。 ConsumerProducerProducer exactly once 需要启用 flink 的检查点，并在实例化 FlinkKafkaProducer 时指定 FlinkKafkaProducer.Semantic.EXACTLY_ONCE ： 1234567891011val env = StreamExecutionEnvironment.getExecutionEnvironmentenv.enableCheckpointing(1000)val properties = new Properties()properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;) val producer = new FlinkKafkaProducer[NameTimestamp]( topic, new NameTimestampSerializationSchema(topic), properties, Semantic.EXACTLY_ONCE) 问题Kafka 事物超时 transaction.timeout.ms：客户端事物协调器超时时间。Flink默认设置为 1 小时。 transaction.max.timeout.ms：设置服务端 broker 支持的最大事物超时时间，默认值为 900000 毫秒（15分钟）。 Interrupted while joining ioThread java.lang.InterruptedException116:02:28,124 ERROR org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId&#x3D;producer-57, transactionalId&#x3D;Sink: name-sink-0a448493b4782967b150582570326227-75] Interrupted while joining ioThread java.lang.InterruptedException 该异常实现上很可能是：Unexpected error in InitProducerIdResponse; The transaction timeout is larger than the maximum value allowed by the broker (as configured by transaction.max.timeout.ms).，我们只需要调整 transaction.timeout.ms 或 transaction.max.timeout.ms 的值即可解决该问题。 修改 transaction.timeout.ms： 1properties.setProperty(&quot;transaction.timeout.ms&quot;, s&quot;$&#123;60 * 5 * 1000&#125;&quot;) watermark assigner 未触发请注意：如果 watermark assigner 依赖于从 Kafka 读取的消息来上涨其 watermark (通常就是这种情况)，那么所有主题和分区都需要有连续的消息流。否则，整个应用程序的 watermark 将无法上涨，所有基于时间的算子(例如时间窗口或带有计时器的函数)也无法运行。单个的 Kafka 分区也会导致这种反应。这是一个已在计划中的 Flink 改进，目的是为了防止这种情况发生（请见FLINK-5479: Per-partition watermarks in FlinkKafkaConsumer should consider idle partitions）。同时，可能的解决方法是将心跳消息发送到所有 consumer 的分区里，从而上涨空闲分区的 watermark。 注：Flink 1.11.0 已提供了此问题的解决方案，通过设置合适 idleness timeouts 来解决此问题（https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamps_watermarks.html#dealing-with-idle-sources）。","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"flink","slug":"bigdata/flink","permalink":"https://yangbajing.github.io/categories/bigdata/flink/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://yangbajing.github.io/tags/kafka/"},{"name":"flink","slug":"flink","permalink":"https://yangbajing.github.io/tags/flink/"},{"name":"exactly-once","slug":"exactly-once","permalink":"https://yangbajing.github.io/tags/exactly-once/"}]},{"title":"微服务开放环境：Spring & Akka & Docker","slug":"反应式微服务开发环境：spring-akka-docker","date":"2020-05-12T02:17:48.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/05/12/反应式微服务开发环境：spring-akka-docker/","link":"","permalink":"https://yangbajing.github.io/2020/05/12/%E5%8F%8D%E5%BA%94%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%9Aspring-akka-docker/","excerpt":"","text":"随着微服务的流行，服务拆分与服务依赖越来越多，想在本机搭建一套完整的开发环境愈来愈有挑战。代码服务还好，多开几个 IDE 并启动多个应用服务即可，但若你使用了多种数据库系统、缓存系统、消息系统等时，在本机手动安装就非常繁琐了……可以通过 Docker 来简化这些系统的安装。 本文是对近一年微服务开发环境实践记录，我们在微服务开发中混合使用了 Spring Cloud 框架和 Akka 库，同时应用 Java 和 Scala 两们语言。本文主要介绍了微服务后端开发环境，未涉及前端。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"micro-service","slug":"micro-service","permalink":"https://yangbajing.github.io/tags/micro-service/"},{"name":"docker","slug":"docker","permalink":"https://yangbajing.github.io/tags/docker/"}]},{"title":"Nacos SDK for Scala","slug":"nacos-sdk-for-scala","date":"2020-04-09T04:56:40.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/04/09/nacos-sdk-for-scala/","link":"","permalink":"https://yangbajing.github.io/2020/04/09/nacos-sdk-for-scala/","excerpt":"","text":"Nacos SDK for Scala：https://github.com/yangbajing/nacos-sdk-scala 。 支持 Scala 2.12, 2.13 ；支持 Akka Discovery 和 Play WS。 使用12345678// Scala APIlibraryDependencies += &quot;me.yangbajing.nacos4s&quot; %% &quot;nacos-client-scala&quot; % &quot;1.2.0&quot;// Akka DiscoverylibraryDependencies += &quot;me.yangbajing.nacos4s&quot; %% &quot;nacos-akka&quot; % &quot;1.2.0&quot;// Play WSlibraryDependencies += &quot;me.yangbajing.nacos4s&quot; %% &quot;nacos-play-ws&quot; % &quot;1.2.0&quot; 需要添加以下源： 1resolvers += Resolver.bintrayRepo(&quot;helloscala&quot;, &quot;maven&quot;) 在线文档在线文档：https://yangbajing.github.io/nacos-sdk-scala 本地阅读： 以下命令将自动编译并打开默认浏览器以阅读文档： 123git clone https:&#x2F;&#x2F;github.com&#x2F;yangbajing&#x2F;nacos-sdk-scalacd nacos-sdk-scalasbt nacos-docs&#x2F;paradoxBrowse","categories":[{"name":"作品","slug":"作品","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/"},{"name":"nacos-sdk-scala","slug":"作品/nacos-sdk-scala","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/nacos-sdk-scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"nacos","slug":"nacos","permalink":"https://yangbajing.github.io/tags/nacos/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://yangbajing.github.io/tags/spring-cloud/"},{"name":"play","slug":"play","permalink":"https://yangbajing.github.io/tags/play/"}]},{"title":"Akka HTTP 非官方中文翻译","slug":"akka-http-chinese-edition","date":"2020-04-06T06:54:36.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/04/06/akka-http-chinese-edition/","link":"","permalink":"https://yangbajing.github.io/2020/04/06/akka-http-chinese-edition/","excerpt":"","text":"Akka HTTP 10.1.11 非官文中文翻译在线阅读地址： 中文文档：Akka HTTP Unofficial Chinese 码云镜像：Akka HTTP Unofficial Chinese 翻译难免有错误或表达不够清楚的地方。因此，Akka HTTP 中文版翻译采用了基于原始 Paradox 的 md 文件对照翻译的形式，英文原文将显示在中文译文的上方。翻译的源码内容可以在 https://github.com/yangbajing/akka-http 仓库的 docs-zh 子项目找到。 欢迎大家指出或改进不好的地方，一起完善并在未来跟进官方版本的更新。欢迎随时编辑并提交 Pull Request。 本次翻译完成了 Scala API 文档和大部分 Java API 文档的中文译文，但有关具体指令（Directives）使用说明的内容还未翻译。接下来除了继续完成剩余的 Java API 文档翻译以外，也将考虑优先挑选翻译常用及重要的指令，另外某些代码示例的注释也会考虑进行中文翻译。 Akka HTTP 模块组在 akka-actor 和 akka-stream 的基础上实现了全HTTP栈（ 服务器-和客户端 ）的功能。它并不是一个 web 框架，而是一个更通用的工具箱，以便生成提供或消费基于 HTTP 的网络服务。虽然与浏览器进行互动是其功能的组成部分，但这个并不是 Akka HTTP 的 主要目的（简单来说，别把 Akka HTTP 模组只当作页面服务器）。Akka HTTP 支持 HTTP 1.1/2.0、WebSocket、SSE等，并默认提供回压功能。 欢迎随时编辑并提交 Pull Request。社区建设靠大家。 Long live Scala!","categories":[{"name":"作品","slug":"作品","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/"},{"name":"akka-http-chinese","slug":"作品/akka-http-chinese","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/akka-http-chinese/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"akka-http-chinese","slug":"akka-http-chinese","permalink":"https://yangbajing.github.io/tags/akka-http-chinese/"}]},{"title":"译：Akka 2.6.4 Released","slug":"译：akka-2-6-4-released","date":"2020-03-16T03:07:42.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/03/16/译：akka-2-6-4-released/","link":"","permalink":"https://yangbajing.github.io/2020/03/16/%E8%AF%91%EF%BC%9Aakka-2-6-4-released/","excerpt":"","text":"原文地址： https://akka.io/blog/news/2020/03/13/akka-2.6.4-released 亲爱的 hakkers 们， 我们很激动的宣布 Akka 2.6 的新的修补版本发布。除了 bug 修复和改进，还有与 Akka Cluster 相关的3个比较大的新特性。它相对 2.6.3（版本）的显著变化包括： 可靠交付（at-least-once-delivery），见以下说明：#20984 分片守护进程，见以下说明：#28710 分布式发布/订阅，见以下说明：#26338 对来自 messageAdapter、pipeToSelf 和 ask 的异常使用监督（机制），#28592 ActorRef 能静默的忽略所有消息，#25306 在 ByteString 中支持 base64，并提高了 ByteString.decodeString 的性能，#28697 提高了 ExplicitlyTriggeredScheduler 的取消效果，感谢 @bszwej，#28604 支持 Streams 里的日志标记（log marker），感谢 @duxet，#28450 InmemJournal 处理标记事件，感谢 @odd，#28552 修复 Java 中 lease（用于集群节点间的分布式协调，见：Akka Coordination）的加载实现，#28685 改善了分片查询，#27406 改善 PostStop 监护人行为，#28557 更新 Jackson 到 2.10.3 版本，#28678 更新 Aeron 到 1.26.0 版本，#28690 从 2.6.3 版本开始关闭的所有问题，完整列表能在 Github 的 2.6.4 milestone 页面找到。 可靠交付可靠交付对于 actor 之间要求至少或确定一次处理交互很有用。检测到丢失消息，根据需要重发和删除重复。另外，也包含消息发送的流量控制，以避免快速生产者压倒慢速消费者或者（避免）以比网络可以处理更高的速率发送消息。 有3种被支持的模式：点对点（point-to-point）、工作拉取（work pulling）和集群分片（Cluster Sharding）。 即使主要是在 Akka Cluster 中使用，它也与本地 ActorSystem 的 API 完全相同。流量控制和工作拉取机制对于 actor 的本地通信可能同样重要。 你可在 可靠交付 文档 找到更多信息和代码示例。 这个新特性被标记为 “可能改变”。在 API 被完成之前，它需要实际使用的反馈，非常欢迎您尝试它并帮助（我们）。也建议你不要在生产中使用此模块。 分片守护进程分片守护进程是一个 Lagom 内部特性，被反向移植到 Akka。它允许大量（正在进行）处理的 actor 在整个集群保持活跃和平衡。设想的主要用例是多个 worker（分割数据处理）消费被标记的 Akka 持久化事件和 CQRS 应用程序的读端投影工作。 你可以在 分片守护进程 文档 找到更多信息和代码示例。 这个新特性被标记为 “可能改变”。由于 API 界面很小，我们预计不会有重要改变。 分页式发布/订阅Akka Typed 的分布式发布/订阅允许定义主题，集群任意节点上的 actor 都可以订阅。当一个消息被发布到主题，消息将被送达到所有已知的订阅者。该集群工具在类型化系统的接待员（receptionist）上实现，而不是基于经典的分布式发布/订阅工具实现。 分布式发布/订阅主题也可以在非集群设置中工作，所有发布者和订阅者都在本地，因此可以使用 ActorSystem 的事件总线（event bus）替代（集群方式实现）。 你可以在 分布式订阅/发布 找到更多信息和代码示例。 功劳此次发布获得了24位提交者的帮助 - 非常感谢！ 12345678910111213141516171819202122232425commits added removed 25 4224 397 Johan Andr?n 17 18929 73 Patrik Nordwall 14 470 65 Christopher Batey 10 273 125 Arnout Engelen 5 417 28 Renato Cavalcanti 4 144 42 Enno 3 170 12 Ignasi Marimon-Clos 3 46 19 Johannes Rudolph 2 3458 1448 Helena Edelson 2 999 2 eyal farago 2 123 5 Razvan Vacaru 2 6 1 Arnaud Burlet 1 127 10 Bart?omiej Szwej 1 115 6 Viktor Klang (?) 1 88 0 mghildiy 1 72 0 Evgeny Sidorov 1 9 6 Odd M?ller 1 6 1 Yury Gribkov 1 3 1 Jacek Ewertowski 1 0 3 yiksanchan 1 2 1 Bartosz Firyn 1 1 1 Nicolas Deverge 1 1 1 Cl?ment Grimal 1 1 1 Oliver Wickham 祝 hakking! – Akka 团队","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"at-least-once-delivery","slug":"at-least-once-delivery","permalink":"https://yangbajing.github.io/tags/at-least-once-delivery/"}]},{"title":"译：Akka gRPC 0.8.0 Released","slug":"译-akka-grpc-0-8-0-released","date":"2020-03-13T07:46:51.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/03/13/译-akka-grpc-0-8-0-released/","link":"","permalink":"https://yangbajing.github.io/2020/03/13/%E8%AF%91-akka-grpc-0-8-0-released/","excerpt":"","text":"亲爱的 hakker 们！ 我们高兴的公布 Akka gRPC 0.8.0 版本！gRPC 是请求/响应和流式处理（非持久化）场景的传输机制。参见 Why gRPC？ （获得）何时使用 gRPC 作为传输机制的更多信息。这个版本引入了许多令人兴奋的新特性，并使我们更接近 1.0.0 （版本），我们预计在数据周内发布。 主要的改进包括： 基本支持 gRPC Server Reflection #380，允许交互式/动态客户端发现（gRPC）服务和方法，基于 Cloudstate 的实现。 支持 gRPC-Web #695，生成 gRPC 可用于浏览器 JavaScript 客户端，由 @timw 贡献。 支持自定义尾随响应头 #838，例如：可用于实现 rich error response ，由 @drmontgomery 贡献。 改善了在多个后端实例上通过 Akka Discovery #81 的客户端负载均衡发现（机制）。 有关所有变更的描述，请见 release overview。 Credits 这个版本包含9位提交者的提交——非常感谢大家！ 12345678910commits added removed 44 3136 984 Arnout Engelen 1 1180 353 Tim Whittington 1 842 214 David Montgomery 1 53 43 tayvs 8 156 45 Enno 2 16 8 Renato Cavalcanti 2 3 10 Ignasi Marimon-Clos 1 13 5 lukasito 1 2 0 Parth 祝愉快！ —— Akka 团队","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-grpc","slug":"akka-grpc","permalink":"https://yangbajing.github.io/tags/akka-grpc/"},{"name":"grpc","slug":"grpc","permalink":"https://yangbajing.github.io/tags/grpc/"}]},{"title":"在 Scala/Java/Spring 微服务中使用日志","slug":"在scala-java-spring-微服务中使用日志","date":"2020-03-09T03:45:13.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/03/09/在scala-java-spring-微服务中使用日志/","link":"","permalink":"https://yangbajing.github.io/2020/03/09/%E5%9C%A8scala-java-spring-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%97%A5%E5%BF%97/","excerpt":"","text":"应用开发、运行时，日志作为调试、留痕的重要工具非常重要。对此，Akka Fusion 库为日志处理提供了开箱即用的支持： 预置的日志 encoder 配置 通过 filebeat 输出日志到 Elasticsearch 良好的自定义支持 使用 fusion-log 库，需要添加以下依赖。 12resolvers +&#x3D; Resolver.bintrayRepo(&quot;helloscala&quot;, &quot;maven&quot;)libraryDependencies +&#x3D; &quot;com.helloscala.fusion&quot; %% &quot;fusion-log&quot; % &quot;2.0.6&quot; 输出日志到终端logback.xml 日志文件内容： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;false&quot;&gt; &lt;include resource=&quot;fusion/log/logback/defaults.xml&quot;/&gt; &lt;include resource=&quot;fusion/log/logback/stdout-appender.xml&quot;/&gt; &lt;logger name=&quot;ch.qos&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;com.zaxxer&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;fusion&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;helloscala&quot; level=&quot;DEBUG&quot;/&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; 输出日志到文件logback.xml 日志文件内容： 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;false&quot;&gt; &lt;property name=&quot;fusion.log.logback.file&quot; value=&quot;fusion-example&quot;/&gt; &lt;property name=&quot;fusion.log.logback.dir&quot; value=&quot;$&#123;user.home&#125;/logs&quot;/&gt; &lt;include resource=&quot;fusion/log/logback/defaults.xml&quot;/&gt; &lt;include resource=&quot;fusion/log/logback/file-appender.xml&quot;/&gt; &lt;include resource=&quot;fusion/log/logback/stdout-appender.xml&quot;/&gt; &lt;logger name=&quot;ch.qos&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;com.zaxxer&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;fusion&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;helloscala&quot; level=&quot;DEBUG&quot;/&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;!-- &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; --&gt; &lt;appender-ref ref=&quot;FILE&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; 属性 说明 fusion.log.logback.dir 指定输出日志文件名 fusion.log.logback.file 指定输出日志保存目录 默认提供的 FILE logback 日志 Appender 为了方便 filebeat 读取并存储日志到 Elasticsearch，使用 JSON 格式输出日志。file-appender.xml 配置及说明请见后文。 在 Scala/Java 应用中使用应用日志使用 logback 输出，可由程序启动命令参数指定日志配置文件路径。如：-Dlogback.configurationFile=$&#123;__APP_PATH__&#125;/logback.xml。 scala-logging 在 Scala 应用中，可以使用 StrictLogging 或 LazyLogging 来引入 Logger 变量，这个特性由 https://github.com/lightbend/scala-logging 库提供。 12345678class MyClass extends StrictLogging &#123; logger.debug(s&quot;Some $expensive message!&quot;) logger.whenDebugEnabled &#123; println(&quot;This would only execute when the debug level is enabled.&quot;) (1 to 10).foreach(x =&gt; println(&quot;Scala logging is great!&quot;)) &#125;&#125; 可以看到，在代码里简单的 extends/with StrictLogging 这个 trait，就可以直接使用 logger 变量来调用它上面的各种日志方法。另外，也不在需要在日志消息里面使用 &#123;&#125; 来作为占位符输出变量，可直接使用 Scala 的字符串插值特性。scala-logging 基于 Scala macros 提供了编译时扩展： 1logger.debug(s&quot;Some $expensive message!&quot;) 将在编译时被替换为： 1if (logger.isDebugEnabled) logger.debug(s&quot;Some $expensive message!&quot;) 在 Akka 应用中使用Akka 有自己的日志级别配置项。所以，最好将 Akka 的日志级别配置与 slf4j 的日志级别保持一致，可以在 HOCON 里面通过以下配置设置 Akka 的日志级别： 1akka.loglevel = &quot;DEBUG&quot; 在 actor 中，可以通过 ActorContext[T] 上提供的 log 方法来使用 Akka 日志。 当 akka-actor-typed 和 akka-slf4j 存在于类依赖路径上时，Akka 的事件日志处理 actor 将向 SLF4J 发送事件，并自动启用 akka.event.slf4j.Slf4jLogger 和 akka.event.slf4j.Slf4jLoggingFilter 类，而无需要任何配置。若需要手动配置 Akka 使用 SLF4J 输出日志，请确保如下配置，否则将使用默认日志实现并输出日志内容到终端。 12345akka &#123; loglevel &#x3D; &quot;DEBUG&quot; loggers &#x3D; [&quot;akka.event.slf4j.Slf4jLogger&quot;] logging-filter &#x3D; &quot;akka.event.slf4j.Slf4jLoggingFilter&quot;&#125; Tip 使用 actor 的过程中，死信消息会在 INFO 级别输出，通常情况下这都是正常的业务状态，可以通过配置抑制这类日志消息在输出几次后被关闭的输出以免干扰我们正常的日志内容。另外，在 ActorSystem 被关闭（terminate）时，actor 邮箱里被挂起的消息将被发送的死信邮箱，我们可以通过配置禁止在 terminate 期间输出死信日志。 1234akka &#123; log-dead-letters &#x3D; 10 log-dead-letters-during-shutdown &#x3D; on&#125; 在 Spring/ Spring Cloud 中使用Spring 应用中需要删除logback-spring.xml文件而使用logback.xml（如果存在）。 Spring 应用需要禁用 LoggingSystem，使用此命令行参数可禁用它：-Dorg.springframework.boot.logging.LoggingSystem=none。点此访问自定义 Spring 日志的更多介绍。 Fusion Log 为日志提供了兼容 Spring Cloud 的参数以在日志输出中输出 Spring应用服务名、启动环境（模式）、IP地址、网络端口等信息。详细映射参数见： #default-xml 自定义 encoder对于默认的 STDOUT 和 FILE 日志格式不满意的，可以自定义自己的日志编码格式。 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;false&quot;&gt; &lt;include resource=&quot;fusion/log/logback/defaults.xml&quot;/&gt; &lt;include resource=&quot;fusion/log/logback/stdout-appender.xml&quot;/&gt; &lt;appender name=&quot;STDOUT_CUSTOM&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;-%d %-5level %fusionEnv %fusionServiceName %fusionServerHost %fusionServerPort [%thread] %logger&#123;36&#125; %line - %msg%n%exception&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;console_custom&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; 预置配置defaults.xml123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;included&gt; &lt;conversionRule conversionWord=&quot;fusionServerHost&quot; converterClass=&quot;fusion.log.logback.LogHostConverter&quot;/&gt; &lt;conversionRule conversionWord=&quot;fusionServerIp&quot; converterClass=&quot;fusion.log.logback.LogHostConverter&quot;/&gt; &lt;conversionRule conversionWord=&quot;fusionServerPort&quot; converterClass=&quot;fusion.log.logback.LogPortConverter&quot;/&gt; &lt;conversionRule conversionWord=&quot;fusionServerHostName&quot; converterClass=&quot;fusion.log.logback.LogHostNameConverter&quot;/&gt; &lt;conversionRule conversionWord=&quot;fusionServiceName&quot; converterClass=&quot;fusion.log.logback.LogServiceNameConverter&quot;/&gt; &lt;conversionRule conversionWord=&quot;fusionEnv&quot; converterClass=&quot;fusion.log.logback.LogEnvConverter&quot;/&gt;&lt;/included&gt; Fusion Log 预定义了几个转换规则参数，可以在 Appender 的编码模式（encoder pattern）里通过 % 参数引用。这几个转换规则参数都将从Java应用Properties变量里查找所需的值。 fusionServerHostName：应用服务所在主机名，用以下方式读取：InetAddress.getLocalHost.getCanonicalHostName fusionServerIp、fusionServerHost：应用服务绑定 IP 地址，查找顺序： -Dfusion.http.default.server.host -Dhttp.host -Dserver.host fusionServerPort：应用服务绑定网络端口，查找顺序： -Dfusion.http.default.server.port -Dhttp.port -Dserver.port fusionServerName：应用服务名字，查找顺序： -Dfusion.name -Dspring.application.name -Dfusion.service.name fusionEnv：应用服务启动环境（模式），如：prod、test、dev等运行环境，查找顺序： -Dfusion.profiles.active -Dspring.profiles.active -Drun.env stdout-appender.xml12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;included&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;fusion.log.logback.console-pattern:-%date&#123;ISO8601&#125; %-5level %thread %logger %X&#123;akkaSource&#125; %line - %msg%n%exception&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt;&lt;!-- &lt;appender name=&quot;ASYNC_STDOUT&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt;--&gt;&lt;!-- &lt;queueSize&gt;1024&lt;/queueSize&gt;--&gt;&lt;!-- &lt;neverBlock&gt;true&lt;/neverBlock&gt;--&gt;&lt;!-- &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;--&gt;&lt;!-- &lt;/appender&gt;--&gt;&lt;/included&gt; file-appender.xml123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;included&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;File&gt;$&#123;fusion.log.logback.dir:-$&#123;user.dir&#125;/logs&#125;/$&#123;fusion.log.logback.file:-$&#123;spring.application.name:-fusion&#125;&#125;.log&lt;/File&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;FileNamePattern&gt;$&#123;fusion.log.logback.dir:-$&#123;user.dir&#125;/logs&#125;/$&#123;fusion.log.logback.file:-$&#123;spring.application.name:-fusion&#125;&#125;.%d&#123;yyyy-MM-dd&#125;.gz&lt;/FileNamePattern&gt; &lt;!--只保留最近7天的日志 --&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;!--用来指定日志文件的上限大小，如果到了这个值，就会删除旧的日志 --&gt; &lt;totalSizeCap&gt;8GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;providers&gt; &lt;mdc/&gt; &lt;timestamp/&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; &quot;level&quot;: &quot;%level&quot;, &quot;serviceName&quot;: &quot;%fusionServiceName&quot;, &quot;env&quot;: &quot;%fusionEnv&quot;, &quot;thread&quot;: &quot;%thread&quot;, &quot;logger&quot;: &quot;%logger&quot;, &quot;akkaSource&quot;: &quot;%X&#123;akkaSource&#125;&quot;, &quot;message&quot;: &quot;%level [%thread] %logger %line -\\n%message&quot;, &quot;server&quot;: &#123; &quot;host&quot;: &quot;%fusionServerHost&quot;, &quot;port&quot;: &quot;#asLong&#123;%fusionServerPort&#125;&quot; &#125;, &quot;exception&quot;: &quot;%exception&quot; &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;callerData/&gt; &lt;version/&gt; &lt;!-- Printing StackTrace has an import on performance. --&gt; &lt;!--&lt;stackTrace/&gt;--&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt;&lt;/included&gt; 通过 LoggingEventCompositeJsonEncoder 提供了 JSON 格式日志输出支持，它是 logstash 提供的一个 logback encoder 和 appender 库，在此可以查询更多详细：https://github.com/logstash/logstash-logback-encoder 。 通过 Filebeat 输出日志到 Elastic-stackfilebeat 配置12345678910111213141516171819202122232425262728293031323334353637filebeat.inputs: - type: log enabled: true json: keys_under_root: true overwrite_keys: true paths: - /home/yangjing/logs/*.log exclude_files: [&#x27;.gz$&#x27;]#============================= Filebeat modules ===============================filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false#==================== Elasticsearch template setting ==========================setup.kibana: host: &quot;localhost:5601&quot; #space.id:#-------------------------- Elasticsearch output ------------------------------output.elasticsearch: hosts: [&quot;localhost:9200&quot;] # Optional protocol and basic auth credentials. #protocol: &quot;https&quot; #username: &quot;elastic&quot; #password: &quot;changeme&quot;#================================ Processors =====================================# Configure processors to enhance or manipulate events generated by the beat.processors: - add_host_metadata: ~ - add_cloud_metadata: ~ 注意是以下三行配置，使filebeat支持json格式日志文件 123json: keys_under_root: true overwrite_keys: true 通过 Docker 启动 elastic-stack这里选择使用 filebeat 直接把日志数据输出到 Elasticsearch，不使用 Logstack 做中转。 通过 docker-compose，可以很方便的启动 elastic-stack：docker-compose up -d docker-compose.yml 12345678910111213141516171819202122232425262728293031323334version: &#x27;3&#x27;services: fusion-elasticsearch: container_name: fusion-elasticsearch image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 #restart: on-failure ports: - 9200:9200 - 9300:9300 environment: - discovery.type=single-node - cluster.name=fusion-docker-es-cluster ulimits: memlock: soft: -1 hard: -1 networks: - fusionlognet fusion-kibana: container_name: fusion-kibana image: docker.elastic.co/kibana/kibana:7.6.1 #restart: on-failure ports: - 5601:5601 environment: SERVER_NAME: fusion-kibana ELASTICSEARCH_HOSTS: http://fusion-elasticsearch:9200 networks: - fusionlognetnetworks: fusionlognet: 小结本文内容来自 Akka Fusion 的 fusio-log 库，Akka Fusion 是作者在日常 Scala 应用开发中经验总结和积累的实用工具库。可以轻松创建独立的，生产级的基于Akka的应用程序。我们集成了Akka生态系统里常用及流行的组件，因此您可以快速搭建开始你的应用。大多数Akka Fusion应用程序只需要很少的配置。Akka Fusion 访问地址：https://github.com/akka-fusion/akka-fusion 。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala-logging","slug":"scala-logging","permalink":"https://yangbajing.github.io/tags/scala-logging/"},{"name":"akka-log","slug":"akka-log","permalink":"https://yangbajing.github.io/tags/akka-log/"},{"name":"slf4j","slug":"slf4j","permalink":"https://yangbajing.github.io/tags/slf4j/"},{"name":"spring-log","slug":"spring-log","permalink":"https://yangbajing.github.io/tags/spring-log/"},{"name":"fusion-log","slug":"fusion-log","permalink":"https://yangbajing.github.io/tags/fusion-log/"}]},{"title":"怎样优雅的关闭 ActorSystem","slug":"怎样优雅的关闭-actorsystem","date":"2020-02-20T12:03:19.000Z","updated":"2022-02-16T02:50:45.202Z","comments":true,"path":"2020/02/20/怎样优雅的关闭-actorsystem/","link":"","permalink":"https://yangbajing.github.io/2020/02/20/%E6%80%8E%E6%A0%B7%E4%BC%98%E9%9B%85%E7%9A%84%E5%85%B3%E9%97%AD-actorsystem/","excerpt":"","text":"使用 CoordinatedShutdown 可以优雅的方式关闭 ActorSystem。默认情况下，需要调用 ActorSystem 上的 terminate 方法才会触发 CoordinatedShutdown，但也可以设置为在 JVM 退出时自动运行（比如接收到操作系统的 SIGTERM 信号或Java虚拟机退出）。要使在程序退出时 CoordinatedShutdown 自动调用，需要如下配置： 启用 CoordinatedShutdown确保启用如下配置，同时加载 CoordinatedShutdown 扩展。 1234akka.jvm-shutdown-hooks &#x3D; onakka.coordinated-shutdown.run-by-jvm-shutdown-hook &#x3D; onakka.coordinated-shutdown.run-by-actor-system-terminate &#x3D; onakka.coordinated-shutdown.terminate-actor-system &#x3D; on 有两种方式加载 CoordinatedShutdown 扩展： 通过配置文件随 ActorSystem 自动加载：akka.extensions += &quot;akka.actor.CoordinatedShutdown&quot; 在代码中手动调用 CoordinatedShutdown(system) 注意 当系统中应用了 akka-cluster-typed、akka-cluster-sharding-typed 等模块时，它们将在内部调用 CoordinatedShutdown 扩展。 使用 CoordinatedShutdownPhase（阶段）CoordinatedShutdown 可通过 Phase(阶段) 来管理关闭时要执行任务的顺序。相同阶段内的多个任务将同时进行，不同阶段的任务以配置的顺序依次进行，默认阶段里 before-service-unbind 在关闭时最先执行。 默认，CoordinatedShutdown 定义了如下阶段： before-service-unbind 取消绑定自定义服务之前 service-unbind 服务已取消绑定，这时不再接收新的请求，但已进入的请求将继续。如：HTTP 请求 service-requests-done 已进入的请求全部执行完成 service-stop 服务已停止 before-cluster-shutdown 集群节点开始停止前 cluster-sharding-shutdown-region 集群节点的分片区域开始关闭 cluster-leave 集群节点发出 Leave 命令后 cluster-exiting 集群节点开始退出 cluster-exiting-done 集群节点退出结束 cluster-shutdown 集群节点已关闭 before-actor-system-terminate ActorSystem 终止前 actor-system-terminate ActorSystem 已终止 警告 注册到 actor-system-terminate 阶段的任务需要注意，这时候 ActorSystem 的线程调度和定时调度已经关闭。也就是说 ActorSystem 上的 ExecutionContext 和 Scheduler 已不可用。 添加关闭任务可以调用 CoordinatedShutdown 上的 addTask 方法来添加关闭任务，addJvmShutdownHook 方法来添加 JVM 退出时执行的关闭任务。 1234567891011CoordinatedShutdown(system) .addCancellableTask(CoordinatedShutdown.PhaseServiceRequestsDone, &quot;CloseJdbcDataSource&quot;) &#123; () =&gt; Future &#123; println(&quot;Close JDBC DataSource.&quot;) Done &#125;(system.dispatcher) &#125;CoordinatedShutdown(system).addJvmShutdownHook &#123; println(&quot;JVM shutdown hook.&quot;)&#125; addCancellableTask 和 addCancellableJvmShutdownHook 方法可以添加可取消的关闭任务，它们将返回 akka.actor.Cancellable 。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"coordinated-shutdown","slug":"coordinated-shutdown","permalink":"https://yangbajing.github.io/tags/coordinated-shutdown/"}]},{"title":"Ambari编译记录","slug":"ambari编译记录","date":"2020-02-14T12:54:36.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2020/02/14/ambari编译记录/","link":"","permalink":"https://yangbajing.github.io/2020/02/14/ambari%E7%BC%96%E8%AF%91%E8%AE%B0%E5%BD%95/","excerpt":"","text":"Download and build Ambari 2.7.5 source12345678wget https:&#x2F;&#x2F;www-eu.apache.org&#x2F;dist&#x2F;ambari&#x2F;ambari-2.7.5&#x2F;apache-ambari-2.7.5-src.tar.gz (use the suggested mirror from above)tar xfvz apache-ambari-2.7.5-src.tar.gzcd apache-ambari-2.7.5-srcmvn versions:set -DnewVersion&#x3D;2.7.5.0.0pushd ambari-metricsmvn versions:set -DnewVersion&#x3D;2.7.5.0.0popd RHEL/CentOS 7 1mvn -B clean install rpm:rpm -DnewVersion&#x3D;2.7.5.0.0 -DbuildNumber&#x3D;5895e4ed6b30a2da8a90fee2403b6cab91d19972 -DskipTests -Dpython.ver&#x3D;&quot;python &gt;&#x3D; 2.6&quot; Ubuntu/Debian 1mvn -B clean install jdeb:jdeb -DnewVersion&#x3D;2.7.5.0.0 -DbuildNumber&#x3D;5895e4ed6b30a2da8a90fee2403b6cab91d19972 -DskipTests -Dpython.ver&#x3D;&quot;python &gt;&#x3D; 2.6&quot; ?? ?? -Drat.skip=true ?? RAT ?? cp account.jar bak-account.jar.date &quot;+%Y%m%dT%H%M%S%z&quot; Step 2: Install Ambari ServerRHEL/CentOS 7 1yum install ambari-server*.rpm #This should also pull in postgres packages as well. Ubuntu/Debian 1apt-get install .&#x2F;ambari-server*.deb #This should also pull in postgres packages as well. Setup and Start Ambari ServerRun the setup command to configure your Ambari Server, Database, JDK, LDAP, and other options: 1ambari-server setup Follow the on-screen instructions to proceed. Once set up is done, start Ambari Server: 1ambari-server start Step 4: Install and Start Ambari Agent on All HostsCopy the rpm package from ambari-agent/target/rpm/ambari-agent/RPMS/x86_64/ and run: RHEL/CentOS 7 1yum install ambari-agent*.rpm Ubuntu/Debian 1apt-get install .&#x2F;ambari-agent*.deb Edit /etc/ambari-agent/ambari.ini. 12345678...[server]hostname&#x3D;localhost...Make sure hostname under the [server] section points to the actual Ambari Server host, rather than &quot;localhost&quot;. ambari-agent start ## Step 5: Deploy Cluster using Ambari Web UI Open up a web browser and go to &lt;a href=&quot;http://&lt;ambari-server-host&gt;:8080&quot; target=&quot;_blank&quot;&gt;http://&lt;ambari-server-host&gt;:8080&lt;/a&gt;. Log in with username `admin` and password `admin` and follow on-screen instructions. Secure your environment by ensuring your administrator details are changed from the default values as soon as possible. Under Install Options page, enter the hosts to add to the cluster. Do not supply any SSH key, and check &quot;Perform manual registration on hosts and do not use SSH&quot; and hit &quot;Next&quot;.","categories":[],"tags":[]},{"title":"Scala实战：求解 Top K 问题","slug":"scala实战：求解-top-k-问题","date":"2020-02-06T09:06:12.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2020/02/06/scala实战：求解-top-k-问题/","link":"","permalink":"https://yangbajing.github.io/2020/02/06/scala%E5%AE%9E%E6%88%98%EF%BC%9A%E6%B1%82%E8%A7%A3-top-k-%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题描述服务器上有一个 movies.csv 文件，里面保存了每部电影的评分（为了简化和专注问题，CSV文件每一行只有两个字段：movieId和rating）。文件通过HTTP服务器发布。要求从文件内找出排名最高的10部电影。 解法1：全量排序求Top 10通过 wget、curl 等工具先将文件下载到本地，再读出文件内所有行并解析出 movieId和rating 字段，按 rating 字段排序并求得分最高的 10 部电影。这种方法逻辑很简单，实现代码如下： 12345678910111213final case class Movie(id: String, rating: Double)val top10 = scala.io.Source.fromFile(&quot;/tmp/movies.csv&quot;).getLines() //.drop(1) // if csv header exists. .flatMap &#123; line =&gt; line.split(&#x27;,&#x27;) match &#123; case Array(movieId, rating) =&gt; Try(Movie(movieId, rating.toDouble)).toOption case _ =&gt; None &#125; &#125; .toVector .sortWith(_.rating &gt; _.rating) .take(10) 解法2：遍历一次文件求出Top 10因为我们只是找出得分最高的10部电影，可以预先定义一个有序 top10 集合，在遍历 movies.csv 的每一部电影时将其与 top10 集合里得分最低的一部电影比较。若得分大于集合里最低的那部电影，则将集合里得分最低的电影去掉，将将当前电影加入集合。这样，我们只需要遍历一次文件即可获得得分最高的10部电影。 12345678910111213141516final case class Movie(id: String, rating: Double)var top10 = Vector[Movie]()scala.io.Source.fromFile(&quot;/tmp/movies.csv&quot;).getLines() //.drop(1) // if csv header exists. .flatMap &#123; line =&gt; line.split(&#x27;,&#x27;) match &#123; case Array(movieId, rating) =&gt; Some(Movie(movieId, rating.toDouble)) case _ =&gt; None &#125; &#125; .foreach &#123; movie =&gt; top10 = if (top10.size &lt; 10) (movie +: top10).sortWith(_.rating &lt; _.rating) else if (top10.head.rating &gt; movie.rating) top10 else (movie +: top10.tail).sortWith(_.rating &lt; _.rating) &#125; 解法3：使用Akka Streams异步求出Top K个得分最高的电影FileIO 是Akka Streams自带的一个文件读、写工具类，可以从一个文件生成 Source[ByteString, Future[IOResult]] 或将 Source[ByteString, Future[IOResult]] 写入文件。Framing.delimiter 可以从Akka Streams 的 ByteString 流以指定分隔符（\\n）按行提取内容，并将每一行数据发送到流程的下一步骤。 注意 这里 Framing.delimiter 的第3个参数 allowTruncation 需要设置为 true ，否则文件在不以 \\n 结尾的情况下将抛出以下异常：akka.stream.scaladsl.Framing$FramingException: Stream finished but there was a truncated final frame in the buffer 。 如果设置为 false，则当正在解码的最后一个帧不包含有效的分隔符时，此流将失败，而不是返回截断的帧数据。* 12345678910111213141516171819implicit val system = ActorSystem(Behaviors.ignore, &quot;topK&quot;)val res = Paths.get(Thread.currentThread().getContextClassLoader.getResource(&quot;movies.csv&quot;).toURI)val topKF = FileIO .fromPath(Paths.get(res.toUri)) .via(CsvParsing.lineScanner()) .drop(1) // Drop CSV Header .mapConcat &#123; case name :: AsDouble(rating) :: _ =&gt; Movie(name.utf8String, rating) :: Nil case _ =&gt; Nil &#125; .runWith(new TopKSink(10))val topN = Await.result(topKF, 5.minutes)topN.foreach(println)println(topN.size)system.terminate() 这里使用 alpakka-csv 来将 ByteString 数据流转换成 CSV 数据格式，可以在 https://doc.akka.io/docs/alpakka/current/data-transformations/csv.html 找到这个库的详细使用说明。 1234567def toMovie(bs: ByteString): Either[Throwable, Movie] = try &#123; val arr = bs.utf8String.split(&#x27;,&#x27;) Right(Movie(arr(0), arr(1).toDouble)) &#125; catch &#123; case e: Throwable =&gt; Left(e) &#125; 自定义Sink：TopKSink.runWith(new TopKSink(10)) 调用自定义的 Akka Streams Sink 来获得得分最高的10部电影。让我们先来看看 TopKSink 的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class TopKSink(TOP_K: Int) extends GraphStageWithMaterializedValue[SinkShape[Movie], Future[List[Movie]]] &#123; val in: Inlet[Movie] = Inlet(&quot;TopKSink.in&quot;) override def shape: SinkShape[Movie] = SinkShape(in) override def createLogicAndMaterializedValue( inheritedAttributes: Attributes): (GraphStageLogic, Future[List[Movie]]) = &#123; val p: Promise[List[Movie]] = Promise() val logic = new GraphStageLogic(shape) with InHandler &#123; var buf = List[Movie]() var bufSize = 0 def insertMovie(list: List[Movie], movie: Movie): List[Movie] = &#123; list match &#123; case Nil =&gt; movie :: Nil case list =&gt; var buf = List[Movie]() var use = false for (item &lt;- list.reverse) &#123; if (!use &amp;&amp; item.rating &lt; movie.rating) &#123; buf ::= movie use = true &#125; buf ::= item &#125; if (!use) &#123; buf ::= movie &#125; buf &#125; &#125; override def preStart(): Unit = pull(in) override def onPush(): Unit = &#123; val movie = grab(in) buf = if (bufSize &lt; TOP_K) &#123; bufSize += 1 insertMovie(buf, movie) &#125; else &#123; if (buf.head.rating &lt; movie.rating) insertMovie(buf.slice(1, TOP_K), movie) else buf &#125; pull(in) &#125; override def onUpstreamFinish(): Unit = &#123; p.trySuccess(buf) &#125; override def onUpstreamFailure(ex: Throwable): Unit = &#123; p.tryFailure(ex) failStage(ex) &#125; override def postStop(): Unit = &#123; if (!p.isCompleted) p.failure(new AbruptStageTerminationException(this)) &#125; setHandler(in, this) &#125; (logic, p.future) &#125;&#125; 解法4：通过 Akka HTTP 在下载文件的同时求出Top K个得分最高的电影Akka HTTP提供了 HTTP Client/Server 实现，同时它也是基于 Akka Streams 实现的。上一步我们已经定义了 TopKSink 来消费流数据，而通过 Akka HTTP Client 获得的响应数据也是一个流（Source[ByteString, Any]）。我们可以将获取 movies.csv 文件的 HTTP 请求与取得分最高的K部电影两个任务结合到一起，实现内存固定、处理数据无限的 Top K 程序（假设网络稳定不会断开）。 1234567891011121314151617181920212223implicit val system = ActorSystem(Behaviors.ignore, &quot;topK&quot;)implicit val ec = system.executionContextval TOP_K = 10val URL = &quot;https://gitee.com/yangbajing/akka-cookbook/raw/master/cookbook-streams/src/main/resources/movies.csv&quot;val topKF = Http(system).singleRequest(HttpRequest(uri = URL)).flatMap &#123; response =&gt; response.entity.dataBytes .via(CsvParsing.lineScanner()) .drop(1) // Drop CSV Header .mapConcat &#123; case name :: AsDouble(rating) :: _ =&gt; Movie(name.utf8String, rating) :: Nil case _ =&gt; Nil &#125; .runWith(new TopKSink(TOP_K))&#125;val topN = Await.result(topKF, 5.minutes)topN.foreach(println)println(topN.size)system.terminate() 通过继承 GraphStageWithMaterializedValue 抽像类，可以定义一个返回特定结果的自定义 Sink，否则流处理结果默认为 NotUsed。 12override def createLogicAndMaterializedValue( inheritedAttributes: Attributes): (GraphStageLogic, Future[List[Movie]]) 函数 createLogicAndMaterializedValue 实现 Sink 处理逻辑并返回 Sink 阶段的处理逻辑 GraphStageLogic 和获得的 Top K 结果 Future[List[Movie]]，流执行后的结果（通过调用 .runWith）是一个异步结果（Future）。这样将不会阻塞调用线程。 buf 用于缓存 Top K 个得分最高的电影，使用 List 模拟了一个堆结构，Top K 里评分最低的电影在链表头且按评分升序排序。 onPush 函数上游有数据传入时调用 grab 函数获取一个元素（movie）。bufSize 保存了当前 buf 的数量，当 bufSize &lt; TOP_K 时，调用 insertMovie 函数将 movie 直接插入到匹配顺序的 buf 里并将 bufSize 加1。否则通过 buf.head.rating &lt; movie.rating 比较，若为 true 则将 movie 加入缓存，否则 buf 保持不变。 insertMovie 函数实现了将新电影插入 buf 的逻辑，并保持 buf 按评分升序排序。 小结本文使用4种方式来求解 Top K 问题，从简单粗暴的全量读入内存并排序；到不使用排序通过一次遍历获得 Top K；再使用 Akka Streams 以流式方式异步获得；最后，通过结合 Akka HTTP 和 Akka Streams，可以HTTP请求的同时计算 Top K。 有关 Akka HTTP 更多内容可阅读 《Scala Web 开发——基于Akka HTTP》 。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-streams","slug":"akka-streams","permalink":"https://yangbajing.github.io/tags/akka-streams/"},{"name":"top-k","slug":"top-k","permalink":"https://yangbajing.github.io/tags/top-k/"}]},{"title":"OAuth 2 服务的 Akka 实现：access_token 管理","slug":"oauth-2-服务的-akka-实现：access-token-管理","date":"2020-01-10T07:20:30.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2020/01/10/oauth-2-服务的-akka-实现：access-token-管理/","link":"","permalink":"https://yangbajing.github.io/2020/01/10/oauth-2-%E6%9C%8D%E5%8A%A1%E7%9A%84-akka-%E5%AE%9E%E7%8E%B0%EF%BC%9Aaccess-token-%E7%AE%A1%E7%90%86/","excerpt":"","text":"实现一个 OAuth 2 服务有几个核心点： OAuth 2 协议解析 连接的用户可能很多，系统需支持横向扩展 每个连接用户的 access_token 的状态控制：有效期控制 服务要支持容错、可恢复、可扩展、高并发等特性 使用 Akka 来实现 OAuth 2 服务会发现逻辑非常的清晰，且能很好的实现以上几个核心点。 每个连接用户或 access_token 可抽像为一个 Actor，这样多个连接用户或 access_token 即可并发访问。在 Actor 内部可以管理过期时间等状态。 使用 akka-cluster-sharding 我们可以实现连接用户的集群部署、横向扩展。而 akka-persistence 提供 EventSourcedBehavior 为 Actor 添加了持久化能力，这实现了可恢复特性。通过使用 Akka Cluster 机制，可以减少对外部缓存系统的依赖。 Akka Actor提供了监管机制，这样我们可对错误快速响应，实现了容错性。 access_token在 Akka 中通过 Actor 模型来设计 access_token 有两种主要方案： 每个 access_token 一个 Actor，通过 ClusterSharding 来水平扩展，将 Akka Actor 做为一种有状态的缓存来使用。 每个用户（User）一个 Actor，在用户 Actor 内部通过状态来保存多个 access_token 。 每个 access_token 一个 Actor每个 access_token 一个 Actor 在设计上比较简单，只需要注意在过期时间到时停止此 Actor。示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465object AccessTokenEntity &#123; final case class State(accessToken: String, expiresEpochMillis: Long = 0L, refreshToken: String = &quot;&quot;) extends CborSerializable sealed trait Command extends CborSerializable case object StopSelf extends Command final case class Check(replyTo: ActorRef[Int]) extends Command final case class Create(refreshToken: String, replTo: ActorRef[AccessToken]) extends Command sealed trait Event extends CborSerializable final case class Created(expiresIn: FiniteDuration, refreshToken: String) extends Event private val DEVIATION = 5000L // 过期时间比实际时间多5秒，保证客户端在过期时间点时刷新时新、旧 access_token 在一定时间内都有效 val TypeKey: EntityTypeKey[Command] = EntityTypeKey(&quot;AccessTokenEntity&quot;) def init(system: ActorSystem[_]): ActorRef[ShardingEnvelope[Command]] = ClusterSharding(system).init( Entity(TypeKey)(ec =&gt; apply(ec.entityId)) .withSettings(ClusterShardingSettings(system).withPassivateIdleEntityAfter(Duration.Zero))) private def apply(accessToken: String): Behavior[Command] = Behaviors.setup(context =&gt; Behaviors.withTimers &#123; timers =&gt; val behavior = EventSourcedBehavior[Command, Event, State]( PersistenceId.of(TypeKey.name, accessToken), State(accessToken), (state, command) =&gt; commandHandler(timers, state, command), (state, event) =&gt; eventHandler(state, event)) behavior.receiveSignal &#123; case (state, RecoveryCompleted) =&gt; val now = System.currentTimeMillis() if (state.expiresEpochMillis &lt; now) context.self ! StopSelf else timers.startSingleTimer(StopSelf, (state.expiresEpochMillis - now).millis) &#125; &#125;) private def commandHandler(timers: TimerScheduler[Command], state: State, command: Command): Effect[Event, State] = command match &#123; case Check(replyTo) =&gt; if (state.expiresEpochMillis == 0L) &#123; Effect.stop().thenReply(replyTo)(_ =&gt; 401) &#125; else &#123; val status = if (System.currentTimeMillis() &lt; state.expiresEpochMillis) 200 else 401 Effect.reply(replyTo)(status) &#125; case Create(refreshToken, replTo) =&gt; if (state.expiresEpochMillis &gt; 0L) // 返回已存在 AccessToken Effect.reply(replTo)(createAccessToken(state)) else Effect.persist(Created(2.hours, refreshToken)).thenReply(replTo) &#123; st =&gt; timers.startSingleTimer(StopSelf, (st.expiresEpochMillis - System.currentTimeMillis()).millis) createAccessToken(st) &#125; case StopSelf =&gt; Effect.stop() &#125; private def eventHandler(state: State, event: Event): State = event match &#123; case Created(expiresIn, refreshToken) =&gt; state.copy( expiresEpochMillis = System.currentTimeMillis() + expiresIn.toMillis + DEVIATION, refreshToken = refreshToken) &#125;&#125; 这种方案的好处在于： 通过 ClusterSharding 可以实现理论上无限水平扩展的集群，无论多少个 access_token 都可以保存下来 容错、可恢复，节点挂掉后可从其它机器上恢复令牌状态 生成的 access_token 令牌不需要含有业务信息，只需要保证唯一性即可 代码逻辑直观 这种方案的缺点有： 每个 access_token 一个 Actor，Actor 所做的功能不多，相对具有过期时间（TTL）的缓存数据存储系统来说优势不明显 每个无效 access_token 都会在生成一个 Actor 后才可以判断是否有效，这会造成创建很多无效的 Actor 每个用户一个 Actor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119object UserEntity &#123; final case class State( tokens: Map[String, DueEpochMillis] = Map(), refreshTokens: Map[String, DueEpochMillis] = Map()) extends CborSerializable &#123; def clear(clearTokens: IterableOnce[String], clearRefreshTokens: IterableOnce[String]): State = copy(tokens = tokens -- clearTokens, refreshTokens = refreshTokens -- clearRefreshTokens) def addToken(created: TokenCreated): State = &#123; val tokenDue = OAuthUtils.expiresInToEpochMillis(created.accessTokenExpiresIn) val refreshTokenDue = OAuthUtils.expiresInToEpochMillis(created.refreshTokenExpiresIn) State(tokens + (created.accessToken -&gt; tokenDue), refreshTokens + (created.refreshToken -&gt; refreshTokenDue)) &#125; def addToken(accessToken: String, expiresIn: FiniteDuration): State = copy(tokens = tokens + (accessToken -&gt; OAuthUtils.expiresInToEpochMillis(expiresIn))) &#125; sealed trait Command extends CborSerializable final case class CreateToken(replyTo: ActorRef[AccessToken]) extends Command final case class CheckToken(accessToken: String, replyTo: ActorRef[Int]) extends Command final case class RefreshToken(refreshToken: String, replyTo: ActorRef[Option[AccessToken]]) extends Command final case object ClearTick extends Command sealed trait Event extends CborSerializable final case class TokenCreated( accessToken: String, accessTokenExpiresIn: FiniteDuration, refreshToken: String, refreshTokenExpiresIn: FiniteDuration) extends Event final case class TokenRefreshed(accessToken: String, expiresIn: FiniteDuration) extends Event final case class ClearEvent(clearTokens: Set[String], clearRefreshTokens: Set[String]) extends Event val TypeKey: EntityTypeKey[Command] = EntityTypeKey(&quot;UserEntity&quot;) def init(system: ActorSystem[_]): ActorRef[ShardingEnvelope[Command]] = ClusterSharding(system).init( Entity(TypeKey)(ec =&gt; apply(ec)) .withSettings(ClusterShardingSettings(system).withPassivateIdleEntityAfter(Duration.Zero))) private def apply(ec: EntityContext[Command]): Behavior[Command] = &#123; val userId = ec.entityId Behaviors.setup( context =&gt; Behaviors.withTimers(timers =&gt; new UserEntity(PersistenceId.of(ec.entityTypeKey.name, ec.entityId), userId, timers, context) .eventSourcedBehavior())) &#125;&#125;import blog.oauth2.peruser.UserEntity._class UserEntity private ( persistenceId: PersistenceId, userId: String, timers: TimerScheduler[Command], context: ActorContext[Command]) &#123; timers.startTimerWithFixedDelay(ClearTick, 2.hours) def eventSourcedBehavior(): EventSourcedBehavior[Command, Event, State] = EventSourcedBehavior( persistenceId, State(), (state, command) =&gt; command match &#123; case CheckToken(accessToken, replyTo) =&gt; processCheckToken(state, accessToken, replyTo) case RefreshToken(refreshToken, replyTo) =&gt; processRefreshToken(state, refreshToken, replyTo) case CreateToken(replyTo) =&gt; processCreateToken(replyTo) case ClearTick =&gt; processClear(state) &#125;, (state, event) =&gt; event match &#123; case TokenRefreshed(accessToken, expiresIn) =&gt; state.addToken(accessToken, expiresIn) case created: TokenCreated =&gt; state.addToken(created) case ClearEvent(clearTokens, clearRefreshTokens) =&gt; state.clear(clearTokens, clearRefreshTokens) &#125;) private def processRefreshToken( state: State, refreshToken: String, replyTo: ActorRef[Option[AccessToken]]): Effect[Event, State] = &#123; if (state.refreshTokens.get(refreshToken).exists(due =&gt; System.currentTimeMillis() &lt; due)) &#123; val refreshed = TokenRefreshed(OAuthUtils.generateToken(userId), 2.hours) Effect .persist(refreshed) .thenReply(replyTo)(_ =&gt; Some(AccessToken(refreshed.accessToken, refreshed.expiresIn.toSeconds, refreshToken))) &#125; else &#123; Effect.reply(replyTo)(None) &#125; &#125; private def processCheckToken(state: State, accessToken: String, replyTo: ActorRef[Int]): Effect[Event, State] = &#123; val status = state.tokens.get(accessToken) match &#123; case Some(dueTimestamp) =&gt; if (System.currentTimeMillis() &lt; dueTimestamp) 200 else 401 case None =&gt; 401 &#125; Effect.reply(replyTo)(status) &#125; private def processCreateToken(replyTo: ActorRef[AccessToken]): Effect[Event, State] = &#123; val createdEvent = TokenCreated(OAuthUtils.generateToken(userId), 2.hours, OAuthUtils.generateToken(userId), 30.days) Effect.persist(createdEvent).thenReply(replyTo) &#123; _ =&gt; AccessToken(createdEvent.accessToken, createdEvent.accessTokenExpiresIn.toSeconds, createdEvent.refreshToken) &#125; &#125; private def processClear(state: State): Effect[Event, State] = &#123; if (state.tokens.isEmpty &amp;&amp; state.refreshTokens.isEmpty) &#123; Effect.stop() &#125; else &#123; val now = System.currentTimeMillis() val clearTokens = state.tokens.view.filterNot &#123; case (_, due) =&gt; now &lt; due &#125;.keys.toSet val clearRefreshTokens = state.refreshTokens.view.filterNot &#123; case (_, due) =&gt; now &lt; due &#125;.keys.toSet Effect.persist(ClearEvent(clearTokens, clearRefreshTokens)) &#125; &#125;&#125; 每个用户一个 Actor 的优势有： 通过 ClusterSharding 可以实现理论上无限水平扩展的集群，无论多少个 access_token 都可以保存下来 容错、可恢复，节点挂掉后可从其它机器上恢复令牌状态 相比每 access_token 一个 Actor，此方案可以显著减少系统 Actor 的数量 相比拥有过期时间（TTL）的缓存数据存储系统，使用 Actor 更灵活，且可于业务（用户）系统在同一集群 无效 access_token 不会生成多于的 Actor 每个用户一个 Actor 的缺点有： 生成的 access_token 令牌不需要含有业务信息，如：用户ID 从代码行数上可看出，相对每 access_token 一个 Actor ，此方案代码逻辑相对复杂，但功能更加强大！ 小结完整源码在Github可以找到 https://github.com/yangbajing/yangbajing-blog/tree/master/src/main/scala/blog/oauth2 。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-cluster","slug":"akka-cluster","permalink":"https://yangbajing.github.io/tags/akka-cluster/"},{"name":"akka-persistence","slug":"akka-persistence","permalink":"https://yangbajing.github.io/tags/akka-persistence/"},{"name":"oauth-2","slug":"oauth-2","permalink":"https://yangbajing.github.io/tags/oauth-2/"},{"name":"oauth2","slug":"oauth2","permalink":"https://yangbajing.github.io/tags/oauth2/"},{"name":"access_token","slug":"access-token","permalink":"https://yangbajing.github.io/tags/access-token/"},{"name":"akka-cluster-sharding","slug":"akka-cluster-sharding","permalink":"https://yangbajing.github.io/tags/akka-cluster-sharding/"}]},{"title":"怎样在 Akka Persistence 中实现分页查询","slug":"怎样在akka-persistence中实现分页查询","date":"2020-01-08T12:01:38.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2020/01/08/怎样在akka-persistence中实现分页查询/","link":"","permalink":"https://yangbajing.github.io/2020/01/08/%E6%80%8E%E6%A0%B7%E5%9C%A8akka-persistence%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"在 Akka Persistence 中，数据都缓存在服务内存（状态），后端存储的都是一些持久化的事件日志，没法使用类似 SQL 一样的 DSL 来进行分页查询。利用 Akka Streams 和 Actor 我们可以通过编码的方式来实现分页查询的效果，而且这个分页查询还是分步式并行的…… EventSourcedBehaviorAkka Persistence的EventSourcedBehavior里实现了CQRS模型，通过commandHandler与eventHandler解耦了命令处理与事件处理。commandHandler处理传入的命令并返回一个事件，并可选择将这个事件持久化；若事件需要持久化，则事件将被传给eventHandler处理，eventHandler处理完事件后将返回一个“新的”状态（也可以不更新，直接返回原状态）。 12345def apply[Command, Event, State]( persistenceId: PersistenceId, emptyState: State, commandHandler: (State, Command) =&gt; Effect[Event, State], eventHandler: (State, Event) =&gt; State): EventSourcedBehavior[Command, Event, State] 建模以我们习惯的数据库表建模来说，我们会有以下一张表： 123456789create table t_config( data_id varchar(64), namespace varchar(64) not null, config_type varchar(32) not null, content text not null, constraint t_config_pk primary key (namespace, data_id));create index t_config_idx_data_id on t_config (data_id); ConfigManager actor 可以看作 t_config 表，它的 entityId 就是 namespace， State 里保存了所有记录的主键值（ConfigManagerState），这就相当于 t_config 表的 t_config_idx_data_id 索引。 而 ConfigEntity actor 可看作 t_config 表里存储的记录，每个 actor 实例就是一行记录。它的 entityId 由 namespace + data_id 组成，这就相当于 t_config 表的 t_config_pk 复合主键。这里我们定义两个 EventSourcedBehavior： ConfigManager：拥有所有配置ID列表，并作为 State 保存在 EventSourcedBehavior ConfigEntity: 拥有每个配置数据，并作为 State 保存在 EventSourcedBehavior 实现这里先贴出 ConfigManager 和 ConfigEntity 的部分代码，接下来再详解怎样实现分页查询。 ConfigManager 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061object ConfigManager &#123; sealed trait Command extends CborSerializable sealed trait Event extends CborSerializable sealed trait Response extends CborSerializable final case class Query(dataId: Option[String], configType: Option[String], page: Int, size: Int) extends Command final case class ReplyCommand(in: AnyRef, replyTo: ActorRef[Response]) extends Command private final case class InternalResponse(replyTo: ActorRef[Response], response: Response) extends Command case class ConfigResponse(status: Int, message: String = &quot;&quot;, data: Option[AnyRef] = None) extends Response final case class ConfigManagerState(dataIds: Vector[String] = Vector()) extends CborSerializable val TypeKey: EntityTypeKey[Command] = EntityTypeKey(&quot;ConfigManager&quot;)&#125;import ConfigManager._class ConfigManager private (namespace: String, context: ActorContext[Command]) &#123; private implicit val system = context.system private implicit val timeout: Timeout = 5.seconds import context.executionContext private val configEntity = ConfigEntity.init(context.system) def eventSourcedBehavior(): EventSourcedBehavior[Command, Event, ConfigManagerState] = EventSourcedBehavior( PersistenceId.of(TypeKey.name, namespace), ConfigManagerState(), &#123; case (state, ReplyCommand(in, replyTo)) =&gt; replyCommandHandler(state, replyTo, in) case (_, InternalResponse(replyTo, response)) =&gt; Effect.reply(replyTo)(response) &#125;, eventHandler) private def processPageQuery( state: ConfigManagerState, replyTo: ActorRef[Response], in: Query): Effect[Event, ConfigManagerState] = &#123; val offset = if (in.page &gt; 0) (in.page - 1) * in.size else 0 val responseF = if (offset &lt; state.dataIds.size) &#123; Source(state.dataIds) .filter(dataId =&gt; in.dataId.forall(v =&gt; v.contains(dataId))) .mapAsync(20) &#123; dataId =&gt; configEntity.ask[Option[ConfigState]](replyTo =&gt; ShardingEnvelope(dataId, ConfigEntity.Query(in.configType, replyTo))) &#125; .collect &#123; case Some(value) =&gt; value &#125; .drop(offset) .take(in.size) .runWith(Sink.seq) .map(items =&gt; ConfigResponse(IntStatus.OK, data = Some(items))) &#125; else &#123; Future.successful(ConfigResponse(IntStatus.NOT_FOUND, data = Some(Nil))) &#125; context.pipeToSelf(responseF) &#123; case Success(value) =&gt; InternalResponse(replyTo, value) case Failure(e) =&gt; InternalResponse(replyTo, ConfigResponse(IntStatus.INTERNAL_ERROR, e.getLocalizedMessage)) &#125; Effect.none &#125;&#125; ConfigEntity 1234567891011121314151617181920212223242526272829object ConfigEntity &#123; case class ConfigState(namespace: String, dataId: String, configType: String, content: String) sealed trait Command extends CborSerializable sealed trait Event extends CborSerializable final case class Query(configType: Option[String], replyTo: ActorRef[Option[ConfigState]]) extends Command final case class ConfigEntityState(config: Option[ConfigState] = None) extends CborSerializable val TypeKey: EntityTypeKey[Command] = EntityTypeKey(&quot;ConfigEntity&quot;)&#125;import ConfigEntity._class ConfigEntity private (namespace: String, dataId: String, context: ActorContext[Command]) &#123; def eventSourcedBehavior(): EventSourcedBehavior[Command, Event, ConfigEntityState] = EventSourcedBehavior(PersistenceId.of(TypeKey.name, dataId), ConfigEntityState(), commandHandler, eventHandler) def commandHandler(state: ConfigEntityState, command: Command): Effect[Event, ConfigEntityState] = command match &#123; case Query(configType, replyTo) =&gt; state.config match &#123; case None =&gt; Effect.reply(replyTo)(None) case Some(config) =&gt; val resp = if (configType.forall(v =&gt; config.configType.contains(v))) Some(config) else None Effect.reply(replyTo)(resp) &#125; &#125;&#125; ConfigManager#processPageQuery 函数实现了大部分的分页查询逻辑（有部分逻辑需要由 ConfigEntity 处理）。 123456val offset = if (in.page &gt; 0) (in.page - 1) * in.size else 0val responseF = if (offset &lt; state.dataIds.size) &#123; // process paging&#125; else &#123; Future.successful(ConfigResponse(IntStatus.OK, data = Some(Nil)))&#125; 这里首先获取实际的分页数据偏移量 offset ，再于 ConfigManager 状态里保存的 dataIds 的大小进行判断，若 offset &lt; state.dataIds.size 则我们进行分页逻辑，否则直接返回一个空列表给前端。 1234567891011Source(state.dataIds) .filter(dataId =&gt; in.dataId.forall(v =&gt; v.contains(dataId))) .mapAsync(20) &#123; dataId =&gt; configEntity.ask[Option[ConfigState]](replyTo =&gt; ShardingEnvelope(s&quot;$namespace@$dataId&quot;, ConfigEntity.Query(in.configType, replyTo))) &#125; .collect &#123; case Some(value) =&gt; value &#125; .drop(offset) .take(in.size) .runWith(Sink.seq) .map(items =&gt; ConfigResponse(IntStatus.OK, data = Some(items))) 这个 Akka Streams 流即是分页处理的主要实现，若是SQL的话，它类似： 1select * from t_config where data_id like &#x27;%&quot;in.dataId&quot;%&#x27; offset &quot;offset&quot; limit &quot;in.size&quot; .mapAsync 在流执行流程中起了20个并发的异步操作，将委托每个匹配的 ConfigEntity （由s&quot;$namespace@$dataId&quot;生成entityId）执行 config_type 字段的查询。这样，完整的SQL语句类似： 1select * from t_config where data_id like &#x27;%&quot;in.dataId&quot;%&#x27; and config_type = &quot;in.configType&quot; offset &quot;offset&quot; limit &quot;in.size&quot; ConfigEntity 对 config_type 部分的查询逻辑实现如下： 12345678case Query(configType, replyTo) =&gt; state.config match &#123; case None =&gt; Effect.reply(replyTo)(None) case Some(config) =&gt; val resp = if (configType.forall(v =&gt; config.configType.contains(v))) Some(config) else None Effect.reply(replyTo)(resp) &#125; 若in.configType为空，既不需要判断 config_type 这个字段，直接返回 Some(config) 即可，而这时的SQL语句类似： 1select * from t_config where data_id like &#x27;%&quot;in.dataId&quot;%&#x27; and true offset &quot;offset&quot; limit &quot;in.size&quot; Tip这里有个小技巧，对于 Option[T] 字段的判断，直接使用了 .forall 方法，它等价于： 1234option match &#123; case Some(x) =&gt; p(x) case None =&gt; true&#125; 小结完整代码可在此 https://github.com/yangbajing/yangbajing-blog/tree/master/src/main/scala/blog/persistence/config 找到。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-persistence","slug":"akka-persistence","permalink":"https://yangbajing.github.io/tags/akka-persistence/"},{"name":"cqrs","slug":"cqrs","permalink":"https://yangbajing.github.io/tags/cqrs/"},{"name":"event-sourced","slug":"event-sourced","permalink":"https://yangbajing.github.io/tags/event-sourced/"}]},{"title":"2019.12深圳Scala Meetup分享《Akka HTTP、gRPC、Typed Actor与Cluster工程实践》演讲视频","slug":"记：2019-12深圳scala-meetup分享《akka-http、grpc、typed-actor与cluster》","date":"2019-12-22T02:37:52.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/12/22/记：2019-12深圳scala-meetup分享《akka-http、grpc、typed-actor与cluster》/","link":"","permalink":"https://yangbajing.github.io/2019/12/22/%E8%AE%B0%EF%BC%9A2019-12%E6%B7%B1%E5%9C%B3scala-meetup%E5%88%86%E4%BA%AB%E3%80%8Aakka-http%E3%80%81grpc%E3%80%81typed-actor%E4%B8%8Ecluster%E3%80%8B/","excerpt":"","text":"我在 2019年12月深圳Scala Meetup 上做了一次有关 Akka 应用的分享：《Akka HTTP、gRPC、Typed Actor与Cluster工程实践》。这次演讲通过一个注册配置和服务管理系统（Fusion-DiscoveryX）讲述了怎样使用 Akka 全家桶进行开发，可在此找到 DiscoveryX 代码：https://github.com/akka-fusion/fusion-discoveryx/。 演讲讲义：https://akka-fusion.github.io/fusion-discoveryx/design/technology.html。 视频地址：https://www.bilibili.com/video/av80180454/。","categories":[{"name":"作品","slug":"作品","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/"},{"name":"lecture","slug":"作品/lecture","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/lecture/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"akka-grpc","slug":"akka-grpc","permalink":"https://yangbajing.github.io/tags/akka-grpc/"},{"name":"akka-cluster","slug":"akka-cluster","permalink":"https://yangbajing.github.io/tags/akka-cluster/"},{"name":"akka-persistence","slug":"akka-persistence","permalink":"https://yangbajing.github.io/tags/akka-persistence/"},{"name":"cluster-sharding","slug":"cluster-sharding","permalink":"https://yangbajing.github.io/tags/cluster-sharding/"},{"name":"cluster-distributedata","slug":"cluster-distributedata","permalink":"https://yangbajing.github.io/tags/cluster-distributedata/"},{"name":"cluster-singleton","slug":"cluster-singleton","permalink":"https://yangbajing.github.io/tags/cluster-singleton/"}]},{"title":"2019年12月深圳Scala Meetup预热：《Akka HTTP、gRPC与Typed Actor工程实践》","slug":"2019年12月深圳scala-meetup预热：《akka-http、grpc与typed-actor工程实践》","date":"2019-12-16T02:06:55.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/12/16/2019年12月深圳scala-meetup预热：《akka-http、grpc与typed-actor工程实践》/","link":"","permalink":"https://yangbajing.github.io/2019/12/16/2019%E5%B9%B412%E6%9C%88%E6%B7%B1%E5%9C%B3scala-meetup%E9%A2%84%E7%83%AD%EF%BC%9A%E3%80%8Aakka-http%E3%80%81grpc%E4%B8%8Etyped-actor%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E3%80%8B/","excerpt":"","text":"2019年12月深圳Scala Meetup1. 活动介绍 好久不见，继Tubi TV赞助的两场北京Scala Meetup圆满落幕，深圳的Scala Meetup又要开幕啦！虽然连深圳都变冷了，但是Scalaer的热情丝毫不减，欢迎大家前来一起探讨Scala在生产环境中的实践和应用！ 2. 时间地点 时间：2019年12月21日下午 13:00-18:00 （13:00开始签到）地点：深圳市罗湖区春风路1005号联城联合大厦二楼 麦子艺术会议厅（地铁9号线文锦站B出口，或者2号线湖贝站A出口步行5分钟） 3. 日程安排 13:00-13:30：活动签到 13:30-13:40：主持人杜宇介绍本次主题和流程 13:40-14:40：《Akka HTTP、gRPC与Typed Actor工程实践》– by 羊八井（杨景） 14:40-15:40：《Scala 的一些实践: Scala、Akka与Slick》– by 刘涛 15:40-16:00：茶歇&amp;互动交流 16:00-17:00：《Scalajs 与前端反应式编程》– by 杜宇 17:00-18:00：《如何用Scala构建数据和通用服务—Scala生态系统和工程实践小结》– by 凤凰木 活动详细介绍和报名链接： OSC活动：https://www.oschina.net/event/2313392 活动行：https://www.huodongxing.com/event/8521930173900 感谢开源中国的赞助，交流会期间将抽奖送出码云（Gitee）超大号鼠标垫3份 《Akka HTTP、gRPC与Typed Actor工程实践》羊八井在本次活动讲述的主题为：Akka HTTP、gRPC与Typed Actor工程实践，主要通过一个示例来拉通介绍Akka的工程实践，示例为一个配置管理与服务发现应用（类似于阿里的Nacos）。这个实例除了标题提到的 Akka HTTP、Akka gRPC与最新的Akka Typed Actor，还有Akka Cluster与Akka Persistence的应用……也许主题名应该叫：《Akka HTTP、gRPC，Cluster，Persistence与Typed Actor工程实践》。 主要内容 Typed Actor：Typed Actor与经典Actor异同，生命周期、兼管、消息类型…… Akka gRPC：通过ScalaPB自动生成case class消息，Protobuf怎样声明ActorRef[T]类型的字段、区分声明gRPC服务使用消息与Actor使用消息，怎样运用gRPC的双向通信…… Akka HTTP：HTTP 2、怎样同时提供gRPC与REST服务…… Akka Cluster：怎样使用ClusterSingleton，怎样使用DistributedPubSub，怎样使用Protobuf作为集群数据序例化协议，怎样使用ClusterSharding将Actor自动分片到集群节点…… Akka Persistence：怎样应用EventSourcedBehavior实例Actor状态的自动持久化，使用JDBC或Cassandra做为底层持久化存储…… 更多精彩内容请报名现场参与，到时大家一起讨论、交流…… Code内容比较多，在Meetup上很难一下子全部讲清，不过不用慌，羊八井提供了示例代码，你可以完整的运行、测试、阅读。代码仓库地址： Gitee：https://gitee.com/akka-fusion/fusion-discoveryx Github：https://github.com/akka-fusion/fusion-discoveryx","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"akka-typed","slug":"akka-typed","permalink":"https://yangbajing.github.io/tags/akka-typed/"},{"name":"akka-grpc","slug":"akka-grpc","permalink":"https://yangbajing.github.io/tags/akka-grpc/"},{"name":"akka-cluster","slug":"akka-cluster","permalink":"https://yangbajing.github.io/tags/akka-cluster/"},{"name":"akka-persistence","slug":"akka-persistence","permalink":"https://yangbajing.github.io/tags/akka-persistence/"}]},{"title":"Why gRPC (Akka) ?","slug":"why-grpc-akka","date":"2019-11-25T01:49:03.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/11/25/why-grpc-akka/","link":"","permalink":"https://yangbajing.github.io/2019/11/25/why-grpc-akka/","excerpt":"","text":"原文链接：https://doc.akka.io/docs/akka-grpc/current/whygrpc.html 什么是gRPC？gRPC是一个支持请求/响应和流式处理（非持久化）用例的传输机制。 它是一个模式优先的RPC框架，协议在 Protobuf服务描述符（protobuf service descriptor）中声明，请求和响应将通过 HTTP/2 连接流式的传输。 它有几个优点： 模式优先设计倾向于定义良好且分享的服务接口，而不是脆弱的自组织方案； 基于Protobuf的wire协议是高效的、众所周知的，并且允许兼容的模式演化； 基于 HTTP/2 ，这样它允许在单个连接上复用多个数据流； 流式处理的请求和响应是第一类的； 许多语言都有可用的工具，不同语言编写的客户端与服务之间可无缝互操作。 这使得gRPC非常适合： 内部服务之间的连接 连接到公开的gRPC API外部服务（甚至是用其它语言编写的服务） 给Web或移动设备前端提供数据 gRPC vs REST REST在编码方面更灵活，而gRPC基于Protobuf标准化了编码格式； REST是无模式的或可以使用第三方模式，而gRPC总是在Protobuf模式定义中声明服务和消息。 注：REST的编码灵活性是有代价的，随着时间的推移，不兼容或不同步会造成越来越多的问题；而gRPC通过Protobuf在编码阶段既强制了模式与数据类型，同时还提供了很好的向后兼容性解决方案。 gRPC vs SOAP SOAP在传输（协议）方面更灵活，而gRPC只能在 HTTP/2 上使用； 在SOPA中，一旦定义了协议，它们通常就固定下来（通常要求每个服务版本都使用一个新的路径），而Protobuf明确地支持模式演进（注：可增加字段）。 gRPC vs Message bus 虽然gRPC建立在高效的非阻塞实现之上，但它仍然是 同步的 ，因为它要求通信 双方 同时可用。当使用（持久地）消息总线（Message bus）时，需要生产者和总线必须启动，消息者可按需启动，从而导致更高程序的分离（解耦）； gRPC支持每个请求的双向数据流处理，而消息总线的数据流处理是分离的。 注：解耦并不总是好的，某些时候更需要请求可以即时响应，通常消息总线并不适合用于提供服务API的场景。 gRPC vs Akka Remoting 虽然Akka Remoting允许在不同的Akka ActorSystem之间透明地交换消息，但它仍然需要大量地工作来支持高效并兼容的消息序列化。且大消息会阻塞消息传输。与gRPC相比，Akka Remoting不是流式的（streaming，不直接支持streams），它需要建立在消息传递的基础之上（例如：使用 StreamRefs 来模拟流式传输）； Akka Remoting的协议（数据序列化协议）可能会随着Akka版本和配置的变化而变化，这需要你确保系统的所有部分都运行足够相似的版本（版本不兼容问题比较突出）。而gRPC，保证了协议的长期稳定，因此gRPC客户端和服务更加松耦合； 当Akka Remoting中的消息使用 fire-and-forget 方式传递会分离服务的执行，而任务类型的RPC都需要等待远程过程调用得到响应。任何RPC情况下等待（甚至是非阻塞的）响应通常都会绑定重要的资源（注：请求ID、上下文、超时等）。公平地说，（Akka）actor通信（Akka Remoting）通常是以请求/响应的方式构造的，这使得它非常类似于更传统的RPC技术，并且具有相同的缺点（比如：需要保持 客户端 状态，在等待响应时需要超时机制）。 Akka生态里怎样使用gRPC？Akka从2.6开始，akka-remote已不建议在用户代码里使用，同时akka-cluster-client也被 Deprecated。这样导致两个结果： 使用 Akka Cluster 机制进行集群内消息通信，如：akka-cluster-sharding、akka-cluster-distributed-data、akka-cluster-pubsub。 Akka Cluster 之间（集群外）使用 Akka gRPC 进行通信。 一句话总结：Akka Cluster之外推荐使用Akka gRPC！ 接下来，也许你会对 《Akka Cookbook》 感兴趣。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-grpc","slug":"akka-grpc","permalink":"https://yangbajing.github.io/tags/akka-grpc/"},{"name":"grpc","slug":"grpc","permalink":"https://yangbajing.github.io/tags/grpc/"}]},{"title":"Akka Cookbook","slug":"akka-cookbook","date":"2019-11-24T11:08:10.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/11/24/akka-cookbook/","link":"","permalink":"https://yangbajing.github.io/2019/11/24/akka-cookbook/","excerpt":"","text":"电子书：《Akka Cookbook》 码云镜像：《Akka Cookbook》","categories":[{"name":"作品","slug":"作品","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/"},{"name":"akka-cookbook","slug":"作品/akka-cookbook","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/akka-cookbook/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"book","slug":"book","permalink":"https://yangbajing.github.io/tags/book/"},{"name":"akka-cookbook","slug":"akka-cookbook","permalink":"https://yangbajing.github.io/tags/akka-cookbook/"},{"name":"akka-streams","slug":"akka-streams","permalink":"https://yangbajing.github.io/tags/akka-streams/"},{"name":"akka-cluster","slug":"akka-cluster","permalink":"https://yangbajing.github.io/tags/akka-cluster/"},{"name":"akka-persistence","slug":"akka-persistence","permalink":"https://yangbajing.github.io/tags/akka-persistence/"}]},{"title":"Akka Typed 常用交互模式","slug":"akka-typed-常用交互模式","date":"2019-11-11T14:29:25.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/11/11/akka-typed-常用交互模式/","link":"","permalink":"https://yangbajing.github.io/2019/11/11/akka-typed-%E5%B8%B8%E7%94%A8%E4%BA%A4%E4%BA%92%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"本文将探讨Akka Typed下actor的常用交互模式，相对经典的untyped actor，typed actor在交互与使用方式上有着显著的区别。对Akka Typed还不太了解的读者可以先参阅我的上一篇文章：《Akka Typed新特性一览》。 本文大量参译了Akka官方文档《Interaction Patterns》一文（原文链接：https://doc.akka.io/docs/akka/current/typed/interaction-patterns.html）。在巨人的基础之上加入了作者自身的理解和解读，希望能给读者带来 1+1&gt;=2 的感受。 发送并忘记 (Fire and Forget) 请求/响应 (Request-Response) 适配响应、消息适配器 (Adapted Response) 两个actor之间的请求/响应 (Request-Response with ask between two actors) 来自actor外部的请求/响应 (Request-Response with ask from outside an Actor) Future结果发送给（actor）自己 (Send Future result to self) 每会话一个子actor (Per session child Actor) 通用响应聚合器 (General purpose response aggregator) 尾部延迟截断 (Latency tail chopping) 调度（定时）消息给（actor）自己 (Scheduling messages to self) 分片actor的回复 (Responding to a sharded actor) 发送并忘记 (Fire and Forget)使用tell或!函数向actor发送消息，并且在消息内没有可回复的actor引用字段（如：replyTo: ActoRef[T]）既是典型的发送并忘记模式。这个模式非常简单，和经典的untyped actor没有区别，在此就不提供代码示例了。 适用范围 消息是否被处理不重要 不需要确保消息被成功交付或处理 吞吐量高（若发送确认回复至少需要创建两位的消息数量） 问题 若消息流入速度高于actor的处理能力，则很可能会将接收者的消息邮箱填满，并有可能导致JVM崩溃 如果消息丢失将无法知道 请求/响应 (Request-Response)actor之间的许多交互需要从接收方返回一个或多个响应消息，这可以是查询的结果、请求或处理的确认ACK或请求订阅的事件等……在Akka Typed，响应的接收者（发起请求的actor，请求方）必须被编码为消息本身的一个字段，这样接收者才能使用此字段来发送（tell或!）响应给请求方。 123456789101112case class Request(query: String, replyTo: ActorRef[Response])case class Response(result: String)// 向接收者发送消息receiver ! Request(&quot;give me cookies&quot;, context.self)// 接收请求并返回响应数据Behaviors.receiveMessage[Request] &#123; case Request(query, replyTo) =&gt; replyTo ! Response(s&quot;Here are the cookies for [$query]!&quot;) Behaviors.same&#125; 适用范围 订阅actor并希望收到被订阅actor响应的多个消息 问题 响应消息也许不匹配请求actor的类型限制，（参阅：适配响应 获取解决方案） 很难检测到请求是否送达或已被处理 当请求actor发起多次请求时，不能保存请求上下文信息（可在消息内加上请求id或引入新的独立接收者可解决此问题） 适配响应、消息适配器 (Adapted Response)通常情况下，发送actor的消息类型与接收actor的响应消息类型不匹配（不然就会退化成大部分actor都继承同一个trait，这样就失去了 Typed 的意义！）。这种情况下，我们提供一个正确类型的ActorRef[T]，并将接收actor返回的响应消息T包装成发送actor可以处理的类型。 1234567891011121314151617181920val backend: ActorRef[Backend.Command] = _final private case class WrappedBackendResponse(response: Backend.Response) extends CommandBehaviors.setup[Command] &#123; context =&gt; val backendAdapter: ActorRef[Backend.Response] = context.messageAdapter(resp =&gt; WrappedBackendResponse(resp)) backend ! Backend.Register(backendAdapter) Behaviors.receiveMessage[Command] &#123; case WrappendBackendResponse(resp) =&gt; resp match &#123; case Backend.Registered(...) =&gt; // process response message case _ =&gt; &#125; Behaviors.same &#125;&#125; 应该为不同的消息类型注册独立的消息适配器，同一个消息类型多次注册的消息适配器只有最后一个生效。 如果响应的消息类与给定消息适配器匹配或是其消息适配器消息类型的子类型，则使用它。若有多个消息适配器符合条件，则将选用最后注册的那个。 消息适配器（context.messageAdapter返回的ActorRef[T]）的生命周期同context所在actor。建议在Behaviors.step或AbstractBehavior构造函数中注册适配器，但也可以在稍后注册它们。 注册适配器时提供的消息映射函数（resp =&gt; WrappedBackendResponse(resp)）在actor中运行，可安全的访问其（actor）内部状态。 但注意不能抛出异常，否则actor将被停止！ 适用范围 在不同的actor消息协议间进行转换 订阅响应消息的actor，并将响应转换成发送actor可接收的类型 问题 难以检测消息是否送达或已被处理 每个响应消息只能进行一次自适应，如果注册了新的适配器则旧的将被替换。如果不同的目标actor使用相同的响应类型，则它们自动选择哪个适配器更合适。这需要在消息中编码某种相关性来解决 除非协议已经包含提供上下文的方法，例如在响应中返回发送的请求ID。否则交互就不能绑定到某个上下文中。 两个actor之间的请求/响应 (Request-Response with ask between two actors)当请求与响应之间存在1:1映射时，可以通过调用ActorContext上的ask函数来与另一个actor进行交互。 构造一个传出消息，它使用context.ask[Response]提供的ActorRef[Response]作为接收响应的actor放入消息中 将成功/失败（Try[V]）转换为发送者actor可接收的消息类型 123456789101112131415161718192021222324val backend: ActorRef[Hal.Command] = _trait Commandfinal private case class WrappedQueryResponse( reqId: String, response: Try[Hal.Response], replyTo: ActorRef[Hal.Response]) extends CommandBehaviors.setup[Command] &#123; context =&gt; implicit val timeout: Timeout = 3.seconds Behaviors.receiveMessage[Command] &#123; case Query(reqId, name, replyTo) =&gt; context.ask(backend, ref =&gt; Backend.Query(name, ref)) &#123; value =&gt; WrappedBackendResponse(reqId, value, replyTo) &#125; Behaviors.same case WrappendQueryResponse(reqId, value, replyTo) =&gt; replyTo ! value .map(resp =&gt; Queried(200, reqId, Some(resp)) .getOrElse(Queried(500, reqId)) Behaviors.same &#125;&#125; context.ask的响应映射函数在接收actor中运行，可以安全的访问actor内部状态， 但抛出异常的话actor将会被停止 。 12def ask[Req, Res](target: RecipientRef[Req], createRequest: ActorRef[Res] =&gt; Req)( mapResponse: Try[Res] =&gt; T) 上面是简化的ask函数签名（省略了隐式参数）： target：接收actor引用 createRequest：创建请求消息函数，参数是ask创建的临时actor，此临时actor用于适配接收actor的消息类型 mapResponse：将获取的响应消息类型Res映射成请求actor可以接收的消息类型 适用范围 单个查询响应的转换 发送actor需要在继续之前知道消息已被处理（通过context.ask(..., ...)(mapResponse)的mapResponse函数） 如果请求超时，允许actor重新发送消息（通过mapResponse函数处理Failure[TimeoutException]） 跟踪未完成的请求 保存上下文。发送者actor接收的请求有上下文信息（context.ask将生成一个临时actor，这个临时actor即可作为一个确定上下文的载体），如：请求ID reqId，而后端协议不支持这个参数时 问题 一个ask只能有一个响应（因为ask会创建一个临时actor，这个actor在收到响应后就会结束自己） 当请求超时时，接收actor（发回响应的那个）并不知道且仍可能将请求处理并完成，甚至若接收actor很忙的话会在请求超时发生以后再处理它 为超时情况找到一个好的（包装）值，特别是在ask函数调用后还会触发链式调用时（一个异步调用完成后进行另一个异步调用）。这时候希望来快速响应超时情况并回复请求者，但同时需要避免误报。 来自actor外部的请求/响应 (Request-Response with ask from outside an Actor)通过ask的另一个版本（由AskPattern._隐式导入）可以在actor外部（actorRef.ask）实现请求/响应式交互。ask调用将返回Future[T]，若在指定超时内没有响应，则以Failure[TimeoutException]作为结果。 123456import akka.actor.typed.scaladsl.AskPattern._implicit val typedSystem: ActorSystem[_] = systemimplicit val timeout: Timeout = 3.secondsval result: Future[CookieFabric.Reply] = cookieFabric.ask(ref =&gt; CookieFabric.GiveMeCookies(3, ref)) 注：import AskPattern._ 导入的ask函数本来需要有一个Scheduler的隐式参数，但object AskPattern还同时提供了一个schedulerFromActorSystem隐式函数从ActorSystem[_]获得Scheduler，这里建议直接使用implicit ActorSystem[_]（在使用Akka Stream时，也提供了从ActorSystem[_]获得Materializer的隐式转换函数，直接使用implicit ActorSystem[_]可以减少样版代码，使代码更清晰）。 适用范围 从actor系统外部访问时，如Akka HTTP请求访问actor获取响应值 问题 在返回的Future回调内很可能意外的捕获了外部状态，因为这些回调将在与ask不同的线程上执行 一个ask只能有一个响应（ask将生成临时actor） 当请求超时时，接收actor并不知道且仍将继续处理请求直至完成，甚至可能会在超时发生后才开始处理它 Future结果发送给（actor）自己 (Send Future result to self)当在actor内部执行异步操作（返回一个Future时）需要小心处理，因为actor与那个异步操作不在同一个线程。ActorContext提供了pipeToSelf方法来将Future的结果安全传给自己。 123456789101112131415case Update(value, replyTo) =&gt; if (operationsInProgress == MaxOperationsInProgress) &#123; // .... Behaviors.same &#125; else &#123; val futureResult = dataAccess.update(value) context.pipeToSelf(futureResult) &#123; case Success(_) =&gt; WrappedUpdateResult(UpdateSuccess(value.id), replyTo) case Failure(e) =&gt; WrappedUpdateResult(UpdateFailure(value.id, e.getMessage), replyTo) &#125; next(dataAccess, operationsInProgress + 1) &#125;case WrappedUpdateResult(result, replyTo) =&gt; replyTo ! result next(dataAccess, operationsInProgress - 1) 在Future的onComplete回调函数里处理异步结果看起来很诱人，但这样会引发很多潜在的危险，因为从外部线程访问actor内部状态不是线程安全的。例如：无法从类似回调中线程安全的访问示例的operationsInProgress计数器，所以，最好将响应映射到消息，并使用actor的消息接收机制来线程安全的执行进一步处理。 适用范围 调用返回Future的外部服务时 当Future完成，actor需要继续处理时 保留原始请求的上下文，并在Future完成时使用它。如：replyTo: ActorRef[_] 问题 为Future结果添加过多的包装消息 每会话一个子actor (Per session child Actor)在某些情况下，对请求的完整响应只能在从其他actor收集多个响应后再创建并发送回请求方。对于这种交互，最好将工作委托给每 session 子actor，还可以包含任意逻辑来实现重试、超时失败、尾部截断、进度检查等。 请注意，这基本上就是ask的实现方式，如果只需要一个带超时的响应，那么使用ask更好。 子actor是用它需要做工作的上下文创建的，包括它可以响应的ActorRef[_]。当完整的结果出现时，子actor会用结果进行响应并停止自身。 由于session actor的协议不是公共API，而是父actor的实现细节，因此使用显式协议并调整session actor与之交互的actor的消息可能并不总是有意义，可以让session actor接收任何消息（Any）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748object Home &#123; sealed trait Command case class LeaveHome(who: String, replyTo: ActorRef[ReadyToLeaveHome]) extends Command case class ReadyToLeaveHome(who: String, keys: Keys, wallet: Wallet) def apply(): Behavior[Command] = &#123; Behaviors.setup[Command] &#123; context =&gt; Behaviors.receiveMessage[Command] &#123; case LeaveHome(who, replyTo) =&gt; context.spawn(prepareToLeaveHome(who, replyTo, keyCabinet, drawer), s&quot;leaving-$who&quot;) Behaviors.same &#125; &#125; &#125; // Per session actor behavior def prepareToLeaveHome( whoIsLeaving: String, replyTo: ActorRef[ReadyToLeaveHome], keyCabinet: ActorRef[KeyCabinet.GetKeys], drawer: ActorRef[Drawer.GetWallet]): Behavior[NotUsed] = &#123; Behaviors.setup[AnyRef] &#123; context =&gt; var wallet: Option[Wallet] = None var keys: Option[Keys] = None keyCabinet ! KeyCabinet.GetKeys(whoIsLeaving, context.self.narrow[Keys]) drawer ! Drawer.GetWallet(whoIsLeaving, context.self.narrow[Wallet]) def nextBehavior(): Behavior[AnyRef] = (keys, wallet) match &#123; case (Some(w), Some(k)) =&gt; replyTo ! ReadyToLeaveHome(whoIsLeaving, w, k) Behaviors.stopped case _ =&gt; Behaviors.same &#125; Behaviors.receiveMessage &#123; case w: Wallet =&gt; wallet = Some(w) nextBehavior() case k: Keys =&gt; keys = Some(k) nextBehavior() case _ =&gt; Behaviors.unhandled &#125; &#125; .narrow[NotUsed] // 标记此actor行为不需要接受任务请求消息 &#125;&#125; prepareToLeaveHome不需要关心actor协议（消息类型），因为除了对查询的响应之外，没有任何地方会向它发送消息。但在交互时会将消息限制为有限的类型。 适用范围 在结果生成前，一个请求会导致与其它actor（或与多个外部服务进行交互） 需要处理请求确认并保证消息至少一次传递时 问题 子actor生命周期必须要小心管理才能避免造成资源泄漏，很容易出现子actor未能停止的情况 增加了复杂性，每个子actor都可与它的父actor并发执行 通用响应聚合器 (General purpose response aggregator)类似上一个 每会话一个子actor 模式，这种模式有很多变体，这里抽像出了一种通用的可复用的聚合模式。 12345678910111213141516171819202122232425262728293031323334353637object Aggregator &#123; sealed trait Command private case object ReceiveTimeout extends Command private case class WrappedReply[R](reply: R) extends Command def apply[Reply: ClassTag, Aggregate]( sendRequests: ActorRef[Reply] =&gt; Unit, expectedReplies: Int, replyTo: ActorRef[Aggregate], aggregateReplies: immutable.IndexedSeq[Reply] =&gt; Aggregate, timeout: FiniteDuration): Behavior[Command] = &#123; Behaviors.setup &#123; context =&gt; context.setReceiveTimeout(timeout, ReceiveTimeout) val replyAdapter = context.messageAdapter[Reply](WrappedReply(_)) sendRequests(replyAdapter) def collecting(replies: immutable.IndexedSeq[Reply]): Behavior[Command] = &#123; Behaviors.receiveMessage &#123; case WrappedReply(reply: Reply) =&gt; val newReplies = replies :+ reply if (newReplies.size == expectedReplies) &#123; val result = aggregateReplies(newReplies) replyTo ! result Behaviors.stopped &#125; else collecting(newReplies) case ReceiveTimeout =&gt; val aggregate = aggregateReplies(replies) replyTo ! aggregate Behaviors.stopped &#125; &#125; collecting(Vector.empty) &#125; &#125;&#125; sendRequest: ActorRef[Reply] =&gt; Unit：处理发送请求，参数ActorRef[Reply]可作为请求消息的replyTo字段发送给接收方用于返回响应结果 expectedReplies: Int：预计期望收到的回复总数 replyTo: ActorRef[Aggregate]：当响应聚合完成或超时达到时，将聚合后的结果回复给指定actor aggregateRepliese: Seq[Reply] =&gt; Aggregate：当响应聚合完成或超时达到时，映射集合为需要的响应消息类型 timeout: FiniteDuration：超时时间 适用范围 通过相同的方式从多个地方的回复中聚合 单个请求需要与多个actor进行多次交互，再生成一个结果返回 需要处理（ACK）确认和至少一次传递的消息时 问题 且有泛型类型的消息协议很困难，因为泛型类型在运行时被删除了 子节点的生命周期必需小心管理 增加了复杂性，因为每一个这样的子actor都可能与其它子actor或父级同时执行 尾部延迟截断 (Latency tail chopping)这个模式类似上一个 通用响应聚合器 模式，但它不需要对多个数据来源进行聚合，只需要取第一个收到的数据即可。 该算法的目标是在多个actor可以执行相同工作的情况下减少尾部延迟。这种情况下，会同时向多个后端actor发现请求（后端请求应保证每次请求得到的响应都一样），取最快的响应做为结果返回，其它忽略掉。这在高并发情况下可显著增强响应速度和吞吐量。 像Cassandra这样的NoSQL数据库就运行了类似技术同时对多个副本进行查询，使用最快返回的值做为响应结果。因为通常情况下所有副本节点不会同时负载很高。 12345678910111213141516171819202122232425262728293031323334353637383940414243sealed trait Commandprivate case object RequestTimeout extends Commandprivate case object FinalTimeout extends Commandprivate case class WrappedReply[R](reply: R) extends Commanddef apply[Reply: ClassTag]( sendRequest: (Int, ActorRef[Reply]) =&gt; Boolean, nextRequestAfter: FiniteDuration, replyTo: ActorRef[Reply], finalTimeout: FiniteDuration, timeoutReply: Reply): Behavior[Command] = &#123; Behaviors.setup &#123; context =&gt; Behaviors.withTimers &#123; timers =&gt; val replyAdapter = context.messageAdapter[Reply](WrappedReply(_)) def waiting(requestCount: Int): Behavior[Command] = &#123; Behaviors.receiveMessage &#123; case WrappedReply(reply: Reply) =&gt; replyTo ! reply Behaviors.stopped case RequestTimeout =&gt; sendNextRequest(requestCount + 1) case FinalTimeout =&gt; replyTo ! timeoutReply Behaviors.stopped &#125; &#125; def sendNextRequest(requestCount: Int): Behavior[Command] = &#123; if (sendRequest(requestCount, replyAdapter)) &#123; timers.startSingleTimer(RequestTimeout, RequestTimeout, nextRequestAfter) &#125; else &#123; timers.startSingleTimer(FinalTimeout, FinalTimeout, finalTimeout) &#125; waiting(requestCount) &#125; sendNextRequest(1) &#125; &#125;&#125; 示例首先以参数1调用sendNextRequest函数开始整个行为，在函数内部使用sendRequest执行实际的请求发送动作。sendRequest返回true则执行一个计时器调度在nextRequestAfter超时后进行另一个发送请求，返回false则执行一个 FinalTimeout 计时器调度，若actor收到 FinalTimeout 消息则代表整个请求超时结束（失败）。 注意： 这个示例需要注意的地方是sendRequest函数需要有一个返回false的判断路径，不然整个actor可能会永不停止！还有一种优化就是将timers.startSingleTimer(FinalTimeout, FinalTimeout, finalTimeout)提到Behaviors.setup代码块开始执行，设置finalTimeout为一个比nextRequestAfter大的值，这样当finalTimeout超时到达时，无论sendRequest是否反回false，整个任务都将超时结束。 适用范围 降低系统整体延迟百分比，使系统延迟变化更平稳 工作（任务） 可以相同的结果多次执行时，例如：请求检索信息 问题 由于相同的任务发送了多次，因此系统整体负载有所增加 任务必须的幂等的，多次执行时能获得相同的结果 子actor有生命周期，必须小心对其进行管理才会不造成资源泄漏。 定义泛型类型的消息协议很困难，因为泛型类型在运行时已被擦除 调度（定时）消息给（actor）自己 (Scheduling messages to self)使用TimerScheduler可以定时将一个特定消息发送给actor自身，支持单次或多次定时调度。 12345678910111213141516171819202122232425262728293031323334353637383940414243object Buncher &#123; sealed trait Command final case class ExcitingMessage(message: String) extends Command final case class Batch(messages: Vector[Command]) private case object Timeout extends Command private case object TimerKey def apply(target: ActorRef[Batch], after: FiniteDuration, maxSize: Int): Behavior[Command] = &#123; Behaviors.withTimers(timers =&gt; new Buncher(timers, target, after, maxSize).idle()) &#125;&#125;class Buncher( timers: TimerScheduler[Buncher.Command], target: ActorRef[Buncher.Batch], after: FiniteDuration, maxSize: Int) &#123; import Buncher._ private def idle(): Behavior[Command] = &#123; Behaviors.receiveMessage[Command] &#123; message =&gt; timers.startSingleTimer(TimerKey, Timeout, after) active(Vector(message)) &#125; &#125; def active(buffer: Vector[Command]): Behavior[Command] = &#123; Behaviors.receiveMessage[Command] &#123; case Timeout =&gt; target ! Batch(buffer) idle() case m =&gt; val newBuffer = buffer :+ m if (newBuffer.size == maxSize) &#123; timers.cancel(TimerKey) target ! Batch(newBuffer) idle() &#125; else active(newBuffer) &#125; &#125;&#125; 一开始idle()函数将启动一个单次定时计时器，然后返回一个新的行为active(buffer: Vector[Command])。active函数默认将缓冲每次收到的消息，并将消息附加到buffer然后做为active函数参数再次返回一个新的行为（这样在整个actor没有可变数据的情况下也可以保存内部状态）。当Timeout消息产生时，actor对buffer数据进行处理，并返回初始的idle()行为，这时将再次进行定时任务调度。 当actor退出时，TimerScheduler将会保证取消所有已注册的定时调度。 每个计时器都需要一个key，若启动了具有相同key的新计时器，则上一个计时器会被取消，并保证不会收到来自上一个计时器的消息，即使那个消息已经在邮箱里排队。 Behaviors.withTimers也可以在Behaviors.supervise中使，当actor重启时，它将自动取消已启动的计时器，以保证新的actor实例不会收到前一个实例的计时消息。 Scheduler选择 定期执行消息可以有两个不同的选择： 固定延迟（fixed-delay）：发送后续消息之章的延迟始终（不小于）为给定的值，使用startTimerWithFixedDelay函数 固定速率（fixed-rate）：一段时间内执行的频率满足给定的间隔，使用startTimerAtFixedRate函数 如果不确定使用哪一个，建议选择startTimerWithFixedDelay。因为 固定速率 在长时间的垃圾收集暂停后可能会导致计划消息的突发，这在最坏的情况下可能会导致系统上出现预期外的负载。通常首选具有 固定延迟 的调度计划。 当使用固定延迟时，如果由于某种原因，调度延迟超过指定的时间，则它不会补偿消息之间的延迟。发送后续消息之间的延迟总是（至少）给定的延迟。从长远来看，消息的频率通常会略低于指定延迟的倒数。 固定延迟执行适用于需要“平滑度”的重复性活动。换句话说，它适用于短期内比长期内保持频率准确更为重要的活动。 使用固定速率时，如果先前的消息延迟太长，它将补偿后续任务的延迟。在这种情况下，实际的发送间隔将不同于传递给 固定速率 方法的间隔。 如果任务延迟超过间隔时间，则在前一个任务之后立即发送后续消息。这还会导致在长时间的垃圾收集暂停或JVM暂停时的其他原因之后，当进程再次唤醒时，将执行所有“错过”的任务。例如，间隔1秒的 固定速率 和暂停30秒的进程将导致连续快速发送30条消息以赶上之前错过的调度。从长远来看，执行频率正好是指定间隔的倒数。 固定速率执行适用于对绝对时间敏感或执行固定数量执行的总时间很重要的重复活动，例如每秒计时一次并持续10秒的倒计时计时器。 分片actor的回复 (Responding to a sharded actor)当在Akka集群里使用分片（shard）actor时，你需要考虑到actor可能会被移动（到其它节点）或被钝化（Passivated）。这时候若还将分片actor自身的引用（context.self）包含到消息里转递，若分片actor被移动或钝化，则回复被会被发送到列信actor…… 正确的做法是，在使用分片actor时在消息里传递entityId，并使用Sharding来发送回复。 123456789101112131415161718192021222324252627object CounterConsumer &#123; sealed trait Command final case class NewCount(count: Long) extends Command val TypeKey: EntityTypeKey[Command] = EntityTypeKey[Command](&quot;example-sharded-response&quot;)&#125;object Counter &#123; trait Command case object Increment extends Command final case class GetValue(replyToEntityId: String) extends Command val TypeKey: EntityTypeKey[Command] = EntityTypeKey[Command](&quot;example-sharded-counter&quot;) private def apply(): Behavior[Command] = Behaviors.setup &#123; context =&gt; counter(ClusterSharding(context.system), 0) &#125; private def counter(sharding: ClusterSharding, value: Long): Behavior[Command] = Behaviors.receiveMessage &#123; case Increment =&gt; counter(sharding, value + 1) case GetValue(replyToEntityId) =&gt; val replyToEntityRef = sharding.entityRefFor(CounterConsumer.TypeKey, replyToEntityId) replyToEntityRef ! CounterConsumer.NewCount(value) Behaviors.same &#125;&#125; 问题 这样做缺点是不能使用消息适配器，因为响应必须在被响应的actor的协议中。此外，如果不能确定EntityTypeKey[T]的具体类型，则可以将它包含在消息中一起发送。 1final case class CommandSharding(...., replyEntityId: String, replyEntityType: EntityTypeKey[Reply]) extends Command 小结本文为对官方文档 https://doc.akka.io/docs/akka/current/typed/interaction-patterns.html 的 学习，不全只是翻译，一切以官网文档为准。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-typed","slug":"akka-typed","permalink":"https://yangbajing.github.io/tags/akka-typed/"},{"name":"design-pattern","slug":"design-pattern","permalink":"https://yangbajing.github.io/tags/design-pattern/"}]},{"title":"Akka Typed新特性一览","slug":"akka-typed新特性一览","date":"2019-11-06T13:54:36.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/11/06/akka-typed新特性一览/","link":"","permalink":"https://yangbajing.github.io/2019/11/06/akka-typed%E6%96%B0%E7%89%B9%E6%80%A7%E4%B8%80%E8%A7%88/","excerpt":"","text":"Hello Scala!Akka Typed Actor从2.4开始直到2.5可以商用，进而Akka 2.6已经把Akka Typed Actor做为推荐的Actor使用模式。Typed Actor与原先的Untyped Actor最大的区别Actor有类型了，其签名也改成了akka.actor.typed.ActorRef[T]。通过一个简单的示例来看看在Akka Typed环境下怎样使用Actor。 1234567891011121314151617sealed trait Commandfinal case class Hello(message: String, replyTo: ActorRef[Reply]) extends Commandfinal case class Tell(message: String) extends Commandsealed trait Replyfinal case class HelloReply(message: String) extends Replydef apply(): Behavior[Command] = Behaviors.setup &#123; context =&gt; Behaviors.receiveMessage &#123; case Hello(message, replyTo) =&gt; replyTo ! HelloReply(s&quot;$message, scala!&quot;) Behaviors.same case Tell(message) =&gt; context.log.debug(&quot;收到消息：&#123;&#125;&quot;, message) Behaviors.same &#125;&#125; Akka Typed不再需要通过类的形式来实现Actor接口定义，而是函数的形式来定义actor。可以看到，定义的actor类型为Behavior[T]（形为），通过Behaviors.receiveMessage[T](T =&gt; Behavior[T]): Receive[T]函数来处理接收到的消息，而Receive继承了Behavior trait。通过函数签名可以看到，每次接收到消息并对其处理完成后，都必需要返回一个新的形为。 apply(): Behavior[Command]函数签名里的范性参数类型Command限制了这个actor将只接收Command或Command子类型的消息，编译器将在编译期对传给actor的消息做类型检查，相对于从前的untyped actor可以向actor传入任何类型的消息，这可以限制的减少程序中的bug。特别是在程序规模很大，当你定义了成百上千个消息时。 也因为有类型的actor，在Akka Typed中没有了隐式发送的sender: ActorRef，必需在发送的消息里面包含回复字段，就如Hello消息定义里的replyTo: ActorRef[Reply]字段一样。actor在处理完Hello消息后可以通过它向发送者回复处理结果。 1234567891011121314151617181920212223242526class HelloScalaSpec extends ScalaTestWithActorTestKit with WordSpecLike &#123; &quot;HelloScala&quot; should &#123; &quot;tell&quot; in &#123; val actorRef = spawn(HelloScala(), &quot;tell&quot;) actorRef ! Tell(&quot;Hello&quot;) &#125; &quot;replyTo&quot; in &#123; val actorRef = spawn(HelloScala(), &quot;replyTo&quot;) val probe = createTestProbe[Reply]() actorRef ! Hello(&quot;hello&quot;, probe.ref) probe.expectMessageType[HelloReply] should be(HelloReply(&quot;hello, scala!&quot;)) &#125; &quot;ask&quot; in &#123; import akka.actor.typed.scaladsl.AskPattern._ val actorRef = spawn(HelloScala(), &quot;ask&quot;) val reply = actorRef .ask[Reply](replyTo =&gt; Hello(&quot;Hello&quot;, replyTo)) .mapTo[HelloReply] .futureValue reply.message should be(&quot;Hello, scala!&quot;) &#125; &#125;&#125; 更复杂的一个示例上一个示例简单的演示了Akka Typed Actor的功能和基本使用方式，接下来看一个更复杂的示例，将展示Akka Typed更多的特性及功能。 首先是消息定义： 123456789101112131415sealed trait Commandtrait ControlCommand extends Command &#123; val clientId: String &#125;trait ReplyCommand extends Command &#123; val replyTo: ActorRef[Reply] &#125;final case class Connect(clientId: String, replyTo: ActorRef[Reply]) extends ControlCommand with ReplyCommandfinal case class Disconnect(clientId: String, replyTo: ActorRef[Reply]) extends ControlCommand with ReplyCommandfinal case class QueryResource(clientId: String, replyTo: ActorRef[Reply]) extends ReplyCommandfinal private[typed] case object SessionTimeout extends Commandfinal private case class ServiceKeyRegistered(registered: Receptionist.Registered) extends Commandsealed trait Replyfinal case class Connected(status: Int, clientId: String) extends Replyfinal case class Disconnected(status: Int, clientId: String) extends Replyfinal case class ResourceQueried(status: Int, clientId: String, resources: Seq[String]) extends Replyfinal case class ReplyError(status: Int) extends Reply 上面分别定义了actor可接收的请求消息：Command和返回结果消息：Reply。建议对于需要返回值的消息使用：replyTo来命名收受返回值的actor字段，这里也可以不定义Reply trait来做为统一的返回值类型，可以直接返回结果类型，如：ActorRef[String。 这里将定义两个actor，一个做为父actor，一个做为子actor。父actor为：ComplexActor，管理连接客户端和转发消息到子actor，每次有新的客户端连接上来时做以客户端clientId做为名字创建一个子actor；子actor：ComplexClient，保持客户端连接会话，处理消息…… ComplexActor 1234567891011121314151617181920212223242526272829303132333435363738final class ComplexActor private(context: ActorContext[ComplexActor.Command]) &#123; import ComplexActor._ private var connects = Map.empty[String, ActorRef[Command]] def init(): Behavior[Command] = Behaviors.receiveMessage &#123; case ServiceKeyRegistered(registered) if registered.isForKey(serviceKey) =&gt; context.log.info(&quot;Actor be registered, serviceKey: &#123;&#125;&quot;, serviceKey) receive() .... &#125; def receive(): Behavior[Command] = Behaviors .receiveMessage[Command] &#123; case cmd @ Connect(clientId, replyTo) =&gt; if (connects.contains(clientId)) &#123; replyTo ! Connected(IntStatus.CONFLICT, clientId) &#125; else &#123; val child = context.spawn( Behaviors .supervise(ComplexClient(clientId)) .onFailure(SupervisorStrategy.restart), clientId) context.watch(child) connects = connects.updated(clientId, child) child ! cmd &#125; Behaviors.same .... &#125; .receiveSignal &#123; case (_, Terminated(child)) =&gt; val clientId = child.path.name connects -= clientId context.unwatch(child) Behaviors.same &#125;&#125; ComplexActor在收到Connect消息后将首先判断请求客户端ID（clientId）是否已经连接，若重复连接将直接返回409错误（Connected(IntStatus.CONFLICT, _)）。若是一个新连接将调用context.spawn函数在创建一个字actor：ComplexClient。spawn函数签名如下： 1def spawn[U](behavior: Behavior[U], name: String, props: Props = Props.empty): ActorRef[U] behavior是要创建的actor，name为子actor的名字，需要保证在同一级内唯一（兄弟之间），props可对actor作一些自定义，如：线程执行器（Dispatcher）、邮箱等。 receiveSignal用于接收系统控制信号消息，经典actor的preRestart和postStop回调函数（将分别做为PreRestart和PostStop信号），以及Terminated消息都将做为信号发送到这里。 ComplexClient 123456789101112131415161718192021final class ComplexClient private ( clientId: String, context: ActorContext[ComplexActor.Command]) &#123; import ComplexActor._ def active(): Behavior[Command] = Behaviors.receiveMessagePartial &#123; .... case SessionTimeout =&gt; context.log.warn(&quot;Inactive timeout, stop!&quot;) Behaviors.stopped &#125; def init(): Behavior[Command] = Behaviors.receiveMessage &#123; case Connect(`clientId`, replyTo) =&gt; replyTo ! Connected(IntStatus.OK, clientId) context.setReceiveTimeout(120.seconds, SessionTimeout) active() case other =&gt; context.log.warn(&quot;Receive invalid command: &#123;&#125;&quot;, other) Behaviors.same &#125; ComplexClient定义了两个形为函数，init()和active。当客户端连接成功以后会返回active()函数作为actor新的形为来接收之后的消息。这种返回一个新的Behavior函数的形式替代了经典actor里的become、unbecome函数，它更直观，甚至还可以使用这种方式来实现状态机。 context.setReceiveTimeout(120.seconds, SessionTimeout)用来设置两次消息接收之间的超时时间，这里设备为120秒。可以通过方式来实现服务端会话（session）超时判断，当session超时时返回Behaviors.stopped消息来停止actor（自己）。这里需要注意的是context.stop只能用来停止直接子actor，停止actor自身返回stopped形为即可，这与经典actor有着明显的区别。 发现actorAkka Typed取消了actorSelection函数，不再允许通过actor path路径来查找ActorRef。取而代之的是使用Receptionist机制来注册服务（actor实例）。也就是说，在Akka Typed中，actor默认情况下是不能查找的，只能通过引用（ActorRef[T]）来使用，要么actor之间具有父子关系，要么通过消息传递ActorRef[T]…… 123456789object ComplexActor &#123; val serviceKey = ServiceKey[Command](&quot;complex&quot;) def apply(): Behavior[Command] = Behaviors.setup &#123; context =&gt; val registerAdapter = context.messageAdapter[Receptionist.Registered](value =&gt; ServiceKeyRegistered(value)) context.system.receptionist ! Receptionist.Register(serviceKey, context.self, registerAdapter) new ComplexActor(context).init() &#125;&#125; 上面代码通过Receptionist.Register将actor（context.self引用）以serviceKey注册到Actor系统的receptionist表，之后就可以通过serviceKey来发现并获取此actor的引用。 12345678val actorRef: ActorRef[ComplexActor.Command] = system.receptionist .ask[Receptionist.Listing](Receptionist.Find(ComplexActor.serviceKey)) .map &#123; listing =&gt; if (listing.isForKey(serviceKey)) listing.serviceInstances(serviceKey).head else throw new IllegalAccessException(s&quot;Actor reference not found: $serviceKey&quot;) &#125; 消息适配器有时候，需要将不匹配的消息发送给actor，比如：把receptionist服务注册结果 Receptionist.Registered发送给一个actor，我们可以通过将消息包装到一个实现了Command trait的case class来实现。如下面的代码示例： 12val registerAdapter: ActorRef[Receptionist.Registered] = context.messageAdapter[Receptionist.Registered](value =&gt; ServiceKeyRegistered(value)) 在使用Receptionist.Register时将registerAdapter作为第3个参数传入，这样服务注册结果就将被包装成ServiceKeyRegistered消息传给actor。 在actor内部处理异步任务actor内部消息都是串行执行的，在actor内执行异步操作时需要小心。不能在Future的回调函数里直接操作actor内部变量，因为它们很可能在两个不同的线程中。 可以通过context.pipeToSelf将异步结果转换成一个消息传递给actor，这样异步结果将进入actor的邮箱列队，通过正确的消息处理机制来处理。 123456789case QueryResource(_, replyTo) =&gt; context.pipeToSelf(findExternalResource())(value =&gt; InternalQueryResource(value, replyTo)) Behaviors.samecase InternalQueryResource(tryValue, replyTo) =&gt; replyTo ! tryValue .map(ResourceQueried(IntStatus.OK, clientId, _)) .getOrElse(ResourceQueried(IntStatus.INTERNAL_ERROR, clientId, Nil)) Behaviors.same 在ActorSystem[_]外部创建actorAkka Typed开始，ActorSystem[T]也拥有一个泛型参数，在构造ActorSystem时需要传入一个默认Behavior[T]，并将其作为经典actor下的user守卫（也就类似拥有akka://system-name/user这个路径的actor），同时ActorSystem[T]的actorOf函数也被取消。Akka Typed推荐应用都从传给ActorSystem的默认Behavior[T]开始构建actor树。但有时，也许通过ActorSystem[T]的实例来创建actor是有意义的，可以通过将typed的ActorSystem[T]转换成经典的untyped ActorSystem来实现。代码如下： 1234567891011121314implicit val timeout = Timeout(2.seconds)implicit val system: ActorSystem[_] = _ // ....val spawnActor: ActorRef[SpawnProtocol.Command] = system.toClassic .actorOf( PropsAdapter(Behaviors.supervise(SpawnProtocol()) .onFailure(SupervisorStrategy.resume)), &quot;spawn&quot;) .toTyped[SpawnProtocol.Command]val helloScalaF: Future[ActorRef[HelloScala.Command]] = spawnActor.ask[ActorRef[HelloScala.Command]](replyTo =&gt; SpawnProtocol.Spawn(HelloScala(), &quot;sample&quot;, Props.empty, replyTo))val helloScala: ActorRef[HelloScala.Command] = Await.result(helloScalaF, 2.seconds) 也可以将SpawnProtocol()作为ActorSystem[_]的初始Behavior[T]来构造ActorSystem，这样就可以通过system.ask[ActorRef[T]](SpawnProtocol.Spawn(....))来创建在user守卫下的actor了。 小结本文通过两个例子展示了Akka Typed的特性，它与经典actor的区别还是挺大的。从untyped和typed，actor拥有了类型，这对于大规模actor系统开发可以在编译期发现很多重复，它将强制你在设计actor时首先考虑消息的定义。定义的消息即是actor之间的数据交互协议，消息定义的过程也是业务模式和模块划分的过程。 完整示例代码 https://github.com/yangbajing/scala-web-development/blob/master/book/src/test/scala/book/typed/HelloScala.scala https://github.com/yangbajing/scala-web-development/blob/master/book/src/test/scala/book/typed/ComplexActor.scala","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-typed","slug":"akka-typed","permalink":"https://yangbajing.github.io/tags/akka-typed/"},{"name":"akka-grpc","slug":"akka-grpc","permalink":"https://yangbajing.github.io/tags/akka-grpc/"},{"name":"akka-2.6","slug":"akka-2-6","permalink":"https://yangbajing.github.io/tags/akka-2-6/"}]},{"title":"Akka微服务实践-初探","slug":"akka微服务实践-初探","date":"2019-09-21T14:13:20.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/09/21/akka微服务实践-初探/","link":"","permalink":"https://yangbajing.github.io/2019/09/21/akka%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5-%E5%88%9D%E6%8E%A2/","excerpt":"","text":"目录 微服务 配置 Java Properties Typesafe Config 服务发现 Akka Discovery Nacos（溶入Spring Cloud） 服务 序列化 JSON Protobuf 服务协议 RESTful（Akka HTTP） gRPC（HTTP 2） 集群 使用Akka Discovery + Akka gRPC构建微服务集群 Akka Cluster可用于业务服务内部 反应式（Reactive） Akka Streams Alpakka 技术降级：Java里好用的工具可继续使用 监控 通过HTTP Header实现简单的调用链监控 kamon：自动检测、监视和调试的分布式系统 实践 全栈 Akka 现实：与Spring Cloud一起 Why not Play Lagom Akka 微服务介绍微服务的文章和书箱已经很多了，这里就不再对此阐述过多。这里链接到 Martin Fowler的文章《Microservices》https://martinfowler.com/articles/microservices.html 。 本文要介绍的Akka微服务简化结构图如下： 使用Akka来实现微服务，有如下函数式、异步、分布式、高并发、可扩展等特性和优势。 最重要的是，你将实现一个反应式的微服务。 配置应用的运行都会从配置开始，在我们的实践中主要到两类配置方式： Java Properties Typesafe Config 传统应用，会从某个配置文件里读取应用需要的配置。而微服务架构下，会从一个统一的配置中心读取。配置中心有很多的选择，比如：Consul、Etcd、Spring Config、Nacos、Database等。同时，还希望可通过命令行参数设置配置项，而它的优先级应该比配置中心或配置文件更高。 Java PropertiesJava Properties想必大家已经很熟悉了，可通过 .properties 文件或JVM命令行参数 -D 来指定。这里使用 -D 这样的命令行参数在启动时覆盖配置文件里的配置，而 .properties 配置文件的方式并不使用，因为你接下来会发现更好的配置文件。 Typesafe ConfigTypesafe Config使用HOCON（Human-Optimized Config Object Notation）语言来编写配置，https://github.com/lightbend/config 能找到关于 Typesafe Config 更多的文档。 使-D命令行配置优先于Typesafe Config配置123val cc = ConfigFactory.parseString(&quot;&quot;&quot;&#123;&#125;&quot;&quot;&quot;) // .load()val c = ConfigFactory.defaultOverrides().withFallback(cc)val config = c.withFallback(ConfigFactory.load()).resolve() 获取初始配置； defaultOverrides函数将JVM命令行参数（使用-D）解析到一个Config，同时将其与cc合并（cc与JVM命令行参数的配置合并，JVM命令行参数将覆盖cc里相同键的值）； 将合并了命令行参数的配置再与Typesafe Config默认配置合并，得到最终的配置。 服务发现服务发现，作为微服务治理方面非常重要的一环，它是微服务的一个核心组件。通常大部分服务发现工具还带有健康检查等功能，比如：Nacos。 Akka DiscoveryAkka Discovery是Akka团队专为Akka生态开发的服务发现接口（提供了统一的服务发现API，但并不实现具体的服务发现功能），支持：DNS、静态配置、Console、k8s等服务发现功能。Akka Discovery本身不带健康检查功能，由下层具体实现提供，同时，Akka Discovery设计为可扩展的，我们可以很容易的扩展它支持更多的服务发现框架。 NacosNacos是阿里巴巴开源的一套使用Java语言编写的服务注册、服务发现框架，它提供了HTTP API、Java SDK等易用的集成方式，可单独使用，也集成到Spring Cloud里使用。Akka Discovery因其设计上强大的可扩展性，我们可以将其与Nacos集成。同时，对于已使用了Spring Cloud的团队来说，Akka服务也需要与已存在的Spring Cloud进行集成，而通过Akka Discovery -&gt; Nacos -&gt; Spring Cloud的形式集成两者是非常吸引人的。 12345678910111213141516171819202122232425262728293031final class Lookup(val serviceName: String, val portName: Option[String], val protocol: Option[String])final class Resolved(val serviceName: String, val addresses: immutable.Seq[ResolvedTarget])final class ResolvedTarget(val host: String, val port: Option[Int], val address: Option[InetAddress])class NacosServiceDiscovery(system: ExtendedActorSystem) extends ServiceDiscovery with StrictLogging &#123; import system.dispatcher private val namingService = FusionNacos(system).component.namingService private val c = FusionCore(system).configuration.getConfiguration(&quot;akka.discovery.nacos&quot;) private def oneHealth = c.getBoolean(&quot;one-health&quot;) override def lookup(lookup: Lookup, resolveTimeout: FiniteDuration): Future[ServiceDiscovery.Resolved] = &#123; val f = Future &#123; val instances = if (oneHealth) &#123; val instance = namingService.selectOneHealthyInstance(lookup.serviceName) Vector(ResolvedTarget(instance.ip, Some(instance.port), None)) &#125; else &#123; namingService .selectInstances(lookup.serviceName, true) .map(instance =&gt; ResolvedTarget(instance.ip, Some(instance.port), None)) .toVector &#125; Resolved(lookup.serviceName, instances) &#125;.recover &#123; case e: NacosException =&gt; logger.debug(s&quot;Nacos服务 $&#123;lookup.serviceName&#125; 未能找到；$&#123;e.toString&#125;&quot;) Resolved(lookup.serviceName, Nil) &#125; Await.ready(f, resolveTimeout) &#125;&#125; NacosServiceDiscovery为集成Nacos的Akka Discovery实现，代码非常简单，我们只需要实现def lookup(lookup: Lookup, resolveTimeout: FiniteDuration): Future[ServiceDiscovery.Resolved]函数即可。 服务微服务，重点在服务。包括：服务API、服务拆分、服务发现、服务治理等等。服务API最常用的就是基于HTTP RESTful来实现，同时也有很多采用RPC的方式，比如：gRPC、Thrift、Dubbo等。 序列化服务API发布后，需要有一个序列化格式来说明API暴露的数据是怎样组成的，这就是数据的序列化。数据序列化通常是成对的，服务提供方编码（Marshal）数据，而服务消费方则解码（Unmarshal）数据。 JSONJSON（JavaScript Object Notation，https://json.org/）是现在最常使用的服务间序列化方式，具有简单、简单、简单的特点。但使用JSON也有如下不足： 数据类型不够丰富； 没有类型静态约束； 文件传输，相比二进制数据还是偏大。 ProtobufProtobuf是Google开发的一款二进制序列化工具，类似的还有Thrift、Flatbuf（速度比Protobuf更快，但二进制数据更大，相应网络传输占用会更多）、Dubbo（Dubbo可支持的语言现在还比较少，移动端支持也很弱）等，它相对JSON具有以下优点： 更丰富的数据类型； 静态类型约束； 有Shema描述文件，可自动生成数据类； 二进制传输，更省带宽。 服务协议RESTful（Akka HTTP）微服务发布的API，需要由某个协议来承载，最常用的就是基于HTTP协议的RESTful风格的形式了。Akka HTTP提供了丰富的HTTP特性，支持HTTP 1.0、1.1、2.0。 Akka HTTP提供了 Routing DSL（https://doc.akka.io/docs/akka-http/current/routing-dsl/index.html）高级API来定义服务接口。 123456val route = path(&quot;hello&quot;) &#123; get &#123; complete(HttpEntity(ContentTypes.`text/html(UTF-8)`, &quot;&lt;h1&gt;Say hello to akka-http&lt;/h1&gt;&quot;)) &#125; &#125; 你可以在《Scala Web开发》（https://www.yangbajing.me/scala-web-development/）学到更多有关Akka HTTP的知识。 gRPC（HTTP 2）gRPC使用Protobuf进行数据序列化，基于HTTP 2提供RPC通信。具有快速、高效、易用、可扩展等特点。采用HTTP 2作为底层协议，可以更好的与已有的HTTP基础服务整合，简化了运维管理（不需要为了RPC单独开放网络端口，并对其进行管理）。gRPC支持请求/响应和Stream两种接口形式，可以实现服务端推送功能。 Akka提供了开箱即用的akka-grpc（https://doc.akka.io/docs/akka-grpc/current/），从编译、构建、发布……与Scala/Akka生态完美整合。**Why gRPC**（https://doc.akka.io/docs/akka-grpc/current/whygrpc.html）这篇文章详细的说明了为什么需要gRPC，特别是gRPC与REST、SOAP、Message Bus和Akka Remoting的区别，阐述的简明扼要。 1234567891011121314151617message HelloRequest &#123; string name &#x3D; 1;&#125;message HelloReply &#123; string message &#x3D; 1;&#125;service GreeterService &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125; rpc ItKeepsTalking (stream HelloRequest) returns (HelloReply) &#123;&#125; rpc ItKeepsReplying (HelloRequest) returns (stream HelloReply) &#123;&#125; rpc StreamHellos (stream HelloRequest) returns (stream HelloReply) &#123;&#125;&#125; GreeterService描述了一个gRPC服务定义，接受HelloRequest并响应HelloReply。sbt-akka-grpc 插件提供了自动化构建gRPC的sbt插件，你可以如下使用： 1addSbtPlugin(&quot;com.lightbend.sbt&quot; % &quot;sbt-javaagent&quot; % &quot;0.1.5&quot;) 更多sbt配置请查阅：https://doc.akka.io/docs/akka-grpc/current/buildtools/sbt.html 集群多个服务之间相互通信，服务与服务既形成了集群。Akka基于actor模型，天然就是分布式的。Akka Cluster对于集群提供了原生支持。 这里建议服务与服务之间通过Akka Discovery来做服务发现，gRPC为通信协议； 有状态服务内多个实例之间使用Akka Cluster来形成一个服务的小集群（无状态服务的多个实例不需要集群），比如主/从架构。而对于多个实例之间需要共享数据的情况，可以使用Akka Distributed Data（https://doc.akka.io/docs/akka/2.6/typed/distributed-data.html） 使用Akka Discovery + Akka gRPC构建微服务集群之前 服务发现 一章已介绍了 Akka Discovery，它是可扩展的，可快速的把你所使用的服务发现工具集成到Akka中。Akka gRPC提供了对Akka Discovery的支持，Akka gRPC客户端可通过Akka Discovery来发现服务。让我们来看一个服务发现配置的例子： 12345678910akka.grpc.client &#123; &quot;sample.HelloService&quot; &#123; service-discovery &#123; mechanism &#x3D; &quot;nacos&quot; service-name &#x3D; &quot;sample-hello&quot; &#125; use-tls &#x3D; false &#125; # 可配置更多服务（endpoint）发现&#125; Endpoint：sample.HelloService是gRPC服务的全限定路径，每个Endpoint都需要有一个配置（注意：服务路径需要用双引号括起来，不然Typesafe Config会认为这个配置分割符）。在service-discovery配置内指定服务发现机制和服务名，而use-tls设置为false可以关闭https，对于内网服务之前的调用来说是可行的，它可以减少些流量。但若你的服务需要暴露到公网，强烈建议设置为true（默认值）。可以通过如下代码构造一个提供了服务发现支持的gRPC客户端： 12val settings = GrpcClientSettings.fromConfig(clientName = &quot;sample.HelloService&quot;)val client = HelloServiceClient(settings) Akka Cluster可用于业务服务内部Akka Cluster Singleton对于服务内多个实例之间，有时也需要集群化的需求。比如一个调用服务，为了保证高可用需要同时启多个实例，但（通常）只会有一个实例管理任务调度，其它实例只做为具体执行任务的Worker，或者不做任何事情，只是为了容错而在Primary节点挂掉是可自动选择其中一个提升为Primary以继续管理任务调度。Akka Cluster Singleton为此类Primary/Secondary模式提供了支持 （更多内容请参阅：https://doc.akka.io/docs/akka/2.6/typed/cluster-singleton.html） ，它可以保证声明为Singleton的actor在集群内有且只有一个实例存在，同时，在Primary节点挂点后会自动将Singleton actor转移到其它节点。 Akka Distributed Data对于服务内需要共享数据、计算的情况，可以使用 Akka Distributed Data（之后简称 ADD）。比如：缓存（某种程度上可用于替代类似 Ehcache 和 Caffeine 这样的进程外缓存机制，你只需要更改一个节点的缓存数据，ADD 可以自动在所有节点间同步）、计数（用户积分计算）等。 ADD 使用了CRDTs（Conflict Free Replicated Data Type），所有数据项都通过直接复制或基于gossip协议传播到所有节点或具有特定角色（role）的节点。同时，你还可以对读、写的一致性进行细粒度的控制（ADD 实现了最终一致性，细粒度可用性可以使数据在写入后更及时地在其它节点可见）。 反应式（Reactive）反应式是近来很火的一个概念，而反应式的理念与微服务非常契合。《反应式宣言》（https://www.reactivemanifesto.org/zh-CN ）是一个用户了解反应式概念的很好的开始。Akka提供了强大而丰富的特性以使你可以很方便的基于它开发一个具有反应式特性的系统。 有一本对怎样实现一个反应式系统写得很好的书：《反应式设计模式》，作者为前Akka CTO：Roland Kuhn，值得深读！ Akka Streamshttps://doc.akka.io/docs/akka/2.6/stream/ Akka Streams是你用来实现反应式系统的核心，从数据的接收（Akka HTTP），到数据存储（Alpakka JDBC、Alpakka Kafka），可以基于Akka Stream打通整个数据流。 Akka Streams为反应式流开发提供了易于使用的DSL，内建回压支持。Akka Streams是Reactive Streams（Reactive Streams，https://www.reactive-streams.org/ ）和JDK 9+ java.util.concurrent.Flow的兼容实现，可与其它实现进行互操作。 Alpakkahttps://doc.akka.io/docs/alpakka/current/ Alpakka开源项目为Java和Scala实现了流感知和反应式集成流水线，它建立于Akka Streams之上。Alpakka为常见的数据服务提供了Akka Stream驱动，如：Kafka、Mongodb、Cassandra、JDBC（Slick）…… 你可以通过Alpakka Kafka从某个Kafka Topic中消费数据；使用Akka Streams对数据流进行处理；然后使用Alpakka JDBC、Alpakka Mongodb、Alpakka Cassandra的数据库连接器将处理后的数据通过流的方式持久化到PostgreSQL、Mongodb、Cassandra等数据库中。你也可以从持久化数据库中读取数据，通过Akka Streams数据流转换处理后再由Akka HTTP作为服务API发布出去，或由Alpakka Kafka生产数据到Kafka Topic中…… Slickhttp://slick.lightbend.com/ Slick是针对Scala语言实现的函数式关系映射库（Functional Relational Mapping，FRM），使得对数据库的操作变得容易，就像操作Scala集合库（Collection）一样。同时，Slick也支持直接使用SQL语句（Slick Plain SQL，http://slick.lightbend.com/doc/3.3.1/sql.html ）。 一个典型的Slick查询类似： 123456val q3 = for &#123; c &lt;- coffees if c.price &lt; 9.0 s &lt;- c.supplier&#125; yield (c.name, s.name)// Equivalent SQL code:// select c.COF_NAME, s.SUP_NAME from COFFEES c, SUPPLIERS s where c.PRICE &lt; 9.0 and s.SUP_ID = c.SUP_ID 而直接使用SQL： 12345// A value to insert into the statementval state = &quot;CA&quot;// Construct a SQL statement manually with an interpolated valueval plainQuery = sql&quot;select SUP_NAME from SUPPLIERS where STATE = $state&quot;.as[String] 在函数式编程中，推荐使用Slick来替代传统的JPA、MyBatis和直接使用JDBC API等作为数据层访问库。Slick具备静态类型（安全）、异步、可组合等特性，同时在某些复杂SQL查询下也支持直接使用SQL语句，但相对于使用JDBC API，Slick Plain SQL也具备静态类型（安全）的特性。 技术降级：Java里好用的工具可继续使用应用了反应式后，是否以前使用的Java下传统的、非反应式的库、工具都不能使用了呢？答案显然是否定的。比如：MyBatis，Spring的用户大多都使用MyBatis作为持久化层（国内用户），它就是一个典型的非反应式的技术，而且还是一个Scala不友好的技术：可变变量、非编译期检查（使用XML编写SQL语句）……但这里认为，它还是可以使用的，特别是从Spring技术架构迁移到Scala/Akka时。 微服务的一个好外是服务的隔离，我们只需要把可变状态隔离起来即可，隔离的维度可以是服务。我们可以在每个服务内部使用MyBatis，甚至延用Java里定义的DO/Entity类、集合类型（这是Scala对Java友好的地方）。 在这里你能找到在Scala下使用MyBatis的例子（例子使用了MyBatis-plus）：https://github.com/ihongka/akka-fusion/blob/master/fusion-mybatis/src/test/scala/fusion/mybatis/FusionMybatisTest.scala 。让我们来看一个测试示例： 1234567891011121314151617181920test(&quot;file insert&quot;) &#123; val sqlSessionFactory = FusionMybatis(system).component sqlSessionFactory.transactional &#123; session =&gt; val fileMapper = session.getMapper(classOf[FileMapper]) val file = CFile(&quot;file_id&quot;, &quot;文件&quot;, &quot;/32/234242.jpg&quot;, 98234) fileMapper.insert(file) &#125;&#125;test(&quot;file list&quot;) &#123; val sqlSessionFactory = FusionMybatis(system).component sqlSessionFactory.transactional &#123; session =&gt; val fileMapper = session.getMapper(classOf[FileMapper]) val list = fileMapper.list(10) list.forEach(new Consumer[CFile] &#123; override def accept(t: CFile): Unit = println(t) &#125;) list must not be empty &#125;&#125; TODO以下内容敬待下一篇： 监控 通过HTTP Header实现简单的调用链监控 kamon：自动检测、监视和调试的分布式系统 实践 全栈 Akka 现实：与Spring Cloud一起 其它 Play Lagom","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"reactive","slug":"reactive","permalink":"https://yangbajing.github.io/tags/reactive/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"策服务","slug":"策服务","permalink":"https://yangbajing.github.io/tags/%E7%AD%96%E6%9C%8D%E5%8A%A1/"}]},{"title":"使用Lightbend Config","slug":"使用lightbend-config","date":"2019-08-04T12:40:30.000Z","updated":"2022-02-16T02:50:45.201Z","comments":true,"path":"2019/08/04/使用lightbend-config/","link":"","permalink":"https://yangbajing.github.io/2019/08/04/%E4%BD%BF%E7%94%A8lightbend-config/","excerpt":"","text":"Lightbend config 提供了一种叫 HOCON 的标记语言来进行配置管理，它是JVM上的配置管理工具，可用来替代Java自带的Properties；而相对于使用JSON来管理配置，它具有注释、变量、可组合等更丰富的特性。本文分享些日常开发工作中使用Lightbend config的经验和技巧。 Lightbend config以前叫Typesafe config，Github地址为：https://github.com/lightbend/config 。 HOCON 特性 Comments, with # or // Allow omitting the {} around a root object Allow = as a synonym for : Allow omitting the = or : before a { so foo { a : 42 } Allow omitting commas as long as there’s a newline Allow trailing commas after last element in objects and arrays Allow unquoted strings for keys and values Unquoted keys can use dot-notation for nested objects, foo.bar=42 means foo { bar : 42 } Duplicate keys are allowed; later values override earlier, except for object-valued keys where the two objects are merged recursively include feature merges root object in another file into current object, so foo { include “bar.json” } merges keys in bar.json into the object foo include with no file extension includes any of .conf, .json, .properties you can include files, URLs, or classpath resources; use include url(“http://example.com&quot;) or file() or classpath() syntax to force the type, or use just include “whatever” to have the library do what you probably mean (Note: url()/file()/classpath() syntax is not supported in Play/Akka 2.0, only in later releases.) substitutions foo : ${a.b} sets key foo to the same value as the b field in the a object substitutions concatenate into unquoted strings, foo : the quick ${colors.fox} jumped substitutions fall back to environment variables if they don’t resolve in the config itself, so ${HOME} would work as you expect. Also, most configs have system properties merged in so you could use ${user.home}. substitutions normally cause an error if unresolved, but there is a syntax ${?a.b} to permit them to be missing. += syntax to append elements to arrays, path += “/bin” multi-line strings with triple quotes as in Python or Scala 起步Ligthbend config非常简单，使用之前需要引入相关依赖： 1libraryDependencies += &quot;com.typesafe&quot; % &quot;config&quot; % &quot;1.3.4&quot; 或 12345&lt;dependency&gt; &lt;groupId&gt;com.typesafe&lt;/groupId&gt; &lt;artifactId&gt;config&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 技巧从URL地址或注册中心获取配置使用Java命令行配置-Dconfig.url就可以从网络地址上直接获得配置。比如通过如下从Nacos中获取配置可如","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"config","slug":"config","permalink":"https://yangbajing.github.io/tags/config/"},{"name":"配置","slug":"配置","permalink":"https://yangbajing.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"Scala实战：使用Akka Stream优化异步代码","slug":"scala实战：使用akka-stream优化异步代码","date":"2019-07-17T13:17:34.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/07/17/scala实战：使用akka-stream优化异步代码/","link":"","permalink":"https://yangbajing.github.io/2019/07/17/scala%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8akka-stream%E4%BC%98%E5%8C%96%E5%BC%82%E6%AD%A5%E4%BB%A3%E7%A0%81/","excerpt":"","text":"Scala扫盲行动 背景今天同事在开发一个消息推送功能，业务还是比较简单的： 通过地区查找这个区域内的所有组织 通过组织ID获取每个组织的所有用户 通过用户ID获得所有绑定了设备IMEI号 通过IMEI号向设备上推送消息 0 业务代码123456789101112131415implicit val system = ActorSystem()implicit val mat = ActorMaterializer()import system.dispatcherdef findOrgIdsByArea(area: String): Future[List[String]] = Future &#123; (0 until Random.nextInt(50)).map(_.toString).toList&#125;def findUserIdsByOrgId(orgId: String): Future[List[String]] = Future &#123; (0 until Random.nextInt(50)).map(n =&gt; s&quot;$orgId-$n&quot;).toList&#125;def findImeisByUserIds(userIds: Iterable[String]): Future[List[String]] = Future &#123; userIds.map(id =&gt; &quot;imei-&quot; + id).toList&#125; 这段代码定义了3个函数，因为是演示，实现逻辑就非常简单。分别是： 通过地区名查询地区内的所有组织ID 通过组织ID获取组织内所有用户的ID 通过用户ID列表查询绑定的设备IMEI 1 使用Future1234567891011121314def firstOnFuture(): Future[Unit] = &#123; findOrgIdsByArea(&quot;北京&quot;) .flatMap &#123; orgIds =&gt; val futures = orgIds.map(id =&gt; findUserIdsByOrgId(id)) Future.sequence(futures) &#125; .flatMap &#123; orgUserIdList =&gt; val futures = orgUserIdList.map(userIds =&gt; findImeisByUserIds(userIds)) Future.sequence(futures) &#125; .map &#123; orgImeiList =&gt; orgImeiList.foreach(imeis =&gt; batchSendMessage(imeis, &quot;推送消息&quot;)) &#125;&#125; 第一版代码使用Scala Future来实现，它可以正确的实现业务功能，但代码看起来并不优雅。且它有一些问题： 若所查询地区内用户非常多，会造成orgImeiList这个列表对象非常大，有可能会超过内存限制 若每个组织内的用户很少，但组织很多。会造成batchSendMessage的批量发送优化失去效果，因为极端情况下有可能1000个组织的每个组织都只有一个用户 2 使用Akka Stream12345678910def secondOnAkkaStream(): Future[Done] = &#123; Source .fromFuture(findOrgIdsByArea(&quot;北京&quot;)) // (1) .mapConcat(identity) // (2) .mapAsync(4)(orgId =&gt; findUserIdsByOrgId(orgId)) // (3) .mapAsync(4)(userIds =&gt; findImeisByUserIds(userIds)) .mapConcat(identity) .grouped(1000) // (4) .runForeach(imeis =&gt; batchSendMessage(imeis, &quot;推送消息&quot;)) // (5)&#125; 第二版代码使用Akka Stream来优化之前的基于Future的异步代码。 (1) Source.fromFuture将一个Future[T]类型转换成Source[T, Any]类型的Akka Stream流 (2) .mapContact(identity)将一个List[T]类型的流拉平成T类型的流：Source[T, Any]。identity内置函数类似：def identity(v: T): T = v (3) .mapAsync(N)(func: T =&gt; Future[R])将一个返回Future结果的函数集成到Akka Stream流，mapAsync(N)这里的参数N用于设置使用几个线程来并发执行Akka Stream流中的元素 (4) 将流中的元素按每1000个进行分组 (5) runForeach运行Akka Stream流并按grouped(1000)生成的批次进行调用 可以看到，Akka Stream的代码解决了之前使用Scala Future的所有问题：代码更优雅、不会有内存泄露、有效的利用批量发送。 3 优化Akka Stream代码123456789101112def secondOnAkkaStreamThrottle(): Future[Done] = &#123; import scala.concurrent.duration._ Source .fromFuture(findOrgIdsByArea(&quot;北京&quot;)) .mapConcat(identity) .mapAsync(4)(orgId =&gt; findUserIdsByOrgId(orgId)) .mapAsync(4)(userIds =&gt; findImeisByUserIds(userIds)) .mapConcat(identity) .grouped(1000) .throttle(5, 10.seconds) .runForeach(imeis =&gt; batchSendMessage(imeis, &quot;推送消息&quot;))&#125; 这段代码在上一个使用Akka Stream的代码之上加上了流控的功能，限制每10秒内最多5次消息推送。 4 集成消息系统 Kafka1234567891011121314151617181920212223case class SendMessageByArea(area: String, content: String)def secondOnAkkaStreamKafka(): Future[Done] = &#123; import scala.concurrent.duration._ val consumerSettings = ConsumerSettings(system, new StringDeserializer, new StringDeserializer) .withBootstrapServers(&quot;localhost:9092&quot;) .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;) Consumer .plainSource(consumerSettings, Subscriptions.topics(&quot;message&quot;)) .map(record =&gt; Jackson.convertValue[SendMessageByArea](record.value())) .flatMapConcat &#123; req =&gt; Source .fromFuture(findOrgIdsByArea(req.area)) .mapConcat(identity) .mapAsync(4)(orgId =&gt; findUserIdsByOrgId(orgId)) .mapAsync(4)(userIds =&gt; findImeisByUserIds(userIds)) .mapConcat(identity) .grouped(1000) .throttle(5, 10.seconds) .map(imeis =&gt; batchSendMessage(imeis, req.content)) &#125; .runWith(Sink.ignore)&#125; So easy! 是的，这段代码就实现了从Kafka中获取消息、分组批量推送和并发次数流控的完整的一个消息系统的功能。 小结以上都是些很实用的列子，但可以明显的体现出Akka Stream相对于默认的Scala Future的解决方案的优势。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"scala实战","slug":"scala/scala实战","permalink":"https://yangbajing.github.io/categories/scala/scala%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"reactive","slug":"reactive","permalink":"https://yangbajing.github.io/tags/reactive/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-stream","slug":"akka-stream","permalink":"https://yangbajing.github.io/tags/akka-stream/"}]},{"title":"PostgreSQL高可用：JDBC优化","slug":"postgresql高可用：jdbc优化","date":"2019-07-13T14:23:30.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/07/13/postgresql高可用：jdbc优化/","link":"","permalink":"https://yangbajing.github.io/2019/07/13/postgresql%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9Ajdbc%E4%BC%98%E5%8C%96/","excerpt":"","text":"JDBC URL连接参数 targetServerType = String: 只允许连接到具有所需状态的服务器，许可的值有any、master、secondary、preferSecondary。主/从区别目前是通过观察服务器是否允许写入来实现的。如果有可用的值，preferSecondary将尝试连接到secondary，否则将返回到允许连接的master。 loadBalanceHosts = boolean: 默认（false）；若设为true则会从一组合适的候选主机中随机选择一个。 reWriteBatchedInserts = boolean: 优化批量插入，从insert into foo values(); insert into foo values() 改进为 insert into foo values (), ()。可能会有2-3倍的性能提升。 FusionJdbc配置示例连接主节点 1234567891011fusion.jdbc &#123; default &#123; poolName &#x3D; &quot;hongka_openapi&quot; jdbcUrl &#x3D; &quot;jdbc:postgresql:&#x2F;&#x2F;10.0.32.37:5432,10.0.32.36:5432,10.0.32.35:5432&#x2F;hongka_openapi?reWriteBatchedInserts&#x3D;true&amp;targetServerType&#x3D;master&quot; username &#x3D; &quot;hongka&quot; password &#x3D; &quot;ZDexPJYTLi2Z&quot; connectionTestQuery &#x3D; &quot;select 1;&quot; maximumPoolSize &#x3D; 4 numThreads &#x3D; 4 &#125;&#125; 连接从节点 1234567891011fusion.jdbc &#123; default &#123; poolName &#x3D; &quot;hongka_openapi&quot; jdbcUrl &#x3D; &quot;jdbc:postgresql:&#x2F;&#x2F;10.0.32.37:5432,10.0.32.36:5432,10.0.32.35:5432&#x2F;hongka_openapi?reWriteBatchedInserts&#x3D;true&amp;targetServerType&#x3D;preferSecondary&amp;loadBalanceHosts&#x3D;true&quot; username &#x3D; &quot;hongka&quot; password &#x3D; &quot;ZDexPJYTLi2Z&quot; connectionTestQuery &#x3D; &quot;select 1;&quot; maximumPoolSize &#x3D; 4 numThreads &#x3D; 4 &#125;&#125;","categories":[],"tags":[]},{"title":"PostgreSQL高可用 - PG 11集群","slug":"postgresql高可用-PG11集群","date":"2019-07-12T07:04:31.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/07/12/postgresql高可用-PG11集群/","link":"","permalink":"https://yangbajing.github.io/2019/07/12/postgresql%E9%AB%98%E5%8F%AF%E7%94%A8-PG11%E9%9B%86%E7%BE%A4/","excerpt":"","text":"《PostgreSQL从入门到不后悔》 《PostgreSQL高可用：逻辑复制》 《PostgreSQL高可用 - PG 11集群》 高可用性：数据库服务器可以一起工作， 这样如果主要的服务器失效则允许一个第二服务器快速接手它的任务 负载均衡: 允许多个计算机提供相同的数据 本文使用的主要技术有： CentOS 7 x86_64 PostgreSQL 11.4 系统安装、配置12345$ sudo localectl set-locale &quot;LANG&#x3D;zh_CN.utf8&quot;$ sudo timedatectl set-timezone Asia&#x2F;Shanghai$ sudo yum -y install https:&#x2F;&#x2F;download.postgresql.org&#x2F;pub&#x2F;repos&#x2F;yum&#x2F;reporpms&#x2F;EL-7-x86_64&#x2F;pgdg-redhat-repo-latest.noarch.rpm epel-release vim$ sudo yum -y update$ sudo yum -y install postgresql11-server postgresql11-contrib postgresql 更多关于PG安装和基础使用方面内容可阅读 《PostgreSQL从入门到不后悔》 和 《PostgreSQL高可用：逻辑复制》 。 PostgreSQL 集群设置这里列出官方对各种高可用、负载均衡和复制特性实现方式的比较： 本文将基于PostgreSQL官方提供的基于流式的WAL数据复制功能搭建一个 主/热备 数据库集群。 根据 PostgreSQL单机配置，安装3台服务器。IP地址设置分别如下，并加入 /etc/hosts 中： 主节点：10.0.32.37 热备节点：10.0.32.35 逻辑复制节点：10.0.32.36，有关逻辑复制的内容请阅读：《PostgreSQL高可用：逻辑复制》 主节点（10.0.32.37）1.. 创建一个传用于复制的账号： 1CREATE ROLE pgrepuser REPLICATION LOGIN ENCRYPTED PASSWORD &#39;pgreppass&#39;; 2.. 在 postgresql.conf 设置以下配置项： 1234567listen_addresses &#x3D; &#39;*&#39;max_connections &#x3D; 1024password_encryption &#x3D; onwal_level &#x3D; logical # logical包含replica的功能，这样可使主节点同时具备流复制来源和逻辑复制发布者archive_mode &#x3D; onmax_wal_sender &#x3D; 4wal_keep_segments &#x3D; 10 3.. 在 pg_hba.conf 文件中为 pgrepuser 设置权限规则。允许 pgrepuser 从所有地址连接到主节点，并使用基于MD5的密码加密方式。 1host replication pgrepuser 0.0.0.0&#x2F;0 md5 主服务器配置好后需要重启数据库： 1$ sudo systemctl restart postgresql-11 若在生产环境中没有条件进行数据库重启，也可以使用 pg_ctl reload 指令重新加载配置： 1$ sudo systemctl reload postgresql-11 主节点的配置到此即可，接下来对从节点进行配置。 从节点1.. 首先停止从机上的PostgreSQL服务（非启动过刚可忽略此步骤）。 1sudo systemctl stop postgresql-11 2.. 使用 pg_basebackup 生成备库 首先清空 $PGDATA 目录。 12-bash-4.2$ cd &#x2F;var&#x2F;lib&#x2F;pgsql&#x2F;11&#x2F;data-bash-4.2$ rm -rf * 使用 pg_basebackup 命令生成备库： 1-bash-4.2$ &#x2F;usr&#x2F;pgsql-11&#x2F;bin&#x2F;pg_basebackup -D $PGDATA -Fp -Xstream -R -c fast -v -P -h 10.0.32.37 -U pgrepuser -W 我们看到以下的操作输出，代表生成备库成功。 123456789Password: pg_basebackup: initiating base backup, waiting for checkpoint to completepg_basebackup: checkpoint completedpg_basebackup: write-ahead log start point: 0&#x2F;6000028 on timeline 1pg_basebackup: starting background WAL receiverpg_basebackup: created temporary replication slot &quot;pg_basebackup_27275&quot;pg_basebackup: write-ahead log end point: 0&#x2F;60000F8pg_basebackup: waiting for background process to finish streaming ...pg_basebackup: base backup completed 3.. 将下面的配置设置添加到 postgresql.conf 文件中。 1hot_standby &#x3D; on 4.. 在 $PGDATA 目录创建 recovery.conf 文件，内容如下： 12345standby_mode &#x3D; &#39;on&#39;primary_conninfo &#x3D; &#39;host&#x3D;10.0.32.37 port&#x3D;5432 user&#x3D;pgrepuser password&#x3D;pgreppass application_name&#x3D;replica1&#39;trigger_file&#x3D;&#39;recovery.fail&#39;recovery_target_timeline &#x3D; &#39;latest&#39;restore_command &#x3D; cp %p ..&#x2F;archive&#x2F;%f&#39; restore_command 如果发现从属服务器处理事务日志的速度较慢，跟不上主服务器产生日志的速度，为避免主服务器产生积压，你可以在从属服务器上指定一个路径用于缓存暂未处理的日志。请在 recovery.conf 中添加如下一个代码行，该代码行在不同操作系统下会有所不同。 5.. 启动从数据库 1$ sudo systemctl start postgresql-11 启动复制进程的注意事项 一般情况下，我们建议先启动所有从属服务器再启动主服务器，如果顺序反过来，会导致主服务器已经开始修改数据并生成事务日志了，但从属服务器却还无法进行复制处理，这会导致主服务器的日志积压。如果在未启动主服务器的情况下先启动从属服务器，那么从属服务器日志中会报错，说无法连接到主服务器，但这没有关系，忽略即可。等所有从属服务器都启动完毕后，就可以启动主服务器了。 此时所有主从属服务器应该都是能访问的。主服务器的任何修改，包括安装一个扩展包或者是新建表这种对系统元数据的修改，都会被同步到从属服务器。从属服务器可对外提供查询服务。 如果希望某个从属服务器脱离当前的主从复制环境，即此后以一台独立的 PostgreSQL 服务器身份而存在，请直接在其 data 文件夹下创建一个名为 failover.now 的空文件。从属服务器会在处理完当前接收到的最后一条事务日志后停止接收新的日志，然后将 recovery.conf 改名为 recovery.done。此时从属服务器已与主服务器彻底解除了复制关系，此后这台PostgreSQL 服务器会作为一台独立的数据库服务器存在，其数据的初始状态就是它作为从属服务器时处理完最后一条事务日志后的状态。一旦从属服务器脱离了主从复制环境，就不可能再切换回主从复制状态了，要想切回去，必须按照前述步骤一切从零开始。 测试主/备服务分别登录 10.0.32.37 和 10.0.32.35 两台数据库使用 \\l 命令查看数据库列表： PostgreSQL: Prod-DataHouse-3 123456789101112131415$ psql -h 10.0.32.37 -U postgres用户 postgres 的口令：psql (11.4)输入 &quot;help&quot; 来获取帮助信息.postgres&#x3D;# \\l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres(3 行记录) PostgreSQL: Prod-DataHouse-1 123456789101112131415$ psql -h 10.0.32.35 -U postgres用户 postgres 的口令：psql (11.4)输入 &quot;help&quot; 来获取帮助信息.postgres&#x3D;# \\l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres(3 行记录) 我们在 10.0.32.37 上创建一个测试数据库：test 1postgres&#x3D;# create database test template&#x3D;template1; test 数据库创建成功后，我们可以在 10.0.32.35 从服务器上看到 test 数据库已经同步过来。 1234567891011postgres&#x3D;# \\l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres test | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | (4 行记录) 继续在从库上尝试 DDL 操作，可以发现从库已被正确的设置为只读模式： 123456postgres&#x3D;# \\c test您现在已经连接到数据库 &quot;test&quot;,用户 &quot;postgres&quot;.test&#x3D;# CREATE TABLE test (id BIGStest&#x3D;# CREATE TABLE test (id BIGSERIAL PRIMARY KEY, name VARCHAR(255), age INT);错误: 不能在一个只读模式的事务中执行CREATE TABLE 在主库上，我们可以正常的进行读写操作。同时主节点的 恢复（recovery） 模式为 false。 1234567891011121314151617test&#x3D;# CREATE TABLE test (id BIGSERIAL PRIMARY KEY, name VARCHAR(255), age INT);CREATE TABLEtest&#x3D;# INSERT INTO test(name, age) VALUES(&#39;羊八井&#39;, 31), (&#39;杨景&#39;, 31);INSERT 0 2test&#x3D;# SELECT * FROM test; id | name | age ----+--------+----- 1 | 羊八井 | 31 2 | 杨景 | 31(2 行记录)test&#x3D;# select pg_is_in_recovery(); pg_is_in_recovery ------------------- f(1 行记录) 让我们再切换到从库，执行 SELECT * FROM test 查询语句可以看到之前在主库上写入的两条记录已被成功复制过来。 数据库复制状态Prod-DataHouse-3 在主节点上，我们可以看到有一个复制节点连接上来，客户端地址（client_addr）为：10.0.32.37，使用流式复制（state），同步模式（sync_state）为异步复制。 1234567891011121314151617181920test&#x3D;# \\x扩展显示已打开。test&#x3D;# select * from pg_stat_replication;-[ RECORD 1 ]----+------------------------------pid | 1287usesysid | 16384usename | pgrepuserapplication_name | walreceiverclient_addr | 10.0.32.35client_hostname | client_port | 42338backend_start | 2019-07-11 10:08:37.842367+08backend_xmin | state | streamingsent_location | 0&#x2F;501EB20write_location | 0&#x2F;501EB20flush_location | 0&#x2F;501EB20replay_location | 0&#x2F;501EB20sync_priority | 0sync_state | async 主/备切换1.. 关闭主节点数据库服务： 1[Prod-DataHouse-3 ~]$ sudo systemctl stop postgresql-11 2.. 将从节点变为主节点 12[Prod-DataHouse-1 ~]$ sudo su - postgres-bash-4.2$ &#x2F;usr&#x2F;pgsql-11&#x2F;bin&#x2F;pg_ctl promote -D $PGDATA 此时在节点 centos7-002 上，PostgreSQL数据库已经从备节点转换成了主节点。同时，recovery.conf 文件也变为了 recovery.done 文件，表示此节点不再做为从节点进行数据复制。 12345678910111213test&#x3D;# select pg_is_in_recovery();-[ RECORD 1 ]-----+--pg_is_in_recovery | ftest&#x3D;# DELETE FROM test WHERE id &#x3D; 1;DELETE 1test&#x3D;# SELECT * FROM test; id | name | age ----+------+----- 2 | 杨景 | 31(1 行记录) 3.. 将原主节点（centos7-001）变为级联从节点（当前主节点已改为centos7-002）。 在 centos7-001 节点上编辑 postgresql.conf，并开启热备模式： 1hot_standby &#x3D; on 添加并编辑 recovery.conf 文件： 12345standby_mode &#x3D; &#39;on&#39;primary_conninfo &#x3D; &#39;host&#x3D;centos7-003 port&#x3D;5432 user&#x3D;pgrepuser password&#x3D;pgreppass application_name&#x3D;replic1&#39;trigger_file&#x3D;&#39;recovery.fail&#39;recovery_target_timeline &#x3D; &#39;latest&#39;restore_command &#x3D; cp %p ..&#x2F;archive&#x2F;%f&#39; （重）启动PostgreSQL数据库，节点 centos7-001 现在成为了一个 级联从节点 。 总结PostgreSQL官方支持基于流式复制的WAL实现的主/热备高可用集群机制，同时我们还可以搭配 PgPool-II 在应用层实现","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"postgresql","slug":"bigdata/postgresql","permalink":"https://yangbajing.github.io/categories/bigdata/postgresql/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://yangbajing.github.io/tags/postgresql/"},{"name":"集群","slug":"集群","permalink":"https://yangbajing.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"cluster","slug":"cluster","permalink":"https://yangbajing.github.io/tags/cluster/"}]},{"title":"PostgreSQL高可用：逻辑复制","slug":"postgresql高可用：逻辑复制","date":"2019-07-10T11:39:36.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/07/10/postgresql高可用：逻辑复制/","link":"","permalink":"https://yangbajing.github.io/2019/07/10/postgresql%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9A%E9%80%BB%E8%BE%91%E5%A4%8D%E5%88%B6/","excerpt":"","text":"《PostgreSQL从入门到不后悔》 《PostgreSQL高可用：逻辑复制》 《PostgreSQL高可用 - PG 11集群》 从PostgreSQL 10（以下简称PG）开始，PG支持逻辑复制能力，可实现仅复制部分表或PG服务器上的部分database。逻辑复制的一大优点是支持跨版本间复制，也不需要主从节点的操作系统和硬件架构相同。例如，我们可以实现一台Linux服务器上的PG 11和Windows服务器上的PG 10之间的复制；通过逻辑复制还可以实现不停服的数据库版本更新。 在PG逻辑复制的概念体系中，数据提供方被称为发布者（publisher），数据接收方被称为订阅者（subscriber）。同一个PG即可以作为发布者，同时也可以作为订阅者，这样即可实现级联复制，可以及大的减轻主节点的负担。 注意：但需要注意的是，逻辑复制是单向的。你在从节点上修改的数据行将不会反向同步的主节点，同时相应行也不会再响应主节点的数据变更。 设置逻辑复制本文使用两台主机来演示PG的逻辑复制： 10.0.32.37：主节点，数据发布端 10.0.32.36：从节点，数据订阅端 配置启用逻辑复制非常简单，设置PG的系统参数wal_level为logical即可。可在SQL控制台通过以下命令修改： 1alter system set wal_level = logical; 也可逻辑配置文件以使其全局生效（并重启PG）,编辑postgresql.conf并设置如下参数： 12wal_level &#x3D; logical # minimal, replica, or logical 创建数据发布者使用具有superuser权限的用户登录需要设置为数据发布者的数据库： 1psql -h 10.0.32.35 -U devuser -d watch_log -W 创建数据发布者 12watch_log=# create publication custom_watch_log for table l_basic, l_contact; -- 多张表使用英文逗号分隔列出CREATE PUBLICATION 注意：这里不要使用for all tables创建数据发布者，因为这将造成发布者在以后不能增、删表。 默认PG只对insert、delete语句进行逻辑复制，若需要对其它DML语句也先进逻辑复制需要设置表的replica identity [option]属性。 1alter table l_basic replica identity full ; 创建数据订阅者使用具有superuser权限的用户登录需要设置为数据订阅者的数据库： 1psql -h 10.0.32.36 -U devuser -d watch_log -W PG的逻辑复制不会同步DDL语句，需要在订阅者数据库上提前创建后需要进行逻辑复制的表。 创建数据订阅者 123watch_log=# create subscription full_watch_log connection &#x27;host=10.0.32.37 port=5432 dbname=watch_log user=devuser password=dbuser.password&#x27; publication full_watch_log;NOTICE: created replication slot &quot;custom_watch_log&quot; on publisherCREATE SUBSCRIPTION 演示1: 初始数据发布 123456watch_log=&gt; \\conninfo以用户 &quot;devuser&quot; 的身份, 在主机&quot;10.0.32.37&quot;, 端口&quot;5432&quot;连接到数据库 &quot;watch_log&quot;watch_log=&gt; select * from l_basic ; imei | i | p | s | o | u ------+---+---+---+---+---(0 行记录) 数据订阅 123456watch_log=&gt; \\conninfo以用户 &quot;devuser&quot; 的身份, 在主机&quot;10.0.32.36&quot;, 端口&quot;5432&quot;连接到数据库 &quot;watch_log&quot;watch_log=&gt; select * from l_basic ; imei | i | p | s | o | u ------+---+---+---+---+---(0 行记录) 2: 数据发布者插入记录数据发布 12345678watch_log=&gt; insert into l_basic(imei, i, p, s, o, u) values(&#x27;imei-1&#x27;, now(), 11, 11, 11.11, 11.11), (&#x27;imei-2&#x27;, now(), 22, 22, 22.22, 22.22);INSERT 0 2watch_log=&gt; select * from l_basic ; imei | i | p | s | o | u--------+----------------------------+----+----+-------+------- imei-1 | 2019-07-10 19:37:39.283234 | 11 | 11 | 11.11 | 11.11 imei-2 | 2019-07-10 19:37:39.283234 | 22 | 22 | 22.22 | 22.22(2 行记录) 数据订阅 123456watch_log=&gt; select * from l_basic ; imei | i | p | s | o | u--------+----------------------------+----+----+-------+------- imei-1 | 2019-07-10 19:44:47.357619 | 11 | 11 | 11.11 | 11.11 imei-2 | 2019-07-10 19:44:47.357619 | 22 | 22 | 22.22 | 22.22(2 行记录) 3: 数据发布者编辑记录数据发布 123456789watch_log=&gt; update l_basic set p = 44, o = 44.44 where imei = &#x27;imei-1&#x27;;UPDATE 1watch_log=&gt; delete from l_basic where imei = &#x27;imei-2&#x27;;DELETE 1watch_log=&gt; select * from l_basic ; imei | i | p | s | o | u--------+----------------------------+----+----+-------+------- imei-1 | 2019-07-10 19:44:47.357619 | 44 | 11 | 44.44 | 11.11(1 行记录) 数据订阅 12345watch_log=&gt; select * from l_basic ; imei | i | p | s | o | u--------+----------------------------+----+----+-------+------- imei-1 | 2019-07-10 19:44:47.357619 | 44 | 11 | 44.44 | 11.11(1 行记录) 增加新的数据发布表数据发布端添加新表使用之前创建publication时的用户登录数据库 123psql -h 10.0.32.37 -U postgres -d watch_log -Wwatch_log&#x3D;# alter publication custom_watch_log add table test ;ALTER PUBLICATION 数据订阅端添加新表并刷新subscription创建数据表test： 123psql -h 10.0.32.36 -U devuser -d watch_log -Wwatch_log=&gt; create table test(id serial primary key, name varchar(255));CREATE TABLE 使用之前创建publication时的用户登录数据库 123psql -h 10.0.32.36 -U postgres -d watch_log -Wwatch_log2&#x3D;# alter subscription custom_watch_log refresh publication ;ALTER SUBSCRIPTION 小结最后放张图：","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"postgresql","slug":"bigdata/postgresql","permalink":"https://yangbajing.github.io/categories/bigdata/postgresql/"}],"tags":[{"name":"逻辑复制","slug":"逻辑复制","permalink":"https://yangbajing.github.io/tags/%E9%80%BB%E8%BE%91%E5%A4%8D%E5%88%B6/"},{"name":"logical replication","slug":"logical-replication","permalink":"https://yangbajing.github.io/tags/logical-replication/"},{"name":"replication","slug":"replication","permalink":"https://yangbajing.github.io/tags/replication/"},{"name":"wal","slug":"wal","permalink":"https://yangbajing.github.io/tags/wal/"}]},{"title":"Akka启用ssl和HTTP 2","slug":"akka启用ssl和http-2","date":"2019-06-18T13:40:14.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/06/18/akka启用ssl和http-2/","link":"","permalink":"https://yangbajing.github.io/2019/06/18/akka%E5%90%AF%E7%94%A8ssl%E5%92%8Chttp-2/","excerpt":"","text":"Akka原生支持SSL、HTTPS、HTTP 2，本文记录下各SSL的使用配置。 X.509证书 公钥证书是解决身份问题的一种方法。若仅加密是可以建立一个安全的连接，但不能保证你正在与你认为正在与之通信的服务器通信。如果没有某种方法来验证远程服务器的身份，攻击者仍然可以将自己作为远程服务器，然后将安全连接转发到伪造的远程服务器。公钥证书就是用来解决这个问题的。 考虑公共密钥证书的最佳方法是使用护照系统。证书用于以一种难以伪造的方式建立有关信息持有人的信息。这就是为什么证书验证如此重要：接受任何证书意味着即使是攻击者的证书也将被盲目接受。 生成 X.509 证书本文示例使用Java 1.8的keytool来创建证书。 生成随机密码通过pwgen命令生成10位字符的随机密码到password文件，这个密码文件将在接下来各步骤中使用。 1pwgen -Bs 10 1 &gt; password Linux：sudo apt install pwgen或sudo yum install pwgen，Mac：brew install pwgen 服务器配置你将需要一个分配了DNS主机名的服务器来验证主机名。在这个例子中，我们假设主机名是yangbajing.dev。 创建自签名证书生成服务端SSL证书第一步是创建将对yangbajing.me证书进行签名的证书颁发机构。根CA证书有几个附加属性（ca:true，keyCertSign），这些属性明确地将其标记为CA证书，并将保存在信任存储中。 12345678910111213141516171819202122232425262728293031#!/bin/shexport PW=`cat password`KEY_FILE=ssl-key# 创建自签名密钥CA证书和私钥keytool -genkeypair -v \\ -dname &quot;CN=www.yangbajing.me, OU=Yangbajing, O=Yangbajing, L=Beijing, ST=Beijing, C=CN&quot; \\ -keyalg RSA \\ -keysize 4096 \\ -ext KeyUsage:critical=&quot;keyCertSign&quot; \\ -ext BasicConstraints:critical=&quot;ca:true&quot; \\ -ext SAN=&quot;DNS:www.yangbajing.me,DNS:yangbajing.me,DNS:about.yangbajing.me&quot; \\ -validity 9999 \\ -alias $&#123;KEY_FILE&#125; \\ -keystore $&#123;KEY_FILE&#125;.jks \\ -keypass:env PW \\ -storepass:env PW# 以下命令查看刚生成的证书密钥内容：# keytool -keystore $&#123;KEY_FILE&#125;.jks -list -v# 导出$&#123;KEY_FILE&#125;公共证书上为$&#123;KEY_FILE&#125;.crt，以便在信任存储中使用keytool -export -v \\ -alias $&#123;KEY_FILE&#125; \\ -file $&#123;KEY_FILE&#125;.crt \\ -keypass:env PW \\ -storepass:env PW \\ -keystore $&#123;KEY_FILE&#125;.jks \\ -rfc 生成 yangbajing.dev 证书SSL证书配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#!/bin/sh# 生成 $&#123;DOMAIN&#125; 证书，$&#123;DOMAIN&#125; 证书由 $&#123;DOMAIN&#125; 服务器在握手时提供LANG=en_US.UTF-8export PW=`cat password`export DOMAIN=&quot;yangbajing.dev&quot;export KEY_FILE=ssl-key# 创建绑定到 $&#123;DOMAIN&#125; 的服务器证书keytool -genkeypair -v \\ -alias $&#123;DOMAIN&#125; \\ -dname &quot;CN=$&#123;DOMAIN&#125;, OU=Yangbajing, O=Yangbajing, L=Beijing, ST=Beijing, C=CN&quot; \\ -keystore $&#123;DOMAIN&#125;.jks \\ -keypass:env PW \\ -storepass:env PW \\ -keyalg RSA \\ -keysize 2048 \\ -validity 385#keytool -importkeystore -srckeystore localdev.com.jks -destkeystore localdev.com.jks -deststoretype pkcs12# 为 $&#123;DOMAIN&#125; 创建证书签名请求# 从技术上讲，密码使用DHE或ECDHE数字签名，RSA进行密码加密。# 在你创建完自签名证书和密钥后,还需要前进一小步来创建证书签名申请 (certificate signingrequest,CSR):# 现在可以将文件 $&#123;DOMAIN&#125;.csr 提交给你的CA用于签发正式证书了。keytool -certreq -v \\ -alias $&#123;DOMAIN&#125; \\ -keypass:env PW \\ -storepass:env PW \\ -keystore $&#123;DOMAIN&#125;.jks \\ -file $&#123;DOMAIN&#125;.csr# 告诉 $&#123;KEY_FILE&#125; 签署 $&#123;DOMAIN&#125; 证书。注意，扩展是根据请求而不是原始证书。# csr -&gt; crtkeytool -gencert -v \\ -alias $&#123;KEY_FILE&#125; \\ -keypass:env PW \\ -storepass:env PW \\ -keystore $&#123;KEY_FILE&#125;.jks \\ -infile $&#123;DOMAIN&#125;.csr \\ -outfile $&#123;DOMAIN&#125;.crt \\ -ext KeyUsage:critical=&quot;digitalSignature,keyEncipherment&quot; \\ -ext EKU=&quot;serverAuth&quot; \\ -ext SAN=&quot;DNS:$&#123;DOMAIN&#125;&quot; \\ -rfc# 告诉 $&#123;DOMAIN&#125;.jks 可以信任 $&#123;KEY_FILE&#125; 作为签名者keytool -import -v \\ -alias $&#123;KEY_FILE&#125; \\ -file $&#123;KEY_FILE&#125;.crt \\ -keystore $&#123;DOMAIN&#125;.jks \\ -storetype JKS \\ -storepass:env PW &lt;&lt; EOFyesEOF# 将签名导入到 $&#123;DOMAIN&#125;.jkskeytool -import -v \\ -alias $&#123;DOMAIN&#125; \\ -file $&#123;DOMAIN&#125;.crt \\ -keystore $&#123;DOMAIN&#125;.jks \\ -storetype JKS \\ -storepass:env PW 可以列出yangbajing.jks的内容以确认。若使用Play（等Java应用），这将存储到服务器的密钥存储区。 1keytool -list -v -keystore yangbajing.jks -storepass:env PW 将可看到类似如下输出： 12345678910111213Keystore type: jksKeystore provider: SUNYour keystore contains 1 entryAlias name: yangbajing.devCreation date: Jun 18, 2019Entry type: PrivateKeyEntryCertificate chain length: 1Certificate[1]:Owner: CN&#x3D;yangbajing.dev, OU&#x3D;Yangbajing, O&#x3D;Yangbajing, L&#x3D;Beijing, ST&#x3D;Beijing, C&#x3D;CNIssuer: CN&#x3D;yangbajing.dev, OU&#x3D;Yangbajing, O&#x3D;Yangbajing, L&#x3D;Beijing, ST&#x3D;Beijing, C&#x3D;CN.... 导出Nginx可用的PEM如果 yangbajing.me 不使用Java作为TLS端点，同时你想使用Nginx。可需要导出 PEM 格式的证书。这需要 openssl 来导出私钥。 123456789101112131415161718192021222324252627282930313233343536#!/bin/shexport PW=`cat password`DOMAIN=hongkazhijia.dev# 导出 $&#123;DOMAIN&#125; 公钥供 Nginx 使用keytool -export -v \\ -alias $&#123;DOMAIN&#125; \\ -file $&#123;DOMAIN&#125;.crt \\ -keypass:env PW \\ -storepass:env PW \\ -keystore $&#123;DOMAIN&#125;.jks \\ -rfc# 创建包含公钥和私钥的 PKCS12 密钥库keytool -importkeystore -v \\ -srcalias $&#123;DOMAIN&#125; \\ -srckeystore $&#123;DOMAIN&#125;.jks \\ -srcstoretype jks \\ -srcstorepass:env PW \\ -destkeystore $&#123;DOMAIN&#125;.p12 \\ -destkeypass:env PW \\ -deststorepass:env PW \\ -deststoretype PKCS12# 导出 $&#123;DOMAIN&#125; 私钥以在 Nginx 中使用。注意，这需要使用 opensslopenssl pkcs12 \\ -nocerts \\ -nodes \\ -in $&#123;DOMAIN&#125;.p12 \\ -out $&#123;DOMAIN&#125;.key \\ -passout env:PW \\ -passin env:PW# 清理rm $&#123;DOMAIN&#125;.p12 生成的 yangbajing.dev.crt（公钥）和 yangbajing.dev.key（私钥）两个文件。作为示例，可以这样配置Nginx使用。 12ssl_certificate &#x2F;etc&#x2F;nginx&#x2F;certs&#x2F;yangbajing.dev.crt;ssl_certificate_key &#x2F;etc&#x2F;nginx&#x2F;certs&#x2F;yangbajing.dev.key; 如果使用的是客户端身份验证，还需要添加： 12ssl_client_certificate &#x2F;etc&#x2F;nginx&#x2F;certs&#x2F;clientca.crt;ssl_verify_client on; 可以通过如下命令来检查服务器的证书（需要先启动 yangbajing.dev HTTP服务器）： 1keytool -printcert -sslserver yangbajing.dev HTTP 2TODO 小结TODO","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"ssl","slug":"ssl","permalink":"https://yangbajing.github.io/tags/ssl/"},{"name":"https","slug":"https","permalink":"https://yangbajing.github.io/tags/https/"},{"name":"http-2","slug":"http-2","permalink":"https://yangbajing.github.io/tags/http-2/"}]},{"title":"WS SSL快速起步 - lightbend SSL Config","slug":"lightbend-ssl-config-quick-start-to-ws-ssl","date":"2019-06-18T03:36:10.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/06/18/lightbend-ssl-config-quick-start-to-ws-ssl/","link":"","permalink":"https://yangbajing.github.io/2019/06/18/lightbend-ssl-config-quick-start-to-ws-ssl/","excerpt":"","text":"原文：Quick Start to WS SSL 本文适用于需要通过 HTTPS 连接到远程 Web 服务而不想阅读整个手册的用户。如果需要设置 Web 服务或配置客户端身份认证，请阅读 Generating X.509 Certificates 。 通过 HTTPS 连接到远程服务器如果远程服务器正在使用一个由已知证书颁发机构签发的证书，那么WS应该在不进行任何额外配置的情况下即可正常工作。这里就结束了！ 如果Web服务未使用众所周知的证书颁发机构，则它正在使用私有CA或自签名证书。您可以通过使用curl轻松确定这一点： 1curl https:&#x2F;&#x2F;financialcryptography.com # uses cacert.org as a CA 如果收到以下错误，则必须获得CA的证书并将其添加到信任存储。 12345678910111213curl: (60) SSL certificate problem: Invalid certificate chainMore details here: http:&#x2F;&#x2F;curl.haxx.se&#x2F;docs&#x2F;sslcerts.htmlcurl performs SSL certificate verification by default, using a &quot;bundle&quot; of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn&#39;t adequate, you can specify an alternate file using the --cacert option.If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL).If you&#39;d like to turn off curl&#39;s verification of the certificate, use the -k (or --insecure) option. 获取根CA证书理想情况下，这应该在外部完成：Web服务的所有者应该以一种不可伪造的方式，最好是亲自向您提供根CA证书。 在没有通信的情况下（不建议这样做），您有时可以使用JDK 1.8中的keytool直接从证书链获取根CA证书： 1keytool -printcert -sslserver playframework.com 返回的 #2 部分即是根证书： 1234Certificate #2&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Owner: CN&#x3D;GlobalSign Root CA, OU&#x3D;Root CA, O&#x3D;GlobalSign nv-sa, C&#x3D;BEIssuer: CN&#x3D;GlobalSign Root CA, OU&#x3D;Root CA, O&#x3D;GlobalSign nv-sa, C&#x3D;BE 要获得可导出格式的证书链，请使用-rfc选项： 1keytool -printcert -sslserver playframework.com -rfc 将返回一系列PEM格式的证书： 123-----BEGIN CERTIFICATE-----...-----END CERTIFICATE----- 可以复制粘贴到文件中。链中最后一个证书将是根CA证书。 注意 并非所有网站都包含根CA证书。您应该使用keytool或证书解码器对证书进行解码，以确保您拥有正确的证书。 将trust manager（信任管理器）指向PEM文件将以下内容添加到application.conf中，具体指定pem格式： 1234567ssl-config &#123; trustManager &#x3D; &#123; stores &#x3D; [ &#123; type &#x3D; &quot;PEM&quot;, path &#x3D; &quot;&#x2F;path&#x2F;to&#x2F;cert&#x2F;globalsign.crt&quot; &#125; ] &#125;&#125; 这将告诉信任管理器忽略证书的默认的cacerts存储，并且只使用您的自定义CA证书。 之后，将配置WS，您可以测试您的连接是否可以使用： 1WS.url(&quot;https:&#x2F;&#x2F;example.com&quot;).get() 您可以在 示例配置 页面上看到更多示例。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"ssl-config","slug":"ssl-config","permalink":"https://yangbajing.github.io/tags/ssl-config/"}]},{"title":"Akka实战：再谈断点上传","slug":"akka实战：再谈断点续传","date":"2019-06-01T10:08:20.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/06/01/akka实战：再谈断点续传/","link":"","permalink":"https://yangbajing.github.io/2019/06/01/akka%E5%AE%9E%E6%88%98%EF%BC%9A%E5%86%8D%E8%B0%88%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0/","excerpt":"","text":"去年的文章：《Akka实战：HTTP大文件断点上传、下载，秒传》 通过示例介绍了在Akka HTTP里怎样实现断点上传功能。通过一段时间的应用，发现了些问题，这篇文章再深入介绍下。在 https://github.com/yangbajing/scala-applications/tree/master/file-upload能找到完整的源码。 Nginx代理Nginx代理时默认会在Nginx端收到完整的请求数据以后再将其转发到被代理的服务，这样会造成通过Akka HTTP实现的断点上传功能用不上。原因： 客户端断开或网络问题会造成Nginx端返回错误响应，根本就不向被代理的服务发送数据。 需要断点上传的一般都是大文件，若文件太大会使Nginx服务的资源造成不必要的浪费。因为我们使用Akka HTTP实现的断点上传是通过stream处理实时将上传数据存储到磁盘上的，这样可以保证在一定的内存使用情况下支持大文件上传。 对于第2点，就因为Nginx默认缓冲整个请求数据，造成我们第一版文件服务申请了一台64G内存的服务器（第一版未使用Akka HTTP来实现断点上传功能，是直接使用Spring写的一个文件服务）。 这个问题要解决也比较简单，在Nginx中添加如下配置即可： 123client_max_body_size 4g;proxy_request_buffering off;proxy_http_version 1.1; client_max_body_size 指令告诉Nginx在判断Content-Length头时，超过4G的请求才报错。 proxy_request_buffering 指令关闭Nginx的代理缓冲，将客户端的请求数据直接转发到被代码服务。 proxy_http_version 强制代理使用HTTP 1.1版本，否则通过proxy_request_buffering off在通过Chunk的方式进行的请求时还是会在Nginx端缓冲数据。 但请注意：Tengine（Taobao的Nginx发行版）或低于1.7.11的官方发行版是没法通过这种方式来调整的。 proxy_request_buffering指令在1.7.11版才添加到官方Nginx。 Tengine的proxy_request_buffering语言与官方的不一样，它始终会在Nginx端缓冲数据，区别是在内存缓冲还是在磁盘缓冲。 这种情况下需要将Akka HTTP服务直接开发出去，或通过TCP代理来转发请求到Akka HTTP。 异常时保存状态","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"akka-stream","slug":"akka-stream","permalink":"https://yangbajing.github.io/tags/akka-stream/"}]},{"title":"Firewall快速使用","slug":"firewall快速使用","date":"2019-05-30T02:42:58.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/05/30/firewall快速使用/","link":"","permalink":"https://yangbajing.github.io/2019/05/30/firewall%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8/","excerpt":"","text":"基本使用查询状态1sudo firewall-cmd --zone&#x3D;public --list-all 打开端口1sudo firewall-cmd --zone&#x3D;public --permanent --add-port&#x3D;3306&#x2F;tcp --permanent选项设置匹配永久生效，但需要调用--reload使firewall重新加载配置使其马上生效。 使规则生效1sudo firewall-cmd --reload 端口转发开启伪装IP1sudo firewall-cmd --permanent --add-masquerade 配置端口转发1sudo firewall-cmd --permanent --add-forward-port&#x3D;port&#x3D;15432:proto&#x3D;tcp:toaddr&#x3D;10.0.0.8:toport&#x3D;5432 将本机端口15432转发到10.0.0.8:5432 删除端口转发1sudo firewall-cmd --permanent --remove-forward-port&#x3D;port&#x3D;15432:proto&#x3D;tcp:toaddr&#x3D;10.0.0.8:toport&#x3D;5432","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"},{"name":"firewall","slug":"firewall","permalink":"https://yangbajing.github.io/tags/firewall/"}]},{"title":"转发：一次操作系统报错OutOfMemory Error的处理记录","slug":"转发：一次操作系统报错outofmemory-error的处理记录","date":"2019-05-30T02:34:52.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/05/30/转发：一次操作系统报错outofmemory-error的处理记录/","link":"","permalink":"https://yangbajing.github.io/2019/05/30/%E8%BD%AC%E5%8F%91%EF%BC%9A%E4%B8%80%E6%AC%A1%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8A%A5%E9%94%99outofmemory-error%E7%9A%84%E5%A4%84%E7%90%86%E8%AE%B0%E5%BD%95/","excerpt":"","text":"原文地址：https://www.jianshu.com/p/3f8692eb3660 原文作者：1nfinity 在启动公司内嵌的tomcat容器时出现报错, 如下： 1234# There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (malloc) failed to allocate 160088 bytes for AllocateHeap# An error report file with more information is saved as:# &#x2F;users&#x2F;xxx&#x2F;hs_err_pidxxxx.log 然后查看/users/xxx/hs_err_pidxxxx.log内容： 1234567891011121314151617181920212223242526## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 357564416 bytes for committing reserved memory.# Possible reasons:# The system is out of physical RAM or swap space# The process is running with CompressedOops enabled, and the Java Heap may be blocking the growth of the native heap# Possible solutions:# Reduce memory load on the system# Increase physical memory or swap space# Check if swap backing store is full# Decrease Java heap size (-Xmx&#x2F;-Xms)# Decrease number of Java threads# Decrease Java thread stack sizes (-Xss)# Set larger code cache with -XX:ReservedCodeCacheSize&#x3D;# JVM is running with Unscaled Compressed Oops mode in which the Java heap is# placed in the first 4GB address space. The Java Heap base address is the# maximum limit for the native heap growth. Please use -XX:HeapBaseMinAddress# to set the Java Heap base and to place the Java Heap above 4GB virtual address.# This output file may be truncated or incomplete.## Out of Memory Error (os_linux.cpp:2749), pid&#x3D;4252, tid&#x3D;0x00007f3f38bb5700## JRE version: (8.0_201-b09) (build )# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.201-b09 mixed mode linux-amd64 compressed oops)# Core dump written. Default location: &#x2F;users&#x2F;ems&#x2F;core or core.4252 (max size 521000 kB). To ensure a full core dump, try &quot;ulimit -c unlimited&quot; before starting Java again# 翻译过来就是本地内存分配失败, 可能的原因有两种 系统物理内存或虚拟内存不足 程序在压缩指针模式下运行, Java堆会阻塞本地堆的增长 然后使用free -m命令查询, 发现内存足够: 那么尝试按第二个问题进行解决, 可能的方案有两种: 禁止使用压缩指针模式 方法: 在catalina.sh中JAVA_OPTS的值后面添加-XX:-UseCompressedOops, 再重启tomcat 将Java堆的起始地址设置成使Java堆大小+起始地址大于4G, 原因: 请参考 https://blogs.oracle.com/poonam/running-on-a-64bit-platform-and-still-running-out-of-memory, 方法: 在这里我将起始地址简单直接的设为4G即4294967296 在尝试过这两种方法后发现依然报同样的错误这时我在想会不会是堆内存过大, 导致系统无法分配内存, 于是进行尝试: 把堆内存减少一半, 看看效果. 方法: 在catalina.sh中JAVA_OPTS的值中把原来的-Xms1024m -Xmx2048m改为-Xms512m -Xmx1024m, 再重启tomcat 结果JVM启动成功, 问题解决。 后续思考: 为什么在可用内存充足的情况下系统无法分配给JVM更多内存? 一直没有想到完美的解释, 如果有明白的兄弟可以指教一下.尝试对后续思考进行解答: 原因应该还是内存不足, 可能操作系统会预留一些内存, 而我的机器上默认的启动参数是-Xms1024m -Xmx2048m,可能已经超过了系统允许分配的最高值, 因此无法分配内存. 当我使用java -Xms10m -Xmx20m可以启动成功, `java -Xms500m -Xmx2000m会失败,因此, 应该还是内存不足的问题对后续思考的最终解答及该问题的完美解决方案: 这个问题是由于/proc/meminfo下的vm.overcommit_memory被设置成不允许overcommit造成的 首先了解一下overcommit的意思: 用户进程申请的是虚拟地址, 而这个虚拟地址是不允许任意申请的, 因为虚拟内存需要物理内存做支撑, 如果分配太多虚拟内存, 会对性能参数影响. overcommit就是对虚拟内存的过量分配vm.overcommit_memory的用处: 控制过量分配的策略. 这个参数一共有3个可选值: 0: Heuristic overcommit handling. 就是由操作系统自己决定过量分配策略 1: Always overcommit. 一直允许过量分配 2: Don’t overcommit. 不允许过量分配 在这个案例里面, 使用sysctl vm.overcommit_memory来查看, 发现vm.overcommit_memory = 2, 即采用的是不允许过量分配的设置. 而在错误日志中也证明了这一点： 12CommitLimit: 15951192 kBCommitted_AS: 15837036 kB 解决方案是sudo sysctl vm.overcommit_memory=0, 即vm.overcommit_memory = 0, 允许系统自己决定过量分配策略（推荐编辑/etc/sysctl.conf文件使永久生效）。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"outofmemory","slug":"outofmemory","permalink":"https://yangbajing.github.io/tags/outofmemory/"},{"name":"vm.overcommit_memory","slug":"vm-overcommit-memory","permalink":"https://yangbajing.github.io/tags/vm-overcommit-memory/"}]},{"title":"使用WebFlux与Reactor-当流为 Empty 时的注意事项","slug":"使用webflux与reactor","date":"2019-05-07T13:48:18.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/05/07/使用webflux与reactor/","link":"","permalink":"https://yangbajing.github.io/2019/05/07/%E4%BD%BF%E7%94%A8webflux%E4%B8%8Ereactor/","excerpt":"","text":"注意empty会造成之后的所有转换操作不执行当Mono&lt;T&gt;的计算结果为empty时，在它之后添加的多个转换操作都不会被触发执行。有一些方法可以解决这个问题： 使用Optional&lt;T&gt;来包裹可能为空的数据类型。 1Mono&lt;Optional&lt;User&gt;&gt; findById(String userId); 使用.switchIfEmpty或.defaultIfEmpty来将empty转换成其它有值的结果。 1234Mono&lt;User&gt; findById(String userId);findById(userId) .switchIfEmpty(Mono.","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"reactor","slug":"reactor","permalink":"https://yangbajing.github.io/tags/reactor/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"webflux","slug":"webflux","permalink":"https://yangbajing.github.io/tags/webflux/"},{"name":"functional","slug":"functional","permalink":"https://yangbajing.github.io/tags/functional/"}]},{"title":"反应式的Spring","slug":"反应式的spring","date":"2019-04-21T15:13:53.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/04/21/反应式的spring/","link":"","permalink":"https://yangbajing.github.io/2019/04/21/%E5%8F%8D%E5%BA%94%E5%BC%8F%E7%9A%84spring/","excerpt":"","text":"Spring从5.0开始拥抱反应式（Reactive）开发，通过Reactor和WebFlux来支持反应式的开发模式。有关反应式更多的内容可以阅读 《反应式宣言》 。反应式系统具有以下物质：即时响应性（Responsive）、回弹性（Resilient）、弹性（Elastic）以及消息驱动（Message Driven）。 对于这样的系统，我们称之为反应式系统（Reactive System）。这里，推荐一本反应式讲得很好的书籍：《反应式设计模式》，可在 https://item.jd.com/12518824.html 购买。 Spring Boot 2.0在传统的Servlet Stack之外提供了Reactive Stack来支持反应式的编程。Spring官方对Reactive Stack的说明为：Spring WebFlux是一个从头开始构建的无阻塞Web框架，它利用多核技术和下一代处理器来处理大量的并发连接。 WebFlux实现了Reactive Streams（反应式流处理），由 Project Reactor 提供支持。类似 Akka Stream 、RxJava 等其它实现了 Reactive Streams 规范的库，它提供了在JVM平台上构建非阻塞应用的强大工具。 起步本文不是反应式编程原理的介绍及说明文章，本文只是告诉你怎样在Spring生态中起步反应式编程。简单说就是怎样使用Spring 5新推出的WebFlux来进行应用开发。本文使用Maven做为示例的构建工具，需要引入spring-boot-starter-webflux来代替传统的基于Servlet模型的spring-boot-starter-web依赖。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt; 你可以在 https://github.com/yangbajing/spring-reactive-sample/blob/master/pom.xml 找到完整的配置。 Spring Boot 2默认未启用WebFlux特性，需要使用@EnableWebFlux注解来启用，通常可以在一个@Configuration上配置： 12345678@EnableWebFlux@Configurationpublic class ApplicationConfiguration implements WebFluxConfigurer &#123; @Override public void configureHttpMessageCodecs(ServerCodecConfigurer configurer) &#123; configurer.defaultCodecs().enableLoggingRequestDetails(true); &#125;&#125; 请求与响应对应请求、响应（Request/Response），WebFlux提供了两种实现方式： 类似WebMVC的基于注解的控制器方式 全新的函数式端点方式（类似Akka HTTP Routing那样通过函数来组合定义HTTP路由） 本文将介绍基于注解的控制器方式。 1234@GetMapping(path = &quot;world&quot;)public Hello world(String hello, String world) &#123; return Hello.builder().hello(hello).world(world).build();&#125; 基于注解的控制器方式和使用Spring MVC Web时的方式类似，从函数参数获取请求值，返回的结果将通过默认的HttpMessageConverter进行转换（序列化成JSON数据）。 Header与CookieWebFlux下，获取Header与Cookie需要使用ServerHttpRequest来获得，因为通常情况下使用WebFlux是基于Netty实现的，在这种情况下ServletHttpRequest是没有加载的。 123456@GetMappingpublic ApiResult findFromSession(ServerHttpRequest request) &#123; HttpCookie tokenCookie = request.getCookies().getFirst(&quot;token&quot;); String tokenHeader = request.getHeaders().getFirst(&quot;token&quot;); ......&#125; 数据校验请求数据的校验需要把@Valid注解加到请求参数上，但与Spring 4及更早版本不同的地方是需要把请求参数使用Mono&lt;T&gt;包起来。Bean校验的错误将作为Mono的错误（Error）被发送。 1234567891011121314151617181920@PostMapping(path = &quot;signup&quot;)public Mono&lt;ApiResult&gt; signup(@Valid @RequestBody Mono&lt;SignupDTO&gt; mono) &#123; return mono .map(signupDTO -&gt; ApiResult.ok(credentialService.signup(signupDTO))) .onErrorResume(httpComponent::justApiResult);&#125;public Mono&lt;ApiResult&gt; justApiResult(Throwable t) &#123; ApiResult result = ApiResult.error(StatusEnum.INTERNAL_SERVER_ERROR); if (t instanceof WebExchangeBindException) &#123; result.setStatus(StatusEnum.BAD_REQUEST); WebExchangeBindException e = (WebExchangeBindException) t; ObjectNode data = objectMapper.createObjectNode(); e.getFieldErrors().forEach(field -&gt; data.put(field.getField(), field.getDefaultMessage())); result.setData(data); &#125; else &#123; result.setMessage(t.getLocalizedMessage()); &#125; return Mono.just(result);&#125; Reactive CoreSpring WebFlux的反应式核心有以下基本支持： HttpHandler: HTTP服务处理，主要用于在不同的HTTP服务器上实现一个统一的请求/响应处理抽象； WebHandler API: 是提供Web应用程序中常用的一组更广泛的功能，如：具有属性的用户会话、请求属性、表单处理、文件上传/下载等； Filters: 过滤器，可控制处理流程； Exceptions: 全局异常处理； Codecs: HTTP请求/响应编码器，通过无阻塞I/O和反应流回压对更高级别的对象之间的字节进行序列化与反序列化； Logging: 日志。 自定义编码器 123456@Overridepublic void configureHttpMessageCodecs(ServerCodecConfigurer configurer) &#123; ServerCodecConfigurer.ServerDefaultCodecs defaultCodecs = configurer.defaultCodecs(); defaultCodecs.jackson2JsonEncoder(new Jackson2JsonEncoder(objectMapper)); defaultCodecs.jackson2JsonDecoder(new Jackson2JsonDecoder(objectMapper));&#125; 小结Spring 5开始已经拥抱反应式编程，本文通过一些简单的示例来演示了Spring 5引入的WebFlux，也算缓缓打开了反应式（Reactive）编程的大门。 完整的代码在Github上可以访问：https://github.com/yangbajing/spring-reactive-sample","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"reactive","slug":"reactive","permalink":"https://yangbajing.github.io/tags/reactive/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"webflux","slug":"webflux","permalink":"https://yangbajing.github.io/tags/webflux/"}]},{"title":"Spring应用enum处理","slug":"spring应用enum处理","date":"2019-04-17T11:10:12.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/04/17/spring应用enum处理/","link":"","permalink":"https://yangbajing.github.io/2019/04/17/spring%E5%BA%94%E7%94%A8enum%E5%A4%84%E7%90%86/","excerpt":"","text":"原文地址：https://www.yangbajing.me/2019/04/17/spring应用enum处理/ 在Spring应用开发中，Java枚举（enum）默认都是使用字符串进行序列化/反序列化的。都通常我们都想将其序列化/反序列化为int值。 MyBatisMyBatis-plus提供了插件用于自定义enum的序列化/反序列化，非常方便。只需要在application.properties配置文件中指定默认的枚举处理器即可，配置如下： 1mybatis-plus.configuration.default-enum-type-handler: com.baomidou.mybatisplus.extension.handlers.EnumTypeHandler 枚举类需要实现IEnum接口或将字段标记@EnumValue注解，这样MyBatis-plus在遇到相关枚举类型时就会通过指定的配置来序列/反序列化。 Jackson序列化Jackson的配置要相对复杂一点，Jackson对序列化提供了默认的支持，在要使用的字段上加JsonValue注解即可： 1234567891011121314151617181920212223public enum UserStatusEnum implements IEnum&lt;Integer&gt; &#123; DISABLE(0, &quot;禁用&quot;), NORMAL(1, &quot;正常&quot;), PLAIN(999, &quot;普通&quot;); @JsonValue private Integer value; private String name; UserStatusEnum(Integer value, String name) &#123; this.value = value; this.name = name; &#125; public String getName() &#123; return name; &#125; public Integer getValue() &#123; return value; &#125;&#125; 反序列化从int反序列化到enum，需要自定义IEnumDeserializer反序列化器，代码如下： 12345678910111213141516171819202122232425262728293031323334public class EnumDeserializers extends Deserializers.Base &#123; @Override public JsonDeserializer&lt;?&gt; findEnumDeserializer(Class&lt;?&gt; type, DeserializationConfig config, BeanDescription beanDesc) throws JsonMappingException &#123; if (IEnum.class.isAssignableFrom(type)) &#123; return new IEnumDeserializer(EnumResolver.constructUnsafe(type, config.getAnnotationIntrospector())); &#125; return super.findEnumDeserializer(type, config, beanDesc); &#125;&#125;public class IEnumDeserializer extends StdScalarDeserializer&lt;IEnum&lt;Integer&gt;&gt; implements ContextualDeserializer &#123; private final IEnum&lt;Integer&gt;[] enums; private final EnumResolver enumResolver; public IEnumDeserializer(EnumResolver byNameResolver) &#123; super(byNameResolver.getEnumClass()); this.enumResolver = byNameResolver; this.enums = (IEnum&lt;Integer&gt;[]) enumResolver.getRawEnums(); &#125; @Override public IEnum&lt;Integer&gt; deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException &#123; int value = p.getIntValue(); return Arrays.stream(this.enums).filter(e -&gt; e.getValue() == value).findFirst() .orElseThrow(() -&gt; new JsonParseException(p, &quot;枚举需要为整数类型&quot;)); &#125; @Override public JsonDeserializer&lt;?&gt; createContextual(DeserializationContext ctxt, BeanProperty property) throws JsonMappingException &#123; return this; &#125;&#125; 并实现Jackson Module： 12345678910111213141516public class MyModule extends Module &#123; @Override public String getModuleName() &#123; return &quot;MyModule&quot;; &#125; @Override public Version version() &#123; return Version.unknownVersion(); &#125; @Override public void setupModule(SetupContext context) &#123; context.addDeserializers(new EnumDeserializers()); &#125;&#125; 反序列化器和Jackson Module定义好后就需要把它加入Jackson里了，有两种方式： 手动注册：获取objectMapper，将MyModule注册到Jackson。 objectMapper.registerModule(new MyModule()); 自动注册：通过Java自带的ServiceLoader服务提供商加载机制来自动注册模块到Jackson。在resources资源目录创建服务配置文件，文件路径如下： 123resources META-INF.services com.fasterxml.jackson.databind.Module 服务配置文件内容： 1com.fasterxml.jackson.module.yangbajing.MyModule 自定义Spring Boot Jackson 反序列化器、Jackson模块都写好了，我们需要自定义Spring Boot来启动Jackson的模块自动注册功能： 123456789101112131415161718192021@EnableWebFlux@Configurationpublic class WebConfiguration implements WebFluxConfigurer &#123; @Autowired private ObjectMapper objectMapper; @Override public void configureHttpMessageCodecs(ServerCodecConfigurer configurer) &#123; ServerCodecConfigurer.ServerDefaultCodecs defaultCodecs = configurer.defaultCodecs(); defaultCodecs.jackson2JsonEncoder(new Jackson2JsonEncoder(objectMapper)); defaultCodecs.jackson2JsonDecoder(new Jackson2JsonDecoder(objectMapper)); &#125; @Bean @Order(-1) public ObjectMapper objectMapper(Jackson2ObjectMapperBuilder builder) &#123; return builder.createXmlMapper(false).build().findAndRegisterModules(); &#125;&#125; findAndRegisterModules()方法将通过ServiceLoader机制从classpath路径中找到所有的Module并注册到Jackson。 在void configureHttpMessageCodecs(ServerCodecConfigurer configurer)函数中自定义ServerDefaultCodecs，使用新的ObjectMapper来注册jackson2JsonEncoder和jackson2JsonDecoder。 小结Java提供了丰富而完善的enum机制，但大部化序列化/反序列化工具都使用文字来对其进行序列化/反序列化。而通常我们都会枚举序列化/反序列化为int。 Spring还是一个优秀的框架的，从公司/组织层面选择它不会错。 可以在 https://github.com/yangbajing/spring-reactive-sample 找到示例代码。","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"jackson","slug":"jackson","permalink":"https://yangbajing.github.io/tags/jackson/"},{"name":"enum","slug":"enum","permalink":"https://yangbajing.github.io/tags/enum/"},{"name":"mybatis-plus","slug":"mybatis-plus","permalink":"https://yangbajing.github.io/tags/mybatis-plus/"},{"name":"mybatis","slug":"mybatis","permalink":"https://yangbajing.github.io/tags/mybatis/"}]},{"title":"Scala实战：迁移文件","slug":"scala实战：迁移文件","date":"2019-03-22T13:24:50.000Z","updated":"2022-02-16T02:50:45.200Z","comments":true,"path":"2019/03/22/scala实战：迁移文件/","link":"","permalink":"https://yangbajing.github.io/2019/03/22/scala%E5%AE%9E%E6%88%98%EF%BC%9A%E8%BF%81%E7%A7%BB%E6%96%87%E4%BB%B6/","excerpt":"","text":"Scala作为script使用也是非常的方便。 原文地址：https://www.yangbajing.me/2019/03/22/scala实战：迁移文件/ 前因最近因为线上文件越来越多，导致磁盘不够用。需要将磁盘上数据迁移到一块新的磁盘上（不用问为啥没用云存储，因为用了的话就不会有这篇文章了）。迁移数据时遇到几个问题： 迁移过程中服务不能中断 因为磁盘文件较大，文件移动耗费时间较长……等copy完的话再重新挂载磁盘会造成移动时间这段时间内新上传文件丢失 终上，我想到一个一个子目录的进行迁移，在迁移完后再将新目录做一个符号连接回原地址。这样在完成整体迁移之前若有新文件上传，文件将通过符号连接最终存储到新的磁盘上。 实现所用Scala script代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.nio.file.&#123;Files, Path, Paths&#125;import java.time.&#123;Duration, Instant&#125;import scala.sys.process._if (args.length != 2) &#123; println(&quot;&quot;&quot;请输入参数：scala MoveDir.scala &lt;src_dir&gt; &lt;dest_dir&gt;&quot;&quot;&quot;)&#125;// 从命令行参数中函数“解构”直接获得源目录和目的目录val Array(srcDir, distDir) = argsval IGNORE_NAMES = Set(&quot;s1&quot;)def ignoreDirectories(dir: Path) = &#123; val name = dir.getName(dir.getNameCount - 1).toString IGNORE_NAMES(name) || name.length != 2&#125;Files .list(Paths.get(srcDir)) .forEach &#123; // 模式匹配 case dir: Path if !Files.isDirectory(dir) || Files.isSymbolicLink(dir) =&gt; println(s&quot;$dir 不是目录或为符号链接&quot;) case dir: Path if ignoreDirectories(dir) =&gt; println(s&quot;强制忽略目录：$dir&quot;) case dir: Path =&gt; val name = dir.getName(dir.getNameCount - 1).toString val target = s&quot;$distDir/$name&quot; val start = Instant.now() try &#123; // 通过 .!! 隐式方法直接执行系统命令 s&quot;mv $dir $target&quot;.!! s&quot;ln -sf $target $srcDir/$name&quot;.!! val cost = Duration.between(start, Instant.now()) println(s&quot;移动目录成功，耗时$cost；$dir --&gt; $target&quot;) &#125; catch &#123; case e: Throwable =&gt; val cost = Duration.between(start, Instant.now()) System.err.println(s&quot;移动目录失败，耗时$cost；$dir --&gt; $target。$&#123;e.toString&#125;&quot;) &#125; &#125; 脚本执行后的部分输出如下： 1234567891011121314$ scala MoveDir.scala &#x2F;home&#x2F;upload &#x2F;data移动目录成功，耗时PT0.012S；&#x2F;home&#x2F;upload&#x2F;d4 --&gt; &#x2F;data&#x2F;d4移动目录成功，耗时PT0.002S；&#x2F;home&#x2F;upload&#x2F;ba --&gt; &#x2F;data&#x2F;ba移动目录成功，耗时PT0.002S；&#x2F;home&#x2F;upload&#x2F;fd --&gt; &#x2F;data&#x2F;fd移动目录成功，耗时PT0.002S；&#x2F;home&#x2F;upload&#x2F;7e --&gt; &#x2F;data&#x2F;7e移动目录成功，耗时PT0.002S；&#x2F;home&#x2F;upload&#x2F;b7 --&gt; &#x2F;data&#x2F;b7移动目录成功，耗时PT0.003S；&#x2F;home&#x2F;upload&#x2F;76 --&gt; &#x2F;data&#x2F;76移动目录成功，耗时PT0.002S；&#x2F;home&#x2F;upload&#x2F;43 --&gt; &#x2F;data&#x2F;43强制忽略目录：&#x2F;home&#x2F;upload&#x2F;hongka-tmp移动目录成功，耗时PT0.001S；&#x2F;home&#x2F;upload&#x2F;df --&gt; &#x2F;data&#x2F;df&#x2F;home&#x2F;upload&#x2F;logo.jpg 不是目录或为符号链接移动目录成功，耗时PT0.001S；&#x2F;home&#x2F;upload&#x2F;85 --&gt; &#x2F;data&#x2F;85移动目录成功，耗时PT0.001S；&#x2F;home&#x2F;upload&#x2F;f0 --&gt; &#x2F;data&#x2F;f0...... 小结Scala是一门强大的、融合了函数式与面向对象范式的编程语言。同时，Scala也是一门精致的语言，除了通常那些 重量 级应用外，日常工作中的脚本也可以使用。接下来，也许你可以尝试下 lihaoyi 的 http://ammonite.io/。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"script","slug":"script","permalink":"https://yangbajing.github.io/tags/script/"},{"name":"scala-script","slug":"scala-script","permalink":"https://yangbajing.github.io/tags/scala-script/"}]},{"title":"DevOps实践：Gitlab、Jenkins","slug":"devops实践：gitlab、jenkins","date":"2019-03-20T09:31:38.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2019/03/20/devops实践：gitlab、jenkins/","link":"","permalink":"https://yangbajing.github.io/2019/03/20/devops%E5%AE%9E%E8%B7%B5%EF%BC%9Agitlab%E3%80%81jenkins/","excerpt":"","text":"Wiki百科上对DevOps一词的解释：DevOps（Development和Operations的组合詞）是一种重视「软件开发人员（Dev）」和「IT运维技术人员（Ops）」之间沟通合作的文化、运动或慣例。 透过自动化「软件交付」和「架构变更」的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 而Gitlab和Jenkins是我们在DevOps中常用的工具，本文将简单介绍下怎样搭配Gitlab与Jenkins来起步DevOps。 Gitlab生成Access Token访问 User Settings &gt; Access Token，生成Personal Access Tokens。如下图： 点击Create personal access token生成访问令牌，并记住它。之后配置Jenkins时需要。 创建一个Jenkins pipeline作业配置Jenkins的Gitlab访问凭据进入Jenkins的全局设置，配置Gitlab。分别设置Connection name、Gitlab host URL和Credentials。 点击Credentials右侧的Add按钮，添加Gitlab API token。在弹框里选择Gitlab API token类型，并设置API token。 API token为之前从Gitlab里生成的Access Token。 创建Job创建一个流水线（pipeline）风格的作业（Job）。 Build Triggers构建触发规则选中Build when a change is pushed to Gitlab. Gitlab webhook URL: &lt;jenkins job url&gt;。Advanced...按钮，并在Secret token选项点击Generate生成Secret token（记住这个token，在配置Gitlab仓库时需要）。 Pipeline Definition选择Pipeline script from SCM SCM选择Git Repository URL填写需要Jenkins自动化构建的Git仓库 Credentials选择已定义的一个凭据或者新建一个 Branches to build请填写自己希望构建的分支 Script Path填写相对Git仓库根目录的Jenkinsfile路径，这里我们设置为Jenkinsfile.develop 点击Save按钮保存 配置Gitlab代码Push时自动通知Jenkins进入Gitlab某个项目，从左侧菜单选择Settings &gt; Integrations。 URL：填写Jenkins作业地址，如：http://&lt;ip&gt;:&lt;port&gt;/project/&lt;job name&gt; Secret Token：填写在作罢Jenkins作业Build Triggers步骤时获得的token Push events：选中Push events（酌情可以指定具体的分支名）和Merge request events。 最后点击Save chagens按钮保存设置，也可以在保存前先点击Test按钮测试下配置是否正确。也许你需要去掉**Enable SSL verification**，这看你的具体情况设置。 示例Jenkinsfile这里有一个示例的Jenkinsfile配置文件，定义了3个阶段，分别是： Test：执行单元测试，测试完成后收集测试结果。可以在pipeline在Test界面查看测试报告。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354pipeline &#123; agent any options &#123; timeout(time: 2, unit: &#39;HOURS&#39;) &#125; stages &#123; stage(&#39;Test&#39;) &#123; steps &#123; sh &#39;.&#x2F;sbt test&#39; &#125; post &#123; always &#123; junit &#39;**&#x2F;target&#x2F;test-reports&#x2F;*.xml&#39; &#125; &#125; &#125; stage(&#39;Package&#39;) &#123; steps &#123; sh &#39;.&#x2F;sbt &quot;project hongka-resource-app&quot; assembly &quot;project hongka-resource-converter-app&quot; assembly&#39; &#125; &#125; stage(&#39;Deliver for develop&#39;) &#123; when &#123; expression &#123; currentBuild.result &#x3D;&#x3D; null || currentBuild.result &#x3D;&#x3D; &#39;SUCCESS&#39; &#125; &#125; environment &#123; DEPLOY_CREDENTIALS &#x3D; credentials(&#39;develop_username_password&#39;) &#125; steps &#123; sh &quot;.&#x2F;scripts&#x2F;deploy_develop.sh $DEPLOY_CREDENTIALS_USR $DEPLOY_CREDENTIALS_PSW&quot; &#125; &#125; &#125; post &#123; always &#123; echo &#39;This will always run&#39; &#125; success &#123; archiveArtifacts artifacts: &#39;**&#x2F;target&#x2F;scala-2.12&#x2F;*.jar&#39;, fingerprint: true &#125; failure &#123; echo &#39;This will run only if failed&#39; &#125; unstable &#123; echo &#39;This will run only if the run was marked as unstable&#39; &#125; changed &#123; echo &#39;This will run only if the state of the Pipeline has changed&#39; echo &#39;For example, if the Pipeline was previously failing but is now successful&#39; &#125; &#125;&#125; 思考 这里没有选择Jenkins的多分支pipeline构建，而是使用单分支pipeline构建。考虑主要如下： 通常仓库里都会有一些不属于开发、测试的分支及临时分支存在，不希望每次这些分支被Push时都会触发自动编译 多分支构建都使用同一个Jenkinsfile，会造成Jenkinsfile内容变多且复杂 我更喜欢对不同的分支建立不同的Jenkins作业，这样从管理上，特别是权限控制上更方便 因为使用了单分支pipeline，所以需要为不同的构建环境创建不同的Jenkinsfile配置文件。这里有一个推荐： scripts/Jenkinsfile.develop：开发环境 scripts/Jenkinsfile.test：测试环境 scripts/Jenkinsfile.production：所产环境 scripts/Jenkinsfile.master：演示环境（可选）","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://yangbajing.github.io/tags/jenkins/"},{"name":"devops","slug":"devops","permalink":"https://yangbajing.github.io/tags/devops/"},{"name":"gitlab","slug":"gitlab","permalink":"https://yangbajing.github.io/tags/gitlab/"},{"name":"jenkins-pipeline","slug":"jenkins-pipeline","permalink":"https://yangbajing.github.io/tags/jenkins-pipeline/"},{"name":"jenkinsfile","slug":"jenkinsfile","permalink":"https://yangbajing.github.io/tags/jenkinsfile/"}]},{"title":"Alpakka Kafka，反应式Kafka客户端","slug":"alpakka-kafka，反应式kafka客户端","date":"2019-02-23T12:42:46.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2019/02/23/alpakka-kafka，反应式kafka客户端/","link":"","permalink":"https://yangbajing.github.io/2019/02/23/alpakka-kafka%EF%BC%8C%E5%8F%8D%E5%BA%94%E5%BC%8Fkafka%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"Alpakka Kafka 是一个要用于 Java 和 Scala 语言的开源的流感知和反应式集成数据线项目。它建立在 Akka Stream之上，提供了 DSL 来支持反应式和流式编程，内置回压功能。Akka Streams 是 Reactive Streams 和JDK 9+ java.util.concurrent.Flow 的兼容实现，可无缝地与其进行互操作。 要使用 Alpakka Kafka，需要在你的项目添加如下依赖： 1libraryDependencies += &quot;com.typesafe.akka&quot; %% &quot;akka-stream-kafka&quot; % &quot;1.0-RC2&quot; 当前支持 kafka-clients 2.1.x 和 Akka Streams 2.5.21。 快速开始对Akka Streams或Kafka不熟的，可先查阅两者的官方文档： https://akka.io/ https://kafka.apache.org/ Alpakka Kafka 写的代码非常精致且简洁，也许你会一眼爱上它的美。 123456789101112131415161718192021222324252627282930313233343536373839object KafkaGetting extends App &#123; implicit val system = ActorSystem() implicit val mat = ActorMaterializer() import system.dispatcher val config = system.settings.config val producerSettings = ProducerSettings(config.getConfig(&quot;akka.kafka.producer&quot;), new StringSerializer, new StringSerializer) val consumerSettings = ConsumerSettings(config.getConfig(&quot;akka.kafka.consumer&quot;), new StringDeserializer, new StringDeserializer) val producerQueue = Source .queue[String](128, OverflowStrategy.fail) .map(str =&gt; new ProducerRecord[String, String](&quot;test&quot;, str)) .toMat(Producer.plainSink(producerSettings))(Keep.left) .run() val consumerControl = Consumer .plainSource(consumerSettings, Subscriptions.topics(&quot;test&quot;)) .map(record =&gt; record.value()) .toMat(Sink.foreach(value =&gt; println(value)))(Keep.left) .run() Source(1 to 10) .map(_.toString) .throttle(1, 2.seconds) .runForeach(message =&gt; producerQueue.offer(message)) .onComplete(tryValue =&gt; println(s&quot;producer send over, return $tryValue&quot;)) println(&quot;Press &#x27;enter&#x27; key exit.&quot;) StdIn.readLine() producerQueue.complete() consumerControl.shutdown() system.terminate() Await.result(system.whenTerminated, 10.seconds)&#125; 上面的代码实现了一个完整的Kafka生产者、消费者数据处理流程，整个处理都是异步、非阻塞的。没有显示线程创建、没有类似 where(true) 这样的消费处理循环……接下来，让我们分析下以上代码。 代码分析producerSettingsAlpakka Kafka 使用ProducerSettings来封装创建Kafka生产者时需要的参数，它使用了 Typesafe Config 通过可配置的方式来构建生产者。 producerSettings 使用 &quot;akka.kafka.producer&quot; 部分的参数来构造 Kafka 生产者，以下是一个示例的 Typesafe Config 配置： 12345678910111213141516akka.kafka.producer &#123; # 同时可运行的send操作数量 parallelism &#x3D; 100 # 调用 &#96;KafkaProducer.close&#96; 时等待关闭的时间 close-timeout &#x3D; 60s # 线程池 use-dispatcher &#x3D; &quot;akka.kafka.default-dispatcher&quot; # 定义 org.apache.kafka.clients.producer.ProducerConfig 属性需要的参数 kafka-clients &#123; # 使用英文逗号分隔多个Kafka服务地址 bootstrap.servers &#x3D; &quot;localhost:9092&quot; &#125;&#125; consumerSettings consumerSettings 使用 &quot;akka.kafka.consumer&quot; 部分的参数来构造 Kafka 消费者，以下是一个示例的 Typesafe Config 配置： 12345678910111213141516171819202122232425262728akka.kafka.consumer &#123; # 拉取数据间隔周期 poll-interval &#x3D; 50ms # 拉取数据超时时间 poll-timeout &#x3D; 30s # 调用 &#96;KafkaConsumer.close&#96; 时等待关闭的时间 close-timeout &#x3D; 20s # 线程池 use-dispatcher &#x3D; &quot;akka.kafka.default-dispatcher&quot; # 定义 org.apache.kafka.clients.producer.ProducerConfig 属性需要的参数 kafka-clients &#123; # 使用英文逗号分隔多个Kafka服务地址 bootstrap.servers &#x3D; &quot;localhost:9092&quot; # 自动commit消息 enable.auto.commit &#x3D; true # 消费者组ID group.id &#x3D; &quot;resource-dev&quot; # 从最新的offset开始读取消息，否则从头开始读取 auto.offset.reset &#x3D; &quot;earliest&quot; &#125;&#125; producerQueue 使用Akka Streams构造一个生产者队列 producerQueue，再由 Producer.plainSink 来消费发送到 producerQueue 里的消息。需要注意的是构造 Source.queue[String] 时设置的 128 这个参数并不是 Kafka 的消息队列容量，而是 Akka Streams Source 构造出来的一个Queue。Producer.plainSink 是一个 下游 ，它消费来自 producerQueue 这个上游的消息，再将数据发送到 Kafka 服务。 consumerControl 通过 Consumer 这个Akka Streams Source构造了一个Kafka消费者，并监听指定的 “test” 主题。consumerControl 流首先从收到的每个消息（ConsumerRecord）中取得 value，并发送到下游，下游通过 Sink.foreach 接收数据并打印到终端。 Source(1 to 10) 生成从1到10的字符串消息值，并每隔2秒通过 producerQueue 发送一个消息到Kafka。 小结本文通过一个简单的示例展现怎样通过 Alpakka Kafka 来实现对 Kafka 的集成，完成的代码示例见：https://github.com/ihongka/akka-fusion/blob/master/fusion-kafka/src/test/scala/fusion/kafka/getting/KafkaGetting.scala 。 Kafka发展到现在，已不单单再是一个消息系统了，在MQ之外，它还提供了KSQL和Connector特性。应用基于 Kafka 可以有更多的设计和实现，而Akka Stream + Kafka是一个强大的组合，接下来我会写一系列文章介绍怎样使用 Alpakka Kafka 来基于 Kafka 进行应用和架构设计。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"kafka","slug":"kafka","permalink":"https://yangbajing.github.io/tags/kafka/"},{"name":"alpakka-kafka","slug":"alpakka-kafka","permalink":"https://yangbajing.github.io/tags/alpakka-kafka/"},{"name":"alpakka","slug":"alpakka","permalink":"https://yangbajing.github.io/tags/alpakka/"},{"name":"akka-stream","slug":"akka-stream","permalink":"https://yangbajing.github.io/tags/akka-stream/"}]},{"title":"Akka实战：HTTP大文件断点上传、下载，秒传","slug":"akka实战：http大文件断点上传、下载，秒传","date":"2018-12-29T03:24:16.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/12/29/akka实战：http大文件断点上传、下载，秒传/","link":"","permalink":"https://yangbajing.github.io/2018/12/29/akka%E5%AE%9E%E6%88%98%EF%BC%9Ahttp%E5%A4%A7%E6%96%87%E4%BB%B6%E6%96%AD%E7%82%B9%E4%B8%8A%E4%BC%A0%E3%80%81%E4%B8%8B%E8%BD%BD%EF%BC%8C%E7%A7%92%E4%BC%A0/","excerpt":"","text":"访问：https://github.com/yangbajing/scala-applications/tree/master/file-upload 获取本文所述完整源码，包括Akka HTTP后端和HTML5实现的前端。 在很多应用里面都会有类似大文件上传的需求，但很多时候我们程序员都会以不支持或不好实现将其推脱掉^_^。 这次因为公司项目需要，另一个组的同事使用Spring实现了一版。他们是采用在前端对大文件分块上传，后端在所有分块上传完成后合并的方式实现了。这个方案有一个弊端，若文件很大，后期对分块做合并时会非常的耗磁盘资源。 本文，我使用Akka HTTP和Akka Stream做为后端服务，可以很优雅的实现大文件的断点续传。原理其实非常的简单，前端计算文件的hash（使用sha256），将hash传到后端查询是否有相同文件已上传，若有将返回已上传文件及文件长度（bytes）。这时候前端就可以知道文件的上传进度，进而判断还需要断点续传的偏移量或者已上传完成（这就是秒传）。 这里有一个设计取舍：客户端对单个文件不做分片，从文件头开始上传。这样的一个好处是可简化服务端的实现，同时也可以优化服务端对文件的存储 （同一个文件将一直使用APPEND的方式写入文件，这样可以更高效的利用磁盘IO。同时，不需要分块合并，若文件很大，生成的大量分块在文件上传完成后再次合并会是一个非常大的资源开销） 。 断点下载这个怎么说呢？断点下载Akka HTTP原生支持^_^。你只需要使用如下代码： 123private def downloadRoute: Route = path(&quot;download&quot; / Segment) &#123; hash =&gt; getFromFile(FileUtils.getLocalPath(hash).toFile)&#125; FileRoute#downloadRoute FileUtils.getLocalPath(hash) 函数通过对hash值（sha256hex）进行计算和拼接，获取实际文件的本地存储路径再交给Akka HTTP提供的getFromFile指令，剩下的工作就交给Akka。 我们可以通过向Akka HTTP发起HEAD请求来查看支持的HTTP功能，看到在反回的header里有Accept-Ranges: bytes，意思是服务端支持使用字节为单位的范围下载（断点下载功能既基于此实现）。 123456789$ curl --head http:&#x2F;&#x2F;localhost:33333&#x2F;file&#x2F;download&#x2F;7d0559e2f7bf42f0c2becc7fbf91b20ca2e7ec373c941fca21314169de9c7ef4HTTP&#x2F;1.1 200 OKLast-Modified: Fri, 28 Dec 2018 14:12:32 GMTETag: &quot;132766a7f528d080&quot;Accept-Ranges: bytesServer: akka-http&#x2F;10.1.6Date: Sat, 29 Dec 2018 02:17:41 GMTContent-Type: application&#x2F;octet-streamContent-Length: 65463496 断点上传很遗憾，Akka HTTP默认不支持断点上传，这需要自行实现。但是，Akka HTTP做为一个toolkit，足够灵活且强大，实现断点上传功能so easy。 断点上传实现基于常规的代码设计方式，我们需要Controller、Service，那就先从Controller开始： FileRoute#uploadRoute123456789101112def uploadRoute: Route = path(&quot;upload&quot;) &#123; post &#123; withoutSizeLimit &#123; entity(as[Multipart.FormData]) &#123; formData =&gt; onSuccess(fileService.handleUpload(formData)) &#123; results =&gt; import me.yangbajing.fileupload.util.JacksonSupport._ complete(results) &#125; &#125; &#125; &#125;&#125; FileRoute#uploadRoute 对于不熟悉Akka HTTP的朋友，推荐阅读我写的电子书（打个广告）：Scala Web 开发。这里需要注意的一个指令是withoutSizeLimit，默认Akka HTTP对请求大小限制比较低，我们可以通过withoutSizeLimit指令取消对单个API的请求大小限制，同时又不影响整个Web服务的大小限制。另外，这里通过entity(as[Multipart.FormData])以Unmarshaller的方式获取整个Multipart.FormData对象并传入 FileService#handleUpload 函数进行处理。 FileService#handleUpload123456789101112131415override def handleUpload(formData: Multipart.FormData): Future[Seq[FileBO]] = &#123; formData.parts .map &#123; part =&gt; val (hash, contentLength, startPosition) = part.name.split(&#x27;.&#x27;) match &#123; case Array(a, b, c) =&gt; (a, b.toLong, c.toLong) case Array(a, b) =&gt; (a, b.toLong, 0L) case Array(a) =&gt; (a, 0L, 0L) case _ =&gt; throw new IllegalArgumentException(s&quot;Multipart.FormData name格式不符合要求：$&#123;part.name&#125;&quot;) &#125; FileInfo(part, hash, contentLength, startPosition) &#125; .log(&quot;fileInfo&quot;, info =&gt; logger.debug(s&quot;fileInfo: $info&quot;)) .mapAsync(Constants.FILE_PART_MAX)(processFile) .runWith(Sink.seq)&#125; formData.parts是一个Akka Stream流，类型签名为Source[Multipart.FormData.BodyPart, Any]。有关Akka Stream更详细的资料请参阅Akka Streams官方文档。这里，每个part都代表FormData的一个字段（对应HTML 5的FormData类型，同时前端需要使用Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryrP4DAyu31ilqEWmz方式发起请求）。每个part.name都是用英号逗号分隔的三部分来做为请求的字段名，分别是：&lt;hash&gt;.&lt;content length&gt;.&lt;start position&gt;，这样我们就可以在不加入任何其它字段的情况下告知服务端当前上传文件的sha256hex计算出的hash值、文件大小（bytes）和上传起始偏移量。 FileUtils#uploadFile文件上传的核心逻辑在 FileUtils#uploadFile 函数： 12345def uploadFile(fileInfo: FileInfo)(implicit mat: Materializer, ec: ExecutionContext): Future[FileBO] = &#123; val maybeMeta = FileUtils.getFileMeta(fileInfo.hash) val beContinue = maybeMeta.isDefined &amp;&amp; fileInfo.startPosition &gt; 0L if (beContinue) uploadContinue(fileInfo, maybeMeta.get) else uploadNewFile(fileInfo)&#125; uploadFile函数根据是否为续传来分别调用uploadContinue或uploadNewFile函数。首先来看看新文件上传时的代码逻辑： 123456789101112131415161718192021def uploadNewFile(fileInfo: FileInfo)(implicit mat: Materializer, ec: ExecutionContext) = &#123; val bodyPart = fileInfo.bodyPart val tmpPath = if (fileInfo.validHash) FileUtils.getLocalPath(fileInfo.hash) else Files.createTempFile(FileUtils.TMP_DIR, bodyPart.filename.getOrElse(&quot;&quot;), &quot;&quot;) // (1) val sha = MessageDigest.getInstance(&quot;SHA-256&quot;) bodyPart.entity.dataBytes .map &#123; byteString =&gt; byteString.asByteBuffers.foreach(sha.update) // (2) byteString &#125; .runWith(FileIO.toPath(tmpPath)) // (3) .map &#123; ioResult =&gt; val hash = Utils.bytesToHex(sha.digest()) // (4) if (fileInfo.validHash) &#123; require(fileInfo.hash == hash, s&quot;前端上传hash与服务端计算hash值不匹配，$&#123;fileInfo.hash&#125; != $hash&quot;) &#125; val localPath = if (fileInfo.validHash) tmpPath else move(hash, tmpPath, ioResult.count) // (5) FileBO(hash, localPath, ioResult.count, bodyPart.filename, bodyPart.headers) &#125;&#125; 根据前端是否上传了有效的hash值（sha256hex）来判断是把文件先写入临时文件还是直接写入实际的本地存储位置（根据hash值计算出本地实际的存储位置）。 Akka HTTP中，上传的文件以流的方式进入，在此对每个ByteString计算并更新sha256值。 在Akka Stream的Sink端，接收流传入的元素并写入本地文件。 文件写入结束后调用sha.digest()方法获取已上传文件的sha256值。 根据是否临时文件来判断是否需要将临时文件移动到实际的本地存储路径，通过文件的hash值来计算出实际的本地存储路径。 123456789def uploadContinue(fileInfo: FileInfo, meta: FileMeta)(implicit mat: Materializer, ec: ExecutionContext) = &#123; val bodyPart = fileInfo.bodyPart val localPath = FileUtils.getLocalPath(fileInfo.hash) logger.debug(s&quot;断点续传，startPosition：$&#123;fileInfo.startPosition&#125;，路径：$localPath&quot;) val hash = fileInfo.hash bodyPart.entity.dataBytes .runWith(FileIO.toPath(localPath, Set(APPEND), fileInfo.startPosition)) // (1) .map(ioResult =&gt; FileBO(hash, localPath, meta.size + ioResult.count, bodyPart.filename, bodyPart.headers))&#125; 断点上传时的逻辑其实相对简单，需要注意的是在(1)处调用FileIO.toPath将流定入本地时需要以APPEND模式追加写入到已存在文件。 秒传在已实现断点上传功能之上，秒传的实现逻辑就非常清晰了。客户端在调用file/upload接口上传文件之前先调用/file/progress/&#123;hash&#125;接口判断相同hash值文件的上传情况，再决定下一步处理。 客户端计算文件hash，并以文件hash和文件大小作为参数调用/file/progress/&#123;hash&#125;接口 服务端根据上传hash值判断文件是否已上传，若存在返回已上传文档大小（bytes） 客户端收到服务端响应后根据文件是否存在及已存在文件大小判断秒传、断点续传还是新上传 秒传，返回文件长度与当前准备上传文件长度大小一致 断点续传，返回文件大小比当前准备上传文件长度小 新上传，返回文件不存在 其它情况，作为新文件上传 秒传的代码逻辑台下： 12345678def progressRoute: Route = path(&quot;progress&quot; / Segment) &#123; hash =&gt; onSuccess(fileService.progressByHash(hash)) &#123; case Some(v) =&gt; import me.yangbajing.fileupload.util.JacksonSupport._ complete(v) case None =&gt; complete(StatusCodes.NotFound) &#125;&#125; 文件上传进度接口定义如上。 123456789101112131415// FileServiceImpl.scalaoverride def progressByHash(hash: String): Future[Option[FileMeta]] = &#123; require(Objects.nonNull(hash) &amp;&amp; hash.nonEmpty, &quot;hash 不能为空。&quot;) Future.successful(FileUtils.getFileMeta(hash))&#125;// FileUtils.getFileMetadef getFileMeta(hash: String): Option[FileMeta] = &#123; if (hash == null || Constants.HASH_LENGTH != hash.length) &#123; None &#125; else &#123; val path = getLocalPath(hash) if (Files.exists(path) &amp;&amp; Files.isReadable(path)) Some(FileMeta(hash, Files.size(path), path)) else None &#125;&#125; 文件上传进度服务实现定义如上。 小结本文以Akka HTTP和HTML 5讲述了怎样实现一个支持大文件断点上传、下载和秒传的示例应用程序。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"html5","slug":"html5","permalink":"https://yangbajing.github.io/tags/html5/"},{"name":"断点上传","slug":"断点上传","permalink":"https://yangbajing.github.io/tags/%E6%96%AD%E7%82%B9%E4%B8%8A%E4%BC%A0/"},{"name":"断点下载","slug":"断点下载","permalink":"https://yangbajing.github.io/tags/%E6%96%AD%E7%82%B9%E4%B8%8B%E8%BD%BD/"}]},{"title":"《Scala Web开发》","slug":"《scala-web开发》","date":"2018-08-24T05:24:51.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/08/24/《scala-web开发》/","link":"","permalink":"https://yangbajing.github.io/2018/08/24/%E3%80%8Ascala-web%E5%BC%80%E5%8F%91%E3%80%8B/","excerpt":"","text":"电子书：Scala Web开发 码云镜像：Scala Web开发","categories":[{"name":"作品","slug":"作品","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/"},{"name":"scala-web-development","slug":"作品/scala-web-development","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/scala-web-development/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"book","slug":"book","permalink":"https://yangbajing.github.io/tags/book/"},{"name":"scala-web","slug":"scala-web","permalink":"https://yangbajing.github.io/tags/scala-web/"},{"name":"slick","slug":"slick","permalink":"https://yangbajing.github.io/tags/slick/"},{"name":"slick-pg","slug":"slick-pg","permalink":"https://yangbajing.github.io/tags/slick-pg/"}]},{"title":"微服务下的用户系统设计","slug":"微服务下的用户系统设计","date":"2018-08-17T14:16:53.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/08/17/微服务下的用户系统设计/","link":"","permalink":"https://yangbajing.github.io/2018/08/17/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%8B%E7%9A%84%E7%94%A8%E6%88%B7%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"简述微服务下的用户系统从设计与传统单体应用是不一样的，传统单体应用下本质上用户系统是一个模块。用户系统是与整个应用紧耦合在一起的，具体来说，它们共享一套代码、一个数据库、通过代码级的API调用…… 而微服务下的用户系统设计很不一样，因为微服务的特点，各功能都独立成一个Server在运行，那用户系统首先需要支持远程的API调用。基本来说，微服务下的用户系统设计需要满足以下要求： 独立的用户系统：用户系统应该是一个独立的应用程序，它不应该和业务系统紧耦合在一起。 用户认证、授权：用户认证、授权是用户系统的核心，可以基于 OAuth 2 协议来实现闪统一认证、单点登录。 单点登录：统一的用户登录入口。 接入应用管理：对接入用户系统的各个子应用，用户系统可对接入应用进行管理。比如：应用接口账户、应用SSO回调地址、应用用户管理…… 丰富的API：微服务下各服务节点之间都通过API接口进行通信，支持RESTful风格的接口是最低要求，对于像用户系统这样的核心系统可以考虑使用protobuf、grpc这样的机制来提供传输效率。 丰富的功能：像组织管理、角色权限等功能，虽然不是设计用户系统的必要功能，等若能支持对于用户系统来说也是加分项。 高性能、高可用、可扩展 功能基于以上考虑，用户系统计划实现如下功能： 用户管理：所有子系统不再有用户管理模块，统一到用户系统来实现。 统一认证：基于 OAuth 2 实现。 单点登录：可以采用 OAuth 2 的静默登录来实现。 应用管理：各应用接入用户系统，需要通过接口来操作用户，比如：创建、获取、遍历用户信息。同时对于单点登录、角色权限管理等功能也可以进行设置是否启用。 角色权限管理：应用可以选择将角色、权限上提到用户系统来进行统一管理，或者应用可以选择自己管理角色权限，只使用用户系统的统一用户认证和单点登录功能。 组织管理：对于企业级应用，组织架构管理是一个不可或缺的功能。用户系统支持树型机制的组织架构管理功能。 用户模块用户模块本身并不复杂，主要需要规划好数据模型。在设计用户模型时可以充分利用PG的特性来简化用户模型。这里我们来看一个用户模型的示例： 12345678910111213141516171819202122232425262728293031CREATE TABLE IF NOT EXISTS ig_passport( id CHAR(24) NOT NULL CONSTRAINT ig_pk PRIMARY KEY, account VARCHAR(255), code varchar(64) null, salt CHAR(12) NOT NULL, salt_password CHAR(64) NOT NULL, status INTEGER DEFAULT 1 NOT NULL, data JSONB NOT NULL, permissions INTEGER [] DEFAULT &#x27;&#123;&#125;&#x27; :: INTEGER [] NOT NULL, phone varchar(32) null, created_at TIMESTAMP WITH TIME ZONE NOT NULL);create unique index if not exists ig_passport_code_uidx on ig_passport (code);CREATE UNIQUE INDEX IF NOT EXISTS ig_passport_account_uidx ON ig_passport (account);CREATE TABLE IF NOT EXISTS ig_app_user( app_id CHAR(24) NOT NULL, passport_id CHAR(24) NOT NULL, user_id VARCHAR(512) NOT NULL, updated_at TIMESTAMP WITH TIME ZONE NOT NULL, permissions INTEGER [] NOT NULL, status INTEGER NOT NULL, data JSONB, app_resources text [] not null default &#x27;&#123;&#125;&#x27;, CONSTRAINT ig_app_user_pk PRIMARY KEY (app_id, passport_id)); 可以看到，与用户模型相关的有两张表：ig_passport和ig_app_user。ig_passport是实际的用户数据模型。 ig_passport 这里id是用户主键，采用了 ObjectId 的十六进制字符串来表示。没有使用自增的整形字段来作为ID，主要考虑还是数据迁移的方便。为了 ObjectId 是一个分布式系统下的唯一ID，对于多个用户系统需要合并或拆分的情况，就不需要再去处理主键ID重复的情况了，同时，数据备份、恢复时也不会有自增序例不一至的问题。 其它字段都是用户表设计中常见的字段，这里就不再过多介绍。需要注意的是 data 字段，可以看到它的数据类型是：JSONB，这是PG数据库特有的数据类型。它可以让我们在传统的SQL表里存储无模式数据，这里就是JSON数据。使用 data 字段的好处在，对于一些用户个性数据，比如：年龄、爱好、工作等，我们可以让前端将这些数据做为一个JSON类型提交上来。简单说就是，数据模型不限制应用可以上传哪些字段，由应用来决定。因为作为一个用户系统，它只需存储必要的字段即可，如id、登录账号名、密码、状态、权限等。用户的个性化数据可以待系统实现使用时由使用系统来决定，这样即可在不修改数据表（模型）的情况下做到用户模型的可扩展性。 对于需要通过用户个性化数据进行检索的情况，PG也支持对JSONB类型字段建立索引，可以选择对整个JSON字段数据建立索引，也可以选择对具体的key对应的值建立索引。 ig_app_user ig_app_user表是应用内用户的映射，对于某些已建应用集成到用户系统时特别有用。已建应用已经拥有了一套自己的用户体系，当它们集成到用户系统时，已用的用户体系是不能直接废掉的（或者需要一段时间的过滤）。这时候就使用 ig_app_user 来将应用已有用户和用户系统的用户进行映射了。可以看到，ig_app_user里面有一个 user_id 字段，这就是应用已有用户的ID，可以通过 app_id、passport_id、user_id三个字段来唯一确定一个应用内的已有用户。而 ig_app_user.data 字段也是JSONB类型，我们可以将应用原来用户表里的数据当做一个JSON格式数据存储在此，这样无论接入应用的原有用户表是怎么设计的，用户系统都可以在不修改表结构的情况下对其进行存储。 应用管理 用户系统需要管理多个接入应用的用户，甚至角色和权限也可以纳入统一管理。这首先需要一个应用管理模块，用于应用的创建、编辑、接入。应用模型可参考设计如下： 12345678910111213141516CREATE TABLE IF NOT EXISTS ig_app( id CHAR(24) NOT NULL CONSTRAINT ig_app_pk PRIMARY KEY, name VARCHAR(255) NOT NULL, creator CHAR(24) NOT NULL, sso_redirect_uri VARCHAR(1024), domain VARCHAR(255), status INTEGER NOT NULL, created_at timestamptz NOT NULL, data_url varchar(1024), options text [] not null default &#x27;&#123;&#125;&#x27;, updater char(24), updated_at timestamptz not null); 其中几个关键字段说明如下： sso_redirect_uri：单点登录成功后重定向页面到应用的地址 domain：是否校验请求应用的域名是否合法 data_url：数据推送地址。当用户系统发生某些事件时将数据推关给应用。比如：用户创建、修改，应用创建、修改等。 OAuth 2用户系统很重要的一个功能就是用户认证和单点登录，这两个功能可以使用 OAuth 2 协议来实现。这里，我们并没有使用现成的 OAuth 2 库或框架，而是基于 OAuth 2 协议规范 使用 Akka HTTP 实现了一套，因为我们不需要所有的 OAuth 2 功能，另外就是用户系统本身也是使用Akka HTTP 开发的，本着能造轮子就造的原则（正好，这玩意不太复杂，可以造）自行开发了一套。 注：之后会写一篇文章：《Scala实战：OAuth 2 服务》来介绍怎样使用 Akka HTTP 实现 OAuth 2 统一认证OAuth 2 是OAuth协议的延续版本，但不向后兼容OAuth 1.0即完全废止了OAuth 1.0。 OAuth 2关注客户端开发者的简易性。要么通过组织在资源拥有者和HTTP服务商之间的被批准的交互动作代表用户，要么允许第三方应用代表用户获得访问的权限。同时为Web应用，桌面应用和手机，和起居室设备提供专门的认证流程。2012年10月，OAuth 2协议正式发布为 RFC 6749。 Web ServerFlow是把OAuth 1.0的三个步骤缩略为两个步骤，首先这个是适合有server的第三方使用的。 OAuth 2认证流程 客户端通过HTTP请求Authorize 服务端接收到Authorize请求，返回用户登陆页面 用户在登陆页面登陆 登录成功后，服务端将浏览器定位到redirect_uri，并同时传递Authorization Code 客户端使用HTTPS发送Authorization Code 服务器端收到access_token请求，验证Authorization Code——生成access_token，refresh_token和expires_in（过期时间）——access_token和refresh_token和过期时间入库 返回access_token和refresh_token，expires_in（过期时间） 用户使用HTTPS协议，发送access_token及相应参数请求开放平台接口 OAuth 2除了支持浏览器端认证外，还支持APP、C/S客户端认证。 用户系统的单点登录 用户系统除了支持 access_token 这样的登录认证方式外，还支持传统的基于 session 的认证（session加密后通过cookie存储在浏览器端）。这种认证方式对于大部分基于Web的应用来说更熟悉，集成更方便。 它的区别在于 OAuth 2 认证的第4步，redirect_uri重定向回应用时直接带上 sessionCode ，这时客户端就可以通过设置 cookie 来将 session 存储到浏览器上来实现登录会话的保持。 静默登录OAuth 2登录时可以选择静默登录模式。单用户已经登录过一次用户系统，他再访问另一个未登录的应用时，应用将页面重定向到用户系统的登录页面，这时候用户系统可以判断出已经有用户登录session，这时用户系统将直接重定向回到请求登录的应用并带上用户会话信息。一般，这是通过cookie来实现的。 有一个真实的案例来演示这一模式。你先登录新浪微博，这时会跳转到新浪通行证的登录页面。若你之前已经登录过新浪通行证，则回直接返回新浪微博并已设置为登录状态，否则会提示你输入用户名、密码进行登录。 客户端保存 session通过cookie这样的客户端技术来保存session，服务端不需要记录session信息。这样，服务端重启不会影响session会话的状态，也不会造成session的丢失，同时，在服务端扩展时也没有session同步的问题。 但是，在某些业务场景下，服务端保存session是必要的。比如下一节讲到的统一登出和一次登录功能，还有当前登录用户数统计等。 统一登出与一次登录一般情况下，将 session 通过 cookie 存储在浏览器客户端就可以满足用户会话保持的需求。但是，对于很多系统来说，都有统一登出和一次登录的业务需求。 统一登出：用户登出任一应用，则同时所有应用的登录状态都将无效。 一次登录：用户同一时段只能在一个IP地址登录（包括不同应用）。 要实现以上两个功能，就必需在服务端保存 session 。通过在每次收到论证请求时和服务端session数据比较来实现统一拿出和一次登录。除了在服务端保存session以外，对于接入应用也需要做一些改造。 统一登出应用的Server端在每次收到客户端请求时，必需将sessionCode提交到用户系统进行验证。用户系统将返回些sessionCode是否有效。若用户已经在另一个应用上登出，则用户系统将返回此sessionCode已经无效的错误信息，这时应用将重定向请求到用户系统的登录页面或其它不需要登录即可访问的公共页面。 一次登录若用户系统提示用户已经在另一个IP地址登录，则当前sessionCode被新的登录会话给挤掉（当前sessionCode不再指向当前登录用户ID）。这时应用应弹出会话失效提示框告知用户，再跳转到可公开访问页面（若无，则跳转到登录页面）。 角色权限角色权限，应用可以选择自己管理，也可以选择由用户系统来管理。 在角色权限功能的设计上，我们可以通过两个基本的抽象来实现： Resource：资源。资源可以为应用系统的功能权限、菜单权限、接口权限、按钮权限等，在用户系统里统一将此类控制相关的权限称为 资源。 Role：角色。角色就是拥有一系列资源的集合体，通过角色这样的概念来命名并使用。 有了资源和角色，我们就可以实现复杂的权限控制功能。 组织管理组织在企业级应用中非常重要，通常来说组织都需要作为一个树型结构来设计。组织在这里可以代表企业法人、事业法人或政府部门等。 比如在政府行业： 12有市级组织 --&gt; 市发改委 --&gt; 市发改委科室 --&gt; 区&#x2F;县发改委 --&gt; 区&#x2F;县发改委科室 组织模型的设计，可以把 parent 和 parents 两个字段加到表字段中。parent 是直接父组织ID、parents 是完整父组织ID列表： 123456789101112131415161718192021CREATE TABLE IF NOT EXISTS ig_org( id CHAR(24) NOT NULL CONSTRAINT ig_org_pk PRIMARY KEY, name VARCHAR(128) NOT NULL, code varchar(64) null, contact jsonb null, data JSONB NOT NULL, creator CHAR(24) NOT NULL, parent CHAR(24) null, parents CHAR(24) [] not null default &#x27;&#123;&#125;&#x27;, direct_parent char(24) null, sort int not null default 99999, status int not null default 1, updater char(24), app_ids text [] not null default &#x27;&#123;&#125;&#x27;, created_at TIMESTAMP WITH TIME ZONE NOT NULL, updated_at timestamptz null);create unique index if not exists ig_org_code_uidx on ig_org (code); 利用PG的 数组字段类型 使用一个字段就可以存储组织的完整父ID列表。一般数据库需要使用关系表存储或需要把数组按分隔符连接成字符串来存储，使用关系表需要多维护一张表，对工作量有所增加，而且类似的关系表过多有可能会造成表爆炸；而使用分隔符连接的字符串对查询不友好…… 单需要获得某个组织的所有子组织（包括间接子组织时），使用类似如下sql即可： 1select * from ig_org where &#x27;&lt;org id&gt;&#x27; = any(parents); 技术Server 用户系统在微服务架构设计中是一个核心系统，它必需具有高可用、高性能、可扩展。这里，我选择了使用 Akka HTTP 来进行设计。使用 Routing DSL 可以很灵活的设计出用户系统的 RESTful 接口。Marshalling和Unmarshalling可用来对数据模型与HttpRequest、HttpResponse做高效的相互转换。 Akka HTTP完整的支持HTTP/HTTPs，同时也支持 HTTP 2，它底层基于 Akka/Akka Stream 实现。具备高可用、高性能、可扩展，还拥有容错、集群等特性。同时，Akka做为一个库，而非框架。不像 Spring 那样“巨重”，它足够轻量，很适合用来实现一个微服务。 Storage 用户系统使用 PostgreSQL（以下简称：PG）数据库来做为数据存储，PG 10原生已经支持表分区、逻辑复杂等功能，具备良好的横向可扩展性。同时，PG丰富的数据类型可简化我们的数据模型设计，如：JSONB、Array…… 总结在微服务下设计一个用户系统，需要考虑到各接入应用都是独立的服务，在系统设计之初就要考虑到各功能模块的可扩展性。统一认证和单点登录做为核心，可以采用 OAuth 2 协议来设计。 技术架构上，Akka HTTP可作为实现微服务的一套强有力的工作库。具有异步、高性能、集群管理等特性。","categories":[{"name":"essay","slug":"essay","permalink":"https://yangbajing.github.io/categories/essay/"}],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://yangbajing.github.io/tags/micro-service/"},{"name":"4a","slug":"4a","permalink":"https://yangbajing.github.io/tags/4a/"},{"name":"user-system","slug":"user-system","permalink":"https://yangbajing.github.io/tags/user-system/"}]},{"title":"测试：Akka HTTP路由","slug":"测试：akka-http路由","date":"2018-08-05T06:08:46.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/08/05/测试：akka-http路由/","link":"","permalink":"https://yangbajing.github.io/2018/08/05/%E6%B5%8B%E8%AF%95%EF%BC%9Aakka-http%E8%B7%AF%E7%94%B1/","excerpt":"","text":"上一篇文章简单介绍了 ScalaTest，这篇将从一个实例入手介绍在项目中怎样应用 ScalaTest 来应用测试驱动的开发。 Akka HTTP这里我们将使用 Akka HTTP来开发一个很简单的业务应用：组织管理。它只有一个数据模型，Org。组织支持树型结构，所有每个 org 里面都可以有一个可选 parent 属性来指向父组织，若没有则代表此 org 是个一级组织。Org 的数据模型如下： 1234567891011case class Org( id Int, // PK code Option[String], // 组织编码，可选值。Unique index name String, contact: String, parent Option[String], // 父组织 parents List[String], // 父组织全路径 status: Int, createdAt OffsetDateTime, updatedAt Option[OffsetDateTime]) 业务流程上，对一个 Org 模型的操作我们设计如下的简单流程： 1OrgRoute -&gt; OrgService -&gt; OrgRepository OrgRoute 是一个使用 Akka HTTP Routing DSL 来定义实现的路由（从MVC架构术语来说，就是控制器（Controller））。从这个简单的示例来说，它拥有如下接口： createRoute：创建 Org getRoute：根据id或code获取 Org pageRoute：分页查询 updateRoute：更新 Org removeRoute：根据id删除 Org 现在，我们已经设计好了我们需要的5个接口（名字），接下来需要定义具体的接口和实现。这里，我们先从测试开始。 akka-http-testkitAkka HTTP 提供了一个测试套件来简化对 Akka HTTP 和 Akka HTTP Routing DSL的测试，我们需要在 sbt 配置里加上对应的库依赖： 1libraryDependencies +&#x3D; &quot;com.typesafe.akka&quot; %% &quot;akka-http-testkit&quot; % &quot;2.5.14&quot; % Test 定义一个 Akka HTTP Routing DSL 的测试类，需要混入 ScalatestRouteTest 特质，它提供了对 Route DSL 的一系列测试辅助函数。 OrgRouteTest现在，我们从 OrgRouteTest 开始，通过 红-绿-红-绿这样的测试循环来验证并一步一步实现对 Org 的各项接口功能。 首先，让我们来看看这个 OrgRouteTest 类： 123class OrgRouteTest extends WordSpec with MustMatchers with OptionValues with ScalatestRouteTest &#123;&#125; TODO","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"scalatest","slug":"scalatest","permalink":"https://yangbajing.github.io/tags/scalatest/"},{"name":"akka-http-testkit","slug":"akka-http-testkit","permalink":"https://yangbajing.github.io/tags/akka-http-testkit/"},{"name":"route","slug":"route","permalink":"https://yangbajing.github.io/tags/route/"}]},{"title":"测试：使用scalatest","slug":"测试：使用scalatest","date":"2018-08-02T09:38:47.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/08/02/测试：使用scalatest/","link":"","permalink":"https://yangbajing.github.io/2018/08/02/%E6%B5%8B%E8%AF%95%EF%BC%9A%E4%BD%BF%E7%94%A8scalatest/","excerpt":"","text":"ScalaTest通过简单、清晰的测试和可执行的规范来提高团队的生产力，同时改进代码和沟通效率。 ScalaTest是Scala生态系统中最灵活、最流行的测试工具。支持测试：Scala、Scala.js（Javascript）和Java代码。可与JUnit、TestNG、Ant、Maven、sbt、ScalaCheck、JMock、EasyMock、Mockito、ScalaMock、Selenium、Eclipse、Netbeans、Intellij、VSCode等工具集成使用。ScalaTest可使Scala、Scala.js或者Java项目的测试更容易，拥有更高的生产力水平。 为了最大化生产力，ScalaTest内建扩展点并支持多种测试方式。我们可以选择最适合我们团队经验和文化的测试风格。有以下风格可供选择： FunSuite：来自xUnit。 FlatSpec：另一个来自xUnit。 FunSpec：来自Ruby’s RSpec的BDD测试风格。 WordSpec：来自specs、specs2，适合训练有素的团队来定义严格的测试规范。也是Akka、Playframework等推荐的风格。 FreeSpec：适合有经验的团队。 PropSpec：适合追求完美的团队，需要前置测试条件定义。 FeatureSpec：主要用于验收测试。 RefSpec（JVM only）：需要定义一个特殊的测试函数，通过测试函数字面量来代码测试功能。 安装 ScalaTestScalaTest的安装、使用很简单，可以直接在命令行使用，如： 1$ scalac -cp scalatest-app_2.12-3.0.5.jar ExampleSpec.scala 也可以和sbt集成使用。对sbt不了解的读者可以先看：http://www.yangbajing.me/scala-web-development/env.1.html 来快速的学习sbt的使用方法。 在sbt中添加ScalaTest支持非常简单，在构建配置文件（一般是build.sbt）中添加库依赖即可。 1libraryDependencies +&#x3D; &quot;org.scalatest&quot; %% &quot;scalatest&quot; % &quot;3.0.5&quot; % &quot;test&quot; 之后重启sbt或在sbt命令行控制台里输入：reload以使其生效。 第一个测试用例123456789101112131415161718192021import scala.collection.mutableimport org.scalatest._class FirstTest extends WordSpec with MustMatchers &#123; &quot;A Stack&quot; should &#123; &quot;pop values in last-in-first-out order&quot; in &#123; val stack &#x3D; mutable.Stack.empty[Int] stack.push(1) stack.push(2) stack.pop() mustBe 2 stack.pop() mustBe 1 &#125; &quot;throw NoSuchElementException if an empty stack is popped&quot; in &#123; val emptyStack &#x3D; mutable.Stack.empty[Int] assertThrows[NoSuchElementException] &#123; emptyStack.pop() &#125; &#125; &#125;&#125; 运行测试有两种方式： 使用test命令运行所有测试 使用testOnly命令运行单个测试。 在sbt中输入testOnly firstFirstTest运行刚写好的第一个测试，结果如下： 12345678910111213[IJ]scalatest &gt; testOnly first.FirstTest[info] Compiling 1 Scala source to &#x2F;opt&#x2F;workspace&#x2F;scala-applications&#x2F;scalatest&#x2F;target&#x2F;scala-2.12&#x2F;test-classes ...[info] Done compiling.[info] FirstTest:[info] A Stack[info] - should pop values in last-in-first-out order[info] - should throw NoSuchElementException if an empty stack is popped[info] Run completed in 344 milliseconds.[info] Total number of tests run: 2[info] Suites: completed 1, aborted 0[info] Tests: succeeded 2, failed 0, canceled 0, ignored 0, pending 0[info] All tests passed.[success] Total time: 2 s, completed 2018-8-2 18:29:14 使用 Matchers除了默认的断言函数，如：assert、assertResult、assertThrows等，ScalaTest还提供了更好用的 Matchers。Matchers 具有以下特性： 基于表达式断言的DSL，如：stack.pop() mustBe 2。更易读，以人类语言的方式来编写测试断言。 丰富的断言类型，支持更直观的断言表达式，如：&quot;abbccxxx&quot; should startWith regex (&quot;a(b*)(c*)&quot; withGroups (&quot;bb&quot;, &quot;cc&quot;))。 只需要在测试类混入 MustMatchers 特质，就可以使用 ScalaTest 提供的强大的 Matchers 特性。 OptionValuesOptionValues特质提供了一个隐式转换，将一个 value 方法添加到 Option[T] 类型上。若 Option 是有定义的，则 value 方法将返回值，就和调用 .get 一样；若没有，则抛出 TestFailedException 异常，而不是调用 get 方法时抛出的 NoSuchElementException 异常。同时，ScalaTest会输出更友好的错误显示：**The Option on which value was invoked was not defined.**，而不是输出一大堆的错误异常栈而打乱正常的测试输出。 使用.value 123456789101112[info] FirstTest:[info] option[info] - should value *** FAILED ***[info] The Option on which value was invoked was not defined. (FirstTest.scala:30)[info] Run completed in 418 milliseconds.[info] Total number of tests run: 3[info] Suites: completed 1, aborted 0[info] Tests: succeeded 2, failed 1, canceled 0, ignored 0, pending 0[info] *** 1 TEST FAILED ***[error] Failed tests:[error] first.FirstTest[error] (Test &#x2F; testOnly) sbt.TestsFailedException: Tests unsuccessful 使用.get 1234567891011121314151617181920212223[info] FirstTest:[info] option[info] - should value *** FAILED ***[info] java.util.NoSuchElementException: None.get[info] at scala.None$.get(Option.scala:349)[info] at scala.None$.get(Option.scala:347)[info] at first.FirstTest.$anonfun$new$6(FirstTest.scala:31)[info] at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)[info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)[info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)[info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[info] at org.scalatest.Transformer.apply(Transformer.scala:22)[info] at org.scalatest.Transformer.apply(Transformer.scala:20)[info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078)[info] ...[info] Run completed in 211 milliseconds.[info] Total number of tests run: 3[info] Suites: completed 1, aborted 0[info] Tests: succeeded 2, failed 1, canceled 0, ignored 0, pending 0[info] *** 1 TEST FAILED ***[error] Failed tests:[error] first.FirstTest[error] (Test &#x2F; testOnly) sbt.TestsFailedException: Tests unsuccessful ScalaFuturesScalaTest支持对异步代码进行阻塞测试。提供了隐式方法 futureValue 来从 Future[T] 中阻塞获取结果。 12345678910111213override implicit def patienceConfig &#x3D; PatienceConfig(Span(60, Seconds), Span(50, Millis)) &quot;future&quot; should &#123; &quot;await result &#x3D;&#x3D;&#x3D; 3&quot; in &#123; import scala.concurrent.ExecutionContext.Implicits.global val f &#x3D; Future&#123; Thread.sleep(1000) 3 &#125; val result &#x3D; f.futureValue result mustBe 3 &#125; &#125; 上面代码的运行效果如下： 12345678[info] FirstTest:[info] future[info] - should await result &#x3D;&#x3D;&#x3D; 3[info] Run completed in 1 second, 169 milliseconds.[info] Total number of tests run: 1[info] Suites: completed 1, aborted 0[info] Tests: succeeded 1, failed 0, canceled 0, ignored 0, pending 0[info] All tests passed. MockScalaTest为以下4种Mock提供了原生的支持： ScalaMock EasyMock JMock Mockito 这里先简单介绍下 ScalaMock。 ScalaMock是由 Paul Butcher 编写的一个原生的开源Scala Mocking框架，允许模拟对象和函数。ScalaMock支持3种不同的模拟风格： 函数模拟（Function mocks） 代理（动态）模拟（Proxy (dynamic) mocks） 生成类型安全模拟（Generated (type-safe) mocks） 函数模拟 1234567&quot;scalamock&quot; should &#123; &quot;function mock&quot; in &#123; val m &#x3D; mockFunction[Int, String] m expects 42 returning &quot;Forty two&quot; m(42) mustBe &quot;Forty two&quot; &#125;&#125; 这里我们模拟了一个函数 m，它接受一个Int参数并返回一个字符串值。这里看到，我们并没有实际定义这样一个函数，而是使用 m expects 42 returning &quot;Forty two&quot; 声明了这个模拟期待一个输入值：42，并返回结果字符串：Forty row。执行这个测试，运行效果如下： 12345678[info] FirstTest:[info] scalamock[info] - should function mock[info] Run completed in 211 milliseconds.[info] Total number of tests run: 1[info] Suites: completed 1, aborted 0[info] Tests: succeeded 1, failed 0, canceled 0, ignored 0, pending 0[info] All tests passed. 小结这里简单介绍了下 ScalaTest 的基本使用，我们对 ScalaTest 有了一个基本的认识。下一篇文章会基于一个真实的样例来介绍怎样在 Akka HTTP 的开发中使用 ScalaTest 和 akka-http-testkit 来应用测试驱动开发。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"scalatest","slug":"scalatest","permalink":"https://yangbajing.github.io/tags/scalatest/"},{"name":"test","slug":"test","permalink":"https://yangbajing.github.io/tags/test/"}]},{"title":"Nginx限流控制","slug":"nginx限流控制","date":"2018-07-27T03:30:46.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/07/27/nginx限流控制/","link":"","permalink":"https://yangbajing.github.io/2018/07/27/nginx%E9%99%90%E6%B5%81%E6%8E%A7%E5%88%B6/","excerpt":"","text":"最近公司给客户做的系统遇到大量爬虫爬取，造成系统资源消耗增高、系统响应降低…… 因为项目时间比较紧，没有更多时间在功能和代码层面上进行修改来上一套反爬虫系统。权衡以后决定使用Nginx提供的请求限流功能来实现一个简单的反爬虫机制。待以后再详细规划、设计反爬虫系统。 我们一直使用的是阿里发布的Nginx重发行版：Tengine，本文也将基于Tengine来介绍Nginx的限流控制。 ngx_http_limit_req_module 模块Tengine提供了 ngx_http_limit_req_module 模块来实现HTTP请求的限流控制，通过定义的 键值来限制请求处理的频率。特别的，它可以限制来自单个IP地址的请求处理频率。 限制的方法是通过一种“漏桶”的方法——固定每秒处理的请求数，推迟过多的请求处理。提供的主要指令有： **limit_req_log_level**：日志级别设置 **limit_req_zone**：设置一块共享内存限制域的参数，它可以用来保存键值的状态。 它特别保存了当前超出请求的数量。 键的值就是指定的变量（空值不会被计算）。 **limit_req**：设置对应的共享内存限制域和允许被处理的最大请求数阈值。 如果请求的频率超过了限制域配置的值，请求处理会被延迟，所以 所有的请求都是以定义的频率被处理的。 超过频率限制的请求会被延迟，直到被延迟的请求数超过了定义的阈值 这时，这个请求会被终止，并返回503 (Service Temporarily Unavailable) 错误。这个阈值的默认值等于0。 **limit_req_whitelist**：白名单，可以设置不应用 limit_req 限制的IP地址 limit_req_log_level（日志级别） 语法：limit_req_log_level info | notice | warn | error; 默认值：limit_req_log_level error; 上下文：http, server, location 这个指令是设置请求限流控制的日志级别的，设置非常简单，就不在做单独介绍。 limit_req_zone（限制域的参数） 语法：limit_req_zone $variable zone=name:size rate=rate; 上下文：http 1limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;1r&#x2F;s; 这里，状态被存在名为“one”，最大10M字节的共享内存里面。对于这个限制域来说 平均处理的请求频率不能超过每秒一次。 键值是客户端的IP地址。 如果不使用$remote_addr变量，而用$binary_remote_addr变量， 可以将每条状态记录的大小减少到64个字节，这样1M的内存可以保存大约1万6千个64字节的记录。 如果限制域的存储空间耗尽了，对于后续所有请求，服务器都会返回 503 (Service Temporarily Unavailable)错误。 请求频率可以设置为每秒几次（r/s）。如果请求的频率不到每秒一次， 你可以设置每分钟几次(r/m)。比如每秒半次就是30r/m。 limit_req（限制域） 语法：limit_req zone=name [burst=number] [nodelay]; 上下文：http, server, location limit_req_whitelist（白名单） 语法：limit_req_whitelist geo_var_name=var_name geo_var_value=var_value 上下文：http, server, location 另外，还可以使用 **geo** 指令定义变量来设置白名单，白名单内的地址将不受限流的控制。 1234567geo $white_ip &#123; ranges; default 0; 127.0.0.1-127.0.0.255 1;&#125;limit_req_whitelist geo_var_name&#x3D;white_ip geo_var_value&#x3D;1; 上面表示IP在 127.0.0.1~127.0.0.255范围的地址会跳过 limit_req 的处理。 示例12345678910111213141516171819202122232425262728geo $white_ip &#123; ranges; default 0; 127.0.0.1-127.0.0.255 1;&#125;limit_req_whitelist geo_var_name&#x3D;white_ip geo_var_value&#x3D;1;limit_req_zone $binary_remote_addr zone&#x3D;one:3m rate&#x3D;1r&#x2F;s;limit_req_zone $binary_remote_addr $uri zone&#x3D;two:3m rate&#x3D;1r&#x2F;s;limit_req_zone $binary_remote_addr $request_uri zone&#x3D;three:3m rate&#x3D;1r&#x2F;s;location &#x2F; &#123; limit_req zone&#x3D;one burst&#x3D;5; limit_req zone&#x3D;two forbid_action&#x3D;@test1; limit_req zone&#x3D;three burst&#x3D;3 forbid_action&#x3D;@test2;&#125;location &#x2F;off &#123; limit_req off;&#125;location @test1 &#123; rewrite ^ &#x2F;test1.html;&#125;location @test2 &#123; rewrite ^ &#x2F;test2.html;&#125; 以上示例3个域限制策略，分别是： limit_req_zone $binary_remote_addr zone=one:3m rate=1r/s;：相同IP每秒只能发起一次请求。 limit_req_zone $binary_remote_addr $uri zone=two:3m rate=1r/s;：相同IP访问同一资源每秒请求频率为１次。 limit_req_zone $binary_remote_addr $request_uri zone=three:3m rate=1r/s;：同上，但请求URI是整个字符串，保住参数。 limit_req用来启用限制，一般放在 location 段内。支持开关，默认是打开状态。并且一个location支持多个limit_req指令，当有多个limit_req指令的话，这些指令是或的关系，也就是当其中任意一个限制被触发，则执行对应的limit_req。 burst设置允许超过频率限制的请求数，这里设置为3。 forbid_action 表示当条件被触发时，nginx所要执行的动作，支持name location和页面(/)，默认是返回503。 总结Tengine和Nginx官方对于限流控制的文档见： http://tengine.taobao.org/document_cn/http_limit_req_cn.html http://tengine.taobao.org/nginx_docs/cn/docs/http/ngx_http_limit_req_module.html http://tengine.taobao.org/nginx_docs/cn/docs/http/ngx_http_limit_conn_module.html 在时间紧、对反爬虫机制要求不高时，可以先使用Nginx的限流控制来实现一个简单的反爬虫机制。待后期再详细规划、设计更完善的反爬虫系统。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://yangbajing.github.io/tags/nginx/"},{"name":"tengine","slug":"tengine","permalink":"https://yangbajing.github.io/tags/tengine/"}]},{"title":"ETL里的34个子系统","slug":"etl的34个子系统","date":"2018-07-26T17:12:35.000Z","updated":"2022-02-22T00:08:06.393Z","comments":true,"path":"2018/07/27/etl的34个子系统/","link":"","permalink":"https://yangbajing.github.io/2018/07/27/etl%E7%9A%8434%E4%B8%AA%E5%AD%90%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"ETL里的38种子系统和ETL里的34种子系统Ralph Kimball和Joe Caserta于2004年编写的《The Data Warehouse ETL Toolkit》一书系统的阐述了ETL这一概念及建设ETL系统的要点，将ETL从BI的一部分抽离了出来。随后，这本书里的一些思想形成了一篇文章《ETL里的38个子系统》，系统总结了ETL项目要面临的不同任务。我们还可以在网上找到原始的这篇文章https://www.informationweek.com/software/information-management/the-38-subsystems-of-etl/d/d-id/1028653。在2008年，Wiley出版了最流行的一本BI图书的第二版：也是由Kimball和他同事编写的《The Data Warehouse Lifecycle Toolkit》。在这本书里ETL子系统被重构成了34种子系统。 接下来本文将简要介绍这34种ETL里的子系统。这34种子系统提供了一套框架，帮助我们理解ETL解决方案的实现和管理，并对其进行分类。在ETL解决方案的设计与实现之前，我们需要清楚的了解需要、已存在的系统、可用的技巧和技术来确认我们的预期是什么，以及达到预期的推动和限制因素。这34个子系统可以分为４个组成部分，其中很多都是管理类的子系统，因为当项目发布时，系统的生命周期才刚刚开始，管理也是ETL的重中之重。 抽取：ETL的第一个单词Extract就是抽取的意思，数据抽取是ETL系统的最大挑战之一，子系统1~3属于这个主题。 清洗和更正：无论使用什么数据仓库架构，在某个时间点上，数据都要经过清洗以满足业务的要求。精典数据仓库模型，数据进入到数据仓库之前就被清洗了（“真实的数据只有一个版本”）。而DataVault模型，数据是按照原样进入数据仓库的（“事实的数据只有一个版本”），而清洗和更正过程发生在后面的阶段。子系统4~8属于这个主题。 发布：34个子系统中有13个都是关于如何把数据发布到目标数据库中的，发布并不仅仅意味着把数据写入到目标数据库中，也包括把数据写入到维度表或事实表中的那些转换。 管理：任何的信息基础架构都要可以被管理和监控，ETL系统也不例外，子系统22~34属于这一个主题。 下面的主要内容都是摘录网上和书里资料，好记性不如赖笔头。 抽取ETL方案的第一部分就是要从不同的数据源抽取数据。访问数据源会有很多困难，政策性问题是最难以逾越的障碍。另外，基于安全性和性能方面的考虑，数据系统的管理人员不会让未经授权的用户访问系统。一些ERP系统的厂商（SAP或Oracle）也不允许其他系统访问ERP底层数据库。 子系统1：数据剖析系统目标是要分析不同数据源的结构和内容。数据剖析提供了类似行统计、NULL值个数统计等简单的统计项，当然也有一些更复杂的分析，如单词模式分析等。 子系统2：增量数据捕获系统目标是捕获源系统里数据的变化，CDC（Changed Data Capture，变化数据获取）常用的方式有： 审计列：源系统包含审计列，比如插入或修改的时间。 定时获取 全差异化比较 数据库日志抓取 消息队列监控 子系统3：抽取系统抽取子系统从不同的数据源抽取数据，并输入到ETL流程里。Kimball明确区分了基于文件的和基于流的两种抽取。注意，这里基于流的抽取并不意味着实时数据流。这种区分方法不太恰当，因为无论从数据库，文件、实时数据源、Web Services还是其他任何数据源，只要可以访问到数据，数据都是以流的方式通过整个转换的。事实上唯一有区别的地方是在ETL作业运行的过程中，数据源的数据是否在发生变化。所以抽取的主要的区别不是文件或流，而是静态或动态的问题。如果转换失败，这种区分方式就显得更为重要。如果你的数据源是静态的（文件的情况基本都是如此），重新启动一个作业就可以了。而如果你的数据源是动态的。例如事务型的数据库，在你运行作业的时候，数据库里面的数据已经发生了变化。例如，一个加载销售数据的作业，所有的维度都正常加载，在加载销售订单的事实数据时停电了，而在加载维度数据的同时，源系统中有了一个新的客户，并产生了一个新的订单，也就是说在源系统中有了新的维度数据和事实数据。除非把所有的维度表重新跑一遍，否则在重新加载事实表时，就会发现有的客户维度没有找到。另外，CDC的实现方式不同，从这类错误中进行数据恢复也是非常困难的事情。 清洗和更正数据世界上没有任何一个组织的数据是没有质量问题的，这也就是为什么我们在把数据加载到数据仓库之前要增加一些步骤来清洗和更正这些数据，以满足业务的需求。另外，只使用一个单一的系统来存储数据的组织也很少；通常，为了支撑业务运行，都会存在多个系统，可能每个部门都会有自己的系统。如财务、人力、采购或客服管理等。每个系统存储数据的方式可能都不相同。例如在系统A里，客户性别保存为F（female）、M（male）、U（unknown）；在系统B里，分别使用0、1、NULL来代表这三类数据。所有的这些系统都应该遵照数据仓库的统一标准来存储。 子系统4：数据清洗和质量处理系统数据清洗是指修改或整理进入到ETL流程中的脏数据。虽然通常来说，数据清洗应该在原始系统中产生数据的地方进行。但往往提高原始数质量所需要的时间不能满足开发数据仓库的时间要求。但是无论如何，我们都要给用户提供一份干净的数据。所以一般就需要使用ETL项目来提高数据质量，ETL项目的优势在于：首先，在ETL的数据剖析阶段，可以找出有哪些错误数据；其次，在源系统中需要的数据清洗规则，同样可以使用于ETL环境中。最后，最终使用数据的业务人员可以加入到ETL开发中，只有业务人员才能告诉我们哪些数据是正确的数据。理想情况下，业务人员/数据所有者、源系统开发人员/管理者和ETL开发人员需要共同完成提高数据质量的工作。在很多情况下，不正确数据主要来源于那些把数据输入到系统里的业务人员。 例如：一套包括ETL流程的数据质量解决方案，这个方案读取并转换业务系统中的数据，最后把数据加载到一个检查系统，在这个检查系统里用户可以可视化查看数据，并给不正确数据打标记。另外，ETL流程还可以自动给某些常见的错误打标记，如字段为空、不正确的格式或错误的电话号码等。每周数据质量的检查结果就会报告给数据管理人员。尽管业务上要求100%没有错误数据，但实际上，在没有做这个数据质量项目之前，正确数据的比例低于50%，在做了这个可视化的数据质量项目后，第一年，正确数据的比例已经几乎达到了90%。这个例子显示了一个简单的ETL流程再加上一些报告，如何使用户重视并提高数据质量问题。 子系统5：错误事件处理错误事件处理的目的是记录下ETL过程中的每一个错误。这样便于管理员定期监控和分析错误是数据质量错误还是系统错误或其他错误。Kimball提到要使用一个独立的错误事件模式来保留这些错误。 子系统6：审计维度尽管错误事件模式和数据仓库的业务数据是独立的，但审计维度表却是数据仓库内部的。审计维度表是一类特殊的维度表，数据仓库里的所有事实表都和审计维度表关联，审计维度表包含了对事实表变更的元数据，如加载数据的日期和时间、数据的质量指标等。实际上，给数据仓库增加审计维度，可以带来很多好处。就像在多维数据仓库上使用Data Vault架构所带来的好处一样。 子系统7：排除重复记录系统排除重复记录可能是ETL中最棘手的问题，大部分ETL工具也没有能自动处理重复数据的能力。在大多数情况下，排重是指删除重复的数据，或者把不同系统里互相冲突的数据统一。 子系统8：数据一致性数据经过数据排重子系统和前面提到的其他数据质量步骤处理后，就交给数据一致性子系统来处理。这个步骤的目的就是使来源于多个业务系统的事实数据遵照相同的维度。 例如，一个公司有一个客服管理系统，这个系统有自己的客户数据库，为了把客服管理系统和销售系统放到同一个数据仓库里，需要把客服管理系统的客户数据和销售系统的客户数据统一成一个客户维度表，当分别加载来自这两个系统的事实数据时，需要把来自两个系统的事实数据指向同一个客户维度表。解决这个问题最常用的方法就是维度表中保留从不同系统带来的自然键，在加载事实数据时，可以查找维度表中的这些源系统的自然键。 数据发布发布新的数据并不只是往目标数据库里插入新的数据这么简单，发布新的数据其实有很多工作。首先，我们从不同缓慢变更维度技术可以看到，更新维度表就有很多种方式。另外，你需要生成代理键、查询正确的维度键、确保维度数据在事实数据加载前就已经加载完、准备要加载的事实数据。加载事实数据本身也是一项有挑战性的工作：事实数据的数据量可能比较大，也有可能还要更新事实数据，或者同时出现这两种情况。所以需要特别关心表和存储的功能，如OLAP数据库。这也是为什么34种子系统里有很多都属于数据发布范畴。 子系统9：缓慢变更维度处理缓慢变更维度（SCDs）是多维数据仓库或者总线架构的基础。我们知道维度表里保存了用来对事实进行分析或分组的信息。例如，客户维度里有客户所在城市字段，这样我们就可以统计或列出某个城市里客户的销售情况。如果客户换了另一个城市，业务系统里肯定要相应修改这个客户所在的城市，缓慢变更维度的过程也会根据不同的规则来变更数据仓库中的客户维度。总的来说，有以下几种缓慢变更维度的方法。 覆盖：直接用新值代替旧值。 增加新行：把当前行标记为“old”并设置一个“结束”时间戳，同时创建一个新行，标记为“current”，并设置一个“开始”时间戳。 增加新列：给表增加一个新列，来存储新值，同时保留原来的值不变。 增加一个小维度表：把经常变更的表属性从主维度表里分离出来，保存在自己的表里。 分离历史表：把每次变化保存到一个历史表里，同时保存变化的类型和变化的时间。这样的历史表可以回答类似“去年有多少客户从成都移动到了重庆”这样的问题。 混合型：把类型1、2、3结合起来（1+2+3=6）。 子系统10：代理键生成系统ETL流程应该可以生成代理键。一般有三种方式： 使用表里现在代理键的最大值+1。 使用数据库序列。 使用一个自增的字段。后面一种方法也可用于表输出步骤。 子系统11：层次维度构建在数据仓库里还要考虑如何构建和维护数据仓库里的层次。实际上，这个子系统的完整的名称是“构建固定的，可变深度的，可有级别缺失的层次维度系统”。层次可以让用户分析查看维度不同级别上的数据。最简单的层次概念就是时间维度的层次。在现实中，时间维度都需要至少一个以上的层次。例如有“年—季—月—日”这样的层次，也有“年—周—日”这样的层次。时间维度也是“平衡层次”的一个例子。在时间维度里，所有级别的深度都是固定一样的。组织结构的维度更复杂一些，这种维度通常都是“不平衡的”或称为“可变深度的”（子树的深度不同）或“级别缺失的”（在层次上缺失了一些级别）。关于后面“缺失的”，可以想一下地理维度，地理维度通常的层次是“国家—地区—州（省）—城市”。一些国家可能没有“地区”或“州（省）”或都没有，这就是缺失了级别。在源系统里，通常使用“递归”的关系来实现“不平衡的”或“级别缺失的”的情况。 子系统12：特殊维度生成系统除了缓慢变化维度，基于多维模型的数据仓库，至少都包含一个特殊维度，时间维度。下面一些类型的维度也都是特殊维度。 杂项维度（也称为垃圾维度）：一些零散的属性，分析需要但又不适合放在其他维度表里。例如状态标志、yes/no和其他低阶（lowcardinality）字段都可以放在杂项维度表里。 小维度：从大维度表里分离出经常发生变化的一些属性，单独放在一个小维度表里。我们也把这种小维度表称为SCD4。 收缩的或上卷的维度：普通维度表的子集，为了避免冲突，这种维度是根据普通维度表创建和更新的。这种维度适用于聚集的数据，例如底层保存的是每天的数据，聚集的数据是按月保存的。 静态维度：通常是小的字典表或参照表，这类表在源系统中没有对应的数据，如状态编码描述或性别。 用户自定义维度：源系统里没有的而报表需要的自定义的描述、分组和层次。可以是任意的维度。唯一区分它们的就是这些维度是通过用户来维护的，而不是通过数据仓库团队或一个ETL过程。 子系统13：事实表加载（事务粒度、周期快照粒度、累积快照粒度事实表的加载系统）在往数据仓库加载事实表之前，需要把数据准备好。加载事实表过程并不是重点，之所以把加载事实表单独作为一个子系统分出来，主要是为了强调如下三种不同类型的事实表。 事务粒度事实表：以每一个事务或事件为单位，例如一个销售记录、一个电话呼叫记录，作为事实表里的一行数据。 周期快照事实表：事实表里并不保存全部数据，只保存固定时间间隔的数据，例如每天或每月的库存水平，或每月的账户余额。 累积快照事实表：当有新的数据时，更新事实表里的记录。数据仓库里总是保存最新的数据。例如订单过程，订单过程里有很多独立的日期，如订单日期、期望发货日期、实际发货日期、期望收货日期、实际收货日期和付款日期。当这个过程进行时，随着上面各种时间的出现，事实表里的记录也在不断更新。 加载事实表，通常要加载几百万行数据。为了快速加载，大多数数据库系统都提供了批量加载方式，批量加载方式通常规避了数据库的事务引擎，直接把数据写入到目标表。有时为了提高处理数据的速度，要删除事实表上的所有索引，在加载完后再重建索引。 子系统14：代理键管道这个子系统负责抽取正确的代理键，用于加载事实表。这里用“管道”一词是因为事实表的加载看起来像一个工序，工序里的每个环节都使用数据的自然键去查找维度表里的代理键。为了让这个查询过程更高效，最好把要查询的维度数据预先装载到内存里。 子系统15：多值维度桥接表生成系统处理不同深度的层次时需要桥接表。例如一个客户，是一个公司，它有子公司和子子公司。每一级的公司都可能去购买商品，如果想从母公司的角度去看一共购买了多少商品，就需要使用桥接表来实现。当有多个维度项和事实表或其他维度表关联时，也要使用桥接表。例如：电影票和电影演员，如果想汇总一个演员有多少电影票收入，就需要在电影和电影演员维度之间建立一个桥接表，这个桥接表把电影和电影演员关联起来，桥接表里还可以设置电影演员的权重因子。 子系统16：迟到数据处理到目前为止，我们的讨论都是在要处理数据同时到达的假设前提下。但在一些场合下，并非如此：事实表数据和维度表数据都可能晚到。对事实表来说这不是什么大问题，唯一不同的就是要根据维度的有效时间查找业务发生时的维度代理键。只要在查询条件里增加 valid_from 和 valid_to 两个字段就可以。“维度查询和更新”步骤默认就有这两个字段。如果维度表数据晚到，情况就要麻烦一些。如果事实表已经加载完了，但维度表的数据不是最新的。当要更新的维度数据过来后，按照SCD2，会在维度表里增加一条记录，此时要使用新创建的维度的代理键来更新事实表里有上一个代理键的数据。另外还有一个方法，当事实数据过来，但根据事实表里的维度自然键，从维度表里找不到对应的代理键。此时先创建一个新的维度记录，所有的字段都设置成默认值和空值，使用这条记录的代理键。然后当正确的维度数据从源系统中过来时，再更新这些默认值和空值。 子系统17：维度管理系统（中心控制系统）“中心控制系统，用来准备和向数据仓库发布正确的维度”。中心控制系统不只是组织，还负责管理所有和维度相关的任务。 子系统18：事实表管理系统这个子系统负责任何创建、组织、管理和事实表相关的任务。子系统17和18在一起结伴工作：事实表管理系统获取到由维度管理系统管理的维度，并把这些维度放到事实表中。 子系统19：聚集构建如果数据库是用于分析的，一定会有性能方面的要求。这种对速度的要求产生了几种解决方案，在这几种方案里，聚集表对性能的提升最大。如果能把平均30分钟的响应时间降低到几毫秒，客户会非常高兴。聚集表就可以达到这样的效果。但仅有聚集表是不行的，还需要维护聚集表，数据库还需要知道聚集表的存在以利用聚集表。这也就是MySQL、PostgreSQL、Ingres这些开源产品和Oracle，SQLServer及DB2这些商业产品的差距所在（这些商业产品都有自动聚集导航功能）。有聚集表功能的唯一的一个开源产品是Mondrian，但这些聚集表还是需要由Mondrian聚集表设计器来创建和维护。另外，也可以使用特殊的分析型数据库，如LucidDB、InfoBright、MonetDB、InfiniDB、Ingres/Vectorwise，或把分析型数据库如LucidDB和Pentaho聚集表设计器结合起来。生成和加载聚集表数据只是一次性的工作，但当数据仓库的数据发生变化后，LucidDB和Pentaho聚集表设计器都不会去维护聚集表。 子系统20：OLAPCube构建系统OLAP数据库有特殊的存储结构，当加载的时候，可以预先聚集数据。一些OLAP数据库只能写不能更新，所以，在做更新之前要把源数据清除。其他OLAP数据库（如微软的分析服务器）可以更新事实表，但有它自己的更新机制。 子系统21：数据整合管理系统这个子系统用来从数据仓库获取数据，并把数据发送到其他环境中，通常用于离线数据分析或者其他特殊目的，如给特定客户发送报表。 管理ETL环境后将介绍14个ETL子系统，这些子系统用来完成管理功能。 子系统22：作业调度任务的ETL作业任务都需要跑起来，这时就需要作业高度系统来管理这些任务。 子系统23：备份系统备份ETL过程中产生的中间数据也应该是ETL方案的一部分。Ralph Kimball推荐在ETL流程中的三个地方缓存（备份）这些数据： 从源系统中抽取之后，做任何改动之前。 清洗、排重、更正之后，此时可能还在文本文件中或使用正规化的格式。 已经做完最后处理，可以写入到数据仓库之前。备份数据仓库本身通常不是ETL团队的工作，但ETL团队可以和DBA紧密合作来实现错误恢复的方案。 子系统24：恢复和重新启动系统ETL设计的一个重要部分就是在ETL失败时，可以重新启动。我们要尽量避免丢失数据和重复数据的情况，所以这个子系统非常重要。遵照前面子系统描述的策略可以更容易重新启动一个失败的作业。 子系统25：版本控制系统；子系统26：从开发环境到测试、生产环境的版本移植系统有很多种方法可以实现版本控制，可以使用Git这样的版本控制系统来管理。版本控制系统也不应该成为一个事后才想到的问题。在这里引用Ralph Kimball对版本控制系统的观点。你需要给ETL系统里的每个部分都确定一个主版本号，另外ETL系统作为一个整体也要有一个主版本号。这样如果今天发布的版本发生严重的错误，可以快速恢复到昨天的ETL版本。详细见：《The Data Warehouse Lifecycle Toolkit，2nd Edition》。 子系统27：工作流监控是否尝试过不使用计时器和温度指示器来烤蛋糕？非常难吧？同样运行一个ETL作业，而不使用任何方法去监控运行过程，不显示执行作业的执行细节，也会使运行ETL作业非常困难。已经处理了多少行，处理的速度有多快？消耗了多少内存？哪条记录出错了，为什么出错？监控过程应该可以回答所有的这些问题，一般日志框架就是监控过程。 子系统28：排序系统对于一些操作（如分组、排序合并操作），数据事先要进行排序。一般这个步骤在内存里操作，但如果数据太大了会在硬盘上分页。对于非常大的文件，可以需要独立的排序工具。我们不讨论这些专用的排序工具而只是使用我们的“排序”步骤来完成我们的排序工作。 子系统29：血统和依赖分析ETL系统应该同时提供血统分析和影响分析功能。血统分析从处理后的数据开始向后追溯查看这个数据起源于哪里，然后在中间的环节对这个数据进行了哪些处理。依赖或影响分析的方向和血统分析相反，即从数据的起源开始，查看哪些步骤或转换使用了这个数据，这样可以显示出如果一个数据或表发生了变化会影响到系统的哪些部分。 子系统30：问题报告系统万一运行中出了错误（相信我们，肯定会出错的），你需要尽快知道运行中发生了错误。 子系统31：并行/管道系统为了能在短时间内处理大量数据，任务应该可以并行运行，甚至在多台机器上同时运行。现在的Reactive Stream（反应式流）规范是数据处理很好的一个方式。在云计算环境下（如阿里云的ECS、Amazon的EC2）运行ETL作业，可以避免大规模的硬件投资，以很低的运营成本带来大规模的按需可扩展的计算能力。 子系统32：安全系统在现在的IT领域，安全和合规是很热门的主题。数据仓库里保存了企业所有的数据，也是最容易产生风险的地方。另外在很多情况下，ETL过程可以直接访问到很多源系统，所以ETL解决方案本身也是易被攻击的地方。 子系统33：合规报告系统确保一个ETL流程遵照规章制度，所需要的大多数方法已经在其他子系统中涉及到了。合规意味着要对数据进行详细的审计，审计包括数据从哪里来，在数据上面执行了什么操作（血统），数据在写入到数据仓库之前是什么样子（基于时间戳的备份），在每个时间点的值是什么（审计表，SCD2），谁访问了数据（日志）。Data Vault是一种提供了很好审计功能的数据模型。 子系统34：元数据资源库管理系统这个子系统的目标就是捕获到和ETL相关的所有业务、过程和技术元数据。这个子系统中重要的一部分就是把系统文档化，在第11章介绍，当然Kettle的全部架构也是元数据驱动的，我们曾经在第2章讨论过。 总结介绍和解释了Ralph定义的34种ETL子系统。这些子系统的列表也可看成是ETL架构的通用的定义：它描述了每个子系统应该去做那些工作，而不是如何去做或者拿什么工具去做。这34种子系统涉及的四个主要方面如下。 抽取：从不同的数据源里获取数据。 清洗和更正数据：转换和集成数据，为数据进数据仓库之前做准备。 发布数据：加载和更新数据仓库里的数据。 管理环境：控制和监控ETL解决方案所有组件的处理过程。","categories":[{"name":"essay","slug":"essay","permalink":"https://yangbajing.github.io/categories/essay/"}],"tags":[{"name":"etl","slug":"etl","permalink":"https://yangbajing.github.io/tags/etl/"},{"name":"elt","slug":"elt","permalink":"https://yangbajing.github.io/tags/elt/"},{"name":"reactivestream","slug":"reactivestream","permalink":"https://yangbajing.github.io/tags/reactivestream/"},{"name":"mass-data","slug":"mass-data","permalink":"https://yangbajing.github.io/tags/mass-data/"},{"name":"mass-rdi","slug":"mass-rdi","permalink":"https://yangbajing.github.io/tags/mass-rdi/"}]},{"title":"Ambari2.6（HDP2.6.5）安装记要","slug":"ambari2-6（hdp2-6-5）安装记要","date":"2018-06-25T12:10:38.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/06/25/ambari2-6（hdp2-6-5）安装记要/","link":"","permalink":"https://yangbajing.github.io/2018/06/25/ambari2-6%EF%BC%88hdp2-6-5%EF%BC%89%E5%AE%89%E8%A3%85%E8%AE%B0%E8%A6%81/","excerpt":"","text":"本文介绍在 CentOS 7 环境下使用 Ambari2.5 (HDP2.6) 搭建大数据环境。 推荐使用如下脚本将 Ambari/HDP 相关软件包下到本地后配置 yum 源安装，在线安装速度太慢会经常遇到包找不到情况。 1234567891011nohup wget -c http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari.repo \\ https://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari-2.6.2.2-centos7.tar.gz.md5 \\ http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari-2.6.2.2-centos7.tar.gz \\ http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0/HDP-2.6.5.0-292.xml \\ http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0/hdp.repo \\ http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0/HDP-2.6.5.0-centos7-rpm.tar.gz \\ https://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0/HDP-2.6.5.0-centos7-rpm.tar.gz.md5 \\ http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7/HDP-UTILS-1.1.0.22-centos7.tar.gz \\ https://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7/HDP-UTILS-1.1.0.22-centos7.tar.gz.md5 \\ http://public-repo-1.hortonworks.com/HDP-GPL/centos7/2.x/updates/2.6.5.0/hdp.gpl.repo \\ http://public-repo-1.hortonworks.com/HDP-GPL/centos7/2.x/updates/2.6.5.0/HDP-GPL-2.6.5.0-centos7-gpl.tar.gz &amp; CentOS 准备安装CentOS 7 安装时设置静态IP 关闭Kdump 关闭Selinux 使用基础服务进行安装 安装相关软件包挂载系统镜像 12mkdir /media/CentOSmount /dev/sr0 /media/CentOS 编辑 /etc/yum.repos.d/CentOS-Media.repo 启用本地存储库，修改 enabled 为 1 。 12yum install vim ntp yum-utils createrepo yum-plugin-priorities scp curl unzip tar wget 安装前设置调整系统资源限制编辑 /etc/systemd/system.conf、/etc/systemd/user.conf 文件，修改如下： 1DefaultLimitNOFILE&#x3D;65536 设置 NTP123yum install -y ntpsystemctl enable ntpdsystemctl start ntpd 关闭系统防火墙12systemctl disable firewalldservice firewalld stop SELinux、PackageKit、umask编辑 /etc/sysconfig/selinux ，设置SELINUX=disabled。 1echo umask 0022 &gt;&gt; /etc/profile 编辑 /etc/yum/pluginconf.d/refresh-packagekit.conf 1enabled&#x3D;0 设置网络（DNS和NSCD）所有节点都要设置。ambari在安装时需要配置全域名，所以需要检查DNS。为了减轻DNS的负担, 建议在节点里用 Name Service Caching Daemon (NSCD) 1hostnamectl set-hostname ambari001 vim /etc/hosts 123192.168.124.151 ambari001192.168.124.152 ambari002192.168.124.153 ambari003 vim /etc/sysconfig/network 12NETWORKING&#x3D;yesHOSTNAME&#x3D;ambari001 设置静态IP地址编辑文件：/etc/sysconfig/network-scripts/ifcfg-eth0 12345678910TYPE&#x3D;&quot;Ethernet&quot;ONBOOT&#x3D;&quot;yes&quot;DEVICE&#x3D;&quot;eth0&quot;BOOTPROTO&#x3D;&quot;static&quot;IPADDR&#x3D;192.168.124.151NETMASK&#x3D;255.255.255.0GATEWAY&#x3D;192.168.124.1DNS1&#x3D;61.128.128.68NM_CONTROLLED&#x3D;noUUID&#x3D;&quot;006cd5ef-034f-41aa-803c-5891c2241774&quot; 关闭 python 的https verify在需要安装Ambari的所有节点编辑文件：/etc/python/cert-verification.cfg 12[https]verify&#x3D;disable 若修改后还遇到问题，编辑/etc/ambari-agent/conf/ambari-agent.ini文件，设置如下值（添加或修改，其它不变） 123[security]force_https_protocol&#x3D;PROTOCOL_TLSv1_2 然后重启 ambari-agent，ambari-agent restart。 SSH免密码登录使用root账号登录 Ambari Server 主机并生成SSH私钥： 1ssh-keygen 添加`authorized_keys文件： 12cd ~/.sshcat id_rsa.pub &gt;&gt; authorized_keys 修改 ~/.ssh 目录 和 ~/.ssh/authorized_keys 文件系统权限（注意：~/.ssh/authorized_keys文件权限必需为600，不然免密码登录将失效）： 12chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 将 authorized_keys 文件其复制到所有 Ambari Agent 主机（注意：有可能需要在Agent主机上创建 .ssh 目录）： 1scp ~/.ssh/authorized_keys root@&lt;remote.target.host&gt;:~/.ssh/ （请将 &lt;remote.target.host&gt; 替换为集群中每台 Ambari Agent 主机地址） 验证每台主机免密码登录是否成功 1ssh root@&lt;remote.target.host&gt; 本地 ambari/hdp yum源设置（可选）将 ambari.repo 文件入到 /etc/yum.repo.d/ 目录，并将 hdp.repos 地址替换成你实际的本地 yum 服务地址。 我们可以使用 Nginx 来搭建 yum 服务，只需要注意相映路径即可。 Nginx配置HDP YUM源 12345678910111213141516171819server &#123; listen 80; server_name public-repo-1.hortonworks.com hdp.repos; client_max_body_size 250m; proxy_read_timeout 3600; #proxy_connect_timeout 300; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; root /opt/Downloads/HDP/repos; location / &#123; autoindex on; &#125;&#125; ambari.repo 12345678#VERSION_NUMBER&#x3D;2.6.2.2-1[ambari-2.6.2.2]name&#x3D;ambari Version - ambari-2.6.2.2baseurl&#x3D;http:&#x2F;&#x2F;hdp.repos&#x2F;ambari&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.6.2.2gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;hdp.repos&#x2F;ambari&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.6.2.2&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1 安装独立PostgreSQL数据库（可选）12rpm -ivh https:&#x2F;&#x2F;download.postgresql.org&#x2F;pub&#x2F;repos&#x2F;yum&#x2F;9.6&#x2F;redhat&#x2F;rhel-7-x86_64&#x2F;pgdg-centos96-9.6-3.noarch.rpmsudo yum -y install postgresql96-server postgresql96-contrib 选择：**Enter advanced database configuration **，并选择 [4] - PostgreSQL。 创建ambari用户和数据库创建用户和数据库，psql -h localhost -U postgres -d postgres。 1234create user ambari encrypted password &#x27;bigdata&#x27;;create database ambari owner=ambari template=template1;create database hive owner=ambari template=template1;create database oozie owner=ambari template=template1; 设置默认schema，使用ambari用户登录到ambari数据库，psql -h localhost -U ambari -d ambari -W 1set search_path to &quot;$user&quot;,ambari; 初始化表 psql -h localhost -U ambari -d ambari -f /var/lib/ambari-server/resources/Ambari-DDL-Postgres-CREATE.sql 安装/设置 ambari-server为了一些不必要的麻烦，推荐关闭 selinux Install 1yum install ambari-server 配置 ambari-server 1ambari-server setup --java-home=/usr/local/java --jdbc-db=postgres --jdbc-driver=/usr/share/java/postgresql-jdbc.jar --enable-lzo-under-gpl-license --database=postgres --databasehost=hdp2001 --databaseport=5432 --databasename=ambari --postgresschema=ambari --databaseusername=ambari --databasepassword=bigdata 使用 -j 选项指定 JAVA_HOME 目录，这里推荐使用 Oracle JDK 1.8，并配置 Java Cryptography Extension (JCE) 。若不指定 -j 选项，ambari-server 将自动下载配置了JCE的Oracle JDK 1.8版本。 一切使用默认配置即可，当看到以下输出就代表 Ambari Server 配置成功： 123...........Adjusting ambari-server permissions and ownership...Ambari Server &#39;setup&#39; completed successfully. 安装/配置/部署集群启动Ambari-server 1ambari-server start 打开浏览器登录网址：[http://ambari001:8080](http://ambari001:8080)（请使用你自己安装的 Ambari Server地址）。 使用默认用户名/密码 admin/admin 登录，之后你可以修改它。 登录后首先创建我们的第一个大数据集群，点击 Launch Install Wizard 按钮创建集群。 首先我们将需要给集群取一个名字，接下来将选择 HDP 的版本，这里我们选择 2.6 版本。 ***我们将使用本地源来安装 HDP ***，按图设置本地源地址： HDP-2.6: http://hdp.repos/HDP/centos7/2.x/updates/2.6.5.0 HDP-UTILS-1.1.0.22: http://hdp.repos/HDP-UTILS-1.1.0.22/repos/centos7 HDP-GPL: http://hdp.repos/HDP-GPL/centos7/2.x/updates/2.6.5.0","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"ambari/hdp","slug":"bigdata/ambari-hdp","permalink":"https://yangbajing.github.io/categories/bigdata/ambari-hdp/"}],"tags":[{"name":"ambari","slug":"ambari","permalink":"https://yangbajing.github.io/tags/ambari/"},{"name":"hdp","slug":"hdp","permalink":"https://yangbajing.github.io/tags/hdp/"},{"name":"centos7","slug":"centos7","permalink":"https://yangbajing.github.io/tags/centos7/"}]},{"title":"Linux与Shell","slug":"linux与shell","date":"2018-05-04T15:53:15.000Z","updated":"2022-02-16T02:50:45.199Z","comments":true,"path":"2018/05/04/linux与shell/","link":"","permalink":"https://yangbajing.github.io/2018/05/04/linux%E4%B8%8Eshell/","excerpt":"","text":"Linux，你必需知道的磁盘、进程、内存 保存数据的磁盘 实际处理数据的进程 存储各种运行信息的内存 磁盘和文件Linux系统没有盘符的概念，它和所有类UNIX系统一样，有一个树型结构的文件系统。 123456789101112131415161718192021$ tree -d -L 1 &#x2F;&#x2F;├── bin -&gt; usr&#x2F;bin├── boot├── dev├── etc├── home├── lib -&gt; usr&#x2F;lib├── lib64 -&gt; usr&#x2F;lib64├── media├── mnt├── opt├── proc├── root├── run├── sbin -&gt; usr&#x2F;sbin├── srv├── sys├── tmp├── usr└── var 磁盘df 查看系统已挂载文件系统情况，df只会显示已挂载的分区。 12345678$ df -h文件系统 容量 已用 可用 已用% 挂载点/dev/vda1 77G 1.8G 75G 3% /devtmpfs 2.0G 0 2.0G 0% /devtmpfs 2.0G 4.0K 2.0G 1% /dev/shmtmpfs 2.0G 8.4M 2.0G 1% /runtmpfs 2.0G 0 2.0G 0% /sys/fs/cgrouptmpfs 396M 0 396M 0% /run/user/1000 vdaX 指文件系统分区，v在这里代表KVM使用的virto虚拟文件系统，X是分区号。相应的，sata, ssd等磁盘使用s开头，传统的HHD机械硬盘使用h开头。 fdisk 查看磁盘硬件情况，fdisk 并不显示系统分区，显示电脑上的所有磁盘（包括未挂载磁盘）。 12345678910111213$ sudo fdisk -l[sudo] hldev 的密码：磁盘 /dev/vda：85.9 GB, 85899345920 字节，167772160 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x00097eb4 设备 Boot Start End Blocks Id System/dev/vda1 * 2048 161019903 80508928 83 Linux/dev/vda2 161019904 167772159 3376128 82 Linux swap / Solaris 进程控制进程就等于控制Linux fork：通过父进程创建一个子进程，子进程是父进程自身的一个副本。 exec：舍弃进程原本携带信息，在进程执行时用新的程序代码替代调用进程的内容。 后台执行在执行命令的结尾加上 &amp; ，可以使程序在后台运行。如： 1java -jar app.jar &amp; 使用 nohup 命令，可使程序输出不打印到时前端（终端），默认将打印到 nohup.out 文件。 1nohup java -jar app.jar &amp; Ctrl+Z 使在前台运行的进程后台运行。 fg 将后台进程拉回前台运行。 快速的数据处理管道管道蕴含着Linux从Unix中继承的一个重要概念： 程序应该只关注一个目标，并尽可能把它做好。程序应能够互相协同工作。让程序处理文本数据流，这是一个通用的接口 stdin：标准输入，文件描述符 0 stdout：标准输出，文件描述符 1 stderr: 标准错误输出，文件描述符 2 123456$ cat您好， &lt;---- 从键盘输入您好， &lt;---- 在屏幕上输出相同内容海数！ &lt;---- 从键盘输入海数！ &lt;---- 在屏幕上输出相同内容 &lt;---- 按Ctrl+D结束 管道 管道中常用的快捷命令 命令 说明 cut 通过分隔符拆分后，显示指定的域 grep 显示与模式相匹配的行 head 显示文件的开始部分 paste 通过指定的分隔符将两个文件的各行进行合并，或者通过指定的分隔符合并一个文件中的多行 sort 对多行进行排序 tr 替换、删除字符，压缩文字序列 uniq 压缩连续的相同的行 wc 显示文件字节数、字（word）数、行数 12$ history | grep &lt;...&gt; // 从历史记录查找使用过的命令$ ps aux | grep &lt;...&gt; // 查找匹配的进程 过滤并保存系统运行的所有进程号 12$ ps -ef &gt; /tmp/tmp0$ cat /tmp/tmp0 | tr -s &quot; &quot; | cut -d &quot; &quot; -f 2 | grep -v &quot;PID&quot; &gt; /tmp/tmp1 cut 命令把 -d 选项指定的文字作为文字分隔符,仅抽取 -f 选项定位的数据(域)。这个例子中,使用空格作为分隔符。但是，由于连续的空格会被当作多个分隔符,因此要事先通过 tr 命令将连续空格转换成一个空格。 内存物理地址空间和逻辑地址空间 物理内存分为Linux内核自身使用的区域和用户进程使用的区域。内核使用低端内存，高端内存被分配给了用户进程。低端内存中的空闲区域也将被分配给用户进程使用。 进程在访问物理内存时并不直接指定物理地址，而是指定逻辑地址。内存的内核数据区域中预先设置逻辑地址和物理地址的对应“页表”，然后 CPU 上搭载的 MMU(Memory Management Unit)硬件会参照该页表,自动实现对映射后物理地址上的数据的访问。 为每个进程提供独立的内存空间，等于实现了进程之间的安全保护。 通过 /proc/meminfo 系统运行内存信息文件查看内存状态 1234567891011121314$ cat /proc/meminfoMemTotal: 4046524 kBMemFree: 3717696 kBMemAvailable: 3673100 kBBuffers: 2076 kBCached: 182044 kBSwapCached: 0 kBActive: 89820 kB &lt;---- Active(anon) + Active(file)Inactive: 153048 kB &lt;---- Inactive(anon) + Inactive(file)Active(anon): 59104 kBInactive(anon): 46128 kBActive(file): 30716 kBInactive(file): 106920 kB...... 通过 free 命令查看内存状态 1234$ free total used free shared buff/cache availableMem: 4046524 115940 3717364 46484 213220 3672772Swap: 3376124 0 3376124 Linux 发行版Linux本身指 GNU/Linux 内核，但只有内核一般用户是没法使用的。所以世面上就出现了很多 Linux 发行版，它打包并整理了一系列开箱即用的工具。 CentOSCentOS(Community Enterprise Operating System，中文意思是:社区企业操作系统)是Linux发行版之一，它是来自于Red Hat Enterprise Linux依照开放源代码规定释出的源代码所编译而成。由于出自同样的源代码，因此有些要求高度稳定性的服务器以CentOS替代商业版的Red Hat Enterprise Linux使用。两者的不同，在于CentOS并不包含封闭源代码软件。 公司的服务器（测试、生产）环境使用的CentOS 7。 UbuntuUbuntu（友帮拓、优般图、乌班图）是一个以桌面应用为主的开源GNU/Linux操作系统，Ubuntu 是基于Debian GNU/Linux，由全球化的专业开发团队（Canonical Ltd）打造的。其名称来自非洲南部祖鲁语或豪萨语的“ubuntu”一词 [2] ，类似儒家“仁爱”的思想，意思是“人性”、“我的存在是因为大家的存在”，是非洲传统的一种价值观。 公司部分开发人员的开发电脑安装了 Ubuntu 16.04 操作系统。 虚拟化Linux拥有强大的虚拟化能力。常见的有： KVM：完全虚拟化，OpenStack默认使用它做为系统虚拟化工具 Xen：完全虚拟化，类似KVM的另一套虚拟化 Cgroup：半虚拟化，Docker/k8s等容器虚拟化的核心 一个邮件发送系统的虚拟网络构成。 开始使用Linux终端终端会话是用户与shell环境打交道的地方，如果你使用的是基于图形用户界面的系统，这指的就是终端窗口。如果没有图形用户界面(生产服务器或SSH会话),那么登录后你看到的就是shell提示符。 CentOS 7的终端提示如下： 123[hldev@centos7-001 opt]$ cd &#x2F;usr&#x2F;local&#x2F;share&#x2F;[hldev@centos7-001 share]$ pwd&#x2F;usr&#x2F;local&#x2F;share $ 表示普通用户，**#** 表示管理员用户root。root是Linux系统中权限最高的用户。 环境变量环境变量通常保存了可执行文件、库文件等的搜索路径列表。例如 $PATH 和 $LD_LIBRARY_PATH： 1PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;sbin:&#x2F;home&#x2F;hldev&#x2F;.local&#x2F;bin:&#x2F;home&#x2F;hldev&#x2F;bin 设置环境变量可以在命令行直接使用 export 命令：export JAVA_HOME=&quot;/opt/local/jdk1.8。但这样设置在系统重启后就无效了，我们可以把它写到配置文件里面。全局配置：**/etc/profile，用户配置：~/.bash_prfile**。若环境变量写在配置文件内，在重启系统前默认是不会生效的，需要手动使其生效。 1. ~&#x2F;.bash_profile 安装软件在Linux下一般有两种方式来安装软件： 使用包管理器自动安装 使用源码编译安装 RPMCentOS 7 使用yum包管理器安装RPM格式的软件。常用命令有： 列出已安装包：rpm -l 用yum安装软件：sudo yum install &lt;software name&gt; 用yum更新软件： sudo yum update &lt;software name&gt; sudo yum update（更新系统） 用yum卸载软件：sudo yum erase &lt;software name&gt; yum工具和命令命令ls：查看文件ls 列出目录内容。 1234567891011121314151617181920$ lspgdg-centos96-9.6-3.noarch.rpm project$ ls -l总用量 8-rw-rw-r-- 1 hldev hldev 4824 9月 19 2017 pgdg-centos96-9.6-3.noarch.rpmdrwxrwxr-x 2 hldev hldev 6 2月 12 13:04 project$ ls -alhF 总用量 32K drwx------. 3 hldev hldev 173 2月 12 13:04 ./ drwxr-xr-x. 3 root root 19 9月 19 2017 ../ -rw-------. 1 hldev hldev 2.9K 5月 2 10:56 .bash_history -rw-r--r--. 1 hldev hldev 18 8月 3 2017 .bash_logout -rw-r--r--. 1 hldev hldev 193 8月 3 2017 .bash_profile -rw-r--r--. 1 hldev hldev 231 8月 3 2017 .bashrc -rw------- 1 hldev hldev 46 9月 19 2017 .lesshst -rw-rw-r-- 1 hldev hldev 4.8K 9月 19 2017 pgdg-centos96-9.6-3.noarch.rpm drwxrwxr-x 2 hldev hldev 6 2月 12 13:04 project/ -rw------- 1 hldev hldev 460 9月 20 2017 .psql_history -a 列出所有文件 -l 列出文件明细 -h 使用 human 友好的方式显示文件内容大小 -F 将指示符添加到显示的项后面。如：* 可执行，/ 目录，@ 符号连接，= UNIX套接字， tar（解）压缩将多个文件压缩成一个单一文件，或相反。Linux tar 命令支持多种压缩格式。常用的有：gzip和bzip2 1234tar czf dist.tar.gz disttar cjf dist.tar.bz2 disttar xcf dist.tar.gztar xjf dist.tar.bz2 -C &#x2F;opt&#x2F;haishu&#x2F;var&#x2F;www&#x2F;auth-boot -c 压缩文件， -z 使用 gzip 进行（解）压缩 -j 使用 bzip2 进行（解）压缩 -x 解压文件 -f 指定压缩生成/解压文件 cURL：数据传输命令行工具cURL 是传输数据到服务器或从服务器获取数据的工具，支持多种协议。如：DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP。 上传文件 -XPOST：使用HTTP POST方法 -F \\&#39;filename=@app.jar\\&#39;：上传文件字段设置为filename，引用本地目录的 app.jar 文件 1curl -XPOST -F &#39;filename&#x3D;@app.jar&#39; 常用选项 --progress：显示进度条 --silent：不显示进度信息 -O：设置远程文件下载到本地系统的目标文件名 -C -：支持断点续传，-C后面的-选项记cURL推断出正确的续传位置，也可以指定明确的字节偏移。 wget: 命令行HTTP客户端下载文件 -c: 断点下载文件 1wget -c https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;centos&#x2F;7.4.1708&#x2F;isos&#x2F;x86_64&#x2F;CentOS-7-x86_64-DVD-1708.iso 镜像网站 1wget -m -k -e robots&#x3D;off https:&#x2F;&#x2F;www.hualongdata.com&#x2F; -e robots=off：让wget耍流氓无视robots.txt协议 ps：查找进程显示当前进程（所有或指定）的快照。 显示系统所有进程 1ps -ef 显示系统所有终端所有用户进程 1ps -aux tail: 监控文件实时监控 application.log 日志文件最新1024行内容： 1tail -f -n 1024 application.log top：查看系统运行状态实时显示Linux系统运行状况 12345678910111213$ toptop - 15:47:49 up 1:03, 1 user, load average: 0.29, 0.27, 0.42Tasks: 315 total, 2 running, 245 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.5 us, 0.3 sy, 0.0 ni, 99.1 id, 0.0 wa, 0.1 hi, 0.0 si, 0.0 stKiB Mem : 32445240 total, 26918760 free, 3062800 used, 2463680 buff&#x2F;cacheKiB Swap: 16290812 total, 16290812 free, 0 used. 28910020 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1560 yangjing 20 0 983496 121052 75104 S 1.7 0.4 1:29.94 Xorg 1809 yangjing 20 0 4449852 426112 108836 R 1.7 1.3 5:11.92 gnome-shell 2710 yangjing 20 0 1200352 116584 82764 S 1.0 0.4 0:14.09 tilix 6391 yangjing 20 0 7548768 360604 77256 S 0.7 1.1 0:07.54 chrome 6708 yangjing 20 0 162236 4452 3708 R 0.7 0.0 0:00.15 top 第一行：当前时间，系统运行时长，登录用户数，平均系统负载：1分钟、5分钟、15分钟 第二行：任务（进程）总数，运行数，休眠数，已停止数，僵尸进程数 第三行：CPU运行百分比。us: 用户空间占，用户进程空间内改变过优先级的进程占，空闲CPU占，等待输入输出的CPU，硬中断（Hardware IRQ）占，软中断（Software Interrupts）占 第四行：物理内存总数（KB），空闲内存，已使用内存，缓存的内存 第五行：交换空间总数，空闲交换内存，已使用，可使用 PID: 进程号 USER: 运行进程的用户 PR: 进程优先级 NI: nice值。负值表示高优先级，正值表示低优先级 VIRT: 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES: 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR: 共享内存大小，单位kb S: 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU: 上次更新到现在的CPU时间占用百分比 %MEM: 进程使用的物理内存百分比 TIME+: 进程使用的CPU时间总计，单位1/100秒 COMMAND: 进程名称（命令名/命令行） 用户管理group 创建用户组：groupadd -g 1100 devops。创建一个组：devops，并指定组GID为1100 user 创建用户：useradd -u 1100 -g 1100 -G wheel -k -m -d /home/devops devops。 -u: 指定用户UID -g: 指定组GID，需要存在 -G: 指定附加组，需要存在 -k: 骨架目录中的文件和目录将被拷贝到用户主目录 -m: 若 -d 指定目录不存在则创建 -d: 指定用户主目录 sshssh OpenSSH客户端 1$ ssh -p 22222 hldev@centos7-001 sftp 基于SSH协议的FTP客户端，可以通过SSH登录服务器并使用FTP协议上传、下载文件 123456789101112131415$ sftp hldev@centos7-001hldev@centos7-001&#39;s password: Connected to centos7-001.sftp&gt; lsREADME.md pgdg-centos96-9.6-3.noarch.rpm project sftp&gt; get pgdg-centos96-9.6-3.noarch.rpm Fetching &#x2F;home&#x2F;hldev&#x2F;pgdg-centos96-9.6-3.noarch.rpm to pgdg-centos96-9.6-3.noarch.rpm&#x2F;home&#x2F;hldev&#x2F;pgdg-centos96-9.6-3.noarch.rpm 100% 4824 47.0KB&#x2F;s 00:00sftp&gt; !lsassets pgdg-centos96-9.6-3.noarch.rpm README.html README.mdsftp&gt; put README.htmlUploading README.html to &#x2F;home&#x2F;hldev&#x2F;README.htmlREADME.html 100% 10KB 25.2MB&#x2F;s 00:00 sftp&gt; lsREADME.html README.md pgdg-centos96-9.6-3.noarch.rpm project put: 上传本地文件到服务器 get: 从服务器下载文件 !command: 命令前添加!，命令将在本地执行。 put, get 命令还有些参数可以设置，常用如下： -P: 同步完整的文件权限的访问时间 -r: 递归拷贝目录内的所有文件 scp 基于SSH协议的文件拷贝工具，可以将本地文件拷贝到远程服务器。 123$ scp README.md hldev@centos7-001:&#x2F;home&#x2F;hldev&#x2F;hldev@centos7-001&#39;s password: README.md VIM，编辑器之神CentOS系统默认只安装了VI，要使用VIM需要安装：sudo yum -y install vim VIM全称是：Vi IMproved。改进的Vi，程序员的文本编辑器。VIM被称为编辑器之神。使用 VIM 非常简单，在终端输入 vim 即可。VIM支持全键盘操作，不需要使用鼠标即可操作，可显著提供工作效率。 同时也可以指定要打开的文件。打开 vim 时可以使用参数，比如：-R 只读模式。在使用VIM查看比较大的日志文件等时候可以防止误操作修改文件。 VIM运行时有三种模式： Normal模式：在Normal模式下，用户可以移动光标、操纵文字、输入各种控制操作 Edit模式：顾名思义，编辑模式下可以输入内容。 Command模式（指令模式）：在Normal模式下，按 shift+;（输入英文冒号）则可进入指令模式。当编辑器下部出现闪烁的英文冒号时既进入指令模式。 使用VIM打开本文 vim README.md，默认处于 Normal 模式。 VIM 基本使用这时，可以使用键盘上的 H、J、K、L 4个键移动光标，分别为：向左、上、下、右移动。当光标移动到期望的位置后可以有多种方法进入Edit（编辑）模式。i：在光标指定字符前进入编辑模式，a：在光标指定字符后进入编辑模式，s：替换光标指定字符并进入编辑模式。 退出Edit模式有两种方法： 按 Esc 键退出Edit模式并进入Normal模式 按 ctrl+[ 组合键 VIM技巧保存和退出（Command模式）输入 w 将保存当前编辑内容，若是打开的新文件可以在 w 后输入需要保存的文件名。 输入 q 将退出VIM，退出前必需保存已编辑内容。若想放弃当前编辑内容并退出，输入 q! 。 w, q 可以组合输入。比如保存并退出：wq。 快速移动（Normal模式）翻页 ctrl-f 向前翻一页，ctrl-b 向后翻一页（向前翻页时VIM将保留之前页的最后两行）。 快速定位到文本开头或结尾 连按两次 g 键将光标移动到整个文本开头，shift+g将移动光标到整个文本结尾。 复制、粘贴行（Normal模式）连续按两次 y 键复制单行，在需要粘贴的地方使用 p 键进行粘贴（将粘贴到光标所在行之下）。 复制多行 按 shift+v 组合键可以高亮一行，这时可以使用 J、K 进行上下移动，选中需要的多行后再按 y 键即可复制多行。 撤销、恢复编辑（Normal模式）在Normal模式下按 u 键将撤销最后一次编辑（每次保存文件算一次编辑）。按 ctrl+r 将恢复撤销。撤销和恢复可进行多次。 自动补全（Edit模式）在需要实例的文字后按 ctrl+c ctrl+p 会弹出自动补全选择框，这里可以使用 ctrl+n 或 ctrl+p 进行向下、向下移动，选中需要实例的单词后按 Enter 键即可。 将本地路径录入文本（Edit模式）使用 ctrl+c ctrl+f 将弹出本地路径选择框（相对当前编辑文本路径），移动光标选中需要的路径，按 Enter 键后录入到文本中。 VIM配置可以自定义VIM配置，VIM的配置文件为：.vimrc，一般在用户主目录下。编辑配置文件： 1$ vim ~&#x2F;.vimrc 输入以下内容打开高亮和自动缩进。 12syntax onset ai ShellShell是用户使用Linux的桥梁，它既是一种命令语言，又是一种程序。在Linux下，一般默认使用的是 Bash。以下内容非特殊说明，默认使用的Bash。 Bash脚本可以将一系列命令放到一个脚本文件中自动执行，一般这类脚本文件都以 .sh 结尾。 1234567891011121314#!&#x2F;usr&#x2F;bin&#x2F;env bash# $1, $2, $x, .... 代表输入的第一、第二、第三个命令行参数echo $1 $2# $@ 代表所有命令行参数echo $@if [ ! $JAVA_OPTS ]; then JAVA_OPTS&#x3D;&#39; -Xmx1G -Xms1G &#39;fi# 执行Java程序java $JAVA_OPTS -jar application.jar $@ 上面是一个普通的shell脚本，使用Bash执行。","categories":[{"name":"unix/linux","slug":"unix-linux","permalink":"https://yangbajing.github.io/categories/unix-linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://yangbajing.github.io/tags/shell/"},{"name":"vim","slug":"vim","permalink":"https://yangbajing.github.io/tags/vim/"},{"name":"bash","slug":"bash","permalink":"https://yangbajing.github.io/tags/bash/"}]},{"title":"PostgreSQL从入门到不后悔","slug":"postgresql从入门到不后悔","date":"2018-02-05T10:59:08.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2018/02/05/postgresql从入门到不后悔/","link":"","permalink":"https://yangbajing.github.io/2018/02/05/postgresql%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E4%B8%8D%E5%90%8E%E6%82%94/","excerpt":"","text":"《PostgreSQL从入门到不后悔》 《PostgreSQL高可用：逻辑复制》 《PostgreSQL高可用 - PG 11集群》 安装 PostgreSQL 10下载 PostgreSQL 10，postgresql-10.1-3-linux-x64-binaries.tar.gz。下载地址：https://get.enterprisedb.com/postgresql/postgresql-10.1-3-linux-x64-binaries.tar.gz。 （注：安装脚本如下（需要有 /opt/local 写权限），可使用如下命令创建 /opt/local 目录。） 12sudo mkdir &#x2F;opt&#x2F;localsudo chown -R $USER:$USER &#x2F;opt&#x2F;local install_pg.sh 12345678910111213141516171819202122232425262728293031323334353637OPT_BASE&#x3D;&#x2F;optPGVERSION&#x3D;10.1PGBASE&#x3D;$OPT_BASE&#x2F;local&#x2F;pgsqlPGHOME&#x3D;$OPT_BASE&#x2F;local&#x2F;pgsql&#x2F;$PGVERSIONPGDATA&#x3D;$OPT_BASE&#x2F;var&#x2F;pgsql&#x2F;$PGVERSIONPG_SOFT_￥TAR&#x3D;&quot;postgresql-10.1-3-linux-x64-binaries.tar.gz&quot;if [ -d $PGHOME ]; then rm -rf $PGHOMEelif [ ! -d $PGBASE ]; then mkdir -p $PGBASEfiif [ ! -d $PGDATA ]; then mkdir -p $PGDATAfiecho &quot;Install PostgreSQL&quot;tar zxf $PG_SOFT_TAR -C $PGBASEmv $PGBASE&#x2F;pgsql $PGHOMEcp pg-pwfile $PGHOMEecho &quot;Init PostgreSQL&quot;pushd $PGHOME.&#x2F;bin&#x2F;initdb --pgdata&#x3D;&quot;$PGDATA&quot; --auth&#x3D;ident --auth-host&#x3D;md5 --encoding&#x3D;UTF-8 --locale&#x3D;zh_CN.UTF-8 --username&#x3D;postgres --pwfile&#x3D;pg-pwfilerm -f pg-pwfilepopdcp pg_hba.conf $PGDATAcp postgresql.conf $PGDATAchmod 600 $PGDATA&#x2F;*.confecho &quot;Start PostgreSQL&quot;$PGHOME&#x2F;bin&#x2F;pg_ctl -D $PGDATA -l logfile startsleep 5#cp .pgpass ~&#x2F;$PGHOME&#x2F;bin&#x2F;psql -h localhost -U postgres -d postgres -f pg_init.sql install_pg.sh 脚本安装时依赖文件的完整版压缩包在此下载：https://yangbajing.me/files/postgresql10-scripts.tar.gz pg-pwfile：在初始化数据库时设置默认管理员账户的密码 pg_hba.conf：默认只允许 127.0.0.1/8 访问数据库，这里改成允许所有网段可访问 postgresql.conf：修改数据库监听地址为 * ，监听所有本地网络地址 pg_init.sql：创建一个普通账户 yangbajing 和测试用数据库 yangbajing ，密码也设置为 yangbajing 安装后PG数据库管理管理员账号是 postgres，密码为 postgres。同时，还创建了一个普通账号：yangbajing 和同名数据库 yangbajing，密码也是 yangbajing。 将 /opt/local/pgsql/10.1/bin 目录加入系统环境变量。 12echo &#39;export PATH&#x3D;&quot;&#x2F;opt&#x2F;local&#x2F;pgsql&#x2F;10.1&#x2F;bin:$PATH&quot; &gt;&gt; ~&#x2F;.bashrc. ~&#x2F;.bashrc 使用如下命令来启动或停止PostgreSQL 10数据库 启动数据库 1pg_ctl -D &#x2F;opt&#x2F;local&#x2F;var&#x2F;pgsql&#x2F;10.1 -l logfile start 停止数据库 1pg_ctl -D &#x2F;opt&#x2F;local&#x2F;var&#x2F;pgsql&#x2F;10.1 -l logfile stop 体验 PG输入以下命令访问PG数据库： 1psql -h localhost -U yangbajing -d yangbajing -W 根据提示输入密码登录，进入 psql 的 REPL 界面。 12345Password for user yangbajing: psql.bin (10.1)Type &quot;help&quot; for help.yangbajing&#x3D;&gt; 先建立一些测试表： 1234567891011121314151617CREATE TABLE t_role ( id INT PRIMARY KEY, name VARCHAR(255) NOT NULL, created_at TIMESTAMPTZ);CREATE TABLE t_user ( id BIGSERIAL PRIMARY KEY, name VARCHAR(255) NOT NULL, roles INT [] NOT NULL, data JSONB, created_at TIMESTAMPTZ);INSERT INTO t_role (id, name, created_at) VALUES (1, &#x27;超级管理员&#x27;, now()), (2, &#x27;管理员&#x27;, now()), (3, &#x27;用户&#x27;, now());INSERT INTO t_user(name, roles, data, created_at) VALUES (&#x27;root&#x27;, &#x27;&#123;1&#125;&#x27;, &#x27;&#123;&quot;email&quot;:&quot;root@yangbajing.me&quot;&#125;&#x27;, now()), (&#x27;羊八井&#x27;, &#x27;&#123;2,3&#125;&#x27;, &#x27;&#123;&quot;email&quot;:&quot;yangbajing&quot;&#125;&#x27;, now()), (&#x27;哈哈&#x27;, &#x27;&#123;3&#125;&#x27;, &#x27;&#123;&quot;email&quot;:&quot;haha@yangbajing.me&quot;&#125;&#x27;, now()); 先来执行两个简单的 SELECT 查询： 123456789101112131415yangbajing=&gt; select * from t_role; id | name | created_at ----+------------+------------------------------- 1 | 超级管理员 | 2018-02-01 22:03:17.168906+08 2 | 管理员 | 2018-02-01 22:03:17.168906+08 3 | 用户 | 2018-02-01 22:03:17.168906+08(3 rows)yangbajing=&gt; select * from t_user; id | name | roles | data | created_at ----+--------+-------+---------------------------------------+------------------------------- 2 | root | &#123;1&#125; | &#123;&quot;email&quot;: &quot;root@yangbajing.me&quot;&#125; | 2018-02-01 22:06:21.140465+08 3 | 哈哈 | &#123;3&#125; | &#123;&quot;email&quot;: &quot;haha@yangbajing.me&quot;&#125; | 2018-02-01 22:06:21.140465+08 1 | 羊八井 | &#123;2,3&#125; | &#123;&quot;email&quot;: &quot;yangbajing@yangbajing.me&quot;&#125; | 2018-02-01 22:04:41.580203+08(3 rows) 接下来，尝试一些 PG 特色特性。 InsertOrUpdate插入或更新，是一个很有用的特性，当在主键冲突时可以选择更新数据。在PG中，是使用 ON CONFLICT 来实现这个特性的。 1234INSERT INTO t_role (id, name, created_at)VALUES (3, &#x27;普通用户&#x27;, now())ON CONFLICT (id) DO UPDATE SET name = EXCLUDED.name; 在常用的 INSERT 语句后面用 ON CONFLICT (...) DO .... 语句来指定在某个/些字段出现冲突时需要执行的语句。在 on CONFLICT (...) 里的参数需要是主键或唯一索引（可以为复合字段）。当冲突发生时则会执行 DO .... 后面的语句，这里我们选择更新 name 字段的值。EXCLUDED 是用户引用在 VALUES .... 部分我们将插入的数据，EXCLUDED.name 在这里就是 &#39;普通用户&#39; 。除 DO UPDATE，我们还可以使用 DO NOTHING 来简单的忽略插入时的主键冲突。 SERIAL/BIGSERIAL看看表 t_user 的结构： 1234567891011yangbajing&#x3D;&gt; \\d t_user Table &quot;public.t_user&quot; Column | Type | Collation | Nullable | Default ------------+--------------------------+-----------+----------+------------------------------------ id | bigint | | not null | nextval(&#39;t_user_id_seq&#39;::regclass) name | character varying(255) | | not null | roles | integer[] | | not null | data | jsonb | | | created_at | timestamp with time zone | | | Indexes: &quot;t_user_pkey&quot; PRIMARY KEY, btree (id) 在建表时 id 字段的类型定义的是 BIGSERIAL ，但这里却是显示的 bigint 类型；另外，还多了一个默认值：nextval(&#39;t_user_id_seq&#39;::regclass) 。这是 PG 中的 序列 ，PG中使用序列来实现 自增值 的特性。 序列：t_user_id_seq 123456yangbajing&#x3D;&gt; \\d t_user_id_seq Sequence &quot;public.t_user_id_seq&quot; Type | Start | Minimum | Maximum | Increment | Cycles? | Cache --------+-------+---------+---------------------+-----------+---------+------- bigint | 1 | 1 | 9223372036854775807 | 1 | no | 1Owned by: public.t_user.id 也可以先创建序列，再设置字段的默认值为该序列的下一个值。 1CREATE SEQUENCE t_user_id2_seq INCREMENT BY 1 MINVALUE 1 START WITH 1; 这里创建一个序列，设置最小值为1，从1开始按1进行递增。 数组类型在创建 t_user 表的 roles 字段时，使用了数组类型 INT [] 。数组类型对于我们的数据建模来说很有用，使用得好可以大大减少关系表的数量。 根据索引返回值 1234567yangbajing=&gt; SELECT id, name, roles[2], created_at FROM t_user; id | name | roles | created_at ----+--------+-------+------------------------------- 2 | root | | 2018-02-01 22:06:21.140465+08 3 | 哈哈 | | 2018-02-01 22:06:21.140465+08 1 | 羊八井 | 1 | 2018-02-01 22:04:41.580203+08(3 rows) 注意：PG 中，索引下标从0开始 以行的形式输出数组元素 12345678yangbajing=&gt; SELECT id, unnest(roles) AS role_id FROM t_user; id | role_id ----+--------- 2 | 1 3 | 3 1 | 2 1 | 1(4 rows) 包含查找 12345yangbajing=&gt; SELECT * FROM t_user WHERE roles @&gt; ARRAY[1,2]; id | name | roles | data | created_at ----+--------+-------+---------------------------------------+------------------------------- 1 | 羊八井 | &#123;2,1&#125; | &#123;&quot;email&quot;: &quot;yangbajing@yangbajing.me&quot;&#125; | 2018-02-01 22:04:41.580203+08(1 row) 重叠查找 重叠查找和包含查找的不同之处在重叠查找只要匹配数组中的任意一个元素则为 true。 123456yangbajing=&gt; SELECT * FROM t_user WHERE roles &amp;&amp; ARRAY[1,2]; id | name | roles | data | created_at ----+--------+-------+---------------------------------------+------------------------------- 2 | root | &#123;1&#125; | &#123;&quot;email&quot;: &quot;root@yangbajing.me&quot;&#125; | 2018-02-01 22:06:21.140465+08 1 | 羊八井 | &#123;2,1&#125; | &#123;&quot;email&quot;: &quot;yangbajing@yangbajing.me&quot;&#125; | 2018-02-01 22:04:41.580203+08(2 rows) 数组转换成字符串 array_to_string 函数的第二个参数指定转换成字符串后使用的分隔字符。 1234567yangbajing=&gt; SELECT id, name, array_to_string(roles, &#x27;,&#x27;) AS role_ids FROM t_user; id | name | role_ids ----+--------+---------- 2 | root | 1 3 | 哈哈 | 3 1 | 羊八井 | 2,1(3 rows) JSON类型TODO Tooltip随机获取一个用户 使用 random 函数来排序，并返回第一条记录。 1234567891011yangbajing=&gt; SELECT * FROM t_user ORDER BY random() LIMIT 1; id | name | roles | data | created_at ----+------+-------+---------------------------------+------------------------------- 3 | 哈哈 | &#123;3&#125; | &#123;&quot;email&quot;: &quot;haha@yangbajing.me&quot;&#125; | 2018-02-01 22:06:21.140465+08(1 row)yangbajing=&gt; SELECT * FROM t_user ORDER BY random() LIMIT 1; id | name | roles | data | created_at ----+--------+-------+---------------------------------------+------------------------------- 1 | 羊八井 | &#123;2,1&#125; | &#123;&quot;email&quot;: &quot;yangbajing@yangbajing.me&quot;&#125; | 2018-02-01 22:04:41.580203+08(1 row) FDW在之前创建的默认 PG 数据库之外，接下来将创建一个绑定到端口 5433 的另一个 PG 数据库。 （注：PostgreSQL中，创建和操作 xxx_fdw 扩展需要管理员权限） 使用 postgres_fdw 访问其它Postgres数据库先创建第2个数据库，用于模拟远程访问。以下是创建第2个数据库的命令： 1234mkdir &#x2F;opt&#x2F;haishu&#x2F;var&#x2F;pgsql&#x2F;10.1_2echo &quot;postgres&quot; &gt; pg-pwfile&#x2F;opt&#x2F;haishu&#x2F;local&#x2F;pgsql&#x2F;10.1&#x2F;bin&#x2F;initdb --pgdata&#x3D;&#x2F;opt&#x2F;haishu&#x2F;var&#x2F;pgsql&#x2F;10.1_2 --auth&#x3D;ident --auth-host&#x3D;md5 --encoding&#x3D;UTF-8 --locale&#x3D;zh_CN.UTF-8 --username&#x3D;postgres --pwfile&#x3D;pg-pwfilerm pg-pwfile 数据库创建成功后会输入如下提示： 1234....Success. You can now start the database server using: &#x2F;opt&#x2F;haishu&#x2F;local&#x2F;pgsql&#x2F;10.1&#x2F;bin&#x2F;pg_ctl -D &#x2F;opt&#x2F;haishu&#x2F;var&#x2F;pgsql&#x2F;10.1_2 -l logfile start 这里我们需要修改第2个数据库 10.1_2 监听端口号，以免和已安装数据库冲突。编辑 /opt/haishu/var/pgsql/10.1_2/postgresql.conf 文件，修改内容如下： 1port &#x3D; 5433 再使用 /opt/haishu/local/pgsql/10.1/bin/pg_ctl -D /opt/haishu/var/pgsql/10.1_2 -l logfile start 命令启动第2个数据库。 123&#x2F;opt&#x2F;haishu&#x2F;local&#x2F;pgsql&#x2F;10.1&#x2F;bin&#x2F;pg_ctl -D &#x2F;opt&#x2F;haishu&#x2F;var&#x2F;pgsql&#x2F;10.1_2 -l logfile startwaiting for server to start.... doneserver started 现在，第2个PG数据库已建好，我们分别登录两个数据库。 使用账号：yangbajing 登录第1个PG 123456$ psql -h localhost -U yangbajing -d yangbajingPassword for user yangbajing: psql.bin (10.1)Type &quot;help&quot; for help.yangbajing&#x3D;&gt; 使用账号：postgres 登录第2个PG，并创建测试用户 pg2 和测试数据库 pg2 123456789101112]$ psql -h localhost -p 5433 -U postgres -d postgresPassword for user postgres: psql.bin (10.1)Type &quot;help&quot; for help.postgres&#x3D;# create user pg2 encrypted password &#39;pg2&#39;;CREATE ROLEpostgres&#x3D;# create database pg2 owner&#x3D;pg2 template&#x3D;template1;CREATE DATABASEpostgres&#x3D;# \\c pg2You are now connected to database &quot;pg2&quot; as user &quot;postgres&quot;.pg2&#x3D;# 创建 postgres_fdw 扩展，以支持使用外部表的形式访问其它数据库。使用 postgres_fdw 主要步骤如下： 安装扩展 ，CREATE EXTENSION 创建外部服务对象：CREATE SERVER 创建用户映射：CREATE USER MAPPING 创建外部表：CREATE FOREIGN TABLE或IMPORT FOREIGN SCHEMA 操作示例 安装扩展 12pg2&#x3D;# create extension postgres_fdw ;CREATE EXTENSION 创建外部连接数据库 12pg2&#x3D;# CREATE SERVER foreign_server FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host &#39;localhost&#39;, port &#39;5432&#39;, dbname &#39;yangbajing&#39;);CREATE SERVER 创建用户映射 12pg2&#x3D;# CREATE USER MAPPING FOR pg2 SERVER foreign_server OPTIONS (user &#39;yangbajing&#39;, password &#39;yangbajing&#39;);CREATE USER MAPPING 创建外部表 123456CREATE FOREIGN TABLE foreign_t_role ( id INT NOT NULL, name VARCHAR(255) NOT NULL, created_at TIMESTAMPTZ) SERVER foreign_server OPTIONS (schema_name &#39;public&#39;, table_name &#39;t_role&#39;); 在创建用户映射时，是将本地的 pg2 用户映射到远程服务器用户的，我们需要使用 pg2 账号登录来访问外部表。首先给 pg 赋于权限： 12pg2&#x3D;# grant ALL ON TABLE foreign_t_role to pg2 ;GRANT 使用 pg2 账号登录访问外部表 12345678psql -h localhost -U pg2 -d pg2pg2&#x3D;&gt; select * from foreign_t_role ; id | name | created_at ----+------------+------------------------------- 1 | 超级管理员 | 2018-02-01 22:03:17.168906+08 2 | 管理员 | 2018-02-01 22:03:17.168906+08 3 | 普通用户 | 2018-02-01 22:03:17.168906+08(3 rows) 向外部表插入数据： 12pg2&#x3D;&gt; INSERT INTO foreign_t_role(id, name, created_at) VALUES(4, &#39;来宾&#39;, now());INSERT 0 1 回到第1个数据库，我们可以看到由外部表插入进来的数据： 12345678yangbajing&#x3D;&gt; select * from t_role ; id | name | created_at ----+------------+------------------------------- 1 | 超级管理员 | 2018-02-01 22:03:17.168906+08 2 | 管理员 | 2018-02-01 22:03:17.168906+08 3 | 普通用户 | 2018-02-01 22:03:17.168906+08 4 | 来宾 | 2018-02-02 11:47:02.296937+08(4 rows) 使用 mysql_fdw 访问MySQL数据库mysql_fdw 由 EnterpriseDB 公司提供，我们需要从源码开始编译它。https://github.com/EnterpriseDB/mysql_fdw 安装 mysql_fdw 步骤如下： 1、下载源码包。 12git clone https:&#x2F;&#x2F;github.com&#x2F;EnterpriseDB&#x2F;mysql_fdwcd mysql_fdw 2、配置 pg_config 目录：export PATH=/opt/local/pgsql/10.1/bin:$PATH。 3、配置 mysql_config 目录。这里使用官方的 YUM 源安装 MySQL 5.7，详细的安装使用说明请查阅官方文档：https://dev.mysql.com/doc/mysql-yum-repo-quick-guide/en/。 1234sudo rpm -ivh https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql57-community-release-fc27-10.noarch.rpmsudo dnf erase mariadb-*sudo dnf makecachesudo dnf install mysql-community-server mysql-community-devel 4、编译并安装 mysql_fdw 扩展 12make USE_PGXS&#x3D;1 installsudo sudo ldconfig &#x2F;&#x2F; 重建系统动态链接库缓存 在 MySQL 中创建测试数据 （注：MySQL的使用非本文重点，请自行查阅相关文档） 登录 MySQL 并创建测试表及插入测试数据： 12345678SET time_zone &#x3D; &#39;+08:00&#39;;CREATE TABLE t_book( isbn VARCHAR(255) PRIMARY KEY, title VARCHAR(255), created_at DATETIME);INSERT INTO t_book(isbn, title, created_at) VALUES(&#39;978-7-121-32529-8&#39;, &#39;Akka应用模式：分布式应用程序设计实践指南&#39;, &#39;2017-10-01&#39;),(&#39;978-7-115-46938-0&#39;, &#39;Kafka技术内幕：图文详解Kafka源码设计与实现&#39;, &#39;2017-11-01&#39;); 在 PG 中访问 MySQL 类似使用 postgres_fdw，使用 mysql_fdw 也需要 PG 数据库的管理员权限。 1、创建扩展： 1CREATE EXTENSION mysql_fdw; 2、创建外部服务对象： 1CREATE SERVER mysql_server FOREIGN DATA WRAPPER mysql_fdw OPTIONS (host &#39;127.0.0.1&#39;, port &#39;3306&#39;); 3、创建用户映射 1CREATE USER MAPPING FOR yangbajing SERVER mysql_server OPTIONS(username &#39;yangbajing&#39;, password &#39;yang.Bajing2018&#39;); 4、创建外部表 123456CREATE FOREIGN TABLE foreign_t_book( isbn VARCHAR(255), title VARCHAR(255), created_at TIMESTAMPTZ) SERVER mysql_server OPTIONS(dbname &#39;yangbajing&#39;, table_name &#39;t_book&#39;);GRANT ALL ON TABLE foreign_t_book to yangbajing ; 现在，可以在 PG 中访问并使用在 MySQL 中创建的表和数据了，和 postgres_fdw 一样，也可以远程修改原表的内容。 接下来本文简单介绍了 PostgreSQL 10 的安装、使用和一些特性，下一篇文章从应用开发的角度来谈谈怎样使用 PG。介绍怎样使用 JDBC 来访问 PostgreSQL 数据库，使用 Scala 编程语言作示例。","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"postgresql","slug":"bigdata/postgresql","permalink":"https://yangbajing.github.io/categories/bigdata/postgresql/"}],"tags":[{"name":"postgres","slug":"postgres","permalink":"https://yangbajing.github.io/tags/postgres/"},{"name":"postgresql 10","slug":"postgresql-10","permalink":"https://yangbajing.github.io/tags/postgresql-10/"}]},{"title":"Cassandra备份、恢复","slug":"cassandra备份、恢复","date":"2017-12-05T06:27:42.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/12/05/cassandra备份、恢复/","link":"","permalink":"https://yangbajing.github.io/2017/12/05/cassandra%E5%A4%87%E4%BB%BD%E3%80%81%E6%81%A2%E5%A4%8D/","excerpt":"","text":"备份和数据恢复关于镜像Cassandra 通过直接保存所有在data目录中的磁盘数据文件（SSTable file）的镜像来备份数据。当系统还在线的时候，你可以保存所有的keyspace数据或者单个keyspace数据，或者某一张表的数据。 使用并行的ssh工具，比如pssh，你可以给整个集群做镜像。这提供一种最终一致性备份。虽然没有一个节点可以在镜像制作过程中保证他和备份节点数据的一致性，Cassandra内置一致性机制会使用一个恢复镜像恢复一致性。 当整个系统范围内的镜像都已经完成，你可以开启每个节点的增量备份，它将备份那些最后一次镜像后有改变的数据：每次SSTable刷新，一个硬链接被复制到 data目录的/backups 子目录中（provided JNA is enabled） 如果允许JNA，镜像将只是建立一个硬链接。否则io将由于文件被从一个地方拷贝到另一处而增长，将明显降低效率。 创建镜像操作过程 1$ nodetool -h localhost -p 7199 snapshot &lt;keyspace name&gt; 请使用实际的 keyspace 名替换 &lt;keyspace name&gt; 段。 看下面实际操作： 123$ &#x2F;home&#x2F;app&#x2F;local&#x2F;cassandra&#x2F;bin&#x2F;nodetool snapshot ig_crawlerRequested creating snapshot(s) for [ig_crawler] with snapshot name [1514377074990] and options &#123;skipFlush&#x3D;false&#125;Snapshot directory: 1514377074990 1514377074990 为生成的镜像快照名字，我们使用 tree 命令看看执行创建镜像后的 ig_crawler keyspace 目录结构： 12345678910111213141516[devops@dn126 ig_crawler]$ tree -d -L 4.├── c_gather_task_log-7ec1ecb062f411e78129670c2365db09│ ├── backups│ └── snapshots│ └── 1514377074990├── c_web_parsed-ad1019e0567711e7ba3fb1ef858b2357│ ├── backups│ └── snapshots│ └── 1514377074990└── c_web_raw-78427450564611e7ba3fb1ef858b2357 ├── backups └── snapshots └── 151437707499012 directories 可以看到，在 ig_crawler keyspace中有3张表，snapshot 命令为每张表都生成了一个镜像，镜像名为：1514377074990。在这里，我们将需要的 &lt;table name&gt;-&lt;uuid&gt;/&lt;snapshot name&gt; 目录下的数据都拷贝出来，复制到需要恢复的机器上。 恢复数据 确保要恢复的数据表模式存在，Cassandra只能从存在的表模式中恢复镜像里的数据。如果表模式不存在，则必需首先创建它。 如果可行，务必截断表。使用 TRUNCATE TABLE &lt;table name&gt; 将表中数据截断。我们现在做的都是全量备份，如果因为意外的删 除数据造成 tombstone 的时间发生混乱，截断表可以确保不会有本应被删除的数据被恢复的情况发生。 关闭所有节点 nodetool stop 将生成的镜像文件，&lt;table name&gt;-&lt;uuid&gt;/&lt;snapshot name&gt;/* 目录下的所有数据拷贝到目标 Cassandra 的&lt;data directory&gt;/&lt;keyspace&gt;/&lt;table name&gt;-&lt;uuid&gt;/ 目录中。（注意：是将镜像目录的数据拷贝到目录keyspace的表目录里） 启动 Cassandra 并执行 nodetool refresh 命令恢复镜像内的数据","categories":[],"tags":[]},{"title":"Elasticsearch备份、恢复","slug":"elasticsearch备份、恢复","date":"2017-12-05T06:27:33.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/12/05/elasticsearch备份、恢复/","link":"","permalink":"https://yangbajing.github.io/2017/12/05/elasticsearch%E5%A4%87%E4%BB%BD%E3%80%81%E6%81%A2%E5%A4%8D/","excerpt":"","text":"迁移注意事项 保证ES集群不再接受新的数据(如果是备份的话，这一点可以不考虑，但是做数据迁移的话，建议这样做）。同一个repository只应有一个集群可写，其它集群都应以readonly模式连接。 不建议直接在生产环境做这些操作，最好是先在本地搭建一个和生产环境一样的集群环境，创建一些测试数据，把整个过程先跑一遍，然后再到生产环境操作。 dn126 为要备份的源数据节点，而 localhost 为待恢复的目标数据节点 备份本文使用文件系统作为快照仓库的存储，选择一个节点执行命令 12345678curl -X PUT http:&#x2F;&#x2F;dn126:9200&#x2F;_snapshot&#x2F;backups \\ -d &#39;&#123; &quot;type&quot;: &quot;fs&quot;, &quot;settings&quot;: &#123; &quot;location&quot;: &quot;&#x2F;home&#x2F;app&#x2F;var&#x2F;elasticsearch&#x2F;backups&quot;, &quot;compress&quot;: true &#125; &#125;&#39; 生成备份 123456curl -X PUT &#39;http:&#x2F;&#x2F;dn126:9200&#x2F;_snapshot&#x2F;backups&#x2F;snapshot_1?wait_for_completion&#x3D;true&#39; \\ -d &#39;&#123; &quot;indices&quot;: &quot;fgw_search,fgw_search_2&quot;, &quot;ignore_unavailable&quot;: true, &quot;include_global_state&quot;: false&#125;&#39; 恢复删除已有的备份数据 1curl -X DELETE http:&#x2F;&#x2F;localhost:9200&#x2F;_snapshot&#x2F;backups 拷贝备份数据 12tar zxf elasticsearch-backups-2017.12.07.tar.gzmv elasticsearch-backups&#x2F;* &#x2F;opt&#x2F;haishu&#x2F;var&#x2F;elasticsearch&#x2F;backups&#x2F; 恢复数据 1curl -i -X POST http:&#x2F;&#x2F;localhost:9200&#x2F;_snapshot&#x2F;backups&#x2F;snapshot_1&#x2F;_restore","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"elasticsearch","slug":"bigdata/elasticsearch","permalink":"https://yangbajing.github.io/categories/bigdata/elasticsearch/"}],"tags":[]},{"title":"PostgreSQL高可用-主/热备集群","slug":"postgresql高可用-主热备集群","date":"2017-09-20T04:39:37.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/09/20/postgresql高可用-主热备集群/","link":"","permalink":"https://yangbajing.github.io/2017/09/20/postgresql%E9%AB%98%E5%8F%AF%E7%94%A8-%E4%B8%BB%E7%83%AD%E5%A4%87%E9%9B%86%E7%BE%A4/","excerpt":"","text":"高可用性：数据库服务器可以一起工作， 这样如果主要的服务器失效则允许一个第二服务器快速接手它的任务 负载均衡: 允许多个计算机提供相同的数据 本文使用的主要技术有： CentOS 7 x86_64 PostgreSQL 9.6.5 系统安装、配置CentOS 7 安装12[hldev@centos7-001 ~]$ sudo yum -y install https:&#x2F;&#x2F;download.postgresql.org&#x2F;pub&#x2F;repos&#x2F;yum&#x2F;9.6&#x2F;redhat&#x2F;rhel-7-x86_64&#x2F;pgdg-centos96-9.6-3.noarch.rpm epel-release vim[hldev@centos7-001 ~]$ sudo yum -y update CentOS 系统配置Selinux配置 编辑 /etc/sysconfig/selinux，设置 SELINUX 为 disabled： 1234567891011# This file controls the state of SELinux on the system.# SELINUX&#x3D; can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX&#x3D;disabled# SELINUXTYPE&#x3D; can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE&#x3D;targeted 其它配置 TODO 修改完后请重启系统，以确保所有设置生效。 PostgreSQL 安装1[hldev@centos7-001 ~]$ sudo yum -y install postgresql96-server postgresql96-contrib 初始化PostgreSQL数据库 1[hldev@centos7-001 ~]$ sudo &#x2F;usr&#x2F;pgsql-9.6&#x2F;bin&#x2F;postgresql96-setup initdb 启动PostgreSQL 1[hldev@centos7-001 ~]$ sudo systemctl start postgresql-9.6 使用 sudo systemctl status postgresql-9.6 来检测PG运行状态。看到如下输出，则代表数据库安装成功。 12345● postgresql-9.6.service - PostgreSQL 9.6 database server Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;postgresql-9.6.service; enabled; vendor preset: disabled) Active: active (running) since 二 2017-09-19 22:30:46 CST; 1s ago Process: 1466 ExecStartPre&#x3D;&#x2F;usr&#x2F;pgsql-9.6&#x2F;bin&#x2F;postgresql96-check-db-dir $&#123;PGDATA&#125; (code&#x3D;exited, status&#x3D;0&#x2F;SUCCESS) Main PID: 1471 (postmaster) PostgreSQL单机配置配置PostgreSQL 登录 postgres 操作系统账号： 1[hldev@centos7-001 ~]$ sudo su - postgres 编辑 /var/lib/pgsql/9.6/data/pg_hba.conf 文件，将 host all all 127.0.0.1/32 ident 修改为允许所有网络登录，并使用md5方式进行认证： 1host all all 0.0.0.0&#x2F;0 md5 编辑 /var/lib/pgsql/9.6/data/postgresql.conf 文件，找到并设置如下选项： 123listen_addresses &#x3D; &#39;*&#39;max_connections &#x3D; 1024password_encryption &#x3D; on 通过以上配置，我们设置了PostgreSQL允许任何IPv4地址都可以使用密码认证的方式登录数据库，并设置密码使用加密传输/存储，同时还修改了最大连接数限制为1000。 设置postgres（数据库超级管理员）密码 首先使用 psql 命令登录PostgreSQL数据库 12 -bash-4.2$ psql 使用 \\password 命令设置当前用户密码 123postgres&#x3D;# \\password输入新的密码：再次输入： 注意：此处需要在 postgres 操作系统账号下操作 打开防火墙端口 要使本机以外可远程连接数据库，还需要打开操作系统防火墙的对应端口。PostgreSQL在安装时提供了 firewalld 的服务配置文件，我们可以通过服务的方式来打开防火墙： 12sudo firewall-cmd --add-service&#x3D;postgresql --permanentsudo firewall-cmd --reload 以上修改后需要重启PostgreSQL数据库 12exit # 退出postgres账号[hldev@centos7-001 ~]$ sudo systemctl restart postgresql-9.6.service 远程连接PostgreSQL数据库 在远程主机上使用以下命令连接已安装好的PostgreSQL数据库，centos7-001 为已安装数据库服务器主机IP地址对应主机名（通过在 /etc/hosts 中设置 192.168.124.146 centos7-001 来映射）。 1[hldev@centos7-001 ~]$ psql -h centos7-001 -U postgres 登录成功后，我们看到如下提示则代表 PostgreSQL 的单机安装成功完成： 12345用户 postgres 的口令：psql (9.6.5)输入 &quot;help&quot; 来获取帮助信息.postgres&#x3D;# PostgreSQL 集群设置这里列出官方对各种高可用、负载均衡和复制特性实现方式的比较： 本文将基于PostgreSQL官方提供的基于流式的WAL数据复制功能搭建一个 主/热备 数据库集群。 根据 PostgreSQL单机配置，安装3台服务器。IP地址设置分别如下，并加入 /etc/hosts 中： 123192.168.124.161 centos7-001192.168.124.162 centos7-002192.168.124.163 centos7-003 三台服务器的角色分别如下： centos7-001: 主服务器 centos7-002: 从服务器 centos7-003: 级联从服务器 主节点（centos7-001）1.. 创建一个传用于复制的账号： 1CREATE ROLE pgrepuser REPLICATION LOGIN PASSWORD &#39;pgreppass&#39;; 2.. 在 postgresql.conf 设置以下配置项： 1234567listen_addresses &#x3D; &#39;*&#39;max_connections &#x3D; 1024password_encryption &#x3D; onwal_level &#x3D; hot_standbyarchive_mode &#x3D; onmax_wal_sender &#x3D; 4wal_keep_segments &#x3D; 10 3.. 在 pg_hba.conf 文件中为 pgrepuser 设置权限规则。允许 pgrepuser 从IP地址范围为 192.168.124.1 到 192.168.124.254 连接到主服务器，并使用基于MD5的加密密码。 1host replication pgrepuser 0.0.0.0&#x2F;0 md5 主服务器配置好后需要重启数据库： 1[hldev@centos7-001 ~]$ sudo systemctl restart postgresql-9.6 若在生产环境中没有条件进行数据库重启，也可以使用 pg_ctl reload 指令重新加载配置： 1-bash-4.2$ &#x2F;usr&#x2F;pgsql-9.6&#x2F;bin&#x2F;pg_ctl reload -D $PGDATA 从节点1.. 首先停止从机上的PostgreSQL服务。 1sudo systemctl stop postgresql-9.6 2.. 使用 pg_basebackup 生成备库 首先清空 $PGDATA 目录。 12-bash-4.2$ cd &#x2F;var&#x2F;lib&#x2F;pgsql&#x2F;9.6&#x2F;data-bash-4.2$ rm -rf * 使用 pg_basebackup 命令生成备库： 1-bash-4.2$ &#x2F;usr&#x2F;pgsql-9.6&#x2F;bin&#x2F;pg_basebackup -D $PGDATA -Fp -Xs -v -P -h centos7-001 -U pgrepuser 我们看到以下的操作输出，代表生成备库成功。 12345678pg_basebackup: initiating base backup, waiting for checkpoint to completepg_basebackup: checkpoint completed事务日志起始于时间点: 0&#x2F;4000028, 基于时间表1 pg_basebackup: 启动后台 WAL 接收进程22836&#x2F;22836 kB (100%), 1&#x2F;1 表空间 transaction log end point: 0&#x2F;40000F8pg_basebackup: 等待后台进程结束流操作...pg_basebackup: base backup completed 3.. 将下面的配置设置添加到 postgresql.conf 文件中。 1hot_standby &#x3D; on 4.. 在 $PGDATA 目录创建 recovery.conf 文件，内容如下： 1234standby_mode &#x3D; &#39;on&#39;primary_conninfo &#x3D; &#39;host&#x3D;centos7-001 port&#x3D;5432 user&#x3D;pgrepuser password&#x3D;pgreppass&#39;trigger_file &#x3D; &#39;failover.now&#39;recovery_target_timeline &#x3D; &#39;latest&#39; 5.. 如果发现从属服务器处理事务日志的速度较慢，跟不上主服务器产生日志的速度，为避免主服务器产生积压，你可以在从属服务器上指定一个路径用于缓存暂未处理的日志。请在 recovery.conf 中添加如下一个代码行，该代码行在不同操作系统下会有所不同。 1restore_command &#x3D; &#39;cp %p ..&#x2F;archive&#x2F;%f&#39; 6.. 启动从数据库 1[hldev@centos7-002 ~]$ sudo systemctl stop postgresql-9.6 启动复制进程的注意事项 一般情况下，我们建议先启动所有从属服务器再启动主服务器，如果顺序反过来，会导致主服务器已经开始修改数据并生成事务日志了，但从属服务器却还无法进行复制处理，这会导致主服务器的日志积压。如果在未启动主服务器的情况下先启动从属服务器，那么从属服务器日志中会报错，说无法连接到主服务器，但这没有关系，忽略即可。等所有从属服务器都启动完毕后，就可以启动主服务器了。 此时所有主从属服务器应该都是能访问的。主服务器的任何修改，包括安装一个扩展包或者是新建表这种对系统元数据的修改，都会被同步到从属服务器。从属服务器可对外提供查询服务。 如果希望某个从属服务器脱离当前的主从复制环境，即此后以一台独立的 PostgreSQL 服务器身份而存在，请直接在其 data 文件夹下创建一个名为 failover.now 的空文件。从属服务器会在处理完当前接收到的最后一条事务日志后停止接收新的日志，然后将 recovery.conf 改名为 recovery.done。此时从属服务器已与主服务器彻底解除了复制关系，此后这台PostgreSQL 服务器会作为一台独立的数据库服务器存在，其数据的初始状态就是它作为从属服务器时处理完最后一条事务日志后的状态。一旦从属服务器脱离了主从复制环境，就不可能再切换回主从复制状态了，要想切回去，必须按照前述步骤一切从零开始。 测试主/备服务分别登录 centos7-001 和 centos7-002 两台数据库使用 \\l 命令查看数据库列表： PostgreSQL: centos7-001 123456789101112131415[hldev@centos7-001 ~]$ psql -h centos7-001 -U postgres用户 postgres 的口令：psql (9.6.5)输入 &quot;help&quot; 来获取帮助信息.postgres&#x3D;# \\l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres(3 行记录) PostgreSQL: centos7-002 123456789101112131415[hldev@centos7-002 ~]$ psql -h centos7-002 -U postgres用户 postgres 的口令：psql (9.6.5)输入 &quot;help&quot; 来获取帮助信息.postgres&#x3D;# \\l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres(3 行记录) 我们在 centos7-001 上创建一个测试数据库：test 1postgres&#x3D;# create database test template&#x3D;template1; test 数据库创建成功后，我们可以在 centos7-002 从服务器上看到 test 数据库已经同步过来。 1234567891011postgres&#x3D;# \\l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | &#x3D;c&#x2F;postgres + | | | | | postgres&#x3D;CTc&#x2F;postgres test | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | (4 行记录) 继续在从库上尝试 DDL 操作，可以发现从库已被正确的设置为只读模式： 123456postgres&#x3D;# \\c test您现在已经连接到数据库 &quot;test&quot;,用户 &quot;postgres&quot;.test&#x3D;# CREATE TABLE test (id BIGStest&#x3D;# CREATE TABLE test (id BIGSERIAL PRIMARY KEY, name VARCHAR(255), age INT);错误: 不能在一个只读模式的事务中执行CREATE TABLE 在主库上，我们可以正常的进行读写操作。同时主节点的 恢复（recovery） 模式为 false。 1234567891011121314151617test&#x3D;# CREATE TABLE test (id BIGSERIAL PRIMARY KEY, name VARCHAR(255), age INT);CREATE TABLEtest&#x3D;# INSERT INTO test(name, age) VALUES(&#39;羊八井&#39;, 31), (&#39;杨景&#39;, 31);INSERT 0 2test&#x3D;# SELECT * FROM test; id | name | age ----+--------+----- 1 | 羊八井 | 31 2 | 杨景 | 31(2 行记录)test&#x3D;# select pg_is_in_recovery(); pg_is_in_recovery ------------------- f(1 行记录) 让我们再切换到从库，执行 SELECT * FROM test 查询语句可以看到之前在主库上写入的两条记录已被成功复制过来。 级联从节点1.. 按从节点的方式，停止数据库并使用 pg_basebackup 从 从节点 在线备份数据库到 $PGDATA 目录。 1234567891011121314[hldev@centos7-003 ~]$ sudo systemctl stop postgresql-9.6[hldev@centos7-003 ~]$ sudo su - postgres-bash-4.2$ cd $PGDATA-bash-4.2$ rm -rf *-bash-4.2$ &#x2F;usr&#x2F;pgsql-9.6&#x2F;bin&#x2F;pg_basebackup -D $PGDATA -Fp -Xs -v -P -h centos7-002 -U pgrepuser口令: pg_basebackup: initiating base backup, waiting for checkpoint to completepg_basebackup: checkpoint completed事务日志起始于时间点: 0&#x2F;501E7A0, 基于时间表1 pg_basebackup: 启动后台 WAL 接收进程30375&#x2F;30375 kB (100%), 1&#x2F;1 表空间 transaction log end point: 0&#x2F;501E848pg_basebackup: 等待后台进程结束流操作...pg_basebackup: base backup completed 2.. 配置 recovery.conf 运行参数。将 primary_conninfo 的 host 指定为从节点：centos7-002，同时添加恢复目标时间线 recovery_target_timeline 选项： 1234standby_mode &#x3D; &#39;on&#39;primary_conninfo &#x3D; &#39;host&#x3D;centos7-002 port&#x3D;5432 user&#x3D;pgrepuser password&#x3D;pgreppass&#39;trigger_file &#x3D; &#39;failover.now&#39;recovery_target_timeline &#x3D; &#39;latest&#39; 并设置 recovery.conf 文件其它用户不能读取 1-bash-4.2$ chmod 0600 recovery.conf 3.. 启动 级联从节点 ，并测试数据是否已同步。 123456789101112131415161718[hldev@centos7-003 ~]$ sudo systemctl start postgresql-9.6[hldev@centos7-003 ~]$ psql -h centos7-003 -U postgres -d test用户 postgres 的口令：psql (9.6.5)输入 &quot;help&quot; 来获取帮助信息.test&#x3D;# SELECT * FROM test; id | name | age ----+--------+----- 1 | 羊八井 | 31 2 | 杨景 | 31(2 行记录)test&#x3D;# select pg_is_in_recovery(); pg_is_in_recovery ------------------- t(1 行记录) 可以看到，级联从节点已正常的从 从节点 将数据同步过来。同时，我们还可以看到当前数据库处于 恢复（recovery） 模式。 数据库复制状态centos7-001 在主节点上，我们可以看到有一个复制节点连接上来，客户端地址（client_addr）为：192.168.124.162（centos7-002），使用流式复制（state），同步模式（sync_state）为异步复制。 1234567891011121314151617181920test&#x3D;# \\x扩展显示已打开。test&#x3D;# select * from pg_stat_replication;-[ RECORD 1 ]----+------------------------------pid | 1287usesysid | 16384usename | pgrepuserapplication_name | walreceiverclient_addr | 192.168.124.162client_hostname | client_port | 42338backend_start | 2017-09-20 10:08:37.842367+08backend_xmin | state | streamingsent_location | 0&#x2F;501EB20write_location | 0&#x2F;501EB20flush_location | 0&#x2F;501EB20replay_location | 0&#x2F;501EB20sync_priority | 0sync_state | async centos7-002 而在从节点上看到也有一个复制节点连接上来，客户端地址（client_addr）为：192.168.124.163（centos7-003），使用流式复制（state），同步模式（sync_state）为异步复制。 1234567891011121314151617181920test&#x3D;# \\x扩展显示已打开。test&#x3D;# select * from pg_stat_replication;-[ RECORD 1 ]----+------------------------------pid | 1224usesysid | 16384usename | pgrepuserapplication_name | walreceiverclient_addr | 192.168.124.163client_hostname | client_port | 53276backend_start | 2017-09-20 11:12:40.906493+08backend_xmin | state | streamingsent_location | 0&#x2F;501EC00write_location | 0&#x2F;501EC00flush_location | 0&#x2F;501EC00replay_location | 0&#x2F;501EC00sync_priority | 0sync_state | async 主/备切换1.. 关闭主节点数据库服务： 1[hldev@centos7-001 ~]$ sudo systemctl stop postgresql-9.6 2.. 将从节点（centos7-002）变为主节点 1-bash-4.2$ &#x2F;usr&#x2F;pgsql-9.6&#x2F;bin&#x2F;pg_ctl promote -D $PGDATA 此时在节点 centos7-002 上，PostgreSQL数据库已经从备节点转换成了主节点。同时，recovery.conf 文件也变为了 recovery.done 文件，表示此节点不再做为从节点进行数据复制。 12345678910111213test&#x3D;# select pg_is_in_recovery();-[ RECORD 1 ]-----+--pg_is_in_recovery | ftest&#x3D;# DELETE FROM test WHERE id &#x3D; 1;DELETE 1test&#x3D;# SELECT * FROM test; id | name | age ----+------+----- 2 | 杨景 | 31(1 行记录) 3.. 将原主节点（centos7-001）变为级联从节点（当前主节点已改为centos7-002）。 在 centos7-001 节点上编辑 postgresql.conf，并开启热备模式： 1hot_standby &#x3D; on 添加并编辑 recovery.conf 文件： 1234standby_mode &#x3D; &#39;on&#39;primary_conninfo &#x3D; &#39;host&#x3D;centos7-003 port&#x3D;5432 user&#x3D;pgrepuser password&#x3D;pgreppass&#39;trigger_file &#x3D; &#39;failover.now&#39;recovery_target_timeline &#x3D; &#39;latest&#39; （重）启动PostgreSQL数据库，节点 centos7-001 现在成为了一个 级联从节点 。 总结PostgreSQL官方支持基于流式复制的WAL实现的主/热备高可用集群机制，同时我们还可以搭配 PgPool-II 在应用层实现","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"postgresql","slug":"bigdata/postgresql","permalink":"https://yangbajing.github.io/categories/bigdata/postgresql/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://yangbajing.github.io/tags/postgresql/"},{"name":"集群","slug":"集群","permalink":"https://yangbajing.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"cluster","slug":"cluster","permalink":"https://yangbajing.github.io/tags/cluster/"}]},{"title":"学习Scala：环境、工具、工程","slug":"学习scala：环境、工具、工程","date":"2017-09-13T05:04:39.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/09/13/学习scala：环境、工具、工程/","link":"","permalink":"https://yangbajing.github.io/2017/09/13/%E5%AD%A6%E4%B9%A0scala%EF%BC%9A%E7%8E%AF%E5%A2%83%E3%80%81%E5%B7%A5%E5%85%B7%E3%80%81%E5%B7%A5%E7%A8%8B/","excerpt":"","text":"在本章中，你将学到如何从零使用Sbt来搭建一个Scala工程，如何将Scala工程导入Intellij IDEA集成开发环境。同时，我们将使用scalatest以TDD的方式来编写代码。 本章的要点包括： 下载并使用sbt: http://www.scala-sbt.org/ 使用Intellij IDEA编写Scala：https://www.jetbrains.com/idea/ 使用scalatest进行测试驱动的开发：http://www.scalatest.org/ 安装Sbt在官网 http://www.scala-sbt.org/download.html 提供了 sbt 的下载，因为网络原因，很有可能下载失败。这里您可以使用华龙海数公司提供的链接下载：https://file.hualongdata.com/sbt-0.13.16.tgz 。 下载后解压并设置系统环境变量，SBT 就安装好了。 Linux/Unix/Mac 1tar zxf sbt-0.13.16.tgz -C ~&#x2F; 添加如下内容到 ~/.bash_profile： 12export SBT_HOME&#x3D;&quot;$HOME&#x2F;sbt&quot;export PATH&#x3D;$SBT_HOME&#x2F;bin:$PATH 注：若不想重启系统的话，请在终端执行命令使配置生效：. ~/.bash_profile。 Windows Windows 安装见官方文档：http://www.scala-sbt.org/1.x/docs/zh-cn/Installing-sbt-on-Windows.html。对应的，你也可以通过华龙海数公司提供的链接下载：*https://file.hualongdata.com/sbt-0.13.16.tgz*。 建立Scala SBT工程建立工程配置文件 12345678910111213mkdir scala-startercd scala-startermkdir projectecho &quot;sbt.version &#x3D; 1.0.0&quot; &gt; project&#x2F;build.propertiesecho &#39;name :&#x3D; &quot;scala-starter&quot;scalaVersion :&#x3D; &quot;2.12.3&quot;libraryDependencies ++&#x3D; Seq( &quot;org.scalatest&quot; %% &quot;scalatest&quot; % &quot;3.0.1&quot; % Test)&#39; &gt; build.sbt 对于一个Scala工程项目，配置文件非常的简单。你只需要设置 build.sbt 和 project/build.properties 两个文件即可。在build.sbt文件配置项目选项，如：名称、Scala版本、库依赖……。在project/build.properties文件指定用于构建使用的Sbt具体版本。 在build.sbt文件内，我们只指定了3个配置选项： name 项目的名字 scalaVersion 编译此项目使用的Scala版本 libraryDependencies 依赖的第3方库 让我们在终端输入 sbt 命令（你需要按上一节的方式安装好SBT），当看到如下界面就代表Scala工程项目建立成功。 123456789101112$ sbt[info] Loading settings from idea.sbt ...[info] Loading global plugins from &#x2F;opt&#x2F;local&#x2F;share&#x2F;sbt&#x2F;1.0&#x2F;plugins[info] Updating &#123;file:&#x2F;home&#x2F;yangjing&#x2F;.sbt&#x2F;1.0&#x2F;plugins&#x2F;&#125;global-plugins...[info] Done updating.[info] Loading project definition from &#x2F;home&#x2F;yangjing&#x2F;workspace&#x2F;learning-scala-book&#x2F;codes&#x2F;scala-starter&#x2F;project[info] Updating &#123;file:&#x2F;home&#x2F;yangjing&#x2F;workspace&#x2F;learning-scala-book&#x2F;codes&#x2F;scala-starter&#x2F;project&#x2F;&#125;scala-starter-build...[info] Done updating.[info] Loading settings from build.sbt ...[info] Set current project to scala-starter (in build file:&#x2F;home&#x2F;yangjing&#x2F;workspace&#x2F;learning-scala-book&#x2F;codes&#x2F;scala-starter&#x2F;)[info] sbt server started at 127.0.0.1:4751sbt:scala-starter&gt; 注：你所看到的信息可能略有不同，因为可能安装了不同的插件及在不同的目录。 让我们在sbt控制台中输入 console 命令，先来试试Scala语言。 使用IDEA开发首先需要安装 IDEA 的Scala插件。 选择刚才建立好的 scala-starter 项目根目录： 使用 SBT 方式导入项目： 选中 *Use SBT shell for build and import(requires sbt 0.13.5+)*，并点击 finish 完成： 待IDEA下载完依赖后就会打开 scala-starter 项目，显示如下： 这里，我们还没有任务Scala代码。按惯例，我们先来实现一个Scala版的 **hello, world!**。首先，我们需要建立Scala代码目录结构，可以在IDEA中创建目录，也可以通过命令行创建。这里，我们使用命令行来创建： 1mkdir -p src&#x2F;main&#x2F;scala 我们在IDEA中新建一个 Helloword 类。首先选中 src/main/scala 文件夹，点击鼠标右键，并选择新建 Scala class ，在 Name 输入框输入 scalastarter.Helloword ，在 Kind 输入框选择 Object 。如： 修改 Helloword 代码如下： 123object Helloword extends App &#123; println(&quot;Hello, Word!&quot;)&#125; 点击 object Helloword extends App &#123; 右侧的绿色箭头小图标来运行 Helloword 程序，将在 Run 窗口中显示运行结果： 至此，我们从命令行创建 Scala工程项目，导入到 IDEA，创建并运行 Helloword。我们走通了一个工程化的使用Scala编写 helloword 的全流程，感觉良好。 使用Scalatest在开发实践中，TDD（测试驱动开发）是一个很好的开始方式。当然，Scala对TDD有着良好的支持，依托IDEA的强大功能，我们可以方便、优雅的实践TDD。在Scala开发中，推荐使用 scalatest 来实践测试驱动开发。 首先，我们需要创建 src/test/scala 目录来放测试代码，这次我们直接在IDEA中创建目录。在IDEA左侧的 Project 视图的 src 文件夹上点鼠标右键新建目录 test/scala，现在工程的目录结构如下： 我们通过一个Scala类来演示scalatest的使用，这是一个很简单，但足以激发你的兴趣的类： 1234567891011121314151617class Friendships &#123; private var friendships = Map.empty[String, List[String]] def makeFriends(person1: String, person2: String): Unit = &#123; addFriend(person1, person2) &#125; def getFriendList(person: String): List[String] = Nil def isFriends(person: String, friend: String): Boolean = false false private def addFriend(person: String, friend: String): Unit = &#123; &#125;&#125; Friendships 是一个很简单的类，它保存了一个私有的Map[String, List[String]] 变量：friendships ，朋友关系。同时提供了3个函数来对朋友关系进行操作，它们分别是：获取某人的朋友列表、判断一个人是否是某人的朋友、添加一个人到某人的朋友列表中。现在3个函数都还没有真实的功能实现，不用急，先让我们把测试跑起来。通过 红灯 - 绿灯 - 重构 的形式来实现这些功能。 从IDEA打开的 Friendships.scala 代码上，把光标放到 Friendships 类里面，同时按 Ctrl + Shirt + T 键，IDEA会自动生成以 Test 结尾的单元测试类：FriendshipsTest.scala。这里选择超类为：org.scalatest.WordSpec，并勾上下边窗口列出的3个成员方式。 测试类 FriendshipsTest 代码如下： 123456789101112131415161718192021222324252627import org.scalatest.&#123;BeforeAndAfterAll, MustMatchers, WordSpec&#125;class FriendshipsTest extends WordSpec with BeforeAndAfterAll with MustMatchers &#123; private var friendships: Friendships = _ &quot;FriendshipsTest&quot; should &#123; &quot;getFriendList&quot; in &#123; friendships.getFriendList(&quot;羊八井&quot;) must not be empty &#125; &quot;isFriends&quot; in &#123; friendships.isFriends(&quot;羊八井&quot;, &quot;老猪&quot;) mustBe true &#125; &#125; // 这个方法在初始化阶段执行一次 override protected def beforeAll(): Unit = &#123; friendships = new Friendships() friendships.makeFriends(&quot;羊八井&quot;, &quot;大魔头&quot;) friendships.makeFriends(&quot;羊八井&quot;, &quot;老猪&quot;) friendships.makeFriends(&quot;羊八井&quot;, &quot;老高&quot;) &#125;&#125; 现在来运行下测试，两个测试方法 getFriendList 和 isFriends 都失败了。 接下来让我们来完善 Friendships 类，把每个方法的实现都加上正确的逻辑。 1234567891011121314151617181920212223242526class Friendships &#123; private var friendships = Map.empty[String, List[String]] def makeFriends(person1: String, person2: String): Unit = &#123; addFriend(person1, person2) &#125; def getFriendList(person: String): List[String] = friendships.getOrElse(person, Nil) def isFriends(person: String, friend: String): Boolean = friendships.get(person).exists(friends =&gt; friends.contains(friend)) private def addFriend(person: String, friend: String): Unit = &#123; if (!friendships.contains(person)) &#123; friendships = friendships.updated(person, List(friend)) &#125; else &#123; val friends = friendships(person) if (!friends.contains(friend)) &#123; friendships = friendships.updated(person, friend :: friends) &#125; &#125; &#125;&#125; 再次，运行 FriendshipsTest 测试，你将看到代表测试通过的绿色结果：All Tests Passed 总结这一章从无到有，介绍了Scala工程项目的开发和TDD的实践上手方式。希望可以从工程方面带领读者踏入Scala的生态之旅。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"learning scala","slug":"scala/learning-scala","permalink":"https://yangbajing.github.io/categories/scala/learning-scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"sbt","slug":"sbt","permalink":"https://yangbajing.github.io/tags/sbt/"},{"name":"idea","slug":"idea","permalink":"https://yangbajing.github.io/tags/idea/"}]},{"title":"使用Sphinx撰写电子文档","slug":"使用sphinx撰写电子文档","date":"2017-09-12T03:50:12.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/09/12/使用sphinx撰写电子文档/","link":"","permalink":"https://yangbajing.github.io/2017/09/12/%E4%BD%BF%E7%94%A8sphinx%E6%92%B0%E5%86%99%E7%94%B5%E5%AD%90%E6%96%87%E6%A1%A3/","excerpt":"","text":"在日常工作中，写电子文档是个很普遍的事情。之前一直用Microsoft Word、Libreoffice Writer来写，但总感觉不方便，很多的精力都浪费在了调整格式上。而使用 Sphinx 来写电子文档，则可以把你从调整格式的泥潭中解放出来。Sphinx 是一款基于 Python的文档处理工具，Python官方的文档就是使用它来写的。Sphinx 使用reStructuredText 格式来定义文档，它比 Markdown 功能更强大，且不失轻便与灵活。 Sphinx 安装Python安装 Python的安装非常简单，在官网下载对应系统版本的Python：https://www.python.org/downloads/，按官方安装文档步骤即可。 Sphinx安装 Sphinx的安装非常简单，在系统安装好 Python 的情况下直接使用 pip来安装（Sphinx同时支持Py2和Py3）。 1pip install Sphinx Sphinx 简单使用Sphinx 有一个 sphinx-quickstart 命令可以让我们很方便的从零开始创建一个 Sphinx 文档项目。sphinx-quickstart 命令执行后会问我们一些项目相关的问题，按提示输入即可。这里推荐选择 imgmath: include math, rendered as PNG or SVG images，因为很多时候生成的文档很有可能是在内网访问，而 mathjax 会在互联网上下载渲染数据公式的JS脚本，很影响加载时间或造成根本就下载不下来。 Sphinx 文档项目创建好后，目录结构如下： 1234567891011.├── build├── make.bat├── Makefile└── source ├── conf.py ├── index.rst ├── _static └── _templates4 directories, 4 files 对于 Sphinx 的使用教程，网上有很多。这里推荐一些： 使用 sphinx 制作简洁而又美观的文档 Sphinx 使用手册 用Sphinx编写技术文档 写最好的文档：Sphinx + Read the Docs 关于中文Sphinx是通过latex来生成PDF的，所以要解决PDF中文乱码问题就要从latex着手。作者使用了Google Noto字体，这个字体在现代Linux系统都可以从源直接安装，Windows/Mac 系统用户请从 Google Noto 字体官方寻找安装手册。修改 source/conf.py 文件的 latex_elements 配置的 preamble 选项如下： 123456789101112 &#x27;preamble&#x27;: &#x27;&#x27;&#x27;\\\\usepackage&#123;xeCJK&#125;\\\\usepackage&#123;indentfirst&#125;\\\\setlength&#123;\\\\parindent&#125;&#123;2em&#125;\\\\setCJKmainfont&#123;Noto Serif CJK SC&#125;\\\\setCJKmonofont[Scale=0.9]&#123;Noto Sans Mono CJK SC&#125;\\\\setCJKfamilyfont&#123;song&#125;&#123;Noto Sans CJK SC&#125;\\\\setCJKfamilyfont&#123;sf&#125;&#123;Noto Sans CJK SC&#125;&#x27;&#x27;&#x27;使用如下步骤编译PDF文件（注意：这里需要运行两次`xelatex *.tex` 才能生成正常的带目录索引的PDF文档）： make latexcd build/latex/xelatex *.texxelatex *.tex 生成的PDF文件名为： **sphinx.pdf**。 xelatex 需要安装 **texlive**，***注意：不要使用Linux源里的texlive，一定要使用官方的发行版（DVD）***。下载地址：[http://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/](http://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/) 。 ## 总结 最后，我写了一个Sphinx文档模板 **Sphinx 文档起步**，放在Github上。 [https://github.com/yangbajing/sphinx-doc-starter](https://github.com/yangbajing/sphinx-doc-starter)。这是一个配置好的支持生成中文PDF 的Sphinx文档项目模板，朋友们可以这个项目做为起步，一步一步构建自己的Sphinx电子文档。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"Sphinx 撰写 电子文档","slug":"Sphinx-撰写-电子文档","permalink":"https://yangbajing.github.io/tags/Sphinx-%E6%92%B0%E5%86%99-%E7%94%B5%E5%AD%90%E6%96%87%E6%A1%A3/"}]},{"title":"Elasticsearch集群设置","slug":"elasticsearch集群设置","date":"2017-04-12T15:11:11.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/04/12/elasticsearch集群设置/","link":"","permalink":"https://yangbajing.github.io/2017/04/12/elasticsearch%E9%9B%86%E7%BE%A4%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"Elasticsearch是一个优秀的全文检索和分析引擎，由Shay Banon发起的一个开源搜索服务器项目，2010年2月发布。具有分布式性质和实时功能。 本文基于5.x版本，需要使用 Java 8 update 20或更新版。 配置Elasticsearch使用很方便，默认开箱即用。不过做为一个集群，还是需要稍做一些配置。整个配置都位于 config 目录，可以看到两个文件：elasticsearch.yml和logging.yml，分别是Elasticsearch服务配置文件和日志配置文件。 elasticsearch.yml设置服务的默认配置值，但因为设置可在运行时更改，所以这里的值可能并不是服务运行中实际的设置参数。但有两个值在运行时是不能更改的，分别：cluster.name和node.name。 cluster.name: 保存集群的名字，不同的集群用名字来区分，设置成相同名字的各个节点将开成一个集群。 node.name: 节点实例的名字，可以不用设置，服务启动时将自动选择一个唯一的名字。不过需要注意的是，每次服务启动时选择的，所以在每次重启后名字可能都不一样。若需要在API中提及具体实例名或者用监控工具查看具体节点时，自定义一个名字还是很有帮助的。 discovery.zen.ping.unicast.hosts: 集群发现，这里设置Elasticsearch启动时用以连接获取集群信息的服务地址列表。这里我们可以把集群内节点的IP地址或hostname填入即可。 除了集群相关配置，我们还应该修改 path.* 配置项： path.data: 持久化数据存储位置 path.logs: 日志存储位置 系统需求Elasticsearch在建立索引，尤其是在有很多分片和副本的情况下将会创建很多文件。需要修改系统对打开文件描述符的限制，推荐设置为大于32000个。在Linux系统上，一般在 /etc/security/limits.conf 目录修改。 1234root soft nofile 65535root hard nofile 65535* soft nofile 65535* hard nofile 65535","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"elasticsearch","slug":"bigdata/elasticsearch","permalink":"https://yangbajing.github.io/categories/bigdata/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://yangbajing.github.io/tags/elasticsearch/"},{"name":"cluster","slug":"cluster","permalink":"https://yangbajing.github.io/tags/cluster/"}]},{"title":"使用HanLP增强Elasticsearch分词功能","slug":"使用hanlp增强elasticsearch分词功能","date":"2017-04-12T07:17:12.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/04/12/使用hanlp增强elasticsearch分词功能/","link":"","permalink":"https://yangbajing.github.io/2017/04/12/%E4%BD%BF%E7%94%A8hanlp%E5%A2%9E%E5%BC%BAelasticsearch%E5%88%86%E8%AF%8D%E5%8A%9F%E8%83%BD/","excerpt":"","text":"hanlp-ext 插件源码地址：https://github.com/hualongdata/hanlp-ext Elasticsearch 默认对中文分词是按“字”进行分词的，这是肯定不能达到我们进行分词搜索的要求的。官方有一个 SmartCN 中文分词插件，另外还有一个 IK 分词插件使用也比较广。但这里，我们采用 HanLP 这款 自然语言处理工具 来进行中文分词。 ElasticsearchElasticsearch 的默认分词效果是惨不忍睹的。 1234GET &#x2F;_analyze?pretty&#123; &quot;text&quot; : [&quot;重庆华龙网海数科技有限公司&quot;]&#125; 输出： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;重&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 1, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;庆&quot;, &quot;start_offset&quot;: 1, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;华&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 3, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 2 &#125;, &#123; &quot;token&quot;: &quot;龙&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 3 &#125;, &#123; &quot;token&quot;: &quot;网&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 4 &#125;, &#123; &quot;token&quot;: &quot;海&quot;, &quot;start_offset&quot;: 5, &quot;end_offset&quot;: 6, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 5 &#125;, &#123; &quot;token&quot;: &quot;数&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 6 &#125;, &#123; &quot;token&quot;: &quot;科&quot;, &quot;start_offset&quot;: 7, &quot;end_offset&quot;: 8, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 7 &#125;, &#123; &quot;token&quot;: &quot;技&quot;, &quot;start_offset&quot;: 8, &quot;end_offset&quot;: 9, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 8 &#125;, &#123; &quot;token&quot;: &quot;有&quot;, &quot;start_offset&quot;: 9, &quot;end_offset&quot;: 10, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 9 &#125;, &#123; &quot;token&quot;: &quot;限&quot;, &quot;start_offset&quot;: 10, &quot;end_offset&quot;: 11, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 10 &#125;, &#123; &quot;token&quot;: &quot;公&quot;, &quot;start_offset&quot;: 11, &quot;end_offset&quot;: 12, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 11 &#125;, &#123; &quot;token&quot;: &quot;司&quot;, &quot;start_offset&quot;: 12, &quot;end_offset&quot;: 13, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 12 &#125; ]&#125; 可以看到，默认是按字进行分词的。 elasticsearch-hanlpHanLP HanLP 是一款使用 Java 实现的优秀的，具有如下功能： 中文分词 词性标注 命名实体识别 关键词提取 自动摘要 短语提取 拼音转换 简繁转换 文本推荐 依存句法分析 语料库工具 安装 elasticsearch-hanlp（安装见：https://github.com/hualongdata/hanlp-ext/tree/master/es-plugin）插件以后，我们再来看看分词效果。 12345GET &#x2F;_analyze?pretty&#123; &quot;analyzer&quot; : &quot;hanlp&quot;, &quot;text&quot; : [&quot;重庆华龙网海数科技有限公司&quot;]&#125; 输出： 123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;重庆&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;ns&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;华龙网&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;nr&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;海数&quot;, &quot;start_offset&quot;: 5, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;nr&quot;, &quot;position&quot;: 2 &#125;, &#123; &quot;token&quot;: &quot;科技&quot;, &quot;start_offset&quot;: 7, &quot;end_offset&quot;: 9, &quot;type&quot;: &quot;n&quot;, &quot;position&quot;: 3 &#125;, &#123; &quot;token&quot;: &quot;有限公司&quot;, &quot;start_offset&quot;: 9, &quot;end_offset&quot;: 13, &quot;type&quot;: &quot;nis&quot;, &quot;position&quot;: 4 &#125; ]&#125; HanLP 的功能不止简单的中文分词，有很多功能都可以集成到 Elasticsearch 中。 心动不如行动：https://github.com/hualongdata/hanlp-ext。","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"elasticsearch","slug":"bigdata/elasticsearch","permalink":"https://yangbajing.github.io/categories/bigdata/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://yangbajing.github.io/tags/elasticsearch/"},{"name":"hanlp","slug":"hanlp","permalink":"https://yangbajing.github.io/tags/hanlp/"}]},{"title":"Akka HTTP 快速上手","slug":"akkahttp快速上手","date":"2017-04-10T11:53:50.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/04/10/akkahttp快速上手/","link":"","permalink":"https://yangbajing.github.io/2017/04/10/akkahttp%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/","excerpt":"","text":"Akka Http 是Akka社区提供的一个 Http服务端/客户端通用工具包，支持 Http 1.0/1.1标准及WebSocket，现在 Http 2 的支持也在紧锣密鼓的实现中。 这篇文章将介绍Akka HTTP Server，我们将介绍Akka Http的常用功能模块及使用方式。Akka Http提供了一套强大、易用、易扩展的route dsl来构建路由。Akka Http Client因还不支持超时功能，现在不建议在产品中使用。 本文代码：akka-http-starter 第一个服务我们可以从官方提供的 HttpApp 特质开始，它提供了快捷的方式来启动一个Akka HTTP Server。 123456789class WebServer extends HttpApp &#123; def route: Route = path(&quot;hello&quot;) &#123; get &#123; import akka.http.scaladsl.marshallers.xml.ScalaXmlSupport._ complete(&lt;h1&gt;Say hello to akka-http&lt;/h1&gt;) &#125; &#125;&#125; path(&quot;hello&quot;)定义了一个HTTP访问路由，get代表这个路由提供了GET请示，而complete涵数允许我们提供响应结果来完成这个路由定义，这里我们返回了一段文本。Akka Http的路由看起来向声明式的，以一直新颖而又直观的方式来定义HTTP服务。 用户第一次接触这种涵数套涵数（又像树型结构）的代码方式可能不大习惯，其实我们可以换种方式来实现这段代码： 12345def traditionRoute: Route = &#123; val respResult = complete(&quot;result&quot;) // 响应结果 val hPath = path(&quot;hello&quot;) // 绑定的HTTP访问路径 hPath(get(result)) &#125; 路径(Http方法(结果))，我们用Java式的风格来实现同样的功能。这样是不是更符合你对代码的预期？ 让我们来启动服务： StartBoot01.scalaStartBoot01.scala123456object StartBoot01 &#123; def main(args: Array[String]): Unit = &#123; val server = new WebServer server.startServer(&quot;0.0.0.0&quot;, 8888) &#125;&#125; 通过curl命令来测试下我们的第一个Akka HTTP服务（-i选项可以打印HTTP响应头）： 12345678curl -i http:&#x2F;&#x2F;localhost:8888&#x2F;helloHTTP&#x2F;1.1 200 OKServer: akka-http&#x2F;10.0.5Date: Fri, 31 Mar 2017 17:05:12 GMTContent-Type: text&#x2F;html; charset&#x3D;UTF-8Content-Length: 31&lt;h1&gt;Say hello to akka-http&lt;&#x2F;h1&gt; RouteAkka HTTP 提供了一个灵活的DSL，它有很多可组合的元素（Directive 指令）以简洁、易读的方式来构建服务。让我们来看下面这个示例： 12345678path(&quot;book&quot;) &#123; get &#123; parameters(&#x27;name.as[Option[String]], &#x27;isbn.as[Option[String]], &#x27;author.as[Option[String]]) &#123; (maybeName, maybeIsbn, maybeAuthor) =&gt; complete(s&quot;name: $maybeName, isbn: $maybeIsbn, author: $maybeAuthor&quot;) &#125; &#125;&#125; 对于上面这个定义，类似的 Play 路由定义如： 1GET &#x2F;book controller.Page.book(name: Option[String], isbn: Option[String], author: Option[String) 我们可以看到，对一个API路由的定义拆成了几个函数嵌套的形式。path指定访问路径，get决定这个API提供HTTP GET服务，parameters可以抽取请求参数，而complete将一个字符串返回给前端。 JSON现在大部分的服务都提供JSON格式的数据，Akka HTTP提供了 Mashaller/Unmashaller机制，用户可以基于此灵活的定制自己的序列化/反序列化方式。这里我们使用 Jackson 来解析/处理 JSON。 首选，我们实现自定义的 Mashaller/Unmashaller： JacksonSupport.scalaJacksonSupport.scala123456789101112131415161718192021222324252627trait JacksonSupport &#123; private val jsonStringUnmarshaller = Unmarshaller.byteStringUnmarshaller .forContentTypes(MediaTypes.`application/json`) .mapWithCharset &#123; case (ByteString.empty, _) =&gt; throw Unmarshaller.NoContentException case (data, charset) =&gt; data.decodeString(charset.nioCharset.name) &#125; // HTTP entity =&gt; `A` implicit def unmarshaller[A]( implicit ct: ClassTag[A], objectMapper: ObjectMapper = Jackson.defaultObjectMapper ): FromEntityUnmarshaller[A] = jsonStringUnmarshaller.map( data =&gt; objectMapper.readValue(data, ct.runtimeClass).asInstanceOf[A] ) // `A` =&gt; HTTP entity implicit def marshaller[A]( implicit objectMapper: ObjectMapper = Jackson.defaultObjectMapper ): ToEntityMarshaller[A] = &#123; JacksonHelper.marshaller[A](objectMapper) &#125;&#125; 实现自定义的 Marshaller/Unmarshaller 后，我们就可以在 Akka HTTP 中提供 Json 支持了。 PageRoute.scalaPageRoute.scala123456789101112131415161718import akka.http.scaladsl.server.Directives._import akka.http.scaladsl.server.Routeimport starter.akka.http.json.JacksonSupport._case class PageInput(title: String, content: String)class PageRoute &#123; def route: Route = path(&quot;page&quot;) &#123; post &#123; entity(as[PageInput]) &#123; pageInput =&gt; complete(pageInput) &#125; &#125; &#125;&#125; Akka HTTP使用了Scala的隐式转换特性来自定义数据序列化，这是一个非侵入式的设计，用户可以在每个模块选择自己的数据序列化方式。 Route类型Route 是 Akka HTTP 路由 DSL 里的核心概念，用它构建的所有结构，不管是一条线还是很多条线组成，它们都会是这个类型的实例。 1type Route = RequestContext =&gt; Future[RouteResult] 组合路由 Akka HTTP 提供3个基本的操作来让我们创建更复杂的路由链： 路由转换：它代理一个“内部”的路由，并在这个过程中改变一些请求传入的属性，然后传出响应或两者。 路由过滤：只允许满足给定条件的请求被传递，并拒绝所有其它访问请求。 路由链：如果第一个请求被拒绝，将尝试第二个路由。使用 ~ 操作符连接多个路由定义。 Akka HTTP 实现了很多默认的指令 akka.http.scaladsl.server.Directives._ ，你也可以很轻松地创建自己的指令。指令提供了强大和灵活的方式来构建 Akka HTTP。 路由树 当通过嵌套和操作符组合指令和自定义路径时，将构建一个路由结构并形成一颗树。当一个 HTTP 请求进来，它将从根进行这颗树，并以深度优先的方式流过所有分支，直到某个节点完成或全部被拒绝为止。 123456789101112131415val route = a &#123; b &#123; c &#123; ... // route 1 &#125; ~ d &#123; ... // route 2 &#125; ~ ... // route 3 &#125; ~ e &#123; ... // route 4 &#125; &#125; 这里由5个指令构建了一个路由树： 当 a, b, c都通过，才到到达路由 1 当 a 和 b 通过，但 c 被拒绝且 d 通过，将到达路由 2 当 a 和 b 通过，但 c 和 d 被拒绝，路由 3 被到达 若路由 3 前面的请求都被拒绝，则它将“捕获”所有请求。这个机制使复杂的过滤逻辑可以很容易的实现。把简单和最具体的放在顶端，一般和普通的放到最后。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"}]},{"title":"使用Ambari2.5（HDP2.6）搭建大数据环境","slug":"使用ambari2-5（hdp2-6）搭建大数据环境","date":"2017-04-06T01:12:59.000Z","updated":"2017-09-04T06:12:59.000Z","comments":true,"path":"2017/04/06/使用ambari2-5（hdp2-6）搭建大数据环境/","link":"","permalink":"https://yangbajing.github.io/2017/04/06/%E4%BD%BF%E7%94%A8ambari2-5%EF%BC%88hdp2-6%EF%BC%89%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/","excerpt":"","text":"本文介绍在 CentOS 7 环境下使用 Ambari2.5 (HDP2.6) 搭建大数据环境。 推荐使用如下脚本将 Ambari/HDP 相关软件包下到本地后配置 yum 源安装，在线安装速度太慢会经常遇到包找不到情况。 12345wget -c http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.1.0/ambari-2.5.1.0-centos7.tar.gz \\ http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.1.0/ambari.repo \\ http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.1.0/hdp.repo \\ http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.1.0/HDP-2.6.1.0-centos7-rpm.tar.gz \\ http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7/HDP-UTILS-1.1.0.21-centos7.tar.gz CentOS 准备安装CentOS 7 安装时设置静态IP 关闭Kdump 关闭Selinux 使用最小化安装 安装相关软件包挂载系统镜像 12mkdir /media/CentOSmount /dev/sr0 /media/CentOS 编辑 /etc/yum.repos.d/CentOS-Media.repo 启用本地存储库，修改 enabled 为 1 。 12yum install postgresql-server postgresql-contrib vim ntp unzip 安装前设置SSH免密码登录使用root账号登录 Ambari Server 主机并生成SSH私钥： 1ssh-keygen 添加`authorized_keys文件： 12cd ~/.sshcat id_rsa.pub &gt;&gt; authorized_keys 修改 ~/.ssh 目录 和 ~/.ssh/authorized_keys 文件系统权限（注意：~/.ssh/authorized_keys文件权限必需为600，不然免密码登录将失效）： 12chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 将 authorized_keys 文件其复制到所有 Ambari Agent 主机（注意：有可能需要在Agent主机上创建 .ssh 目录）： 1scp ~/.ssh/authorized_keys root@&lt;remote.target.host&gt;:~/.ssh/ （请将 &lt;remote.target.host&gt; 替换为集群中每台 Ambari Agent 主机地址） 验证每台主机免密码登录是否成功 1ssh root@&lt;remote.target.host&gt; 设置 NTP123yum install -y ntpsystemctl enable ntpdsystemctl start ntpd 关闭系统防火墙12systemctl disable firewalldservice firewalld stop SELinux、PackageKit、umask编辑 /etc/sysconfig/selinux ，设置SELINUX=disabled。 1echo umask 0022 &gt;&gt; /etc/profile 设置网络（DNS和NSCD）所有节点都要设置。ambari在安装时需要配置全域名，所以需要检查DNS。为了减轻DNS的负担, 建议在节点里用 Name Service Caching Daemon (NSCD) 12345678910vim &#x2F;etc&#x2F;hosts192.168.124.151 ambari001192.168.124.152 ambari002192.168.124.153 ambari003vim &#x2F;etc&#x2F;sysconfig&#x2F;networkNETWORKING&#x3D;yesHOSTNAME&#x3D;ambari001 本地 ambari/hdp yum源设置将 ambari.repo 和 hdp.repo 文件入到 /etc/yum.repo.d/ 目录，并将 192.168.32.101 地址替换成你实际的本地 yum 服务地址。 我们可以使用 Nginx 来搭建 yum 服务，只需要注意相映路径即可。 安装nginx 1234567$ vim /etc/yum.repos.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/7/$basearch/gpgcheck=0enabled=1 ambari.repo 12345678#VERSION_NUMBER&#x3D;2.5.0.3-7[ambari-2.5.0.3]name&#x3D;ambari Version - ambari-2.5.0.3baseurl&#x3D;http:&#x2F;&#x2F;192.168.32.101&#x2F;ambari&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.5.0.3gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.32.101&#x2F;ambari&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.5.0.3&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1 hdp.repo 1234567891011121314151617#VERSION_NUMBER&#x3D;2.6.0.3-8[HDP-2.6.0.3]name&#x3D;HDP Version - HDP-2.6.0.3baseurl&#x3D;http:&#x2F;&#x2F;192.168.32.101&#x2F;HDP&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.6.0.3gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.32.101&#x2F;HDP&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.6.0.3&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1[HDP-UTILS-1.1.0.21]name&#x3D;HDP-UTILS Version - HDP-UTILS-1.1.0.21baseurl&#x3D;http:&#x2F;&#x2F;192.168.32.101&#x2F;HDP-UTILS-1.1.0.21&#x2F;repos&#x2F;centos7gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.32.101&#x2F;HDP&#x2F;centos7&#x2F;2.x&#x2F;updates&#x2F;2.6.0.3&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1 安装独立PostgreSQL数据库（可选）12rpm -ivh https:&#x2F;&#x2F;download.postgresql.org&#x2F;pub&#x2F;repos&#x2F;yum&#x2F;9.6&#x2F;redhat&#x2F;rhel-7-x86_64&#x2F;pgdg-centos96-9.6-3.noarch.rpmsudo yum -y install postgresql96-server postgresql96-contrib 选择：**Enter advanced database configuration **，并选择 [4] - PostgreSQL。 设置默认schema 1set search_path to &quot;$user&quot;,ambari; 安装/设置 ambari-server为了一些不必要的麻烦，推荐关闭 selinux Install 1yum install ambari-server 配置 ambari-server 1ambari-server setup --jdbc-db=postgres --jdbc-driver=/home/software/postgresql-42.0.0.jar 使用 -j 选项指定 JAVA_HOME 目录，这里推荐使用 Oracle JDK 1.8，并配置 Java Cryptography Extension (JCE) 。若不指定 -j 选项，ambari-server 将自动下载配置了JCE的Oracle JDK 1.8版本。 一切使用默认配置即可，当看到以下输出就代表 Ambari Server 配置成功： 123...........Adjusting ambari-server permissions and ownership...Ambari Server &#39;setup&#39; completed successfully. 完整输出如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@ambari001 ~]# ambari-server setupUsing python /usr/bin/pythonSetup ambari-serverChecking SELinux...SELinux status is &#x27;disabled&#x27;Customize user account for ambari-server daemon [y/n] (n)? nAdjusting ambari-server permissions and ownership...Checking firewall status...Checking JDK...[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7[3] Custom JDK==============================================================================Enter choice (1): 3WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.Path to JAVA_HOME: /opt/local/jdkValidating JDK on Ambari Server...done.Completing setup...Configuring database...Enter advanced database configuration [y/n] (n)? yConfiguring database...==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle[3] - MySQL / MariaDB[4] - PostgreSQL[5] - Microsoft SQL Server (Tech Preview)[6] - SQL Anywhere[7] - BDB==============================================================================Enter choice (1): 4Hostname (localhost): 127.0.0.1Port (5432): Database name (ambari): Postgres schema (ambari): Username (ambari): Enter Database Password (bigdata): Configuring ambari database...Configuring remote database connection properties...WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-Postgres-CREATE.sqlProceed with configuring remote database connection properties [y/n] (y)? yExtracting system views...ambari-admin-2.5.1.0.159.jar...........Adjusting ambari-server permissions and ownership...Ambari Server &#x27;setup&#x27; completed successfully. 安装/配置/部署集群启动Ambari-server 1ambari-server start 打开浏览器登录网址：[http://192.168.32.112:8080](http://192.168.32.112:8080)（请使用你自己安装的 Ambari Server地址）。 使用默认用户名/密码 admin/admin 登录，之后你可以修改它。 登录后首先创建我们的第一个大数据集群，点击 Launch Install Wizard 按钮创建集群。 首先我们将需要给集群取一个名字，接下来将选择 HDP 的版本，这里我们选择 2.6 版本。 ***我们将使用本地源来安装 HDP ***，按图设置本地源地址： HDP-2.6: http://192.168.32.101/HDP/centos7/2.x/updates/2.6.0.3 HDP-UTILS-1.1.0.21: http://192.168.32.101/HDP-UTILS-1.1.0.21/repos/centos7","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"ambari/hdp","slug":"bigdata/ambari-hdp","permalink":"https://yangbajing.github.io/categories/bigdata/ambari-hdp/"}],"tags":[{"name":"ambari","slug":"ambari","permalink":"https://yangbajing.github.io/tags/ambari/"},{"name":"hdp","slug":"hdp","permalink":"https://yangbajing.github.io/tags/hdp/"},{"name":"centos7","slug":"centos7","permalink":"https://yangbajing.github.io/tags/centos7/"}]},{"title":"Cassandra设置","slug":"cassandra设置","date":"2017-04-01T04:29:41.000Z","updated":"2022-02-16T02:50:45.198Z","comments":true,"path":"2017/04/01/cassandra设置/","link":"","permalink":"https://yangbajing.github.io/2017/04/01/cassandra%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"操作系统修改操作系统的TCP keepalive 1sudo &#x2F;sbin&#x2F;sysctl -w net.ipv4.tcp_keepalive_time&#x3D;60 net.ipv4.tcp_keepalive_intvl&#x3D;60 net.ipv4.tcp_keepalive_probes&#x3D;5 集群机制一致性哈希 Gossip协议：用于在环内节点之间传播Cassandra状态信息 Snitch：支持多个数据中心 复制策略：数据的冗余生策略 commit log 进行写操作时，先把数据定入commit log 只有数据被写入commit log时，才算写入成功 当发生掉电、实例崩溃等问题时，可以使用commit log进行恢复 memtable 数据成功写入commit log后，就开始写入内存中的memtable memtable中的数据达到一定阈值后，开始把数据写入硬盘中的SSTable，然后在内存中重新建立一个memtable接收下一批数据 上述过程是非阻塞的 查询时优先查询memtable 副本因子—-控制数据的冗余份数 12CREATE KEYSPACE Excelsior WITH REPLICATION = &#123; &#x27;class&#x27; : &#x27;SimpleStrategy&#x27;, &#x27;replication_factor&#x27; : 3 &#125;;CREATE KEYSPACE Excalibur WITH REPLICATION = &#123;&#x27;class&#x27; : &#x27;NetworkTopologyStrategy&#x27;, &#x27;dc1&#x27; : 3, &#x27;dc2&#x27; : 2&#125;; 可调节的一致性写操作的Consistency LevelANY 任意一个节点写操作已经成功。如果所有的replica节点都挂了，写操作还是可以在记录一个hinted handoff事件之后，返回成功。如果所有的replica节点都挂了，写入的数据，在挂掉的replica节点恢复之前，读不到。 最小的延时等待，并且确保写请求不会失败。相对于其他级别提供最低的一致性和最高的可用性。 ALL 写操作必须将指定行的数据写到所有replica节点的commit log和memtable。 相对于其他级别提供最高的一致性和最低的可用性。 EACH_QUORUM 写操作必须将指定行的数据写到每个数据中心的quorum数量的replica节点的commit log和memtable。 用于多数据中心集群严格的保证相同级别的一致性。例如，如果你希望，当一个数据中心挂掉了，或者不能满足quorum数量的replica节点写操作成功时，写请求返回失败。 LOCAL_ONE 任何一个本地数据中心内的replica节点写操作成功。 对于多数据中心的情况，往往期望至少一个replica节点写成功，但是，又不希望有任何跨数据中心的通信。LOCAL_ONE正好能满足这样的需求。 LOCAL_QUORUM 本地数据中心内quorum数量的replica节点写操作成功。避免跨数据中心的通信。 不能和SimpleStrategy一起使用。用于保证本地数据中心的数据一致性。 LOCAL_SERIAL 本地数据中心内quorum数量的replica节点有条件地（conditionally）写成功。 用于轻量级事务（lightweight transaction）下实现linearizable consistency，避免发生无条件的（unconditional）更新。。 ONE 任意一个replica节点写操作已经成功。 满足大多数用户的需求。一般离coordinator节点具体最近的replica节点优先执行。 （即使指定了consistency level ON或LOCAL_QUORUM，写操作还是会被发送给所有的replica节点，包括其他数据中心的里replica节点。consistency level只是决定了，通知客户端请求成功之前，需要确保写操作成功的replica节点的数量。） 读操作的Consistency LevelALL 向所有replica节点查询数据，返回所有的replica返回的数据中，timestamp最新的数据。如果某个replica节点没有响应，读操作会失败。 相对于其他级别，提供最高的一致性和最低的可用性。 EACH_QUORUM 向每个数据中心内quorum数量的replica节点查询数据，返回时间戳最新的数据。 同LOCAL_QUORUM。 LOCAL_SERIAL 同SERIAL，但是只限制为本地数据中心。 同SERIAL。 LOCAL_QUORUM 向每个数据中心内quorum数量的replica节点查询数据，返回时间戳最新的数据。避免跨数据中心的通信。 使用SimpleStrategy时会失败。 LOCAL_ONE 返回本地数据中心内离coordinator节点最近的replica节点的数据。 同写操作Consistency level中该级别的用法。 ONE 返回由snitch决定的最近的replica返回的结果。默认情况下，后台会触发read repair确保其他replica的数据一致。 提供最高级别的可用性，但是返回的结果不一定最新。 QUORUM 读取所有数据中心中quorum数量的节点的结果，返回合并后timestamp最新的结果。 保证很强的一致性，虽然有可能读取失败。 SERIAL 允许读取当前的（包括uncommitted的）数据，如果读的过程中发现uncommitted的事务，则commit它。 轻量级事务。 TWO 返回两个最近的replica的最新数据。 和ONE类似。 THREE 返回三个最近的replica的最新数据。 和TWO类似。 关于QUORUM级别QUORUM级别确保数据写到指定quorum数量的节点。一个quorum的值由下面的公式四舍五入计算而得： 1(sum_of_replication_factors &#x2F; 2) + 1 sum_of_replication_factors 指每个数据中心的所有 replication_factor 设置的总和。 例如，如果某个单数据中心的replication factor是3，quorum值为2-表示集群可以最多容忍1个节点down。如果replication factor是6，quorum值为4-表示集群可以最多容忍2个节点down。如果是双数据中心，每个数据中心的replication factor是3，quorum值为4-表示集群可以最多容忍2个节点down。如果是5数据中心，每个数据中心的replication factor of 3，quorum值为8 。 如果想确保读写一致性可以使用下面的公式： 1(nodes_written + nodes_read) &gt; replication_factor 例如，如果应用程序使用QUORUM级别来读和写，replication factor 值为3，那么，该设置能够确保2个节点一定会被写入和读取。读节点数加上写写点数（4）个节点比replication factor （3）大，这样就能确保一致性。 应用开发Java批量查询、写入配置在使用 BatchStatement 进行插入操作时会发现，当数据量稍大以后数据库中并没有加入新的数据。这是因为Cassandra默认对批量操作的数据大小限制得比较低。我们将其修改即可。 123456# Log WARN on any batch size exceeding this value. 5kb per batch by default.# Caution should be taken on increasing the size of this threshold as it can lead to node instability.batch_size_warn_threshold_in_kb: 1000# Fail any batch exceeding this value. 50kb (10x warn threshold) by default.batch_size_fail_threshold_in_kb: 2000","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"cassandra","slug":"bigdata/cassandra","permalink":"https://yangbajing.github.io/categories/bigdata/cassandra/"}],"tags":[{"name":"cassandra","slug":"cassandra","permalink":"https://yangbajing.github.io/tags/cassandra/"}]},{"title":"Linux部署Oracle11G","slug":"linux部署oracle11g","date":"2016-10-30T14:40:09.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/10/30/linux部署oracle11g/","link":"","permalink":"https://yangbajing.github.io/2016/10/30/linux%E9%83%A8%E7%BD%B2oracle11g/","excerpt":"","text":"安装Oracle数据库本文基于RHEL6/Centos6/Neokylin6，其它发行版请注意区别。 安装依赖软件包 1sudo yum install binutils compat-libcap1 compat-libstdc++-33 compat-libstdc++-33.i686 gcc-c++ glibc glibc.i686 glibc-devel glibc-devel.i686 ksh libgcc libgcc.i686 libstdc++ libstdc++.i686 libstdc++-devel libstdc++-devel.i686 libaio libaio.i686 libaio-devel libaio-devel.i686 make sysstat unixODBC unixODBC.i686 unixODBC-devel unixODBC-devel.i686 elfutils-libelf-devel mksh 创建操作系统用户和组 查看/etc/oraInst.loc文件是否存在，不存在则创建： 1# more &#x2F;etc&#x2F;oraInst.loc 不存在则创建文件并保存如下内容： 12inventory_loc&#x3D;&#x2F;opt&#x2F;app&#x2F;oraInventoryinst_group&#x3D;oinstall 创建用户组 12sudo groupadd oinstallsudo groupadd dba 创建用户 1sudo useradd -g oinstall -G dba oracle 用户存在则修改用户： 1sudo usermod -g oinstall -G dba oracle 配置内核参数编辑/etc/sysct.conf文件，添加或修改如下配置： 1234567891011fs.aio-max-nr &#x3D; 1048576fs.file-max &#x3D; 6815744kernel.shmall &#x3D; 2097152kernel.shmmax &#x3D; 536870912kernel.shmmni &#x3D; 4096kernel.sem &#x3D; 250 32000 100 128net.ipv4.ip_local_port_range &#x3D; 9000 65500net.core.rmem_default &#x3D; 262144net.core.rmem_max &#x3D; 4194304net.core.wmem_default &#x3D; 262144net.core.wmem_max &#x3D; 1048576 编辑/etc/security/limits.conf文件，添加或修改如下配置： 123456* soft nofile 4996* hard nofile 65536* soft stack 10240* hard stack 32768* soft nproc 2047* hard nproc 16384 创建需要的目录123sudo mkdir -p &#x2F;opt&#x2F;app&#x2F;oraclesudo chown -R oracle:oinstall &#x2F;opt&#x2F;app&#x2F;sudo chmod -R 775 &#x2F;opt&#x2F;app&#x2F; 设置用户环境变量切换到oracle用户，编辑~/.bash_profile文件添加如下配置荐： 123456export ORACLE_BASE&#x3D;&quot;&#x2F;opt&#x2F;app&#x2F;oracle&quot;export ORACLE_UNQNAME&#x3D;DB11Gexport ORACLE_SID&#x3D;DB11Gexport ORACLE_HOME&#x3D;&quot;$ORACLE_BASE&#x2F;product&#x2F;11.2.0&#x2F;dbhome_1&quot;export LD_LIBRARY_PATH&#x3D;&quot;$ORACLE_HOME&#x2F;lib:$LD_LIBRARY_PATH&quot;export PATH&#x3D;&quot;$ORACLE_HOME&#x2F;bin:$PATH:$HOME&#x2F;bin&quot; 安装数据库为了使之前的配置生效，需要重启操作系统。使用oracle账号登录系统，并执行runInstaller命令安装Oracle11G数据库系统。 1.&#x2F;runInstaller 安装时注意事项 使用静态IP安装Oracle11G 若安装时报虚拟内存不足，可以挂一个文件做为虚拟内存： 创建一个1G大小的空白文件： 1sudo if&#x3D;&#x2F;dev&#x2F;zero bs&#x3D;&#x2F;opt&#x2F;swapfile bs&#x3D;1024k count&#x3D;1024 创建swap文件： 1sudo &#x2F;sbin&#x2F;mkswap swapfile 挂载swap文件： 1sudo swapon swapfile 本文介绍的Oracle数据库安装需要Linux图形界面支持。 在执行安装数据库步骤：17/20 检查 依赖项时提示某些程序包未找到，其实这里相应报已经安装。可以使用rpm -qa | grep &lt;package name&gt;命令查看，在确认已安装后可以全部忽略。 使用Oracle11G手动启动Oracle数据库启动数据库 12sqlplus &#x2F; as sysdba&gt; start 启动网络监听 1lsnrctl start 启动管理控制台 1emctl start dbconsole 用户管理创建用户 12create user 用户名 identified by 密码;alter user 用户名 account unlock; 授权 TODO 资源限制查看resource_limit参数： 1&gt; show parameter resource_limit 若为FALSE，则设置资源限制参数为TRUE： 1alter system set resource_limit = TRUE; 该改变对密码资源无效，密码资源总是可用的 创建PROFILE： 1&gt; create profile user_session_limit limit sessions_per_user 5; --最大连接数限制为5 将PROFILE指定给用户： 1&gt; alter user ydgwb profile sess;","categories":[{"name":"data","slug":"data","permalink":"https://yangbajing.github.io/categories/data/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"},{"name":"oracle","slug":"oracle","permalink":"https://yangbajing.github.io/tags/oracle/"},{"name":"neokylin","slug":"neokylin","permalink":"https://yangbajing.github.io/tags/neokylin/"}]},{"title":"Java/Scala互操作实践 1：基础操作","slug":"java-scala互操作实践 1：基础操作","date":"2016-10-10T03:32:12.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/10/10/java-scala互操作实践 1：基础操作/","link":"","permalink":"https://yangbajing.github.io/2016/10/10/java-scala%E4%BA%92%E6%93%8D%E4%BD%9C%E5%AE%9E%E8%B7%B5%201%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/","excerpt":"","text":"本文将以Spring Boot为例，介绍下实际工作中的Java/Scala互操作。在提高个人效率、满足自我追求的情况下更多的照顾到团队不同人的实际。同时也是想说明，在同一个工程里混用Java和Scala语言是可能的。 本文源代码在：http://git.oschina.net/hualongdata/spring-starter 对于Scala不熟悉的Java程序员可以先看看：《写给Java程序员的Scala入门教程》 对于Spring不了解的Scala程序员可以先看看：《Scala开发者的Spring-Boot快速上手指南 01》和《Scala开发者的Spring-Boot快速上手指南 02：Scala惯用法》 Java BeanJava Bean有个特点，就是对于可修改属性都会有对应的getter和setter方法（final属性将只有getter方法）。由Java定义的对象在Scala中可以直接使用，并无二样。而在Scala中定义Java Bean却有些不同。 其实在Scala中可以像Java一样来定义Java Bean： 1234567891011121314// Scala中默认为public访问权限，包括属性和方法class Person &#123; // 下划线在这里是一个占位符，它代码相应属性对应类型的默认值 private var id: Int = _ private var name: String = _; def getId: Int = id; def setId(id: Int) &#123; this.id = id &#125; def getName: String = name; def setName(name: String) &#123; this.name = name; &#125;&#125; 这样写的话，除了语法上与Java有些差别，其实定义的方式是一样的。但其实Scala提供了注解来自动生成getter和setter函数： 123456789import scala.beans.BeanPropertyclass Person &#123; @BeanProperty var id: Int = _ @BeanProperty var name: String = _ @BeanProperty val createdAt: LocalDateTime = _&#125; 除了使用传统的class，在Scala中还可以使用case class来定义POJO： 12345678case class SignRequest(@BeanProperty account: String &#x3D; null, @BeanProperty password: String &#x3D; null, @BeanProperty captcha: String &#x3D; null, @BeanProperty var smsCode: String &#x3D; null) case class的主构造函数声明的参数将同时做为SignRequest的履性，且是val的（类似Java的public final）。在这里，account、password和captcha将只生成getter函数。而smsCode将生成getter和setter函数，因为它使用var来修饰。 这里有一个Java里没有的特\u0005\u0006性：参数默认值，像C++、Python、ES6+ 一样，Scala的参数是可以设置默认值的。因为Java Bean规范要求类必需有参数为空的默认构造函数，而当case class的主构造函数所有参数都设置默认值后，在实例化这个类时将相当于拥有一个空的默认构造函数。 在Java中调用case class可见：com/hualongdata/springstarter/data/repository/UserRepositoryImpl.java。 基于注解的依赖注入在Spring开发中，依赖注入是很常用的一个特性\u0010。基于属性的注解注入在Java和Scala中都是一样的。但基于构造函数的依赖注入在Scala中有些特别，代码如下： 12345class SignController @Autowired()(userService: UserService, webUtils: WebUtils, hlTokenComponent: HlTokenComponent) &#123; ......&#125; 在Scala中，单注解作用于构造函数上时需要类似方法调用的形式：@Autowired()。又因为Scala中，主构造函数必需定义在类名之后的小括号内，所以注解需要紧跟在类名之号，主构造函数左括号之前。 在Scala中使用主构造函数的注入组件是一个更好的实践，它同时拥有注入的\u0005组件为private final访问权限。相同效果的Java代码需要更多： 1234567891011public SignController &#123; private final UserService userService; private final WebUtils webUtils; private final HlTokenComponent hlTokenComponent; public SignController(UserService userService, WebUtils webUtils, HlTokenComponent hlTokenComponent) &#123; this.userService = userService; this.webUtils = webUtils; this.hlTokenComponent = hlTokenComponent; &#125;&#125; 可以看到，Scala的版本代码量更少，同时看起来更简洁。 注解参数数组参数 1234@RestController@RequestMapping(Array(&quot;/sign&quot;))class SignController @Autowired()(userService: UserService, ...... 在Scala中，对于注解的数组参数当只设置一个元素时是不能像Java一样贱一个字符串的，必需显示的定义一个数组。 参数值必需为常量 在Scala中，当为注解的某个参数贱值时必需使用常量，像：@RequestMapping(Array(Constants.API_BASE + &quot;/sign&quot;))这样的形式都是非法的。只能像这样贱值：@RequestMapping(Array(&quot;/aip/sign&quot;)) 变长参数在Scala中变长参数通过星号(*)来定义，代码如下： 1def log(format: String, value: String*) 但是这样定义出来的变参在Java中是不能访问的，因为Scala默认实现中value的类型为: Seq[Any]，而Java中的变参类型实际上是一个数组（\u0005String[]）。要解决这个问题非常简单，在函数定义前加上scala.annotation.varargs注解就可以强制Scala使用Java的实现来实现变长参数。 集合库Scala有自己的一套集合库实现：\u0005scala.collection，分为不可变集合scala.collection.immutable和可变集合scala.collection.mutable。两者都实现了很多高阶函数，可以简化日常编程，同时Scala中推荐使用不可变集合。 Java集合到Scala集合 Scala提供了scala.collection.JavaConverters来转换Java集合到Scala集合： 1234567891011121314import scala.collection.JavaConverters._ /** * 根据sheet名获取sheet所有单元格 * * @param workbook Excel [[Workbook]]对象 * @param sheetName sheet 名 * @return 返回所有有效单元格可迭代二维列表 */ def getSheetCells(workbook: Workbook, sheetName: String): Iterable[Iterable[RichCell]] = &#123; workbook.getSheet(sheetName) .asScala .map(row =&gt; row.asScala.map(cell =&gt; new RichCell(cell))) &#125; workbook.getSheet方法返回的Sheet类型是实现了java.lang.Iterable接口的可迭代类型。为了使用Scala集合上提供的map高阶函数，我们需要把Java集合转换成Scala集合。可以通过在Java集合上调用.asScala函数来将其转换成Scala集合，这里运用了Scala里的隐式转换特性来实现。 Scala集合到Java集合 接下来我们看另外一个函数： 1234@varargsdef getSheets(workbook: Workbook, sheetNames: String*): java.util.List[Sheet] = &#123; sheets(workbook, sheetNames: _ *).asJava&#125; 这个函数实现的功能是根据传入的一个或多个Sheet名字从Excel里获取Sheet列表。sheets函数返回的是一个Scala集合：Seq[Sheet]，通过getSheets代理函数将其转换成Java集合，通过在Seq[Sheet]上调用.asJava方法来实现自动转换。同样的，这里也运用了Scala的隐式转换特性。 Java代码中做集合转换 之前的例子都是在Scala代码中实现的，通过隐式转换这一特性我们发现做Java/Scala集合的相互转换是非常方便的。但在Java代码中做两者的转换就不那么直观了，因为Java没有隐式转换这一特性，我们需要显示的调用代码来先生成包装类，再调用.asScala或.asJava方法来转换集合类型： 1234567891011import scala.collection.JavaConverters$;import scala.collection.mutable.Buffer; public static void demo() &#123; List&lt;String&gt; list = Arrays.asList(&quot;dd&quot;, &quot;dd&quot;); // Java List 到 Scala Buffer Buffer&lt;String&gt; scalaBuffer = JavaConverters$.MODULE$.asScalaBufferConverter(list).asScala(); // Scala Buffer 到 Java List List&lt;String&gt; javaList = JavaConverters$.MODULE$.bufferAsJavaListConverter(scalaBuffer).asJava(); &#125; 为Java和Scala同时提供API当在项目中混用Java和Scala语言时，有个问题不得不重视。提供的API是用Java还是Scala来实现？实现的API是优先考虑兼容Java还是Scala？ 对于API的实现，用Java或Scala均可。若使用Java实现，在Scala中调用是基本无压力的。而使用Scala实现时，为了兼容Java你可能不得不作一些折中。一个常用的方式是：使用Scala或Java来实现API，而再用Java或Scala来实现一个封装层（代理）作兼容。比如：Spark、Akka……，它们使用Scala来实现API，但提供了包装的Java API层。 一个好的实践是把Scala API放到scalaapi包路径（或者反之把Java API放到javaapi包路径）。\u0010\u0006 若我们只提供一个API，那就要尽量同时支持Java和Scala方便的\u0005调用。比如使用@varargs注解来修饰变长参数。 对于参数需要集合类型，或返回值为集合类型的函数。我们除了使用上一节提供的JavaConverters来做自动/手动转换以外，也可以通过装饰器形式来提供Java或Scala专有的API。这里，我推荐Scala API函数名直接使用代表操作的名词/动词实现，而Java API在之前加上：get、set、create等前缀进行修饰。 12345678def sheets(workbook: Workbook, sheetNames: String*): Seq[Sheet] = &#123; sheetNames.map(sheetName =&gt; workbook.getSheet(sheetName))&#125;@varargsdef getSheets(workbook: Workbook, sheetNames: String*): java.util.List[Sheet] = &#123; sheets(workbook, sheetNames: _ *).asJava&#125; 这里sheets和getSheets实现相同的功能，区别是第一个是Scala API，第二个是Java API。 结语本文较详细的介绍了Java/Scala的互操作性，以上示例都来自作者及团队的实际工作。 这篇文章简单介绍了一些基础的Java/Scala互操作方法，接下来的文章将介绍些高级的互操作：Future、Optional/Option、lamdba函数、类与接口等。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"互操作","slug":"互操作","permalink":"https://yangbajing.github.io/tags/%E4%BA%92%E6%93%8D%E4%BD%9C/"}]},{"title":"Scala开发者的Spring-Boot快速上手指南 02：Scala惯用法","slug":"scala开发者的spring-boot快速上手指南-02：scala惯用法","date":"2016-08-25T14:11:21.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/08/25/scala开发者的spring-boot快速上手指南-02：scala惯用法/","link":"","permalink":"https://yangbajing.github.io/2016/08/25/scala%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84spring-boot%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97-02%EF%BC%9Ascala%E6%83%AF%E7%94%A8%E6%B3%95/","excerpt":"","text":"(这是一篇迟来的文章，从3月份计划到成文花了5个月多……以后需要避免这样的低效率。) 之前写第一篇文章时，只是想试试在Spring中使用Scala。但现在随着工作的需要，已经决定在应用层基于Spring boot进行开发。后面的数据服务和数据整合部分将采用Akka。作者是一个Scala粉，但不脑残。鉴于团队、招人及社区生态多方面考虑，整体使用Scala技术栈还是比较困难的。之前就有考虑过把Spring和Scala结合起来。后来了解到挖财的技术选型，他们就是基于Spring和Scala的，还开源了很多不错的Spring Boot增强插件。这坚定了我之前的想法，也有了我5个月后续写第2篇的能量。 对于Scala还不熟悉的朋友可以先看看《写给Java程序员的Scala入门教程》，好对Scala有个初步映像。 从Maven到Gradle第一篇文章是基于Maven做项目配置的，现在换成了Gradle。原因？Spring官方默认都是基于Gradle了，而且现在很多大型的Java项目都是基于Gradle进行构建了。如：Android、Kafka（Linkdin整体采用Gradle）。再加上我是一个比较爱折腾的人，既然现在有时间，为什么不试试Gradle呢？ 代码在这里：https://github.com/yangbajing/spring-boot-scala，这次不但把构建工具换成了Gradle，还一步到位使用了多项目的构建方式，这样更符合真实开发的场景。 **注意：在build.gradle配置中，需要重新设置Scala和Java源码的搜索路径，把Java源码路径移动Scala的搜索路径来。不然编译时会遇到Java代码找不到Scala代码符号问题** 123456789101112131415161718sourceSets &#123; main &#123; scala &#123; srcDirs = [&#x27;src/main/scala&#x27;, &#x27;src/main/java&#x27;] &#125; java &#123; srcDirs = [] &#125; &#125; test &#123; scala &#123; srcDirs = [&#x27;src/test/scala&#x27;, &#x27;src/test/java&#x27;] &#125; java &#123; srcDirs = [] &#125; &#125;&#125; 支持Scala数据类型Spring Boot默认可以自动转换JSON数据格式到Java类型或反之，但怎样支持Scala数据类型呢？其实很简单，只需要加入jackson-module-scala依赖： 1compile(&quot;com.fasterxml.jackson.module:jackson-module-scala_$scalaLibVersion:2.8.0.rc2&quot;) 并添加jacksonModuleScala Bean 即可： 1234@Beanpublic Module jacksonModuleScala() &#123; return new DefaultScalaModule();&#125; 现在，我们就可以在Spring中自由的使用case class、Scala Collection、Option等类型和数据结构，甚至还可以和Java类型混合使用。比如我们把Java类型嵌入到Scala的case class里。 User.java 12345678910111213141516public class User &#123; private String name; private String nickname; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125;&#125; Message.scala 123456case class Message(name: String, age: Int, user: User, status: Option[Boolean]) &#123; @BeanProperty val createdAt: LocalDateTime = LocalDateTime.now()&#125; Scala控制器 (ApiController.scala）： 1234567@RequestMapping(path = Array(&quot;message&quot;), method = Array(RequestMethod.POST))def message(@RequestBody reqMsg: Message): Seq[Message] = &#123; List( reqMsg, reqMsg.copy(age = reqMsg.age + 1, status = Some(true)) )&#125; 使用Scala编写Spring控制器方法，有些和Java不一样的地方和Scala的惯用法： 注解属性为数组时，Scala必需显示使用数组形式传参。如@RequestMapping注解的path发型是一个数组类型，在Scala中需要显示传入一个数组类型的参数：Array(&quot;message&quot;)。 Scala中，方法返回值类型是可以自动推导的。但在写Spring控制器方法时推荐显示注明返回类型。 Scala的所有表达式都有值，且代码块最后一个表达式的值就是代码块的值。这样，在Scala的函数里不需要使用return显示返回数据，也不推荐使用return。 另外，若在Java代码中使用Scala的数据类型。如：case class。在Java中必需使用new关键字进行实例化，像Scala那样直接通过类名实例化是不支持的。 Java控制器（WebController.java）： 1234@RequestMapping(path = &quot;message&quot;, method = RequestMethod.POST)public Message message(@RequestBody User user) &#123; return new Message(&quot;Yang Jing&quot;, 30, user, new Some(false));&#125; 测试效果如下： 1234567$ curl -XPOST -H &#39;content-type: application&#x2F;json;utf8&#39; -d &#39;&#123;&quot;user&quot;:&quot;杨景&quot;,&quot;nickname&quot;:&quot;羊八井&quot;&#125;&#39; http:&#x2F;&#x2F;localhost:18080&#x2F;web&#x2F;message&#123;&quot;name&quot;:&quot;Yang Jing&quot;,&quot;age&quot;:30,&quot;user&quot;:&#123;&quot;name&quot;:null,&quot;nickname&quot;:&quot;羊八井&quot;&#125;,&quot;status&quot;:false,&quot;createdAt&quot;:&quot;2016-08-25T17:22:50.841&quot;&#125;$ curl -XPOST -H &#39;content-type: application&#x2F;json;utf8&#39; -d &#39;&#123;&quot;name&quot;:&quot;yangbajing&quot;,&quot;age&quot;:30,&quot;user&quot;:&#123;&quot;name&quot;:&quot;杨景&quot;,&quot;nickname&quot;:&quot;羊八井&quot;&#125;&#125;&#39; http:&#x2F;&#x2F;localhost:18080&#x2F;api&#x2F;message[&#123;&quot;name&quot;:&quot;yangbajing&quot;,&quot;age&quot;:30,&quot;user&quot;:&#123;&quot;name&quot;:&quot;杨景&quot;,&quot;nickname&quot;:&quot;羊八井&quot;&#125;,&quot;status&quot;:null,&quot;createdAt&quot;:&quot;2016-08-25T17:26:03.352&quot;&#125;,&#123;&quot;name&quot;:&quot;yangbajing&quot;,&quot;age&quot;:31,&quot;user&quot;:&#123;&quot;name&quot;:&quot;杨景&quot;,&quot;nickname&quot;:&quot;羊八井&quot;&#125;,&quot;status&quot;:true,&quot;createdAt&quot;:&quot;2016-08-25T17:26:03.352&quot;&#125;] Java Function 和 Scala Function[N]Java 8开始，支持Lambda函数。但是Java的Lambda函数与Scala的函数类型是不兼容的（好消息是，从Scala 2.12开始，将兼容Java Lambda函数）。我们可以使用scala-java8-compat这个库来还算优雅的解决这个问题。 首先添加scala-java8-comat依赖： 1compile(&quot;org.scala-lang.modules:scala-java8-compat_$scalaLibVersion:0.7.0&quot;) 在Scala中访问Java8 Function，可以使用如下方式： 12345import scala.compat.java8.FunctionConverters._def(@RequestParam name: Optional[String], ... name.orElseGet(asJavaSupplier(() =&gt; reqMsg.name)) 除了显示的使用asJavaSupplier来转换特定的Java8 Function，还可以使用asJava隐式转换来自动转换： 1name.orElseGet((() =&gt; reqMsg.name).asJava) 总结也许你并不喜欢Scala，也不需要在Spring中使用Scala，Java 8也足够。但我希望能为你打开了一扇门，在JVM平台上还有如此有意思的语言。 本系列文章 Scala开发者的Spring-Boot快速上手指南 01 Scala开发者的Spring-Boot快速上手指南 02：Scala惯用法","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://yangbajing.github.io/tags/spring-boot/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"gradle","slug":"gradle","permalink":"https://yangbajing.github.io/tags/gradle/"}]},{"title":"我的Ubuntu开发环境设置","slug":"我的ubuntu开发环境设置","date":"2016-08-21T10:43:01.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/08/21/我的ubuntu开发环境设置/","link":"","permalink":"https://yangbajing.github.io/2016/08/21/%E6%88%91%E7%9A%84ubuntu%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"输入法（fcitx）解决某些软件不能使用问题，如：Idea, Emacs 设置如下环境变量到/etc/bash.bashrc或~/.bashrc配置文件，重启系统或注销后重新登录即可。 1234export XMODIFIERS&#x3D;&quot;@im&#x3D;fcitx&quot;export QT_IM_MODULE&#x3D;&quot;fcitx&quot;export QT4_IM_MODULE&#x3D;&quot;fcitx&quot;export GTK_IM_MODULE&#x3D;&quot;fcitx&quot; 文档与代码片断管理https://zealdocs.org/ 可用于替代Mac下的Dash。 PostgreSQLhttps://wiki.postgresql.org/wiki/Apt CassandraCassandra 3.7 单节点开发环境安装：http://docs.datastax.com/en/cassandra/3.x/cassandra/install/installDeb.html 运行cqlsh报不能连接任务服务器错误： 12$ cqlshConnection error: (&#39;Unable to connect to any servers&#39;, &#123;&#39;127.0.0.1&#39;: TypeError(&#39;ref() does not take keyword arguments&#39;,)&#125;) 解决 12export CQLSH_NO_BUNDLED&#x3D;truepip install cassandra-driver KVMhttps://help.ubuntu.com/lts/serverguide/libvirt.html","categories":[],"tags":[]},{"title":"About","slug":"about","date":"2016-07-26T07:09:23.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/07/26/about/","link":"","permalink":"https://yangbajing.github.io/2016/07/26/about/","excerpt":"","text":"这里有我的工作体会和生活感悟。 杨景：yangbajing.me 知乎专栏：羊八井花园 Github: yangbajing Gitee：yangbajing Weibo: yangbajing Twitter: yangbajing1 微信公众号：yangbajing-garden 技能 擅长Java/Scala编程，熟悉多线程、并发程序设计 熟悉actor（编程模型）、Akka，可基于JVM/Akka设计反应式应用 可使用ES6/7（Javascript）、React编写前端程序，曾经领导并组建过前端开发团队 对PostgreSQL/MySQL、Cassandra、Elasticsearch、MongoDB具有实战经验 熟悉Linux系统，可配置、搭建开发、生产环境 对TDD、BDD，项目管理，自动化、持续集成有一定研究，对Gitlab、Jenkins等工具较熟悉 大数据产品环境建设，大数据应用开发（Spark） 能力 建设研发团队，包括前、后端，数据（偏工程）团队建设 需求、产品的研发落地设计，项目/产品质量及进度管控","categories":[],"tags":[{"name":"about","slug":"about","permalink":"https://yangbajing.github.io/tags/about/"}]},{"title":"Scala实战：巧用集合实现数据脱敏","slug":"scala实战：巧用集合实现数据脱敏","date":"2016-07-25T12:54:53.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/07/25/scala实战：巧用集合实现数据脱敏/","link":"","permalink":"https://yangbajing.github.io/2016/07/25/scala%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B7%A7%E7%94%A8%E9%9B%86%E5%90%88%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E8%84%B1%E6%95%8F/","excerpt":"","text":"（原文在：《http://www.yangbajing.me/2016/07/25/Scala实战：巧用集合实现数据脱敏》，转载请注明！） 在日常开发中，经常会遇到对数据进行脱敏处理的需求。像隐藏身份证或者手机号中间几位。比如对于：13812345678这个手机号，我们会使用*号替换中间4位来达到隐藏的目的，就像这样：138****5678。这是一个很常见也很简单的功能需求，这里记录下开发中对这个需求的实现。从一开始命令式的风格到函数式风格，从一开始硬编码隐藏范围和替换字符到调用者可以自定义，从繁琐和代码实现到清晰、简洁……本文将一步一步的给读者展示Scala强大的表现力、丰富的API和高效的生产率体现。 命令式首先来看看一开始实现的隐藏手机号函数： 1234567scala&gt; def hidePhone(phone: String): String = &#123; | phone.substring(0, 3) + &quot;****&quot; + phone.substring(7) | &#125;hidePhone: (phone: String)Stringscala&gt; hidePhone(&quot;13812345678&quot;)res1: String = 138****5678 咋一看，代码量很少嘛，也很简洁明了，需求实现的非常好。但其实这段代码有很多坏的和不完善的地方。如：有3个数字，它们决定了哪些字符需要原样保留。但万一业务需求是隐藏末尾5个字符呢？难到我们需要再写一个hideLastPhone函数？这样子太low了…… 于是，对hidePhone完成第一次改进，我们让调用方来决定需要隐藏哪些字符而不是在代码里写死保留哪些字符。 12345678910def hidePhone(phone: String, start: Int, end: Int): String = &#123; val builder = new StringBuilder(phone.substring(0, start)) var i = start while (i &lt; end) &#123; builder.append(&#x27;*&#x27;) i += 1 &#125; builder.append(phone.substring(end)) builder.toString()&#125; 代码看起来有点多，但实现了调用方设置隐藏范围，实用性更好了。来看看测试效果： 12345scala&gt; hidePhone(&quot;13812345678&quot;, 6, 6 + 5)res2: String = 138123*****scala&gt; hidePhone(&quot;13812345678&quot;, 3, 3 + 4)res3: String = 138****5678 不错，效果很好。正确！但是，我们换个参数再试试…… 12345scala&gt; hidePhone(&quot;13812345678&quot;, 6, 6 + 6)java.lang.StringIndexOutOfBoundsException: String index out of range: -1 at java.lang.String.substring(String.java:1931) at .hidePhone(&lt;console&gt;:18) ... 32 elided Oh……数据越界错误。要修正这个错误也很简单： 123456789101112def hidePhone(phone: String, start: Int, end: Int): String = &#123; val builder = new StringBuilder(phone.substring(0, start)) var i = start while (i &lt; math.min(phone.length, end)) &#123; builder.append(&#x27;*&#x27;) i += 1 &#125; if (end &lt; phone.length) &#123; builder.append(phone.substring(end)) &#125; builder.toString()&#125; 我们修复了两个地方： while语句不是直接小于end变量，而是小于phone.length和end两个变量之间更小的那个 最后一个builder.append语句加上了一个if防卫措施，只有当end小于手机号长度时才添加。 这时，我们再次尝试刚才错误的那个示例。发现它已经可以正确的执行了。 12scala&gt; hidePhone(&quot;13812345678&quot;, 6, 6 + 6)res5: String = 138123***** 函数式我们已经看过了命令式的数据税敏代码，没想到这样一个简单的功能还是需要写不少代码的。现在已经使用了具有函数式特性的高级的Scala语言，我们能不能把代码写得更functional、更漂亮呢（代码丑陋也是不可忍的……）？我们尝试着再次改进一下。 123456def hidePhone(phone: String, start: Int, end: Int): String = &#123; phone .zipWithIndex .map &#123; case (ch, idx) =&gt; if (idx &gt;= start &amp;&amp; idx &lt; end) &#x27;*&#x27; else ch &#125; .mkString&#125; 相比之前那段命令式的代码，这是不是简洁、清晰了很多？我们先使用.zipWithIndex方法将字符串变成一个带索引的Tuple序列，形如：Seq((&#39;1&#39;, 0), (&#39;3&#39;, 1), (&#39;8&#39;, 2), ....)。再通过判断索引idx是否在[start, end)范围来判断返回对应字符还是返回替换后的*号字符。最后再调用mkString方法把Seq[Char]（字符序列）格式化成一个字符串。 到了这里，我们还有改进的地方： 我们想可以自定义替换字符，用户可以使用’-‘、’|’等符号来替换，而不是默认的’*’号。 对于end这个参数，当前代码实现是不替换这个索引的字符。那万一我们的需求是要替换这个索引的字符呢？当然，你可以说传入参数时将end + 1不就行了，但感觉不太好……因为我们还有更好的方案。 123456def hidePhone(phone: String, replaceRange: Range, replaceChar: Char = &#x27;*&#x27;): String = &#123; phone .zipWithIndex .map &#123; case (ch, idx) =&gt; if (replaceRange.contains(idx)) replaceChar else ch &#125; .mkString&#125; 这时的使用方式就和之前不一样了： 1234567891011scala&gt; hidePhone(&quot;13812345678&quot;, 6 until 6 + 5)res6: String = 138123*****scala&gt; hidePhone(&quot;13812345678&quot;, 3 until 3 + 4, &#x27;-&#x27;)res9: String = 138----5678scala&gt; hidePhone(&quot;13812345678&quot;, 3 to 3 + 4, &#x27;-&#x27;)res7: String = 138-----678scala&gt; hidePhone(&quot;13812345678&quot;, 6 until 6 + 6, &#x27;^&#x27;)res8: String = 138123^^^^^ 总结一个常用的数据脱敏函数，需要注意的地方还是挺多的。而函数式风格的实现相对命令式风格来说从可读性上更具优势。Scala以一种从左到右顺序编写、链式调用实现了数据脱敏这个功能，同时兼具了灵活性和健壮性。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"scala实战","slug":"scala/scala实战","permalink":"https://yangbajing.github.io/categories/scala/scala%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"collection","slug":"collection","permalink":"https://yangbajing.github.io/tags/collection/"}]},{"title":"写给Java程序员的Scala入门教程","slug":"写给java程序员的scala入门教程","date":"2016-07-24T13:09:41.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/07/24/写给java程序员的scala入门教程/","link":"","permalink":"https://yangbajing.github.io/2016/07/24/%E5%86%99%E7%BB%99java%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84scala%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"（原文链接：http://www.yangbajing.me/2016/07/24/写给java程序员的scala入门教程/，转载请注明） 之前因为Spark的引入，写了一篇《写给Python程序员的Scala入门教程》。那篇文章简单对比了Scala与Python的异同，并介绍了一些Scala的常用编程技巧。今天这篇文章将面向广大的Java程序员，带领Javaer进入函数式编程的世界。 Java 8拥有了一些初步的函数式编程能力：闭包等，还有新的并发编程模型及Stream这个带高阶函数和延迟计算的数据集合。在尝试了Java 8以后，也许会觉得意犹未尽。是的，你会发现Scala能满足你在初步尝试函数式编程后那求知的欲望。 安装Scala到Scala官方下载地址下载：http://scala-lang.org/download/： 123456789wget -c http:&#x2F;&#x2F;downloads.lightbend.com&#x2F;scala&#x2F;2.11.8&#x2F;scala-2.11.8.tgztar zxf scala-2.11.8.tgzcd scala-2.11.8.&#x2F;bin&#x2F;scalaWelcome to Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_60).Type in expressions to have them evaluated.Type :help for more information.scala&gt; RELP 刚才我们已经启动了Scala RELP，它是一个基于命令行的交互式编程环境。对于有着Python、Ruby等动态语言的同学来说，这是一个很常用和工具。但Javaer们第一次见到会觉得比较神奇。我们可以在RELP中做一些代码尝试而不用启动笨拙的IDE，这在我们思考问题时非常的方便。对于Javaer有一个好消息，JDK 9干始将内建支持RELP功能。 对于Scala常用的IDE（集成开发环境），推荐使用IDEA for scala plugins和scala-ide。 Scala的强大，除了它自身对多核编程更好的支持、函数式特性及一些基于Scala的第3方库和框架（如：Akka、Playframework、Spark、Kafka……），还在于它可以无缝与Java结合。所有为Java开发的库、框架都可以自然的融入Scala环境。当然，Scala也可以很方便的Java环境集成，比如：Spring。若你需要第3方库的支持，可以使用Maven、Gradle、Sbt等编译环境来引入。 Scala是一个面向对象的函数式特性编程语言，它继承了Java的面向对特性，同时又从Haskell等其它语言那里吸收了很多函数式特性并做了增强。 变量、基础数据类型Scala中变量不需要显示指定类型，但需要提前声明。这可以避免很多命名空间污染问题。Scala有一个很强大的类型自动推导功能，它可以根据右值及上下文自动推导出变量的类型。你可以通过如下方式来直接声明并赋值。 123456789101112scala&gt; val a = 1a: Int = 1scala&gt; val b = trueb: Boolean = truescala&gt; val c = 1.0c: Double = 1.0scala&gt; val a = 30 + &quot;岁&quot;a: String = 30岁 Immutable （注：函数式编程有一个很重要的特性：不可变性。Scala中除了变量的不可变性，它还定义了一套不可变集合scala.collection.immutable._。） val代表这是一个final variable，它是一个常量。定义后就不可以改变，相应的，使用var定义的就是平常所见的变量了，是可以改变的。从终端的打印可以看出，Scala从右值自动推导出了变量的类型。Scala可以如动态语言似的编写代码，但又有静态语言的编译时检查。这对于Java中冗长、重复的类型声明来说是一种很好的进步。 （注：在RELP中，val变量是可以重新赋值的，这是｀RELP`的特性。在平常的代码中是不可以的。） 基础数据类型 Scala中基础数据类型有：Byte、Short、Int、Long、Float、Double，Boolean，Char、String。和Java不同的是，Scala中没在区分原生类型和装箱类型，如：int和Integer。它统一抽象成Int类型，这样在Scala中所有类型都是对象了。编译器在编译时将自动决定使用原生类型还是装箱类型。 字符串 Scala中的字符串有3种。 分别是普通字符串，它的特性和Java字符串一至。 连线3个双引号在Scala中也有特殊含义，它代表被包裹的内容是原始字符串，可以不需要字符转码。这一特性在定义正则表达式时很有优势。 还有一种被称为“字符串插值”的字符串，他可以直接引用上下文中的变量，并把结果插入字符串中。 1234567891011121314scala&gt; val c2 = &#x27;杨&#x27;c2: Char = 杨scala&gt; val s1 = &quot;重庆誉存企业信用管理有限公司&quot;s1: String = 重庆誉存企业信用管理有限公司scala&gt; val s2 = s&quot;重庆誉存企业信用管理有限公司$&#123;c2&#125;景&quot;s2: String = 重庆誉存企业信用管理有限公司scala&gt; val s3 = s&quot;&quot;&quot;重庆誉存企业信用管理有限公司&quot;工程师&quot;\\n$&#123;c2&#125;景是江津人&quot;&quot;&quot;s3: String =重庆誉存企业信用管理有限公司&quot;工程师&quot;杨景是江津人 运算符和命名Scala中的运算符其实是定义在对象上的方法（函数），你看到的诸如：3 + 2其实是这样子的：3.+(2)。+符号是定义在Int对象上的一个方法。支持和Java一至的运算符（方法）： （注：在Scala中，方法前的.号和方法两边的小括号在不引起歧义的情况下是可以省略的。这样我们就可以定义出很优美的DSL） ==、!=：比较运算 !、|、&amp;、^：逻辑运算 &gt;&gt;、&lt;&lt;：位运算 注意 在Scala中，修正了（算更符合一般人的常规理解吧）==和!=运算符的含义。在Scala中，==和!=是执行对象的值比较，相当于Java中的equals方法（实际上编译器在编译时也是这么做的）。而对象的引用比较需要使用eq和ne两个方法来实现。 控制语句（表达式）Scala中支持if、while、for comprehension（for表达式)、match case（模式匹配）四大主要控制语句。Scala不支持switch和? :两种控制语句，但它的if和match case会有更好的实现。 if Scala支持if语句，其基本使用和Java、Python中的一样。但不同的时，它是有返回值的。 （注：Scala是函数式语言，函数式语言还有一大特性就是：表达式。函数式语言中所有语句都是基于“表达式”的，而“表达式”的一个特性就是它会有一个值。所有像Java中的? :3目运算符可以使用if语句来代替）。 1234567891011scala&gt; if (true) &quot;真&quot; else &quot;假&quot;res0: String = 真scala&gt; val f = if (false) &quot;真&quot; else &quot;假&quot;f: String = 假scala&gt; val unit = if (false) &quot;真&quot;unit: Any = ()scala&gt; val unit2 = if (true) &quot;真&quot; unit2: Any = 真 可以看到，if语句也是有返回值的，将表达式的结果赋给变量，编译器也能正常推导出变量的类型。unit和unit2变量的类型是Any，这是因为else语句的缺失，Scala编译器就按最大化类型来推导，而Any类型是Scala中的根类型。()在Scala中是Unit类型的实例，可以看做是Java中的Void。 while Scala中的while循环语句： 123while (条件) &#123; 语句块&#125; for comprehension Scala中也有for表达式，但它和Java中的for不太一样，它具有更强大的特性。通常的for语句如下： 123for (变量 &lt;- 集合) &#123; 语句块&#125; Scala中for表达式除了上面那样的常规用法，它还可以使用yield关键字将集合映射为另一个集合： 12345scala&gt; val list = List(1, 2, 3, 4, 5)list: List[Int] = List(1, 2, 3, 4, 5)scala&gt; val list2 = for (item &lt;- list) yield item + 1list2: List[Int] = List(2, 3, 4, 5, 6) 还可以在表达式中使用if判断： 12scala&gt; val list3 = for (item &lt;- list if item % 2 == 0) yield itemlist3: List[Int] = List(2, 4) 还可以做flatMap操作，解析2维列表并将结果摊平（将2维列表拉平为一维列表）： 12345678scala&gt; val llist = List(List(1, 2, 3), List(4, 5, 6), List(7, 8, 9))llist: List[List[Int]] = List(List(1, 2, 3), List(4, 5, 6), List(7, 8, 9))scala&gt; for &#123; | l &lt;- llist | item &lt;- l if item % 2 == 0 | &#125; yield itemres3: List[Int] = List(2, 4, 6, 8) 看到了，Scala中for comprehension的特性是很强大的。Scala的整个集合库都支持这一特性，包括：Seq、Map、Set、Array…… Scala没有C-Like语言里的for (int i = 0; i &lt; 10; i++)语法，但Range（范围这个概念），可以基于它来实现循环迭代功能。在Scala中的使用方式如下： 12345678910111213scala&gt; for (i &lt;- (0 until 10)) &#123; | println(i) | &#125;0123456789 Scala中还有一个to方法： 12scala&gt; for (i &lt;- (0 to 10)) print(&quot; &quot; + i) 0 1 2 3 4 5 6 7 8 9 10 你还可以控制每次步进的步长，只需要简单的使用by方法即可： 12scala&gt; for (i &lt;- 0 to 10 by 2) print(&quot; &quot; + i) 0 2 4 6 8 10 match case 模式匹配，是函数式语言很强大的一个特性。它比命令式语言里的switch更好用，表达性更强。 1234567891011121314151617scala&gt; def level(s: Int) = s match &#123; | case n if n &gt;= 90 =&gt; &quot;优秀&quot; | case n if n &gt;= 80 =&gt; &quot;良好&quot; | case n if n &gt;= 70 =&gt; &quot;良&quot; | case n if n &gt;= 60 =&gt; &quot;及格&quot; | case _ =&gt; &quot;差&quot; | &#125;level: (s: Int)Stringscala&gt; level(51)res28: String = 差scala&gt; level(93)res29: String = 优秀scala&gt; level(80)res30: String = 良好 可以看到，模式匹配可以实现switch相似的功能。但与switch需要使用break明确告知终止之后的判断不同，Scala中的match case是默认break的。只要其中一个case语句匹配，就终止之后的所以比较。且对应case语句的表达式值将作为整个match case表达式的值返回。 Scala中的模式匹配还有类型匹配、数据抽取、谓词判断等其它有用的功能。这里只做简单介绍，之后会单独一个章节来做较详细的解读。 集合在java.util包下有丰富的集合库。Scala除了可以使用Java定义的集合库外，它还自己定义了一套功能强大、特性丰富的scala.collection集合库API。 在Scala中，常用的集合类型有：List、Set、Map、Tuple、Vector等。 List Scala中List是一个不可变列表集合，它很精妙的使用递归结构定义了一个列表集合。 12scala&gt; val list = List(1, 2, 3, 4, 5)list: List[Int] = List(1, 2, 3, 4, 5) 除了之前使用Listobject来定义一个列表，还可以使用如下方式： 12scala&gt; val list = 1 :: 2 :: 3 :: 4 :: 5 :: Nillist: List[Int] = List(1, 2, 3, 4, 5) List采用前缀操作的方式（所有操作都在列表顶端（开头））进行，::操作符的作用是将一个元素和列表连接起来，并把元素放在列表的开头。这样List的操作就可以定义成一个递归操作。添加一个元素就是把元素加到列表的开头，List只需要更改下头指针，而删除一个元素就是把List的头指针指向列表中的第2个元素。这样，List的实现就非常的高效，它也不需要对内存做任何的转移操作。List有很多常用的方法： 1234567891011121314151617181920212223242526scala&gt; list.indexOf(3)res6: Int = 2scala&gt; 0 :: listres8: List[Int] = List(0, 1, 2, 3, 4, 5)scala&gt; list.reverseres9: List[Int] = List(5, 4, 3, 2, 1)scala&gt; list.filter(item =&gt; item == 3)res11: List[Int] = List(3)scala&gt; listres12: List[Int] = List(1, 2, 3, 4, 5)scala&gt; val list2 = List(4, 5, 6, 7, 8, 9)list2: List[Int] = List(4, 5, 6, 7, 8, 9)scala&gt; list.intersect(list2)res13: List[Int] = List(4, 5)scala&gt; list.union(list2)res14: List[Int] = List(1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 9)scala&gt; list.diff(list2)res15: List[Int] = List(1, 2, 3) Scala中默认都是Immutable collection，在集合上定义的操作都不会更改集合本身，而是生成一个新的集合。这与Java集合是一个根本的区别，Java集合默认都是可变的。 Tuple Scala中也支持Tuple（元组）这种集合，但最多只支持22个元素（事实上Scala中定义了Tuple0、Tuple1……Tuple22这样22个TupleX类，实现方式与C++ Boost库中的Tuple类似）。和大多数语言的Tuple类似（比如：Python），Scala也采用小括号来定义元组。 12345678scala&gt; val tuple3 = (1, 2, 3)tuple1: (Int, Int, Int) = (1,2,3)scala&gt; tuple3._2res17: Int = 2scala&gt; val tuple2 = Tuple2(&quot;杨&quot;, &quot;景&quot;)tuple2: (String, String) = (杨,景) 可以使用xxx._[X]的形式来引用Tuple中某一个具体元素，其_[X]下标是从1开始的，一直到22（若有定义这么多）。 Set Set是一个不重复且无序的集合，初始化一个Set需要使用Set对象： 12345678scala&gt; val set = Set(&quot;Scala&quot;, &quot;Java&quot;, &quot;C++&quot;, &quot;Javascript&quot;, &quot;C#&quot;, &quot;Python&quot;, &quot;PHP&quot;) set: scala.collection.immutable.Set[String] = Set(Scala, C#, Python, Javascript, PHP, C++, Java)scala&gt; set + &quot;Go&quot;res21: scala.collection.immutable.Set[String] = Set(Scala, C#, Go, Python, Javascript, PHP, C++, Java)scala&gt; set filterNot (item =&gt; item == &quot;PHP&quot;)res22: scala.collection.immutable.Set[String] = Set(Scala, C#, Python, Javascript, C++, Java) Map Scala中的Map默认是一个HashMap，其特性与Java版的HashMap基本一至，除了它是Immutable的： 12345scala&gt; val map = Map(&quot;a&quot; -&gt; &quot;A&quot;, &quot;b&quot; -&gt; &quot;B&quot;)map: scala.collection.immutable.Map[String,String] = Map(a -&gt; A, b -&gt; B)scala&gt; val map2 = Map((&quot;b&quot;, &quot;B&quot;), (&quot;c&quot;, &quot;C&quot;))map2: scala.collection.immutable.Map[String,String] = Map(b -&gt; B, c -&gt; C) Scala中定义Map时，传入的每个Entry（K、V对）其实就是一个Tuple2（有两个元素的元组），而-&gt;是定义Tuple2的一种便捷方式。 1234567891011scala&gt; map + (&quot;z&quot; -&gt; &quot;Z&quot;)res23: scala.collection.immutable.Map[String,String] = Map(a -&gt; A, b -&gt; B, z -&gt; Z)scala&gt; map.filterNot(entry =&gt; entry._1 == &quot;a&quot;)res24: scala.collection.immutable.Map[String,String] = Map(b -&gt; B)scala&gt; val map3 = map - &quot;a&quot;map3: scala.collection.immutable.Map[String,String] = Map(b -&gt; B)scala&gt; mapres25: scala.collection.immutable.Map[String,String] = Map(a -&gt; A, b -&gt; B) Scala的immutable collection并没有添加和删除元素的操作，其定义+（List使用::在头部添加）操作都是生成一个新的集合，而要删除一个元素一般使用 - 操作直接将Key从map中减掉即可。 （注：Scala中也scala.collection.mutable._集合，它定义了不可变集合的相应可变集合版本。一般情况下，除非一此性能优先的操作（其实Scala集合采用了共享存储的优化，生成一个新集合并不会生成所有元素的复本，它将会和老的集合共享大元素。因为Scala中变量默认都是不可变的），推荐还是采用不可变集合。因为它更直观、线程安全，你可以确定你的变量不会在其它地方被不小心的更改。） ClassScala里也有class关键字，不过它定义类的方式与Java有些区别。Scala中，类默认是public的，且类属性和方法默认也是public的。Scala中，每个类都有一个“主构造函数”，主构造函数类似函数参数一样写在类名后的小括号中。因为Scala没有像Java那样的“构造函数”，所以属性变量都会在类被创建后初始化。所以当你需要在构造函数里初始化某些属性或资源时，写在类中的属性变量就相当于构造初始化了。 在Scala中定义类非常简单： 123class Person(name: String, val age: Int) &#123; override def toString(): String = s&quot;姓名：$name, 年龄: $age&quot;&#125; 默认，Scala主构造函数定义的属性是private的，可以显示指定：val或var来使其可见性为：public。 Scala中覆写一个方法必需添加：override关键字，这对于Java来说可以是一个修正。当标记了override关键字的方法在编译时，若编译器未能在父类中找到可覆写的方法时会报错。而在Java中，你只能通过@Override注解来实现类似功能，它的问题是它只是一个可选项，且编译器只提供警告。这样你还是很容易写出错误的“覆写”方法，你以后覆写了父类函数，但其实很有可能你是实现了一个新的方法，从而引入难以察觉的BUG。 实例化一个类的方式和Java一样，也是使用new关键字。 12345678910111213scala&gt; val me = new Person(&quot;杨景&quot;, 30)me: Person = 姓名：杨景, 年龄: 30scala&gt; println(me)姓名：杨景, 年龄: 30scala&gt; me.name&lt;console&gt;:20: error: value name is not a member of Person me.name ^scala&gt; me.ageres11: Int = 30 case class（样本类） case class是Scala中学用的一个特性，像Kotlin这样的语言也学习并引入了类似特性（在Kotlin中叫做：data class）。case class具有如下特性： 不需要使用new关键词创建，直接使用类名即可 默认变量都是public final的，不可变的。当然也可以显示指定var、private等特性，但一般不推荐这样用 自动实现了：equals、hashcode、toString等函数 自动实现了：Serializable接口，默认是可序列化的 可应用到match case（模式匹配）中 自带一个copy方法，可以方便的根据某个case class实例来生成一个新的实例 …… 这里给出一个case class的使用样例： 1234567891011121314151617scala&gt; trait Persondefined trait Personscala&gt; case class Man(name: String, age: Int) extends Persondefined class Manscala&gt; case class Woman(name: String, age: Int) extends Persondefined class Womanscala&gt; val man = Man(&quot;杨景&quot;, 30)man: Man = Man(杨景,30)scala&gt; val woman = Woman(&quot;女人&quot;, 23)woman: Woman = Woman(女人,23)scala&gt; val manNextYear = man.copy(age = 31)manNextYear: Man = Man(杨景,31) objectScala有一种不同于Java的特殊类型，Singleton Objects。 123object Blah &#123; def sum(l: List[Int]): Int = l.sum&#125; 在Scala中，没有Java里的static静态变量和静态作用域的概念，取而代之的是：object。它除了可以实现Java里static的功能，它同时还是一个线程安全的单例类。 伴身对象 大多数的object都不是独立的，通常它都会与一个同名的class定义在一起。这样的object称为伴身对象。 1234567class IntPair(val x: Int, val y: Int)object IntPair &#123; import math.Ordering implicit def ipord: Ordering[IntPair] = Ordering.by(ip =&gt; (ip.x, ip.y))&#125; 注意 伴身对象必需和它关联的类定义定义在同一个**.scala**文件。 伴身对象和它相关的类之间可以相互访问受保护的成员。在Java程序中，很多时候会把static成员设置成private的，在Scala中需要这样实现此特性： 1234567class X &#123; import X._ def blah = foo&#125;object X &#123; private def foo = 42&#125; 函数在Scala中，函数是一等公民。函数可以像类型一样被赋值给一个变量，也可以做为一个函数的参数被传入，甚至还可以做为函数的返回值返回。 从Java 8开始，Java也具备了部分函数式编程特性。其Lamdba函数允许将一个函数做值赋给变量、做为方法参数、做为函数返回值。 在Scala中，使用def关键ygnk来定义一个函数方法： 12345678scala&gt; def calc(n1: Int, n2: Int): (Int, Int) = &#123; | (n1 + n2, n1 * n2) | &#125;calc: (n1: Int, n2: Int)(Int, Int)scala&gt; val (add, sub) = calc(5, 1)add: Int = 6sub: Int = 5 这里定义了一个函数：calc，它有两个参数：n1和n2，其类型为：Int。cala函数的返回值类型是一个有两个元素的元组，在Scala中可以简写为：(Int, Int)。在Scala中，代码段的最后一句将做为函数返回值，所以这里不需要显示的写return关键字。 而val (add, sub) = calc(5, 1)一句，是Scala中的抽取功能。它直接把calc函数返回的一个Tuple2值赋给了add他sub两个变量。 函数可以赋给变量： 1234567891011scala&gt; val calcVar = calc _calcVar: (Int, Int) =&gt; (Int, Int) = &lt;function2&gt;scala&gt; calcVar(2, 3)res4: (Int, Int) = (5,6)scala&gt; val sum: (Int, Int) =&gt; Int = (x, y) =&gt; x + ysum: (Int, Int) =&gt; Int = &lt;function2&gt;scala&gt; sum(5, 7)res5: Int = 12 在Scala中，有两种定义函数的方式： 将一个现成的函数/方法赋值给一个变量，如：val calcVar = calc _。下划线在此处的含意是将函数赋给了变量，函数本身的参数将在变量被调用时再传入。 直接定义函数并同时赋给变量，如：val sum: (Int, Int) =&gt; Int = (x, y) =&gt; x + y，在冒号之后，等号之前部分：(Int, Int) =&gt; Int是函数签名，代表sum这个函数值接收两个Int类型参数并返回一个Int类型参数。等号之后部分是函数体，在函数函数时，x、y参数类型及返回值类型在此可以省略。 一个函数示例：自动资源管理 在我们的日常代码中，资源回收是一个很常见的操作。在Java 7之前，我们必需写很多的try &#123; ... &#125; finally &#123; xxx.close() &#125;这样的样版代码来手动回收资源。Java 7开始，提供了try with close这样的自动资源回收功能。Scala并不能使用Java 7新加的try with close资源自动回收功能，但Scala中有很方便的方式实现类似功能： 1234567891011121314151617181920212223def using[T &lt;: AutoCloseable, R](res: T)(func: T =&gt; R): R = &#123; try &#123; func(res) &#125; finally &#123; if (res != null) res.close() &#125;&#125;val allLine = using(Files.newBufferedReader(Paths.get(&quot;/etc/hosts&quot;))) &#123; reader =&gt; @tailrec def readAll(buffer: StringBuilder, line: String): String = &#123; if (line == null) buffer.toString else &#123; buffer.append(line).append(&#x27;\\n&#x27;) readAll(buffer, reader.readLine()) &#125; &#125; readAll(new StringBuilder(), reader.readLine())&#125;println(allLine) using是我们定义的一个自动化资源管帮助函数，它接爱两个参数化类型参数，一个是实现了AutoCloseable接口的资源类，一个是形如：T =&gt; R的函数值。func是由用户定义的对res进行操作的函数代码体，它将被传给using函数并由using代执行。而res这个资源将在using执行完成返回前调用finally代码块执行.close方法来清理打开的资源。 这个：T &lt;: AutoCloseable范型参数限制了T类型必需为AutoCloseable类型或其子类。R范型指定using函数的返回值类型将在实际调用时被自动参数化推导出来。我们在Scala Console中参看allLine变量的类型可以看到 allLine将被正确的赋予String类型，因为我们传给using函数参数func的函数值返回类型就为String： 12scala&gt; :type allLineString 在readAll函数的定义处，有两个特别的地方： 这个函数定义在了其它函数代码体内部 它有一个@tailrec注解 在Scala中，因为函数是第一类的，它可以被赋值给一个变量。所以Scala中的def定义函数可以等价val func = (x: Int, y: Int) =&gt; x + y这个的函数字面量定义函数形式。所以，既然通过变量定义的函数可以放在其它函数代码体内，通过def定义的函数也一样可以放在其它代码体内，这和Javascript很像。 @tailrec注解的含义是这个函数是尾递归函数，编译器在编译时将对其优化成相应的while循环。若一个函数不是尾递归的，加上此注解在编译时将报错。 模式匹配（match case）模式匹配是函数式编程里面很强大的一个特性。 之前已经见识过了模式匹配的简单使用方式，可以用它替代：if else、switch这样的分支判断。除了这些简单的功能，模式匹配还有一系列强大、易用的特性。 match 中的值、变量和类型 123456789101112131415161718192021scala&gt; for &#123; | x &lt;- Seq(1, false, 2.7, &quot;one&quot;, &#x27;four, new java.util.Date(), new RuntimeException(&quot;运行时异常&quot;)) | &#125; &#123; | val str = x match &#123; | case d: Double =&gt; s&quot;double: $d&quot; | case false =&gt; &quot;boolean false&quot; | case d: java.util.Date =&gt; s&quot;java.util.Date: $d&quot; | case 1 =&gt; &quot;int 1&quot; | case s: String =&gt; s&quot;string: $s&quot; | case symbol: Symbol =&gt; s&quot;symbol: $symbol&quot; | case unexpected =&gt; s&quot;unexpected value: $unexpected&quot; | &#125; | println(str) | &#125;int 1boolean falsedouble: 2.7string: onesymbol: &#x27;fourjava.util.Date: Sun Jul 24 16:51:20 CST 2016unexpected value: java.lang.RuntimeException: 运行时异常 上面小试牛刀校验变量类型的同时完成类型转换功能。在Java中，你肯定写过或见过如下的代码： 123456789public void receive(message: Object) &#123; if (message isInstanceOf String) &#123; String strMsg = (String) message; .... &#125; else if (message isInstanceOf java.util.Date) &#123; java.util.Date dateMsg = (java.util.Date) message; .... &#125; ....&#125; 对于这样的代码，真是辣眼睛啊~~~。 序列的匹配 12345678910111213141516171819202122232425262728293031323334scala&gt; val nonEmptySeq = Seq(1, 2, 3, 4, 5)scala&gt; val emptySeq = Seq.empty[Int]scala&gt; val emptyList = Nilscala&gt; val nonEmptyList = List(1, 2, 3, 4, 5)scala&gt; val nonEmptyVector = Vector(1, 2, 3, 4, 5)scala&gt; val emptyVector = Vector.empty[Int]scala&gt; val nonEmptyMap = Map(&quot;one&quot; -&gt; 1, &quot;two&quot; -&gt; 2, &quot;three&quot; -&gt; 3)scala&gt; val emptyMap = Map.empty[String, Int]scala&gt; def seqToString[T](seq: Seq[T]): String = seq match &#123; | case head +: tail =&gt; s&quot;$head +: &quot; + seqToString(tail) | case Nil =&gt; &quot;Nil&quot; | &#125;scala&gt; for (seq &lt;- Seq( | nonEmptySeq, emptySeq, nonEmptyList, emptyList, | nonEmptyVector, emptyVector, nonEmptyMap.toSeq, emptyMap.toSeq)) &#123; | println(seqToString(seq)) | &#125;1 +: 2 +: 3 +: 4 +: 5 +: NilNil1 +: 2 +: 3 +: 4 +: 5 +: NilNil1 +: 2 +: 3 +: 4 +: 5 +: NilNil(one,1) +: (two,2) +: (three,3) +: NilNil 模式匹配能很方便的抽取序列的元素，seqToString使用了模式匹配以递归的方式来将序列转换成字符串。case head +: tail将序列抽取成“头部”和“非头部剩下”两部分，head将保存序列第一个元素，tail保存序列剩下部分。而case Nil将匹配一个空序列。 case class的匹配 12345678910111213141516171819202122232425262728scala&gt; trait Personscala&gt; case class Man(name: String, age: Int) extends Personscala&gt; case class Woman(name: String, age: Int) extends Personscala&gt; case class Boy(name: String, age: Int) extends Personscala&gt; val father = Man(&quot;父亲&quot;, 33)scala&gt; val mather = Woman(&quot;母亲&quot;, 30)scala&gt; val son = Man(&quot;儿子&quot;, 7)scala&gt; val daughter = Woman(&quot;女儿&quot;, 3)scala&gt; for (person &lt;- Seq[Person](father, mather, son, daughter)) &#123; | person match &#123; | case Man(&quot;父亲&quot;, age) =&gt; println(s&quot;父亲今年$&#123;age&#125;岁&quot;) | case man: Man if man.age &lt; 10 =&gt; println(s&quot;man is $man&quot;) | case Woman(name, 30) =&gt; println(s&quot;$&#123;name&#125;今年有30岁&quot;) | case Woman(name, age) =&gt; println(s&quot;$&#123;name&#125;今年有$&#123;age&#125;岁&quot;) | &#125; | &#125;父亲今年33岁母亲今年有30岁man is Man(儿子,7)女儿今年有3岁 在模式匹配中对case class进行解构操作，可以直接提取出感兴趣的字段并赋给变量。同时，模式匹配中还可以使用guard语句，给匹配判断添加一个if表达式做条件判断。 并发Scala是对多核和并发编程的支付做得非常好，它的Future类型提供了执行异步操作的高级封装。 Future对象完成构建工作以后，控制权便会立刻返还给调用者，这时结果还不可以立刻可用。Future实例是一个句柄，它指向最终可用的结果值。不论操作成功与否，在future操作执行完成前，代码都可以继续执行而不被阻塞。Scala提供了多种方法用于处理future。 12345678910111213141516171819202122232425scala&gt; :paste// Entering paste mode (ctrl-D to finish)import scala.concurrent.duration.Durationimport scala.concurrent.&#123;Await, Future&#125;import scala.concurrent.ExecutionContext.Implicits.globalval futures = (0 until 10).map &#123; i =&gt; Future &#123; val s = i.toString print(s) s &#125;&#125;val future = Future.reduce(futures)((x, y) =&gt; x + y)val result = Await.result(future, Duration.Inf)// Exiting paste mode, now interpreting.0132564789scala&gt; val result = Await.result(future, Duration.Inf)result: String = 0123456789 上面代码创建了10个Future对象，Future.apply方法有两个参数列表。第一个参数列表包含一个需要并发执行的命名方法体（by-name body）；而第二个参数列表包含了隐式的ExecutionContext对象，可以简单的把它看作一个线程池对象，它决定了这个任务将在哪个异步（线程）执行器中执行。futures对象的类型为IndexedSeq[Future[String]]。本示例中使用Future.reduce把一个futures的IndexedSeq[Future[String]]类型压缩成单独的Future[String]类型对象。Await.result用来阻塞代码并获取结果，输入的Duration.Inf用于设置超时时间，这里是无限制。 这里可以看到，在Future代码内部的println语句打印输出是无序的，但最终获取的result结果却是有序的。这是因为虽然每个Future都是在线程中无序执行，但Future.reduce方法将按传入的序列顺序合并结果。 除了使用Await.result阻塞代码获取结果，我们还可以使用事件回调的方式异步获取结果。Future对象提供了几个方法通过回调将执行的结果返还给调用者，常用的有： onComplete: PartialFunction[Try[T], Unit]：当任务执行完成后调用，无论成功还是失败 onSuccess: PartialFunction[T, Unit]：当任务成功执行完成后调用 onFailure: PartialFunction[Throwable, Unit]：当任务执行失败（异常）时调用 123456789101112131415import scala.concurrent.Futureimport scala.util.&#123;Failure, Success&#125;import scala.concurrent.ExecutionContext.Implicits.globalval futures = (1 to 2) map &#123; case 1 =&gt; Future.successful(&quot;1是奇数&quot;) case 2 =&gt; Future.failed(new RuntimeException(&quot;2不是奇数&quot;))&#125;futures.foreach(_.onComplete &#123; case Success(i) =&gt; println(i) case Failure(t) =&gt; println(t)&#125;)Thread.sleep(2000) futures.onComplete方法是一个偏函数，它的参数是：Try[String]。Try有两个子类，成功是返回Success[String]，失败时返回Failure[Throwable]，可以通过模式匹配的方式获取这个结果。 总结本篇文章简单的介绍了Scala的语言特性，本文并不只限于Java程序员，任何有编程经验的程序员都可以看。现在你应该对Scala有了一个基础的认识，并可以写一些简单的代码了。我在博客中分享了一些《Scala实战（系列）》文章，介绍更函数式的写法及与实际工程中结合的例子。也欢迎对Scala感兴趣的同学与我联系经，一起交流、学习。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"入门","slug":"入门","permalink":"https://yangbajing.github.io/tags/%E5%85%A5%E9%97%A8/"}]},{"title":"Scala实战：使用Actor来控制集成API的并发请求","slug":"scala实战：使用actor来控制集成api的并发请求","date":"2016-06-29T05:52:51.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/06/29/scala实战：使用actor来控制集成api的并发请求/","link":"","permalink":"https://yangbajing.github.io/2016/06/29/scala%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8actor%E6%9D%A5%E6%8E%A7%E5%88%B6%E9%9B%86%E6%88%90api%E7%9A%84%E5%B9%B6%E5%8F%91%E8%AF%B7%E6%B1%82/","excerpt":"","text":"本文源码在：https://github.com/yangbajing/scala-applications/tree/master/combine-request 背景最近在一些大数据相关工作，除了自身的数据外，我们也会接入很多外部的第3方数据。这些第3方数据提供商都提供了基于HTTP的服务。当然，这些数据是收费的。而且重复调用是需要重复收费的。这就需要我们在调用数据后把它存储下来，这样在一定时间内（因为在超过一定时间后我们会需要再次向第3方数据提供商请求，主要是用于确认数据是否更新。这里不得不吐槽下，对方为什么不提供一个数据是否更新的接口呢？）再次使用这份数据就不需要向第3方数据提供商重复付费了。 这里，若同时有A、B、C三个用户请求同一份数据：Company。若假设我们在调用第3方数据提供商是需要持续1秒钟的时间。虽然我们在成功获取到 Company 后都会把数据缓存到DB里。但因为A、B、C三个用户请求是同时发来的，他们都会先读DB来获得是否有要请求的数据。而这个时间DB里是没有他们需要的数据的，这时我们就会向第3方数据提供商发送3次相同 Company 的数据请求，也就是说 Company 这份数据我们向第3方数据提供商付了3次费。想想，心情就不好了…… 这篇文章要介绍的就是怎样基于Akka的Actor模型来解决这一问题。若你还不了解Akka，你可以看看Akka官网：Akka。本文会基于Akka for Scala讲解，若你对Scala还不甚了解，推荐学习 《Scala函数式程序设计原理》 和 《Twitter的Scala入门教学》。 目的要解决之前说到的那个问题，我们需要把同时发来的并发请求合并到一起，只向第3方数据提供商请求一次付费API。同时在收到结果后先把数据缓存到本地数据库以后再向并发请求者们返回已缓存过的结果。这样下一次再查询相同数据时就可以从本地数据库中直接获取到。 代码ForwardCompanyActor 首先我们来看看Actor的定义，我们需要把读本地数据库、向第3方数据提供商发请求、控制多个客户端并发调用这些动作都合并到一个actor中。这里定义了一个ForwardCompanyActor接口来实现这些功能，待会具体的实现类将实现从本地数据库读和从第3方数据提供商读两个函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445 type ReadFromDB = (String) =&gt; Future[Option[JsValue]] type ReadFromInfra = (String) =&gt; Future[Option[JsValue]]trait ForwardCompanyActor extends Actor &#123; val companyListeners = mutable.Map.empty[String, Set[ActorRef]] override def receive = &#123; case QueryCompany(companyName, doSender) =&gt; val listener = if (doSender == Actor.noSender) sender() else doSender registerListener(companyName, listener) case ReceiveQueryCompanyResult(companyName, maybeJsValue) =&gt; dispatchListeners(companyName, maybeJsValue) &#125; def performReadTask(companyName: String): Unit = &#123; import context.dispatcher readFromDB(companyName) .flatMap(maybe =&gt; if (maybe.isEmpty) readFromInfra(companyName) else Future.successful(maybe)) .foreach(maybe =&gt; self ! ReceiveQueryCompanyResult(companyName, maybe)) &#125; def registerListener(companyName: String, listener: ActorRef): Unit = companyListeners.get(companyName) match &#123; case Some(actors) =&gt; companyListeners.put(companyName, actors + listener) case None =&gt; companyListeners.put(companyName, Set(listener)) performReadTask(companyName) &#125; def dispatchListeners(companyName: String, maybeJsValue: Option[JsValue]): Unit = &#123; val maybeListener = companyListeners.get(companyName) maybeListener.foreach &#123; listeners =&gt; for (listener &lt;- listeners) &#123; listener ! maybeJsValue &#125; companyListeners -= companyName &#125; &#125; val readFromInfra: ReadFromInfra val readFromDB: ReadFromDB&#125; 希望你没有被这一大段代码给吓到，接下来我会详解说明每段代码的意思。 type为函数签名定义了两个别名。而Trait中有两个函数值：readFromInfra和readFromDB是需要实现类实现的。它们分别是从第3方数据提供获取数据和从本地数据库中获取数据。 在ForwardCompanyActor的开头，定义了一个可变Map集合：companyListeners，它将保存每一个查询关键词（假定我们要查询一家公司的工商信息，而这家公司的全名就会做为””Key””）在同一时间的所有监听者（同时想查询这家公司工商信息的监听者（就是ActorRef）集合则作为””Value””）。 receive是一个PartialFunction，是每个Actor都要实现的函数，它将处理收到的每一条消息。在这里，我们只处理了两类消息：QueryCompany和ReceiveQueryCompanyResult。它们的作用分别是注册请求监听者和将收到的某个公司的工商信息分发给关注此数据的每一个监听者。 现来看registerListener函数。在每次收到对某个公司的调用请求时它都会判断actor内现在是否已存在正在进行中的对此公司的数据查询任务。若存在，则它会简单的把监听者（就是ActorRef）加到对应companyName的ActorRef集合里。否则，则会创建一个新的Set(listener)，并把它作为””Value””和companyName一起存入companyListeners中，并同时调用performReadTask函数执行实际的读数据请求。 继续看performReadTask函数。它会按着先读本地数据库，若数据库中未找到则再向第3方数据提供商请求，最后再成功获取到数据后向当前actor实例，也就是self发送ReceiveQueryCompanyResult消息。 这里需要注意的是：.foreach(maybe =&gt; self ! ReceiveQueryCompanyResult(companyName, maybe))这段代码。这里之所以没有直接调用dispatchListeners函数来向所有相关监听者发送结果，而是发送一个收到结果消息给self是因为在此直接调用dispatchListeners会有并发争用问题。因为.foreach是在Future的一个事件回调函数，它执行时很有可能是在另一个线程，而这时很有可能ForwardCompanyActor同时会收到其它对此公司查询工商信息的请求。这里收到对公司的工商数据请求和执行dispatchListeners向监听者发送结果消息很有可能是同时发生的。很有可能造成向第3方数据提供商发送两次相同公司的工商数据查询请求，这样就会对同一家公司付两次费了。 而向当前actor发送一个ReceiveQueryCompanyResult消息，则可以解决这个问题。因为Actor在内部对收到的每一个消息是串行处理的（多个Actor相互之间是并行运行的）。在receive函数里收到ReceiveQueryCompanyResult消息时调用dispatcherListeners函数向监听者发送查询结果，若此时有新的相同公司调用请求进来，它会被压入Actor的MailQueue中，在dispatchListeners函数执行完成后receive才会处理新的QueryCompany请求。现在我们再看dispatchListeners函数的内部实现，它在向关注某一companyName的监听方都发送结果后会把此companyName比监控列表（companyListeners）中移除。这样新的QueryCompany请求将会生成一个新的Set(listener)加入监听队列，同时执行performReadTask函数，而在performReadTask函数会从本地数据库中找到这家公司的工商信息，这样就不会向第3方数据提供商重复调用并重复付费了。 ForwardCompanyActor封装了多个并发请求的合并，读本地数据库和读第3方数据提供商的请求，监听都的注册、消息发送通知等功能。 CorpDetailActor 完成ForwardCompanyActor功能接口的定义后，就需要一个具体的Actor来实现从数据库读和从第3方接入商读两个操作。 12345678910111213141516171819202122class CorpDetailActor(infraResource: InfraResource, infraMongodbRepo: InfraMongodbRepo) extends ForwardCompanyActor &#123; import context.dispatcher override val readFromDB: ReadFromDB = (companyName) =&gt; &#123; infraMongodbRepo.findCorpDetail(companyName) &#125; override val readFromInfra: ReadFromInfra = (companyName) =&gt; &#123; infraResource.corpDetail(companyName) .flatMap &#123; case Some(json) =&gt; infraMongodbRepo .saveCorpDetail(companyName, json.asInstanceOf[JsObject]) .map(_ =&gt; Some(json)) case None =&gt; Future.successful(None) &#125; &#125;&#125; 在这里我们实现了readFromDB和readFromInfra两个函数值，代码很直观。需要注意的地方是通过infraResource向第3方数据提供商付费请求数据获得结果后缓存数据到本地数据库这个地方。一定要在本地缓存完成以后再向调用方返回数据，若你直接向调用方返回数据而把缓存操作放到另一个线程中，那这里又会引起一个并发问题。因为在你缓存成功之前很有可能会有另一个请求要求查询相同数据，而这时它在本地数据库中并不能找到，而系统会再次向第3方数据提供收请求你刚刚才付费了的那家公司的工商信息。所以，千万记住！在缓存成功后再向调用方返回数据。 测试CombineExample 合并请示测试效果： 1234[2016-07-02T13:30:29.514] 本地数据库未找到公司：科技公司[2016-07-02T13:30:30.526] 收到查询：科技公司 工商信息付费请求[2016-07-02T13:30:30.529] 保存公司: Company(科技公司) 成功Some(Company(科技公司)), Some(Company(科技公司)), Some(Company(科技公司)) RepetitionExample 未合并请示时测试效果： 12345678910[2016-07-02T17:30:45.182] 本地数据库未找到公司：科技公司[2016-07-02T17:30:45.182] 本地数据库未找到公司：科技公司[2016-07-02T17:30:45.181] 本地数据库未找到公司：科技公司[2016-07-02T17:30:46.204] 收到查询：科技公司 工商信息付费请求[2016-07-02T17:30:46.204] 收到查询：科技公司 工商信息付费请求[2016-07-02T17:30:46.206] 收到查询：科技公司 工商信息付费请求[2016-07-02T17:30:46.216] 保存公司: Company(科技公司) 成功[2016-07-02T17:30:46.216] 保存公司: Company(科技公司) 成功[2016-07-02T17:30:46.216] 保存公司: Company(科技公司) 成功Some(Company(科技公司)), Some(Company(科技公司)), Some(Company(科技公司))","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala, akka, actor","slug":"scala-akka-actor","permalink":"https://yangbajing.github.io/tags/scala-akka-actor/"}]},{"title":"我会做的技术选型","slug":"我会做的技术选型","date":"2016-04-03T03:54:08.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/04/03/我会做的技术选型/","link":"","permalink":"https://yangbajing.github.io/2016/04/03/%E6%88%91%E4%BC%9A%E5%81%9A%E7%9A%84%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/","excerpt":"","text":"Java/Scala：全功能的业务、服务端开发平台。大数据开发：Spark、Scala、Akka Node.js：前端不说了，还有其它更好的选择吗 Go\u0010\u0005：21世纪的C语言，分布式开发、API开发利器 Python：胶水、灵活的脚本语言。数据科学家的最爱 开门见山，先表明下我的态度吧。以上4个是我的首先，个人认为很不错的技术选型。当然，也不是非此不可，技术选型这个除了从技术本身考虑，很多时候还得从团队、成本等多方面考虑。他并不是非此不可的，也不是排它的。不用以上4个，也可以开发出很好的产品；用了，也不代表就可以开发出好的产品。也可以在选择以上4个的同时再使用其它的，这个都可以。说白了，这个更多还是看能说得上话的那个人喜欢什么^_^ Java/ScalaJava是一个平台，并不只是一门语言。基于其上的Spring、Lagom、Play、JFinal等都是很好的应用开发框架。 Spring、Java EE已经成为企业开发事实上的标准了…… 而现在最火的大数据基本都是基于Java的，这就不多细说了。 而Java做为一个平台的标志还在于其上丰富的JVM语言，如：Scala、Kotlin、Groovy、Clojure、JRuby、Jython、Javascript（nashorn）等。可以满足各种层次（技术人员的水平）、各种业务的需要而在一个统一的平台里进行。 Node.jsBabel、Webpack、Glup和React、Angular及ES6、Typescript等都是基于Node的，还需要说些什么吗？ GoGo是一个比较有意思的存在，好像在中国的应用比美国还多。百度、蚂蚁金服、360、小米、美团、金山、七牛……你可以找到一大串的中国高端互联网企业在核心功能中使用它。 这就是他最好的背书！ Python在我眼里，Python算不上好，我觉得他就是一个打了很多补丁、且补得一般般的感觉。 但他够用、方便、灵活，这就够了！","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"工作","slug":"工作","permalink":"https://yangbajing.github.io/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"技术架构","slug":"技术架构","permalink":"https://yangbajing.github.io/tags/%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/"},{"name":"技术选型","slug":"技术选型","permalink":"https://yangbajing.github.io/tags/%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/"},{"name":"Scala","slug":"Scala","permalink":"https://yangbajing.github.io/tags/Scala/"},{"name":"Java","slug":"Java","permalink":"https://yangbajing.github.io/tags/Java/"},{"name":"Node","slug":"Node","permalink":"https://yangbajing.github.io/tags/Node/"},{"name":"Go","slug":"Go","permalink":"https://yangbajing.github.io/tags/Go/"},{"name":"Python","slug":"Python","permalink":"https://yangbajing.github.io/tags/Python/"}]},{"title":"Hive与Spark","slug":"hive与spark","date":"2016-03-31T03:27:39.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/03/31/hive与spark/","link":"","permalink":"https://yangbajing.github.io/2016/03/31/hive%E4%B8%8Espark/","excerpt":"","text":"Spark与Hadoop安装见此：安装Spark1.5与Hadoop2.6 注意：Spark官方提供的二进制发行版是不支持hive的，需要自行编译。 安装hive12wget -c http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;apache&#x2F;hive&#x2F;hive-1.1.1&#x2F;apache-hive-1.1.1-bin.tar.gztar apache-hive-1.1.1-bin.tar.gz -C &#x2F;opt&#x2F;local 设置hive环境变量： 1export HIVE_HOME&#x3D;&quot;&#x2F;opt&#x2F;local&#x2F;apache-hive-1.1.1-bin&quot; 编辑 $HIVE_HOME/conf/hive-site.xml： 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://192.168.31.101/metastore_db?createDatabaseIfNotExist=true&lt;/value&gt; &lt;description&gt;metadata is stored in a MySQL server&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;MySQL JDBC driver class&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hiveuser&lt;/value&gt; &lt;description&gt;user name for connecting to mysql server&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;hive123&lt;/value&gt; &lt;description&gt;password for connecting to mysql server&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 设置MySQL的Hive元数据库。 12345678910111213mysql -u root -pmysql&gt; CREATE DATABASE metastore_db;Query OK, 1 row affected (0.00 sec)mysql&gt; CREATE USER &#39;hiveuser&#39;@&#39;%&#39; IDENTIFIED BY &#39;hive123&#39;;Query OK, 0 rows affected (0.00 sec)mysql&gt; GRANT all on *.* to &#39;hiveuser&#39;@localhost identified by &#39;hive123&#39;;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 执行 $HIVE_HOME/bin/hive 即可进入 hive cli 控制台了。 一些注意事项hive.optimize.ppd BUG在执行一些 hiveQL 操作时， 1Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo.getConvertedNode(Lorg&#x2F;apache&#x2F;hadoop&#x2F;hive&#x2F;ql&#x2F;lib&#x2F;Node;)Lorg&#x2F;apache&#x2F;hadoop&#x2F;hive&#x2F;ql&#x2F;plan&#x2F;ExprNodeDesc; 1hive&gt; set hive.optimize.ppd&#x3D;false; 注意 hive jline与hadoop jline起冲突https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started Hive 已经更新 Jlive2 版本，而 hadoop 还是使用的 0.9x 系列。可以这样设置来解决这个问题：优先使用用户提供的jar包。 1export HADOOP_USER_CLASSPATH_FIRST&#x3D;true 为Spark添加mysql驱动编辑 $SPARK_HOME/conf/spark-defaults.conf 文件，设置以下依赖。当使用 spark-submit提交任务时需要 spark.executor.extraClassPath 配置，而使用 spark-shell和spark-sql 等方式时需要 spark.driver.extraClassPath 配置。 12spark.executor.extraClassPath &#x2F;opt&#x2F;local&#x2F;libs&#x2F;mysql-connector-java-5.1.38.jarspark.driver.extraClassPath &#x2F;opt&#x2F;local&#x2F;libs&#x2F;mysql-connector-java-5.1.38.jar 也可以在使用 spark-sql 时添加命令行参数来设置mysql驱动：--driver-class-path /opt/local/libs/mysql-connector-java-5.1.38.jar","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"spark","slug":"bigdata/spark","permalink":"https://yangbajing.github.io/categories/bigdata/spark/"}],"tags":[{"name":"spark","slug":"spark","permalink":"https://yangbajing.github.io/tags/spark/"},{"name":"hadoop","slug":"hadoop","permalink":"https://yangbajing.github.io/tags/hadoop/"},{"name":"hive","slug":"hive","permalink":"https://yangbajing.github.io/tags/hive/"},{"name":"spark sql","slug":"spark-sql","permalink":"https://yangbajing.github.io/tags/spark-sql/"}]},{"title":"Spark实战：工程实践","slug":"spark实战：工程实践","date":"2016-03-12T09:17:38.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/03/12/spark实战：工程实践/","link":"","permalink":"https://yangbajing.github.io/2016/03/12/spark%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"工欲善其事，必先利其器。 （本文是基于 sbt 来配置 Spark 开发的工程化，支持 Scala/Java 编程语言。Python 和 R 用户需要使用其它方式来实现工程化。） 今天谈谈Spark开发中的工程化问题。我们都知道Spark程序是在集群上跑的，需要把程序打包后使用 $SPARK_HOME/bin/spark-sumibt 到Spark集群上。 在开发、测试时，每次代码修改后都打包、提交、运行……效率还是比较差的。而提交到集群上的程序一般情况下都是连接的生产环境的数据，先不说安全问题，就当每次都要完整跑完生产环境的数据也是很费时的事情。 更佳的实践是我们在开发时连接 local 模式，或者使用一个单独的比较小的集群，以及一个数量比较少的数据集来进行测试。 使用sbt配置开发环境我们来看看 build.sbt 配置，在开发 spark 应用时需要的基本设置。 123456789101112131415161718192021222324scalaVersion := &quot;2.11.7&quot;scalacOptions ++= Seq( &quot;-encoding&quot;, &quot;utf8&quot;, &quot;-unchecked&quot;, &quot;-feature&quot;, &quot;-deprecation&quot;)assemblyJarName in assembly := &quot;spark-startup.jar&quot;assemblyOption in assembly := (assemblyOption in assembly).value.copy(includeScala = false)test in assembly := &#123;&#125;val verSpark = &quot;1.5.2&quot;val verHadoop = &quot;2.6.2&quot; libraryDependencies ++= Seq( &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;1.5.2&quot; % &quot;provided,test&quot;, &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;1.5.2&quot; % &quot;provided,test&quot;, &quot;org.scalatest&quot; %% &quot;scalatest&quot; % &quot;2.2.6&quot;) 我们添加 spark-core、spark-sql和scalatest两个依赖库，前两个提供了 Spark RDD和 Spark SQL/DataFrame 编程支持，后一个提供了测试支持。 这里需要注意的点是：provided 配置，它的含意是在打包所指定的库由运行时环境提供，这里只是开发时需要依赖它。这一点很重要，若我们在提交给 Spark 的jar包里包含了 spark-xxx 库，会引起运行时错误。 我们还需要给 sbt 添加 sbt-assembly 插件，用于更好的控制打包过程。project/plugins.sbt： 1addSbtPlugin(&quot;com.eed3si9n&quot; % &quot;sbt-assembly&quot; % &quot;0.14.2&quot;) 开发Spark的开发不是本文重点，这里会分享些我在日常开发中的经验。关于：测试和提交到集群运行。先来看看代码： 1234567891011121314151617181920212223242526272829303132333435package exampleimport org.apache.spark.sql.SQLContextimport org.apache.spark.&#123;SparkConf, SparkContext&#125;/** * Created by Yang Jing (yangbajing@gmail.com) on 2016-03-12. */class SparkApp(sc: SparkContext) extends Serializable &#123; val sqlContext = new SQLContext(sc) def run() = &#123; val jsonStrings = Seq( &quot;&quot;&quot;&#123;&quot;name&quot;:&quot;杨景&quot;,&quot;age&quot;:31&#125;&quot;&quot;&quot;, &quot;&quot;&quot;&#123;&quot;name&quot;:&quot;羊八井&quot;,&quot;age&quot;31&#125;&quot;&quot;&quot;, &quot;&quot;&quot;&#123;&quot;name&quot;:&quot;yangbajing&quot;,&quot;age&quot;:31&#125;&quot;&quot;&quot; ) val rdd = sc.parallelize(jsonStrings) val sql = sqlContext.read.json(rdd) sql.show() &#125;&#125;object SparkApp &#123; def main(args: Array[String]): Unit = &#123; val conf = new SparkConf() val sc = new SparkContext(conf) val app = new SparkApp(sc) app.run() &#125;&#125; 这里我们定义了 SparkApp 类和它的伴生对象，业务逻辑将写在 SparkApp 类里，SparkConf 将在伴生对象的 main 方法中定义。SparkContext 是做为参数传入 SparkApp 类的，在 object SparkAPP 中并未设置 master 和 appName ，因为这两个值将会在提交脚本（一个简单的shell脚本，用以指定 spark-submit 的相关参数）中设置。 （需要注意的是 SparkApp class要实现 Serializable 接口，只有这样 Spark 才能正常的使用序列化将代码分配的集群中运行。） 提交脚本 1234567891011#!/usr/bin/env bash$SPARK_HOME/bin/spark-submit \\ --class sample.SparkApp \\ --master spark://sc-data-server-1:7077 \\ --name &quot;sample.SparkApp&quot; \\ --executor-memory 10G \\ --driver-memory 2G \\ --total-executor-cores 4 \\ --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \\ ../target/scala-2.11/spark-startup.jar &amp; 提交脚本里我们设置了将程序提交到 Spark 集群运行所需要的参数： –class: 指定 jar 包里要执行的 main 方法所在类 –master: 指定 spark master 地址 –name: 设置程序名字 –executor-memory: 指定每个 Work 所能使用内存 –total-executor-cores: 设置集群使用CPU core总数 –driver-memory: 指定驱动程序使用内存 –conf: 设置额外参数，有多个参数需要设置可使用多个 –conf 配置项 jar path: 脚本的最后一荐设置 jar 包路径 这里 –class, –master, –mane 和最后的 jar 包路径是必需设置的参数。 提交脚本已经写好了，那怎样生成 jar（../target/scala-2.11/spark-startup.jar） 包呢？使用 sbt assembly 命令可以生成 jar 包在 target/scala-2.11` 目录下。 使用 sbt 来开发 spark 的产品级程序，这样就可以了。但若每次修改代码都执行以上打包、提交到集群等步骤。效率还是有点慢，且实际上也不是个好的方式。接下来，再介绍下怎么使用 scalatest 来测试我们的 spark 程序。 测试程序 首先来看看我们的 SparkAppTest 测序程序代码： 12345678910111213141516class SparkAppTest extends WordSpec &#123; &quot;SparkAppTest&quot; should &#123; &quot;run&quot; in &#123; val conf = new SparkConf() .setAppName(&quot;SparkAppTest&quot;) .setMaster(&quot;local[*]&quot;) val sc = new SparkContext(conf) val app = new SparkApp(sc) app.run() &#125; &#125;&#125; 在测试程序中，我们设置了 appName，并将 master 地址设置为：**local[*]**，含义是使用本地 Spark 模式，并使用所有CPU核。 总结\u000e做为一篇实战文章，是肯定会有代码详示的，代码在此：https://github.com/yangbajing/scala-applications/tree/master/spark-startup。 sbt 是一款不错的项目构建工具，但是国内用户使用时会遇到“墙”的问题。现在好了，国内 Scala 社区建立了 Repox 社区公服，它解决了 Scala 开发者除了语法外最大的一个难题。 Spark是优化的大数据工具（平台），希望能和各位爱好者多交流、学习。 相关文章： Learn Spark - 安装","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"spark","slug":"bigdata/spark","permalink":"https://yangbajing.github.io/categories/bigdata/spark/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"sbt","slug":"sbt","permalink":"https://yangbajing.github.io/tags/sbt/"},{"name":"spark","slug":"spark","permalink":"https://yangbajing.github.io/tags/spark/"}]},{"title":"Cassandra升级更新","slug":"cassandra升级更新","date":"2016-03-07T03:52:36.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/03/07/cassandra升级更新/","link":"","permalink":"https://yangbajing.github.io/2016/03/07/cassandra%E5%8D%87%E7%BA%A7%E6%9B%B4%E6%96%B0/","excerpt":"","text":"今天需要把集群安装的 cassandra 2.2.4 升级到 cassandra 2.2.5 ，这里记录下升级步骤。 （升级脚本见：https://gist.github.com/yangbajing/12461fcab190689f2499） 升级的主意事项和限制条件需求条件 Cassandra 2.0.x and 2.1.x: 需要 JRE 7 或更高版本（推荐JDK） Cassandra 2.2.x, 3.0.x, and 3.x: 需要 JRE 8 或更高版本（推荐JDK） 移出所有 dead 节点：nodetool removenode 升级限制 在执行升级步骤时有一些常用限制需要在整个集群遵循： 不要启用新特性（Do not enable new features.） 不要运行nodetool repair命令（Do not run nodetool repair.） 不要运行DDL和TRUNCATE这类CQL查询语句（Do not issue these types of CQL queries during a rolling restart: DDL and TRUNCATE.） 在升级期间，不同版本的节点显示的schema可能会不一致（During upgrades, the nodes on different versions might show a schema disagreement.） 升级步骤 设置新版 cassandra 2.2.5： 1tar zxf &#x2F;home&#x2F;scdata&#x2F;dsc-cassandra-2.2.5-bin.tar.gz -C &#x2F;opt&#x2F;local 如上，先解压新版cassandra到磁盘，再复制配置文件到cassandra 2.2.5目录中覆盖默认配置。可能需要复制的配置文件有： bin/cassandra.in.sh conf/cassandra-env.sh conf/cassandra.yaml conf/cassandra-rackdc.properties conf/cassandra-topology.properties 创建快照，防止升级失败。 1nodetool snapshot KEYSPACE -t snapshot_&#96;date &quot;+%Y-%m-%d&quot;&#96; 把 KEYSPACE 换成实际的keyspace名。若使用了JNA，则快照是通过硬链接实现的，并不会增加磁盘空间。创建快照时间很快。 停节点 12nodetool drain # 关闭写入，同时把数据写入文件nodetool stopdaemon # 停掉本节点 启动新节点 可选的 SSTables 更新 当升级cassandra是一个主要版本更新（如：1.2 to 2.0），或者是一个主要点的更新（如：2.0 to 2.1）时，需要在每个节点升级 SSTable。 1nodetool upgradesstables 结果日志，查看升级过程中是否有：warnings、errors和exceptions 在每个节点上重复以上步骤 最后官方升级详细文档见：upgradeCassandraDetails。 Cassandra的升级与维护应该是一个常态，推荐一年进行一次大版本的升级。这样可以避免版本跨度太大而引起的很多升级问题。","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"cassandra","slug":"bigdata/cassandra","permalink":"https://yangbajing.github.io/categories/bigdata/cassandra/"}],"tags":[{"name":"cassandra","slug":"cassandra","permalink":"https://yangbajing.github.io/tags/cassandra/"},{"name":"upgrading","slug":"upgrading","permalink":"https://yangbajing.github.io/tags/upgrading/"}]},{"title":"Scala开发者的Spring-Boot快速上手指南 01","slug":"scala开发者的spring-boot快速上手指南_01","date":"2016-03-03T13:02:53.000Z","updated":"2022-02-16T02:50:45.197Z","comments":true,"path":"2016/03/03/scala开发者的spring-boot快速上手指南_01/","link":"","permalink":"https://yangbajing.github.io/2016/03/03/scala%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84spring-boot%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97_01/","excerpt":"","text":"做为一个Scala爱好者，是很想基于 Lightbend 的一套架构进行软件开发的。Play，Akka，Scala，Spark……。不过理想很丰满，现实却很骨感。鉴于那批原教旨主义者，他们对 Spring 已经疯狂迷恋，我等讲道理、讲实际的人也只好将 Scala 与 Spring Boot 进行整合。这两兄弟是和睦的，是友好的，并不是有你无他，完全可以在能力和现实中实现一个美好的平衡。 （文章查考了：Scala开发者的SpringBoot快速入门指南 ，谢谢王福强老师的分享。） （本文示例在：https://github.com/yangbajing/spring-boot-scala/tree/v01） 创建支持Scala的Spring Boot应用 Java社区一般使用 Maven或Gradle 管理项目构建，鉴于 Maven 的使用更多，本文将只讲解 Maven 下的配置，Gradle 的配置请读者自行参考网上实现。当然，作为一个 Scalar ，基于 Sbt 的配置是肯定会讲到的，在 Sbt 下还有一个神器：sbt-package-native ，敬待下文详解。 Maven项目首先来看看配置文件 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;me.yangbajing.springscala&lt;/groupId&gt; &lt;artifactId&gt;springscala&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;springscala&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;scala.version&gt;2.11.7&lt;/scala.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-library&lt;/artifactId&gt; &lt;version&gt;$&#123;scala.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-compiler&lt;/artifactId&gt; &lt;version&gt;$&#123;scala.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;compile-scala&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;add-source&lt;/goal&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;test-compile-scala&lt;/id&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;add-source&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;recompileMode&gt;incremental&lt;/recompileMode&gt; &lt;compileOrder&gt;Mixed&lt;/compileOrder&gt; &lt;scalaVersion&gt;$&#123;scala.version&#125;&lt;/scalaVersion&gt; &lt;args&gt; &lt;arg&gt;-deprecation&lt;/arg&gt; &lt;/args&gt; &lt;jvmArgs&gt; &lt;jvmArg&gt;-Xms64m&lt;/jvmArg&gt; &lt;jvmArg&gt;-Xmx1024m&lt;/jvmArg&gt; &lt;/jvmArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 对于 Spring 部分的配置，这里就不多说了。重点说下 Scala 方面的配置。 首先你需要加入 Scala 的依赖库，这里加入了 scala-library 和 scala-compiler 两个包的依赖，这是在Java环境下编译 Scala 代码所必需的。 其次就是要添加 scala-maven-plugin 插件，以让 Maven 支持对 Scala 的编译操作。这里需要注意的是 recompileMode 指令，推荐使用 incremental 配置。 另一个需要注意的配置荐就是 compileOrder ，当项目同时使用了Java和Scala两种语言时它决定了两者的编译顺序。默认是 Mixed （混合顺序），其它还有两个选项是：JavaThenScala 和 ScalaThanJava。 编写Scala代码现在我们可以使用 Scala 来编写 spring boot 应用了，先来写一个 POJO 类。 123456class Message &#123; @BeanProperty var value: String = _&#125; 再来写一个 Controller ： 1234567891011121314@RestController@RequestMapping(Array(&quot;/api&quot;))class ApiController &#123; @RequestMapping(value = Array(&quot;/hello&quot;), method = Array(RequestMethod.GET)) @ResponseBody def hello(): Message = &#123; TimeUnit.SECONDS.sleep(6) val message = new Message() message.value = &quot;Hello, Scala for Spring!&quot; message &#125;&#125; 这里需要注意的是注解参数的传递方式，Scala 里没像 Java 一样会自动把字符串转换成注解里定义的数组参数，我们需要显示的定义一个数据传入。而且传入注解的参数值只能是一个常量，比如：&quot;/api/user&quot; ，不能像这样：Constant.API_PATH + &quot;/user&quot;。 运行项目打开终端，执行以下指令启动 spring boot 应用： 1mvn spring-boot:run 再打开一个终端，测试 API 功能： 1time curl -v http://localhost:8080/hello sbt项目\u000e这里使用了 .scala 的方式来配置 sbt 项目。sbt 的配置文件在项目根目录下的 project 目录： 123project&#x2F;├── Build.scala├── build.properties 在 build.properties 文件内指定了 sbt 的版本号，Build.scala 文件设置了详细的 Sbt 工程设置及编译选项等。我们先来看看配置文件内容： 1234567891011121314151617181920212223242526272829303132333435363738394041import sbt.Keys._import sbt._object Build extends Build &#123; override lazy val settings = super.settings :+ &#123; shellPrompt := (s =&gt; Project.extract(s).currentProject.id + &quot; &gt; &quot;) &#125; lazy val root = Project(&quot;springscala&quot;, file(&quot;.&quot;)) .settings( description := &quot;Spring boot scala&quot;, version := &quot;0.0.1&quot;, homepage := Some(new URL(&quot;https://github.com/yangbajing/spring-boot-scala&quot;)), organization := &quot;me.yangbajing&quot;, organizationHomepage := Some(new URL(&quot;http://www.yangbajing.me&quot;)), startYear := Some(2016), scalaVersion := &quot;2.11.7&quot;, scalacOptions ++= Seq( &quot;-encoding&quot;, &quot;utf8&quot;, &quot;-unchecked&quot;, &quot;-feature&quot;, &quot;-deprecation&quot; ), javacOptions ++= Seq( &quot;-source&quot;, &quot;1.8&quot;, &quot;-target&quot;, &quot;1.8&quot;, &quot;-encoding&quot;, &quot;utf8&quot;, &quot;-Xlint:unchecked&quot;, &quot;-Xlint:deprecation&quot; ), offline := true, libraryDependencies ++= Seq( _springBootStarterWeb, _springBootStarterTest)) val verSpringBoot = &quot;1.3.3.RELEASE&quot; val _springBootStarterWeb = &quot;org.springframework.boot&quot; % &quot;spring-boot-starter-web&quot; % verSpringBoot val _springBootStarterTest = &quot;org.springframework.boot&quot; % &quot;spring-boot-starter-test&quot; % verSpringBoot&#125; 没错，sbt 的配置文件就是实打实的 Scala 代码。sbt 也有一套像 Gradle 一样的 DSL 来定义项目配置信息，是以后缀 .sbt 结尾的文件。不过个人还是认为直接使用 Scala 代码做配置更直观、清晰。 具体配置含义，我这里就不细讲了。官方有很详细的教程和文档说明：sbt Reference Manual 。 总结Scala 从各方面来看，配置和代码，期简洁性都是优于Java。对于一个Scala爱好者，你的选择很多，比如：Play。不过，很多时候你需要考虑到各方面的利益。公司、团队、意愿等各方面。现实中，Spring 在 Java 生态圈还是使用最多的技术，Spring 框架的使用本身是未限制 JVM 平台上的各种主义的，它也可以很好的支持：Groovy、Kotlin 甚至 Clojure…… 本文简单讲解了怎样配置 pom.xml 以在 Spring boot 中支持 Scala，以及 sbt 工程又是怎样支持 Spring 的。这即是 Scala 开发者的 Spring boot 入门指南，亦可是 Java 程序员的 Scala 第一次尝试。希望能打开一座桥梁，让 Java 程序员开眼界，Scala 开发者务实。 下一篇文章我想进一步介绍下使用 Scala 开发 Spring 应用的一些好处和惯用法，接下来的文章还会讲到怎样结合 Akka 基于 Spring 开发一个 WebSocket 应用。 本系列文章 Scala开发者的Spring-Boot快速上手指南 01 Scala开发者的Spring-Boot快速上手指南 02：Scala惯用法","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://yangbajing.github.io/tags/spring-boot/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://yangbajing.github.io/tags/maven/"},{"name":"sbt","slug":"sbt","permalink":"https://yangbajing.github.io/tags/sbt/"}]},{"title":"安装Spark1.5.2与Hadoop2.6.2","slug":"安装spark1-5与hadoop2-6","date":"2016-02-27T09:02:21.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/02/27/安装spark1-5与hadoop2-6/","link":"","permalink":"https://yangbajing.github.io/2016/02/27/%E5%AE%89%E8%A3%85spark1-5%E4%B8%8Ehadoop2-6/","excerpt":"","text":"适用于 Hadoop 2.9 build spark 1.5.212.&#x2F;dev&#x2F;change-scala-version.sh 2.11.&#x2F;make-distribution.sh --name hadoop2.6-scala2.11 --tgz -Phadoop-2.6 -Pyarn -Phive -Phive-thriftserver -Dscala-2.11 1.6+可以添加：-Psparkr以支持 Spark R。 创建用户和组12sudo addgroup scdatasudo adduser --ingroup scdata scdata SSH无密码登录节点12scdata$ cd ~&#x2F;.ssh # 如果该目录不存在，则创建：mkdir ~&#x2F;.sshscdata$ ssh-keygen -t rsa # 一直回车即可，生成的密码保存在 .ssh&#x2F;id_rsa Master节点需要能无密码登录本机，这一步还需要执行： 1scdata$ cat ~&#x2F;.ssh&#x2F;id_rsa.pub &gt;&gt; ~&#x2F;.ssh&#x2F;authorized_keys 完成需要将公匙传到各Slave节点上： 12scdata$ scp ~&#x2F;.ssh&#x2F;authorized_keys scdata@salver1:~&#x2F;.ssh&#x2F;scdata$ scp ~&#x2F;.ssh&#x2F;authorized_keys scdata@salver2:~&#x2F;.ssh&#x2F; 现在就可以直接使用ssh hostname免密码登录到各节点上了。 安装Hadoop12345mkdir -p &#x2F;usr&#x2F;app&#x2F;hadoop&#x2F;datasudo chown -R scdata:scdata &#x2F;usr&#x2F;app&#x2F;hadoopsu - scdatascdata$ wget -c http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;hadoop&#x2F;common&#x2F;hadoop-2.6.2&#x2F;hadoop-2.6.2.tar.gzscdata$ tar zxf hadoop-2.6.2.tar.gz Hadoop伪分布式配置Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的Java进程来运行，节点既作为NameNode也作为DataNode。 （注：若系统 JAVA 比较复杂可以在 $HADOOP_HOME/etc/hadoop/hadoop-env.sh 文件指定 JAVA_HOME） Hadoop的配置文件位于/usr/local/hadoop/etc/hadoop/中，伪分布式需要修改2个配置文件core-site.xml和 hdfs-site.xml。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。 修改配置文件core-site.xml (vim /usr/local/hadoop/etc/hadoop/core-site.xml)，将当中的： 12&lt;configuration&gt;&lt;/configuration&gt; 修改为如下配置： 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/app/hadoop/data/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.31.101:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; （注：IP和PORT设置为想要的） 同样的，修改配置文件hdfs-site.xml： 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;&#x2F;name&gt; &lt;value&gt;1&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;app&#x2F;hadoop&#x2F;data&#x2F;dfs&#x2F;name&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;app&#x2F;hadoop&#x2F;data&#x2F;dfs&#x2F;data&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; 关于Hadoop配置项的说明 虽然只需要配置fs.defaultFS和dfs.replication即可运行（官方教程），但不配置hadoop.tmp.dir参数，刚默认使用的临时目录为/tmp/hadoop-hadoop。这个目录在系统重启后可能会被清理掉，导致必需重新执行format才行。所以最好指定hadoop.tmp.dir目录，同时也指定dfs.namenode.dir和dfs.datanode.data.dir。 配置完成后，执行namenode格式化： 1scdata$ .&#x2F;bin&#x2F;hdfs namenode -format 成功会看到终端输出提示。倒数第5行为：util.ExitUtil: Exiting with status 0时表示成功，否则是出错。若出现错误，请查检之前步骤是否正确。 1234515/12/08 11:43:29 INFO util.ExitUtil: Exiting with status 015/12/08 11:43:29 INFO namenode.NameNode: SHUTDOWN_MSG: /************************************************************SHUTDOWN_MSG: Shutting down NameNode at sc-007/127.0.1.1************************************************************/ 接着开启NameNode和DataNode守护进程： 1scdata$ .&#x2F;sbin&#x2F;start-dfs.sh （注：若出现SSH和登录提示，输入yes和按要求输入即可） 启动完后可以使用jps命令来判断是否启动成功： 12345scdata$ jps25889 DataNode26070 SecondaryNameNode28969 Jps25743 NameNode 成功启动后，可以访问Web界面：http://localhost:50070来查看Hadoop的信息。 导入数据到Hadoop要在HDFS上使用数据，需要先创建用户目录： 1scdata$ .&#x2F;bin&#x2F;hdfs dfs -mkdir -p &#x2F;user&#x2F;hadoop&#x2F;input 接着将 etc/hadoop 中的文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/hadoop/input 中: 12scdata$ .&#x2F;bin&#x2F;hdfs dfs -put etc&#x2F;hadoop&#x2F;*.xml &#x2F;user&#x2F;hadoop&#x2F;input&#x2F;scdata$ .&#x2F;bin&#x2F;hdfs dfs -ls &#x2F;user&#x2F;hadoop&#x2F;input 配置集群/分布式环境设置IP和hostname（注意：在集群/分布式环境下，设置/etc/hosts时127.0.0.1（回还地址IP）不能指向hostname，而只应该使外网IP指向hostname） Hadoop集群/分布式环境需要修改etc/hadoop中的5个配置文件：slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml。 slave编辑etc/hadoop/slave文件，删除localhost，把所有Slave的主机名写上，每行一个。 core-site.xml编辑etc/hadoop/core-site.xml文件如下： 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;app&#x2F;hadoop&#x2F;data&#x2F;tmp&lt;&#x2F;value&gt; &lt;description&gt;Abase for other temporary directories.&lt;&#x2F;description&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt; &lt;value&gt;hdfs:&#x2F;&#x2F;Master:9000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; hdfs-site.xml编辑etc/hadoop/hdfs-site.xml文件如下： 123456789101112131415161718&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt; &lt;value&gt;Master:50090&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;app&#x2F;hadoop&#x2F;data&#x2F;dfs&#x2F;name&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;app&#x2F;hadoop&#x2F;data&#x2F;dfs&#x2F;data&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;&#x2F;name&gt; &lt;value&gt;1&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; 因为只有一个Slave，所以这里dfs.replication的值设为1。 mapred-site.xml文件mapred-site.xml不存在，需要从模板中复制一份，然后修改配置文件如下： 1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt; &lt;value&gt;yarn&lt;&#x2F;value&gt;&lt;&#x2F;property&gt; yarn-site.xml编辑etc/hadoop/yarn-site.xml文件如下： 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt; &lt;value&gt;Master&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt; &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; 配置好后，将 Master 上的 Hadoop 文件复制到各个节点上(虽然直接采用 scp 复制也可以正确运行，但会有所不同，如符号链接 scp 过去后就有点不一样了。所以先打包再复制比较稳妥)。因为之前有跑过伪分布式模式，建议在切换到集群模式前先删除之前的临时文件。 12scdata$ tar zcf hadoop-2.6.tar.gz hadoop-2.6scp hadoop-2.6.tar.gz scdata@Slave:&#x2F;usr&#x2F;app&#x2F;hadoop&#x2F; （注：把hadoop传到每个节点并解压，设置好目录权限） 然后在Master节点上启动Hadoop： 123scdata$ .&#x2F;bin&#x2F;hdfs namenode -format # 首次运行需要执行初始化，后面不再需要scdata$ .&#x2F;sbin&#x2F;start-dfs.shscdata$ .&#x2F;sbin&#x2F;start-yarn.sh 在Master上使用jps命令可以查看各节点启动的进程 12345scdata$ jps28147 Jps27876 ResourceManager27493 NameNode27710 SecondaryNameNode 在Slave上使用jps也可以看到Master已经自动启动了Slave上的DataNode和NodeManager服务。另外也可以在Master节点上通过命令：bin/hdfs dfsadmin -report： 1234567891011121314151617181920212223242526272829$ .&#x2F;bin&#x2F;hdfs dfsadmin -reportConfigured Capacity: 950348005376 (885.08 GB)Present Capacity: 235839873024 (219.64 GB)DFS Remaining: 235839848448 (219.64 GB)DFS Used: 24576 (24 KB)DFS Used%: 0.00%Under replicated blocks: 0Blocks with corrupt replicas: 0Missing blocks: 0-------------------------------------------------Live datanodes (1):Name: 192.168.31.121:50010 (Slave)Hostname: SlaveDecommission Status : NormalConfigured Capacity: 950348005376 (885.08 GB)DFS Used: 24576 (24 KB)Non DFS Used: 714508132352 (665.44 GB)DFS Remaining: 235839848448 (219.64 GB)DFS Used%: 0.00%DFS Remaining%: 24.82%Configured Cache Capacity: 0 (0 B)Cache Used: 0 (0 B)Cache Remaining: 0 (0 B)Cache Used%: 100.00%Cache Remaining%: 0.00%Xceivers: 1Last contact: Tue Dec 08 16:43:28 CST 2015","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"}],"tags":[{"name":"spark","slug":"spark","permalink":"https://yangbajing.github.io/tags/spark/"},{"name":"hadoop","slug":"hadoop","permalink":"https://yangbajing.github.io/tags/hadoop/"}]},{"title":"Cassandra用户认证","slug":"cassandra用户认证","date":"2016-01-23T03:55:37.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/01/23/cassandra用户认证/","link":"","permalink":"https://yangbajing.github.io/2016/01/23/cassandra%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/","excerpt":"","text":"Cassandra默认是不需要用户名和密码登录的，这样其实并不安全。 修改配置文件：conf/cassandra.yaml 启动用户名密码登录： 12authenticator: PasswordAuthenticatorauthorizer: CassandraAuthorizer 重新启动Cassandra，再次使用 bin/cqlsh 登录会提示 **AuthenticationFailed(‘Remote end requires authentication.’,)**。这时使用用户名和密码登录即可。 1.&#x2F;cqlsh 192.168.0.101 -u cassandra -p cassandra 使用 PasswordAuthenticator 后，cassandra会默认创建super user，用户名和密码均为：cassandra。那么，如何修改该super user的密码呢？ 1alter user cassandra with password &#39;cassandra1&#39;; 执行语句后密码立即生效。 创建用户 1create user user1 with password &#39;password1&#39;; 分配权限 1GRANT ALL PERMISSIONS ON KEYSPACE data TO data; 建议分配可访问表 12GRANT select PERMISSION ON system.size_estimates TO devser;GRANT select PERMISSION ON system_auth.roles TO devser; 分配权限语句如下： 12GRANT permission_name PERMISSION| ( GRANT ALL PERMISSIONS ) ON resource TO user_name | role_name 其中 permission_name 为权限列表，有如下： ALL ALTER AUTHORIZE CREATE DROP MODIFY SELECT resource 为被分配的资源，如下几种： ALL KEYSPACES KEYSPACE keyspace_name TABLE keyspace_name.table_name 集群安全 authenticator: org.apache.cassandra.auth.PasswordAuthenticator: 用户密码将保存在 system_auth.credentials 表 authorizer: org.apache.cassandra.auth.CassandraAuthorizer: 用户权限将保存在 system_auth.permissions 表。 system_auth 的默认 replication 因子为1，这在集群中是非常危险的。若其中一个节点挂掉，而正好账号相关数据只保存在挂掉的那一台上会造成登录时不能通过授权认证。最好通过 ALTER KEYSPACE 命令修改默认设置。 SimpleStrategy 1ALTER KEYSPACE &quot;system_auth&quot; WITH REPLICATION &#x3D; &#123; &#39;class&#39; : &#39;SimpleStrategy&#39;, &#39;replication_factor&#39; : 3 &#125;; NetworkTopology 1ALTER KEYSPACE &quot;system_auth&quot; WITH REPLICATION &#x3D; &#123;&#39;class&#39; : &#39;NetworkTopologyStrategy&#39;, &#39;dc1&#39; : 2, &#39;dc2&#39; : 3&#125;; 注：使用NetworkTopology需要设置cassandra.yaml的endpoint_snitch: GossipingPropertyFileSnitch等具有机架感知功能的snitch","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"cassandra","slug":"bigdata/cassandra","permalink":"https://yangbajing.github.io/categories/bigdata/cassandra/"}],"tags":[{"name":"cassandra","slug":"cassandra","permalink":"https://yangbajing.github.io/tags/cassandra/"}]},{"title":"Linux系统运维常用工具","slug":"linux系统运维常用工具","date":"2016-01-12T01:40:17.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/01/12/linux系统运维常用工具/","link":"","permalink":"https://yangbajing.github.io/2016/01/12/linux%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/","excerpt":"","text":"本文记录一些 Linux 日常运维相关工具使用方法。 （注：未做特殊说明，以下设置均指：Ubuntu Server 14.04，并测试通过。） 系统设置更改系统默认字符集 Ubuntu Server下，需要修改 /etc/default/locale 文件使配置生效（需要重启系统）。也可以在每个用户的登录 .bashrc 或 .bash_profile中设置LANG、LANGUAGE等环境变量。 用户管理创建用户 Linux系统下有两个命令可以创建用户：useradd和adduser。 useradd：若后面不添加任何参数，默认创建的是一个三无用户：无主目录、元密码、元系统登录Shell。会添加用户名，并默认创建和用户名相同的组名，但不会提示创建新密码。 adduser：创建用户的过程更像是一种人机对话，系统会提示你输入各种信息，并根据这些信息帮你创建用户 useradd是一个可执行程序，而adduser是一个Perl脚本。adduser更适合初级用户，只要跟着系统提示一步一步走下去即可。而useradd更适合高级用户，可以更灵活的定制。 进程管理ps命令查看进程运行时间 1ps -eo pid,tty,user,comm,stime,etime | grep java 网络管理查看已打开端口 1ss -tln | grep 6070","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"},{"name":"system-manager","slug":"system-manager","permalink":"https://yangbajing.github.io/tags/system-manager/"},{"name":"devops","slug":"devops","permalink":"https://yangbajing.github.io/tags/devops/"}]},{"title":"Mongodb 3.x 用户认证","slug":"mongodb-3-x-用户认证","date":"2016-01-11T08:52:07.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/01/11/mongodb-3-x-用户认证/","link":"","permalink":"https://yangbajing.github.io/2016/01/11/mongodb-3-x-%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/","excerpt":"","text":"Mongodb 3.x 的用户认证和 2.x 方式不一样，创建用户的语法已由 addUser 成成 createUser 了。 创建账号首先不使用 --auth 参数启动Mongodb， 1&#x2F;opt&#x2F;local&#x2F;mongodb&#x2F;mongodb-3.0&#x2F;bin&#x2F;mongod -f &#x2F;opt&#x2F;local&#x2F;mongodb&#x2F;etc&#x2F;mongod.conf 此时登陆Mongodb并执行 show dbs 命令，只会看到一个 local 数据库，而文档里那个 admin 是不存在。使用 mongo 登陆，并创建用户。Mongodb推荐创建一个只能管理用户的用户来做角色权限分配工作：userAdminAnyDatabase。 123456789use admindb.createUser(&#123; user: &quot;sc-admin&quot;, pwd: &quot;xxxxxxxx&quot;, roles: [&#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;]&#125;) roles 中的 db 参数是必选的，不然会报错：* 12345&gt; db.createUser(&#123;user:&quot;admin&quot;,pwd:&quot;xxxxxxxx&quot;,roles:[&#123;role:&quot;userAdminAnyDatabase&quot;&#125;]&#125;)2016-01-11T17:02:46.417+0800 E QUERY Error: couldn&#39;t add user: Missing expected field &quot;db&quot; at Error (&lt;anonymous&gt;) at DB.createUser (src&#x2F;mongo&#x2F;shell&#x2F;db.js:1101:11) at (shell):1:4 at src&#x2F;mongo&#x2F;shell&#x2F;db.js:1101 启动Mongodb服务设置完成后停止Mongodb服务，使用 kill [pid] 或 kill -2 [pid]。 连接Mongodb使用 --auth 参数或在配置文件设置：security.authorization: enabled 启用用户权限认证功能。重启 Mongodb 服务，并打开 mongo shell： 12use admindb.auth(&quot;sc-admin&quot;, &quot;xxxxxxxx&quot;) db.auth 返回 1 代表认证成功。 或者使用命令行参数：mongo -u sc-admin -p xxxxxxxx --authenticationDatabase admin。 此时执行 show collections 命令，Mongodb 会报错： 12345678910111213&gt; show collections2016-01-11T17:13:37.275+0800 E QUERY Error: listCollections failed: &#123; &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not authorized on admin to execute command &#123; listCollections: 1.0 &#125;&quot;, &quot;code&quot; : 13&#125; at Error (&lt;anonymous&gt;) at DB._getCollectionInfosCommand (src&#x2F;mongo&#x2F;shell&#x2F;db.js:646:15) at DB.getCollectionInfos (src&#x2F;mongo&#x2F;shell&#x2F;db.js:658:20) at DB.getCollectionNames (src&#x2F;mongo&#x2F;shell&#x2F;db.js:669:17) at shellHelper.show (src&#x2F;mongo&#x2F;shell&#x2F;utils.js:625:12) at shellHelper (src&#x2F;mongo&#x2F;shell&#x2F;utils.js:524:36) at (shellhelp2):1:1 at src&#x2F;mongo&#x2F;shell&#x2F;db.js:646 这是因为 sc-admin 账号只有用户管理权限，并未其分配数据库相关读、写权限。 为数据库创建用户创建普通用户 接着为各数据库创建相关用户，推荐每个用户都跟着库走。 123456789&gt; use test&gt; db.createUser(&#123; user: &quot;test&quot;, pwd: &quot;testtest&quot;, roles: [&#123; &#123; role: &quot;readWrite&quot;: db: &quot;test&quot; &#125;, &#123; role: &quot;read&quot;, db: &quot;local&quot; &#125; &#125;]&#125;) 可以看到为 test 用户分配了 test 数据库的读写权限、local数据库的只读权限。 查看刚刚创建的用户： 12345678910111213141516&gt; show users&#123; &quot;_id&quot; : &quot;test.test&quot;, &quot;user&quot; : &quot;test&quot;, &quot;db&quot; : &quot;test&quot;, &quot;roles&quot; : [ &#123; &quot;role&quot; : &quot;readWrite&quot;, &quot;db&quot; : &quot;test&quot; &#125;, &#123; &quot;role&quot; : &quot;read&quot;, &quot;db&quot; : &quot;local&quot; &#125; ]&#125; 也可以查看整个Mongodb数据库的全部用户： 1234&gt; use admin&gt; db.system.users.find()&#123; &quot;_id&quot; : &quot;admin.sc-admin&quot;, &quot;user&quot; : &quot;sc-admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;credentials&quot; : &#123; &quot;SCRAM-SHA-1&quot; : &#123; &quot;iterationCount&quot; : 10000, &quot;salt&quot; : &quot;Toe8Z9AhYBmI+fHFhOHA1Q&#x3D;&#x3D;&quot;, &quot;storedKey&quot; : &quot;8y0LenFMPX0b7FYFDN38odJYW4M&#x3D;&quot;, &quot;serverKey&quot; : &quot;qVcYyJL13Tg2UdzsIIlyl3jbc+s&#x3D;&quot; &#125; &#125;, &quot;roles&quot; : [ &#123; &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; &#125; ] &#125;&#123; &quot;_id&quot; : &quot;test.test&quot;, &quot;user&quot; : &quot;test&quot;, &quot;db&quot; : &quot;test&quot;, &quot;credentials&quot; : &#123; &quot;SCRAM-SHA-1&quot; : &#123; &quot;iterationCount&quot; : 10000, &quot;salt&quot; : &quot;cUw0r5tEihHgxWTcCEV8LA&#x3D;&#x3D;&quot;, &quot;storedKey&quot; : &quot;vPZpRaY0P4x0733tQnVllI6og5U&#x3D;&quot;, &quot;serverKey&quot; : &quot;eKQ2sdQTtas8HfgCMKhhdf9ndRs&#x3D;&quot; &#125; &#125;, &quot;roles&quot; : [ &#123; &quot;role&quot; : &quot;readWrite&quot;, &quot;db&quot; : &quot;test&quot; &#125;, &#123; &quot;role&quot; : &quot;read&quot;, &quot;db&quot; : &quot;local&quot; &#125; ] &#125; 使用普通用户操作 现在使用 test 用户登录做此操作。 1234567891011121314151617181920$ mongo 192.168.31.101&#x2F;test -u test -p testtest --authenticationDatabase testMongoDB shell version: 3.0.7connecting to: 192.168.31.101&#x2F;test&gt; show collectionspeople&gt; use localswitched to db local&gt; show collectionsstartup_log&gt; db.test_coll.insert(&#123;&quot;test&quot;:&quot;test&quot;&#125;)WriteResult(&#123; &quot;writeError&quot; : &#123; &quot;code&quot; : 13, &quot;errmsg&quot; : &quot;not authorized on local to execute command &#123; insert: \\&quot;test_coll\\&quot;, documents: [ &#123; _id: ObjectId(&#39;569374f512032e2e67470c98&#39;), test: \\&quot;test\\&quot; &#125; ], ordered: true &#125;&quot; &#125;&#125;)&gt; use testswitched to db test&gt; db.test_coll.insert(&#123;&quot;test&quot;:&quot;test&quot;&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 参考 enable authorization: https://docs.mongodb.org/manual/tutorial/enable-authentication/ security.authorization: https://docs.mongodb.org/manual/reference/configuration-options/#security.authorization built-in-roles: https://docs.mongodb.org/manual/reference/built-in-roles/","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://yangbajing.github.io/tags/mongodb/"}]},{"title":"Nginx（Tengine）使用","slug":"nginx（tengine）使用","date":"2016-01-07T03:37:16.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/01/07/nginx（tengine）使用/","link":"","permalink":"https://yangbajing.github.io/2016/01/07/nginx%EF%BC%88tengine%EF%BC%89%E4%BD%BF%E7%94%A8/","excerpt":"","text":"用了一段时间Tengine了，主要用于静态资源、后端服务的反向代理、负载均衡方面。也有了一些使用经验，现在将一些配置及心得记录于此。 Tengine的安装Tengine的安装非常简单，就是： 123$ .&#x2F;configure$ make$ sudo make install 官方有更详细的说明：http://tengine.taobao.org/document_cn/install_cn.html。我们现在的使用是使用默认编译指令编译的，以后看需要可能会对其进行一些定制化。 基本配置 work_processes: Nginx的work进程，一般设为CPU核数 events.worker_connections: 设置每个worker可服务的最大连接数 events.reuse_port: 设置端口可重用，支持SO_REUSEPORT套接字参数，打开此特性后可明显提高系统响应能力（Linux从内核3.9开始支持） 日志Nginx的日志主要分两类：access和error，从名称就可以看出是访问日志和错误日志。这里分别给出两种日志的示例。 访问日志 12xxx.xxx.xxx.xxx - - [07&#x2F;Jan&#x2F;2016:13:39:36 +0800] &quot;GET &#x2F;api&#x2F;jobui?companyName&#x3D;%E4%B8%B4%E5%AE%89%E5%B0%9A%E5%BA%90%E6%96%87%E5%8C%96%E5%88%9B%E6%84%8F%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8 HTTP&#x2F;1.1&quot; &quot;404&quot; 69 &quot;-&quot; &quot;python-requests&#x2F;2.9.0&quot; &quot;-&quot; &quot;-&quot; 0.005 239 273xx.xxx.xx.xx - - [07&#x2F;Jan&#x2F;2016:13:39:37 +0800] &quot;GET &#x2F;api&#x2F;news?companyName&#x3D;%E4%B8%B4%E5%AE%89%E5%B0%9A%E5%BA%90%E6%96%87%E5%8C%96%E5%88%9B%E6%84%8F%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8 HTTP&#x2F;1.1&quot; &quot;200&quot; 70323 &quot;-&quot; &quot;AHC&#x2F;1.0&quot; &quot;-&quot; &quot;-&quot; 0.066 70547 223 日志格式log_format设置为： 1234log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;&quot;$status&quot; $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#39; &#39;&quot;$gzip_ratio&quot; $request_time $bytes_sent $request_length&#39;; $remote_addr: 请求的远程地址 $remote_user: 远程客户端用户名称 $time_local: 用户访问的时间与时区 $request: 请求HTTP方法、URL与HTTP协议 $status: 响应状态 $body_types_sent: 响应主体内容大小（字节） $http_refere: 请求从哪个页面链接过来 $http_user_agent: 客户端用户User-Agent $http_x_forwarded_for: 若HTTP头信息中有X-Forwarded-For记录客户端的真实IP，这时Nginx日志就可以使用其记录真实IP（一般用于反向代理中） $gzip_ratio: gzip压缩率？ $request_time: 请求处理时间，单位为秒，精度毫秒；从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止 $bytes_sent: 发送给客户端的总字节数 $request_length: 请求的长度（包括请求行，请求头和请求正文） 错误日志 122016&#x2F;01&#x2F;07 13:15:48 [error] 2874#0: check time out with peer: 10.51.xx.xx:7100 2016&#x2F;01&#x2F;07 13:15:53 [error] 2874#0: check time out with peer: 10.51.xx.xx:7100 错误日志显示Nginx运行或启动时的一此错误情况，示例是做负载均衡时检测节点健康状态失败时的错误消息。 代理用Nginx做HTTP反向代理是一个很好的解决方案，代理配置一般放在 location 段。一个示例配置如下： 123456789location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;scnginx001; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host;&#125; proxy_pass: 指定将HTTP请求代理到哪个后端地址 proxy_http_version: 指定代理使用的HTTP协议版本 proxy_set_header: 设置一系列代理HTTP header 其中需要关注的是 proxy_http_version 和 proxy_set_header Connection &quot;&quot; 两条指令，它确定了代理将使用HTTP 1.1的keep-alive功能，这样可以显著提高Nginx与后端被代理服务之间的响应，因为它减少了两者建立连接的次数。 负载均衡与健康检查（Tengine）（注：之前写了一篇介绍 Nginx 官方的健康检查方案文章：Nginx负载均衡与反向代理） 因为Nginx官方的健康检查是一个收费方案，所以这里的设置是基于 Tengine 提供的方案。先给出配置，再细说各指令的 12345678910upstream scnginx001 &#123; #dynamic_resolve fallback&#x3D;stale fail_timeout&#x3D;30s; server xx.xxx.xxx.216:7100; server xx.xxx.xx.147:7100; check interval&#x3D;3000 rise&#x3D;2 fall&#x3D;5 timeout&#x3D;1000 type&#x3D;http; check_keepalive_requests 100; check_http_send &quot;GET &#x2F;api&#x2F;health_check HTTP&#x2F;1.1\\r\\nConnection: keep-alive\\r\\nHost: scnginx-001\\r\\n\\r\\n&quot;; check_http_expect_alive http_2xx http_3xx;&#125; 首先，使用 upstream 要指定一个名字，这里指定为 scnginx001 ，在配置 proxy_pass 时需要使用这个名字来告诉代理使用哪个 upstream 配置。 server: 每个后端节点一个配置， proxy_pass 指令将把请求代理到这些节点上 check: 设置健康查检参数，这里为间隔3秒做一次检查，连续失败2次认为后端服务器状态为down，连续成功5次认为后端服务器状态为up，对后端健康请求的超时时间为1秒，检查类型为 http。 check_keepalive_requests: 设置 Tengine 完成几次请求后关闭连接，默认值为1。对于连接频繁的服务，适当提高此值可以显著提高性能。 check_http_send: 配置 HTTP 健康健查包发送的内容。 check_http_expect_alive: 指定 HTTP 回复成功状态，默认为 2XX 和 3XX 的状态认为后端服务状态是健康的。 Tengine状态Tengine自带了两个服务状态查检器，配置后可以通过HTTP实时看到Tengine和健康检查服务的运行状态。配置如下： 12345678910111213location &#x2F;nginx_status &#123; stub_status on; access_log off; allow xxx.xxx.xxx.xxx; deny all;&#125;location &#x2F;status &#123; check_status; access_log off; allow xxx.xxx.xxx.xxx; deny all;&#125; stub_status: 显示Tengine服务状态 check_status: 显示每个后端服务的健康检查服务状态","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://yangbajing.github.io/tags/nginx/"},{"name":"tengine","slug":"tengine","permalink":"https://yangbajing.github.io/tags/tengine/"}]},{"title":"Linux下对大文件（日志）进行分割","slug":"linux下对大文件（日志）进行分割","date":"2016-01-06T06:03:29.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/01/06/linux下对大文件（日志）进行分割/","link":"","permalink":"https://yangbajing.github.io/2016/01/06/linux%E4%B8%8B%E5%AF%B9%E5%A4%A7%E6%96%87%E4%BB%B6%EF%BC%88%E6%97%A5%E5%BF%97%EF%BC%89%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2/","excerpt":"","text":"logrotate是Linux系统自带的一个做文件（日志）分割的任务，可以很灵活的对文件做分割任务。由crontab定时执行。 一个典型的logrotate配置如下： 123456789101112yangjing:~$ more /etc/logrotate.d/nginx /usr/local/nginx/logs/*.log &#123; notifempty daily dateext compress rotate 60 sharedscripts postrotate /bin/kill -USR1 `/bin/cat /usr/local/nginx/logs/nginx.pid` endscript&#125; 多个日志文件以空格分开，也可以使用通配符进行配置。参数说明： notifempty: 若日志为空，则不做分割 daily: 每天生成一个日志分割文件 dateext: 分割的日志文件加上日期扩展 compress: 对分割出的日志文件做压缩 rotate: 分割出的日志文件最多保留几份 sharedscripts: 在所有日志文件都轮转（分割）完后统一执行一次脚本 logrotate执行的时间？ logrotate服务是由CRON执行的，所以它的执行时间是由CRON控制，我们可以修改 /etc/crontab 文件来控制logrotate服务执行时间。 123456789101112131415yangjing@sc-007:~/studies/playlist$ more /etc/crontab # /etc/crontab: system-wide crontab# Unlike any other crontab you don&#x27;t have to run the `crontab&#x27;# command to install the new version when you edit this file# and files in /etc/cron.d. These files also have username fields,# that none of the other crontabs do.SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin# m h dom mon dow user command17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ) 我们可以把 cron.xxxx 命令对应的时间修改为每天的23时59分，修改后的CRON脚本执行命令如下： 123459 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly59 23 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )59 23 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )59 23 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly )","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"https://yangbajing.github.io/tags/nginx/"},{"name":"log","slug":"log","permalink":"https://yangbajing.github.io/tags/log/"},{"name":"logrotate","slug":"logrotate","permalink":"https://yangbajing.github.io/tags/logrotate/"}]},{"title":"2015总结暨2016展望","slug":"2015总结暨2016展望","date":"2016-01-02T03:47:00.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2016/01/02/2015总结暨2016展望/","link":"","permalink":"https://yangbajing.github.io/2016/01/02/2015%E6%80%BB%E7%BB%93%E6%9A%A82016%E5%B1%95%E6%9C%9B/","excerpt":"","text":"2015已过去，2016到来。展望未来也总结过去。 20152015年到了一家新的公司，是一家做大数据服务的创业公司（准备说是2014年底）。刚到公司时我们只有几人，到现在已经成为一家50人左右的中小型互联网公司了。上半年我们尝试过个人社交、电商、招聘、监控等方向，到现在确定到了企业数据服务上。一路走来，从快速试错到确定目标，还是颇为不易的。 说完公司，再来谈谈个人吧。对于我自己来说，今年还是很有收获，但也有些遗憾。3月8号，在这个特殊的日子里我迎娶了媳妇，在三十而立的这年真正的立（成家）了。公司同事也来参加我的婚礼并送上祝福，老大还做为我主婚人。 工作中，虽然一直不来将自己中意的Scala技术引入产品研发，觉得稍有遗憾。但工作实战中还是接触并提升了很多。 Javascript/React.js有大半年的时间，我是在做前端开发。从刚开始的Angular到React.js，再到引入了ES6和Redux、Immutable.js等现在前端比较潮流和高级的技术及特性。通过这一年来产品的实践、同事使用，至用户反馈，各方面的体验还是很好。可以说，在重庆地区（甚至西南），我们公司在前端方面还是很有实力的（有兴趣的同学可以发简历到我邮箱，邮箱地址在文末）。 Spark/大数据从国庆后开始，慢慢的把前端工作交给了我招来的两个同事。说起这里，自我感觉还挺好的，看人的眼光还是不错啊。他们两人在整个前端方面都可以独当一面，已经超过我这个半路出家人了。 公司成立了一个新的部门（可能叫Team更合适吧），大数据平台。主要工作有：Spark/Hadoop基础平台搭建，Mongodb/Cassandra数据库管理，爬虫团队…… 本来想转去做下数据分析的，但无赖数学底子太差，尝试下还是算了。自己在开发、运维、管理方面更有优势。 从去年10月到现在，接触和搭建了公司的Spark/Hadoop集群、Nginx(Tengine，主要用于反向代理和负载均衡)、Cassandra单数据中心集群、Mongodb的集群…… 虽然各平台现在都还比较初级，还有很多问题没有解决…… 公司也刚开始使用，不过收获还是很多的。 爬虫（Python）另外一部份就是爬虫了，这部分是我一年来投入精力最少的。团队里都是使用Python的，但自己又对Python很不感冒（可能个人认识还是有缺陷吧，我觉得Scala、Go、Node.js都要比Python这个技术架构好，可能Python做大的优势还是在于机器学习和一些管理、运维脚本方面吧）。 虽然中间使用Scala（采用了Akka）解决了一个多线程实时新闻爬虫的问题（注：Python因为对线程支持的问题，采用进程模型总是遇到这样那样的问题，还有一个就是对任务拆分执行并合并，以及超时返回已抓取到的新闻而不是直接返回一个Timeout错误。这一系列操作，Python本身还是缺少一样实用的工具库和方式。有兴趣的朋友可以看看我的另一篇文章 Akka实战：开发一个多线程新闻爬虫 和 Akka实战：分散、聚合模式 ）。 2015年总结因为现阶段个人更想实际的coding，对于公司分配的团队管理任务有所怠慢了。这方面做的非常不好，2016年需要在这两方面做一个平衡。 个人能力上，在前端技术、系统运维管理、数据库和大数据基础平台方面都有些还算不错的提升和积累。希望在2016年在这些方面有更深入的实战。 团队管理方面是个短板，2016需要加强。 20162016已经到了，展望未来，希望个人和公司都能更进一步。 对于个人，今年家里很可能会添加一只小猴子（希望老天眷顾）。古语说成家立业。既已成家，立业当始！今年将是我个人职业生涯和人生的一个重要转折。 个人能力上，需要自己对于新技术的求知能够继续保持。并能平衡技术与工作，与团队，与产品之间的平衡。 前几天读了一篇文章：Go在谷歌：以软件工程为目的的语言设计，感触颇多。先不论Go语言如何，这是一个哲学问题。Go语言团队在设计Go时的出发点很不错，目的性很强。他们就是为了解决Google在实际工程中的问题而开发Go的，且Go在实际应用中也的确解决了很多问题。其实在2012年时，就接触过一段时间Go了，但当时对其语法不感冒，觉得缺少很多现代语言的特性。后来接触到Scala，这个学院派很浓的基于面向对象的函数式编程语言，你基本上能在其身上找到所有现代语言具有的特性。而且个人是一个Java程序员出身，再加上Scala对Java的无缝支持，自然就爱上他了。 对Go的再一次关注，来自于去年底与朋友的一次聚会。朋友是做科学上网工具的，他们用Go开发了客户端软件。而与其它朋友的交流中得知，在重庆有不少公司都在实际项目中使用Go了。再到前几天读了那篇 Go在谷歌：以软件工程为目的的语言设计。然后上网搜索了一些国内外使用Go的案例，发现使用Go的公司还不少啊。其中有几个个人比较感兴趣： https://github.com/wandoulabs/codis: 由豌豆荚开源的一个Redis集群管理工具 http://open-falcon.com/: 由小米开源的互联网企业级监控系统 http://www.docker.com/、http://kubernetes.io/: 容器技术及容器集群管理 个人觉得这些对于我们公司都是很好，很有用的技术，希望2016年能够研究并引入。 Scala能很好的提高个人编程及架构能力，但Go对团队和工程的促进与提高更多。 说完了个人，再谈谈公司吧。创业公司开头最难的就是找准一个发展方向，我们现在已经找准了一个方向，个人也认为很有意思。现在需要的就是大家合心、合力。个人能对各种技术学以致用、将技术融入产品，并创造出价值。 个人发展上，今年需要加强团队建设与管理方面的短板。在保持个人对技术的未知上，与团队能更同步、管理上更用心。 做为一个技术人，说了这么多还是来点干货吧。2016需要关注与加强的地方： 系统监控、管理 Java、Spring Boot、Go Cassandra、Redis、Mongodb Node.js、ES6、React Spark、Hadoop 每个月至少读两本书，1月份的书单如下： 《Http权威指南》 《The Go Programming Language》 好了，2015总结暨2016展望就到此吧。从2016开始，应把此周期缩短，待2月1号时做个月结暨展望…… 对Javascript/React.js/Node.js、Java／Spring boot、Python、系统管理运维、Cassandra/Mongodb数据库感兴趣的，并愿意和我们一起干一番事业的，欢迎把简历投来：yangbajing at gmail com。我们公司是：https://www.socialcredits.cn/","categories":[{"name":"essay","slug":"essay","permalink":"https://yangbajing.github.io/categories/essay/"}],"tags":[{"name":"工作","slug":"工作","permalink":"https://yangbajing.github.io/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"生活","slug":"生活","permalink":"https://yangbajing.github.io/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"Akka实战：开发一个多线程新闻爬虫","slug":"akka实战：开发一个多线程新闻爬虫","date":"2015-12-01T04:32:05.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2015/12/01/akka实战：开发一个多线程新闻爬虫/","link":"","permalink":"https://yangbajing.github.io/2015/12/01/akka%E5%AE%9E%E6%88%98%EF%BC%9A%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%B0%E9%97%BB%E7%88%AC%E8%99%AB/","excerpt":"","text":"代码：https://github.com/yangbajing/crawler-service 使用Scala开发一个多线程爬虫，利用Akka库来管理多个爬虫任务的分散和聚合操作。同时使用scheduleOnce来设置爬取任务在指定时间内完成。详细需求如下： 可同时从多个新闻源（搜索引擎）检索新闻 已爬取过的新闻存库，第二次访问时直接从库里读取 提供duration参数，调用方可设置调用超时。超时到，则Server返回已爬取新闻。且爬虫任务需继续进行，并完成存库","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"cassandra","slug":"cassandra","permalink":"https://yangbajing.github.io/tags/cassandra/"},{"name":"crawler","slug":"crawler","permalink":"https://yangbajing.github.io/tags/crawler/"}]},{"title":"写给Python程序员的Scala入门教程","slug":"写给python程序员的scala入门教程","date":"2015-11-28T10:56:24.000Z","updated":"2015-11-29T12:26:50.000Z","comments":true,"path":"2015/11/28/写给python程序员的scala入门教程/","link":"","permalink":"https://yangbajing.github.io/2015/11/28/%E5%86%99%E7%BB%99python%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84scala%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"随着业务和数据的需要，我们引入了Spark。Spark对Python的支持还是挺好的，但毕竟它还是使用Scala开发的，且现有的API并没有100%覆盖Python。所以就有了这篇文章，让Python程序员可以接触Scala这门更高（级）、更快（速）、更强（大）的（奥运精神）语言。 Scala兼具Python样的开发效率，但又有Java般的执行性能，真是一不可多得的神器！（当然，鱼和熊不可兼得，Scala的入门曲线相比Python是要那么陡峭一丢丢） 安装一般Linux系统都自带Python环境，但Scala是没有的。这需要我们手动安装，还需要安装Java环境。Java环境的安装这里就不介绍了，网上很多。说说Scala的安装吧。下载地址在http://scala-lang.org/download/2.11.7.html。 123456789wget -c http:&#x2F;&#x2F;downloads.typesafe.com&#x2F;scala&#x2F;2.11.7&#x2F;scala-2.11.7.tgztar zxf scala-2.11.7cd scala-2.11.7.&#x2F;bin&#x2F;scalaWelcome to Scala version 2.11.7 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_60).Type in expressions to have them evaluated.Type :help for more information.scala&gt; 我们可以看到终端出现了scala&gt;提示符，这个就像Python的REPL一样，Scala也拥有一个REPL。我们可以在这里很方便的编写一些代码，测试一些想法。 对于Scala常用的IDE（集成开发环境），推荐使用IDEA for scala plugins和scala-ide。 Scala的强大，除了它自身对多核编程更好的支持、函数式特性及一些基于Scala的第3方库和框架（如：Akka、Playframework、Spark、Kafka……），还在于它可以无缝与Java结合。所有为Java开发的库、框架都可以自然的融入Scala环境。当然，Scala也可以很方便的Java环境集成，比如：Spring。若你需要第3方库的支持，可以使用Maven、Gradle、Sbt等编译环境来引入。 Scala是一个面向对象的函数式特性编程语言，它继承了Java的面向对特性，同时又从Haskell那里吸收了很多函数式特性并做了增强。 Hello, world.通常情况下，Java系的程序都需要有一个main方法来执行。并需要放入一个Web container容器，或打成一个jar包来执行。但是Scala不一样，它除了支持传统的Java方式，它也可以像Python一样把代码保存到一个脚本文件里（.scala）执行，就像一个Shell脚本一样。 12345678yangjing-mac-air:scala-2.11.7 jingyang$ cat test.scala #!&#x2F;bin&#x2F;shexec scala &quot;$0&quot; &quot;$@&quot;!#&#x2F;&#x2F; Say hello to the first argumentprintln(&quot;Hello, &quot;+ args(0) +&quot;!&quot;)yangjing-mac-air:scala-2.11.7 jingyang$ .&#x2F;test.scala 杨景Hello, 杨景! （注：需要把$SCALA_HOME/bin加入系统环境变量才能直接执行scala命令） 可以看到，使用Scala，你除了像传统的Java程序一样把它做为一个“服务”的方式来启动，你也可以把它像Python一样做为一个“脚本”来启动。 （注意：Scala不像Python一样通过代码缩进来表示代码的层次关系，而是和通常的语言一样使用&#123;&#125;来表示代码的层级。给程序员更多的自由） 变量、基础数据类型Scala中变量不需要显示指定类型，但需要提前声明。这可以避免很多命名空间污染问题。Scala有一个很强大的类型自动推导功能，它可以根据右值及上下文自动推导出变量的类型。你可以通过如下方式来直接声明并赋值。 123456789101112scala&gt; val a &#x3D; 1a: Int &#x3D; 1scala&gt; val b &#x3D; trueb: Boolean &#x3D; truescala&gt; val c &#x3D; 1.0c: Double &#x3D; 1.0scala&gt; val a &#x3D; 30 + &quot;岁&quot;a: String &#x3D; 30岁 Immutable （注：函数式编程有一个很重要的特性：不可变性。Scala中除了变量的不可变性，它还定义了一套不可变集合scala.collection.immutable._。） val代表这是一个final variable，它是一个常量。定义后就不可以改变，相应的，使用var定义的就是平常所见的变量了，是可以改变的。从终端的打印可以看出，Scala从右值自动推导出了变量的类型。Scala可以如动态语言似的编写代码，但又有静态语言的编译时检查，不会像Python一样留下很多陷阱在运行多时以后才被发现。 （注：在RELP中，val变量是可以重新赋值的，这是｀\u0012RELP`的特性。在平常的代码中是不可以的。） 基础数据类型 Scala中基础数据类型有：Byte、Short、Int、Long、Float、Double，Boolean，Char、String。和Java不同的是，Scala中没在区分原生类型和装箱类型，如：int和Integer。它统一抽象成Int类型，这样在Scala中所有类型都是对象了。编译器在编译时将自动决定使用原生类型还是装箱类型。 字符串 Scala中单引号和双引号包裹是有区别的，单引号用于字符，双引号用于字符串。 1234567891011121314151617scala&gt; val c1 &#x3D; &#39;c&#39;c1: Char &#x3D; cscala&gt; val 字符2 &#x3D; &#39;杨&#39;字符2: Char &#x3D; 杨scala&gt; val s1 &#x3D; &quot;杭州誉存科技有限公司&quot;s1: String &#x3D; 杭州誉存科技有限公司scala&gt; val s2 &#x3D; s&quot;杭州誉存科技有限公司工程师$&#123;c2&#125;景&quot;s2: String &#x3D; 杭州誉存科技有限公司工程师杨景scala&gt; val s3 &#x3D; s&quot;&quot;&quot;杭州誉存科技有限公司&quot;工程师&quot;\\n$&#123;c2&#125;景是江津人&quot;&quot;&quot;s3: String &#x3D;杭州誉存科技有限公司&quot;工程师&quot;杨景是江津人 Scala基于JVM平台，默认使用unicode，所以变量名是可以直接用中文的。而在Scala中，中文也是直接显示的，不像Python2一样会输出成unicdoe编码形式：\\uxxxx。 Scala还支持String Interpolation（“字符串插值”）的特性，可以使用$&#123;variable name&#125;这样的形式引用变量，并将值插入。就像示例s2一样。 而连线3个双引号在Scala中也有特殊含义，它代表被包裹的内容是原始字符串，可以不需要字符转码。这一特性在定义正则表达式时很有优势。 运算符Scala中的运算符其实是定义在对象上的方法（函数），你看到的诸如：3 + 2其实是这样子的：3.+(2)。+符号是定义在Int对象上的一个方法。支持和Java一至的运算符（方法）： （注：在Scala中，方法前的.号和方法两边的小括号在不引起歧义的情况下是可以省略的。这样我们就可以定义出很优美的DSL） ==、!=：比较运算 !、|、&amp;、^：逻辑运算 &gt;&gt;、&lt;&lt;：位运算 在Scala中，修正（算更符合一般人的常规理解吧）==和!=运算符的含义。在Scala中，==和!=是执行对象的值比较，相当于Java中的equals方法（实际上编译器在编译时也是这么做的）。而对象比较需要使用eq和ne两个方法来实现。 控制语句Scala中支持if、while、for comprehension（for表达式)、match case（模式匹配）四大主要控制语句。Scala不支持switch和? :两种控制语句，但它的if和match case会有更好的实现。 if Scala支持if语句，其基本使用和Java、Python中的一样。但不同的时，它是有返回值的。 （注：Scala是函数式语言，函数式语言还有一大特性就是：表达式。函数式语言中所有语句都是基于“表达式”的，而“表达式”的一个特性就是它会有一个值。所有像Java中的? :3目运算符可以使用if语句来代替）。 1234567891011scala&gt; if (true) &quot;真&quot; else &quot;假&quot;res0: String &#x3D; 真scala&gt; val f &#x3D; if (false) &quot;真&quot; else &quot;假&quot;f: String &#x3D; 假scala&gt; val unit &#x3D; if (false) &quot;真&quot;unit: Any &#x3D; ()scala&gt; val unit2 &#x3D; if (true) &quot;真&quot; unit2: Any &#x3D; 真 可以看到，if语句也是有返回值的，将表达式的结果赋给变量，编译器也能正常推导出变量的类型。unit和unit2变量的类型是Any，这是因为else语句的缺失，Scala编译器就按最大化类型来推导，而Any类型是Scala中的根类型。()在Scala中是Unit类型的实例，可以看做是Java中的Void。 while Scala中的while循环语句： 123while (条件) &#123; 语句块&#125; for comprehension Scala中也有for表达式，但它和Java以及Python中的for不太一样，它具有更强大的特性。通常的for语句如下： 123for (变量 &lt;- 集合) &#123; 语句块&#125; Scala中for表达式除了上面那样的常规用法，它还可以使用yield关键字将集合映射为另一个集合： 12345scala&gt; val list &#x3D; List(1, 2, 3, 4, 5)list: List[Int] &#x3D; List(1, 2, 3, 4, 5)scala&gt; val list2 &#x3D; for (item &lt;- list) yield item + 1list2: List[Int] &#x3D; List(2, 3, 4, 5, 6) 还可以在表达式中使用if判断： 12scala&gt; val list3 &#x3D; for (item &lt;- list if item % 2 &#x3D;&#x3D; 0) yield itemlist3: List[Int] &#x3D; List(2, 4) 还可以做flatMap操作，解析2维列表并将结果摊平（将2维列表拉平为一维列表）： 12345678scala&gt; val llist &#x3D; List(List(1, 2, 3), List(4, 5, 6), List(7, 8, 9))llist: List[List[Int]] &#x3D; List(List(1, 2, 3), List(4, 5, 6), List(7, 8, 9))scala&gt; for &#123; | l &lt;- llist | item &lt;- l if item % 2 &#x3D;&#x3D; 0 | &#125; yield itemres3: List[Int] &#x3D; List(2, 4, 6, 8) 看到了，Scala中for comprehension的特性是很强大的。它和Python中的list comprehension很类似，但不同的是在Scala中这一特性并不只限于list中，而是整个集合库都支持这一特性，包括：Seq、Map、Set、Array…… Scala和Python一样，也没有C-Like语言里的for (int i = 0; i &lt; 10; i++)语法，但和Python类似的它也有xrange或range函数样的效果。在Scala中的使用方式如下： 12345678910111213scala&gt; for (i &lt;- (0 until 10)) &#123; | println(i) | &#125;0123456789 比Python更好的一点时，Scala中还有一个to方法（Scala中去处符其实都是定义在对象上的方法/函数）： 12scala&gt; for (i &lt;- (0 to 10)) print(&quot; &quot; + i) 0 1 2 3 4 5 6 7 8 9 10 match case 模式匹配，是函数式语言很强大的一个特性。它比命令式语言里的switch更好用，表达性更强。 1234567891011121314151617scala&gt; def level(s: Int) &#x3D; s match &#123; | case n if n &gt;&#x3D; 90 &#x3D;&gt; &quot;优秀&quot; | case n if n &gt;&#x3D; 80 &#x3D;&gt; &quot;良好&quot; | case n if n &gt;&#x3D; 70 &#x3D;&gt; &quot;良&quot; | case n if n &gt;&#x3D; 60 &#x3D;&gt; &quot;及格&quot; | case _ &#x3D;&gt; &quot;差&quot; | &#125;level: (s: Int)Stringscala&gt; level(51)res28: String &#x3D; 差scala&gt; level(93)res29: String &#x3D; 优秀scala&gt; level(80)res30: String &#x3D; 良好 可以看到，模式匹配可以使用switch相同的功能。但也switch需要使用break明确告知终止之后的判断不同，Scala中的match case是默认break的，只要其中一个case语句匹配，就终止之后的所以比较。且对应case语句的表达式值将作为整个match case表达式的值返回。 Scala中的模式匹配还有类型匹配、数据抽取、谓词判断等其它有用的功能。这里只做简单介绍，之后会单独一个章节来做较详细的解读。 集合在Python中，常用的集合类型有：list、tuple、set、dict。Scala中对应的有：List、Tuple[X]、Set、Map。 List Scala中List是一个递归不可变集合，它很精妙的使用递归结构定义了一个列表集合。除了之前使用Listobject来定义一个列表，还可以使用如下方式： 12scala&gt; val list &#x3D; 1 :: 2 :: 3 :: 4 :: 5 :: Nillist: List[Int] &#x3D; List(1, 2, 3, 4, 5) List采用前缀操作的方式（所有操作都在列表顶端（开头））进行，::操作符的作用是将一个元素和列表连接起来，并把元素放在列表的开头。这样List的操作就可以定义成一个递归操作。添加一个元素就是把元素加到列表的开头，List只需要更改下头指针，而删除一个元素就是把List的头指针指向列表中的第2个元素。这样，List的实现就非常的高效，它也不需要对内存做任何的转移操作。List有很多常用的方法： 1234567891011121314151617181920212223242526scala&gt; list.indexOf(3)res6: Int &#x3D; 2scala&gt; 0 :: listres8: List[Int] &#x3D; List(0, 1, 2, 3, 4, 5)scala&gt; list.reverseres9: List[Int] &#x3D; List(5, 4, 3, 2, 1)scala&gt; list.filter(item &#x3D;&gt; item &#x3D;&#x3D; 3)res11: List[Int] &#x3D; List(3)scala&gt; listres12: List[Int] &#x3D; List(1, 2, 3, 4, 5)scala&gt; val list2 &#x3D; List(4, 5, 6, 7, 8, 9)list2: List[Int] &#x3D; List(4, 5, 6, 7, 8, 9)scala&gt; list.intersect(list2)res13: List[Int] &#x3D; List(4, 5)scala&gt; list.union(list2)res14: List[Int] &#x3D; List(1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 9)scala&gt; list.diff(list2)res15: List[Int] &#x3D; List(1, 2, 3) Scala中默认都是Immutable collection，在集合上定义的操作都不会更改集合本身，而是生成一个新的集合。Python中只有set上有求交、并、差积运算，Scala中将其范化到所以序列集合上（Seq、List、Set、Array……）都可以支持。 Tuple Scala中也支持Tuple（元组）这种集合，但最多只支持22个元素（事实上Scala中定义了Tuple0、Tuple1……Tuple22这样22个TupleX类，实现方式与C++ Boost库中的Tuple类似）。和Python中类似，Scala也采用小括号来定义元组。 12345678scala&gt; val tuple1 &#x3D; (1, 2, 3)tuple1: (Int, Int, Int) &#x3D; (1,2,3)scala&gt; tuple1._2res17: Int &#x3D; 2scala&gt; val tuple2 &#x3D; Tuple2(&quot;杨&quot;, &quot; )tuple2: (String, String) &#x3D; (杨,景) 可以使用xxx._[X]的形式来引用Tuple中某一个具体元素，其_[X]下标是从1开始的，一直到22（若有定义这么多）。 Set Set是一个不重复且无序的集合，初始化一个Set需要使用Set对象： 12345678scala&gt; val set &#x3D; Set(&quot;Python&quot;, &quot;Scala&quot;, &quot;Java&quot;, &quot;C++&quot;, &quot;Javascript&quot;, &quot;C#&quot;, &quot;PHP&quot;) set: scala.collection.immutable.Set[String] &#x3D; Set(Scala, C#, Python, Javascript, PHP, C++, Java)scala&gt; set + &quot;Go&quot;res21: scala.collection.immutable.Set[String] &#x3D; Set(Scala, C#, Go, Python, Javascript, PHP, C++, Java)scala&gt; set filterNot (item &#x3D;&gt; item &#x3D;&#x3D; &quot;PHP&quot;)res22: scala.collection.immutable.Set[String] &#x3D; Set(Scala, C#, Python, Javascript, C++, Java) Map Scala中的Map是一个HashMap，其key也是无序的。Python中的dict对应些类型（可以使用TreeMap来让Map有序）。与Python中不一样，Scala并没有提供一个&#123;&#125;来定义Map，它还是很统一的采用相关类型的object来定义： 12345scala&gt; val map &#x3D; Map(&quot;a&quot; -&gt; &quot;A&quot;, &quot;b&quot; -&gt; &quot;B&quot;)map: scala.collection.immutable.Map[String,String] &#x3D; Map(a -&gt; A, b -&gt; B)scala&gt; val map2 &#x3D; Map((&quot;b&quot;, &quot;B&quot;), (&quot;c&quot;, &quot;C&quot;))map2: scala.collection.immutable.Map[String,String] &#x3D; Map(b -&gt; B, c -&gt; C) Scala中定义Map时，传入的每个Entry（K、V对）其实就是一个Tuple2（有两个元素的元组），而-&gt;是定义Tuple2的一种便捷方式。 12345678scala&gt; map + (&quot;z&quot; -&gt; &quot;Z&quot;)res23: scala.collection.immutable.Map[String,String] &#x3D; Map(a -&gt; A, b -&gt; B, z -&gt; Z)scala&gt; map.filterNot(entry &#x3D;&gt; entry._1 &#x3D;&#x3D; &quot;a&quot;)res24: scala.collection.immutable.Map[String,String] &#x3D; Map(b -&gt; B)scala&gt; mapres25: scala.collection.immutable.Map[String,String] &#x3D; Map(a -&gt; A, b -&gt; B) Scala的immutable collection并没有添加和删除元素的操作，其定义+（List使用::在头部添加）操作都是生成一个新的集合，而要删除一个元素一般使用.filterNot函数来映射一个新的集合实现。 （注：Scala中也scala.collection.mutable._集合，它定义了不可变集合的相应可变集合版本。一般情况下，除非一性性能优先的操作（其实Scala集合采用了共享变量的优化，生成一个新集合并不会生成所有元素的副本，它将会和老的集合共享大元素。因为Scala中变量默认都是不可变的），推荐还是采用不可变集合。因为它更直观、线程安全，你可以确定你的变量不会在其它地方被不小心的更改。） 函数（初级）在Scala中，函数是一等公民。函数可以像类型一样被赋值给一个变量，也可以做为一个函数的参数被传入，甚至还可以做为函数的返回值返回（这就是函数式编程）。 他Python一样，Scala也使用def关键词来定义一个函数： 12345678scala&gt; def calc(n1: Int, n2: Int): (Int, Int) &#x3D; &#123; | (n1 + n2, n1 * n2) | &#125;calc: (n1: Int, n2: Int)(Int, Int)scala&gt; val (add, sub) &#x3D; calc(5, 1)add: Int &#x3D; 6sub: Int &#x3D; 5 这里定义了一个函数：calc，它有两个参数：n1和n2，其类型为：Int。cala函数的返回值类型是一个有两个元素的元组，在Scala中可以简写为：(Int, Int)。在Scala中，代码段的最后一句将做为函数返回值，所以这里不需要显示的写return关键字。 而val (add, sub) = calc(5, 1)一句，是Scala中的抽取功能。它直接把calc函数返回的一个Tuple2值赋给了add他sub两个变量。 总结本篇文章简单的介绍了Scala的语言特性，本文并不只限于Python程序员，任何有编程经验的程序员都可以看。现在你应该对Scala有了一个基础的认识，并可以写一些简单的代码了。之后会分享一些《Scala实战（系列）》，介绍更函数式的写法及与实际工程中结合的例子。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"python","slug":"python","permalink":"https://yangbajing.github.io/tags/python/"}]},{"title":"Scala实战：并发-Future和Promise","slug":"scala实战：并发-future和promise","date":"2015-11-28T07:23:32.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2015/11/28/scala实战：并发-future和promise/","link":"","permalink":"https://yangbajing.github.io/2015/11/28/scala%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B9%B6%E5%8F%91-future%E5%92%8Cpromise/","excerpt":"","text":"并发编程是很困难的，特别是在你没有很好的设计与抽像你的功能层次时。传统的并发解决方案是采用多线程和共享变量，这使得随着代码的增加你很难找到错误根源。 Scala中采用了更好的方案，它不是只基于更低层次的线程的。Scala为用户提供了更高级的抽象：Futures和Promises（Akka还提供了基于actor模式的编程范式，是一种更高层次的并发编程抽象。本文主要讲解Futures和Promises，这里提供一些进一步学习的参考）。 FutureFuture是持有某个值的对象，它完成一些计算并允许在“将来”的某一个时刻获取结果。它也可以是其它计算结果的结果（简单点说就是多个Future可以嵌套）。创建一个Future最简单的方式就调用它的apply方法，它将直接开始一个异步计算，并返回一个Future对象，它将包含计算结果。 123456import scala.concurrent.ExecutionContext.Implicits.globalimport scala.concurrent.Futureimport scala.util.&#123;Success, Failure&#125;def computation(): Int = &#123; 25 + 50 &#125;val theFuture = Future &#123; computation() &#125; 第一行导入了ExecutionContext.Implicits.global作为当前环境的一个默认执行上下文。现在先暂时不管它的具体含意，只要知道它会提供一个线程池，所有任务最终都会被提交给它来异步执行就可以了。在这个示例中先定义computation函数，并在Future &#123; ... &#125;代码块中调用。程序会使用上下文中的找到的线程池（由ExecutionContext.Implicits.global导入）并马上开始异步执行。 访问Future的结果前面说了，Future返回值有两种类型：Success和Failure。而Future在执行后提供了3个回调函数来让你访问结果，它们分别是： def onSuccess[U](pf: PartialFunction[T, U]): 传入一个偏函数，可以使用模式匹配来处理你想要的结果 def onFailure[U](pf: PartialFunction[Throwable, U]): 传入一个偏函数，可以使用模式匹配来处理你想要的异常 def onComplete[U](f: Try[T] =&gt; U): 传一个接受Try[T]（http://www.yangbajing.me/2013/02/16/Option-Either-Try/）类型的函数。 上面3个回调函数都要求返回一个类型为U的返回值，这也得益于Scala的类型自动推导功能，你可以减少很多的样版代码。 当Future完成后，我们注册的回调函数将收到值。一个常用的注册回调函数是onComplete，它期待传入一个偏函数，并处理Success[T]和Failure[E]两种情况。（编函数将另文介绍） 1234theFuture.onComplate &#123; case Success(result) =&gt; println(result) case Fialure(t) =&gt; println(s&quot;Error: %&#123;t.getMessage&#125;&quot;)&#125; 可以看到，在Scala中写多线程代码是非常轻松惬意的。但是，你以为使用Future只是简化了new Thead或new Runnable的代码量而以，那就大错特错了。Scala的Future不只这些功能…… 合并多个Future的结果实际工作中，我们经常遇到需要向多个来源同时异步请求数据的时候。这时我们就需要等所以来源数据都返回后将结果集处理后再返回。使用Future.sequence方法，接收一个包含Future的列表来将一系列Future的结果汇总到一个List单一结果里输出。完整代码在：http://git.oschina.net/yangbajing/codes/08pacy2lubgqnkmv1xojd 1234567891011121314151617181920val f1 = Future &#123; TimeUnit.SECONDS.sleep(1) &quot;f1&quot;&#125;val f2 = Future &#123; TimeUnit.SECONDS.sleep(2) &quot;f2&quot;&#125;val f3 = Future &#123; TimeUnit.SECONDS.sleep(3) 2342&#125;val f4 = Future.sequence(Seq(f1, f2, f3))val results: List[Any] = Await.result(f4, 4.seconds)println(results) // 输出：List(f1, f2, 2342) 代码f1、f2、f3字义了3个异步操作并马上执行。f4将3个异步操作的结果合并到一个List里返回，同时f4也是一个异步操作。除了采用Future.sequence提供的方便函数，我们还可以使用for comprehension特性来更灵活的合并多个Future的结果。 我们把f4的操作改成使用for推导式形式： 12345678910val f4: Future[(String, String, Int)] = for &#123; r2 &lt;- f2 r3 &lt;- f3 r1 &lt;- f1 &#125; yield (r1.take(1), r2.drop(1), r3 + 1)val (f1Str, f2Str, f3Int) = Await.result(f4, 4.seconds)println(s&quot;f1: $f1Str, f2: $f2Str, f3: $f3Int&quot;) // 输出：f1: f, f2: 2, f3: 2342 可以看到for推导式也可以使用在Future上，r2 &lt;- f2代码的含意是在f2这个Future执行完后将结果赋值给变量r2。与Future.sequence将多个线程的返回值合并到一个List不同。使用for推导式，在yield语句部分你可以对每个线程的运算结果做更自由的处理，并返回自己想要的类型（这得益于Scala强大的类型推导功能，不需要你显示的声明变量值类型）。 异常处理前文代码，当Future代码块内有异常抛出时使用Future.sequence和for comprehension也会抛出异常，你将不能正确的获得结果。这时，可以使用Future提供的recover方法处理异常，并把异常恢复成一个正确值返回。 1def recover[U &gt;: T](pf: PartialFunction[Throwable, U]) recover常用使用方式如下： 123Future (6 / 0) recover &#123; case e: ArithmeticException =&gt; 0 &#125; // result: 0Future (6 / 0) recover &#123; case e: NotFoundException =&gt; 0 &#125; // result: exceptionFuture (6 / 2) recover &#123; case e: ArithmeticException =&gt; 0 &#125; // result: 3 接下来看看怎样使用recover来将处理异常并可使返回值可正确应用于Future.sequence和for comprehension中。以之前的f2举例，修改代码如下： 123456val f2 = Future &#123; throw new RuntimeException(&quot;throw exception&quot;)&#125;.recover &#123; case e: Exception =&gt; &quot;handled exception&quot;&#125; 采用上面的步骤将异常转换成一个值返回，f2就可以正确的应用到合并代码里了。 PromisePromise是一个承若，它是一个可修改的对象。一个Promise可以在未来成功的完成一个任务（使用p.success来完成），也可能用来完成一个失败（通过返回一个异常，使用p.failure）。失败了的Promise，可以通过f.recover来处理故障。考虑一个把com.google.common.util.concurrent.FutureCallback&lt;V&gt;封装成Scala的Future的例子，看看Promise是怎样使用的。 12345678910val promise = Promise[R]()Futures.addCallback( resultSetFuture, new FutureCallback[ResultSet] &#123; override def onFailure(t: Throwable): Unit = promise.failure(t) override def onSuccess(rs: ResultSet): Unit = promise.complete(Try(func(rs))) &#125;, ec)promise.future 总结Scala使用Future和Promise对并发编程提供了快捷的支持，同时对多个Future结果的合并和Future的异常恢复也提供了优雅的解决方案。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"scala实战","slug":"scala/scala实战","permalink":"https://yangbajing.github.io/categories/scala/scala%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"并发","slug":"并发","permalink":"https://yangbajing.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"scala实战","slug":"scala实战","permalink":"https://yangbajing.github.io/tags/scala%E5%AE%9E%E6%88%98/"},{"name":"future","slug":"future","permalink":"https://yangbajing.github.io/tags/future/"},{"name":"promise","slug":"promise","permalink":"https://yangbajing.github.io/tags/promise/"}]},{"title":"Akka实战：构建REST风格的微服务","slug":"akka实战：构建rest风格的微服务","date":"2015-11-26T16:05:33.000Z","updated":"2022-02-16T02:50:45.196Z","comments":true,"path":"2015/11/27/akka实战：构建rest风格的微服务/","link":"","permalink":"https://yangbajing.github.io/2015/11/27/akka%E5%AE%9E%E6%88%98%EF%BC%9A%E6%9E%84%E5%BB%BArest%E9%A3%8E%E6%A0%BC%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"使用Akka-Http构建REST风格的微服务，服务API应尽量遵循REST语义，数据使用JSON格式交互。在有错误发生时应返回：&#123;&quot;errcode&quot;:409,&quot;errmsg&quot;:&quot;aa is invalid，the ID is expected to be bb&quot;&#125;类似的JSON错误消息。 代码： https://github.com/yangbajing/akka-action http://git.oschina.net/yangbajing/akka-action 代码首先来看看代码文件结构： 12345678910111213├── ApiRoute.scala├── App.scala├── ContextProps.scala├── book│ ├── Book.scala│ ├── BookContextProps.scala│ ├── BookRoute.scala│ └── BookService.scala└── news ├── News.scala ├── NewsContextProps.scala ├── NewsRoute.scala └── NewsService.scala 通过名字可以看出，App.scala是启动程序，以Route结尾的是API路由定义文件，Service结尾的就是服务实现代码了。ContextProps结尾的是服务与路由交互的上下文属性部分，Service的将会在ContextProps中实例化并传给各个Route。 从目录结构上看，程序是按功能模块进行划分的。book相关的路由、服务、实体都定义在book包下。相应的，与news相关的代码则写于news包。 首先来看看程序的启动文件，App.scala 1234567891011121314def main(args: Array[String]): Unit = &#123; Files.write(Paths.get(&quot;app.pid&quot;), Utils.getPid.getBytes(Utils.CHARSET)) val contextProps = new ContextProps val bindingFuture = Http().bindAndHandle(ApiRoute(contextProps), &quot;0.0.0.0&quot;, 3333) bindingFuture.onComplete &#123; case Success(binding) =&gt; logger.info(binding.toString) case Failure(e) =&gt; logger.error(e.getLocalizedMessage, e) &#125;&#125; 定义akka-http绑定的host和port，设置ContextProps，并把它传给ApiRoute。App.scala的代码还是很简单的，接下来看看ApiRoute的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 定义一个Health Check API，用户第3方工具（如：Nginx/Tengine）验证服务是否正常运行val healthCheck = path(&quot;health_check&quot;) &#123; get &#123; ctx =&gt; logger.debug(ctx.request.toString) ctx.complete(HttpEntity.Empty) &#125; &#125;import me.yangbajing.akkaaction.util.JsonSupport._val customExceptionHandler = ExceptionHandler &#123; case e: MessageException =&gt; extractRequest &#123; req =&gt; val msg = s&quot;&quot;&quot;\\nmethod: $&#123;req.method&#125; |uri: $&#123;req.uri&#125; |headers: |\\t$&#123;req.headers.mkString(&quot;\\n\\t&quot;)&#125; |$e&quot;&quot;&quot;.stripMargin if (e.errcode &gt; 500) logger.error(msg, e) else logger.warn(msg) complete( StatusCodes.getForKey(e.errcode) getOrElse StatusCodes.InternalServerError, JObject(&quot;errcode&quot; -&gt; JInt(e.errcode), &quot;errmsg&quot; -&gt; JString(e.errmsg))) &#125; case e: Exception =&gt; extractRequest &#123; req =&gt; logger.error(req.toString, e) complete( StatusCodes.InternalServerError, JObject(&quot;errcode&quot; -&gt; JInt(500), &quot;errmsg&quot; -&gt; JString(e.getLocalizedMessage))) &#125;&#125;def apply(props: ContextProps)(implicit ec: ExecutionContextExecutor, mat: Materializer) = handleExceptions(customExceptionHandler) &#123; pathPrefix(&quot;api&quot;) &#123; healthCheck ~ NewsRoute(props) ~ BookRoute(props) &#125; &#125; 代码有一点长，现在分别解说。 customExceptionHandler 自定义的异常处理器，主要用于把自定义异常和系统异常转换成JSON消息输出，并设置相对应的HTTP状态码。 apply apply方法定义了实现的API路由，由代码可以看到news、book两个模块的路由分别由NewsRoute和BookRoute两个文件定义。把相同功能的路由、服务、实体定义在同一个逻辑上下文（包）中，个人认为是一种更好的微服务实践。 book模块详解12345book├── Book.scala├── BookContextProps.scala├── BookRoute.scala└── BookService.scala Book：实体 BookContextProps：上下文属性，服务将在此实例化。并把接口混入ContextProps中。 BookRoute：API路由定义 BookService：服务功能实现 BookRotue定义 1234567891011121314151617181920212223pathPrefix(&quot;book&quot;) &#123; pathEnd &#123; post &#123; entity(as[Book]) &#123; book =&gt; onSuccess(props.bookService.persist(book)) &#123; result =&gt; complete(StatusCodes.Created, result) &#125; &#125; &#125; &#125; ~ path(Segment) &#123; bookId =&gt; get &#123; complete(props.bookService.findOneById(bookId)) &#125; ~ put &#123; entity(as[Book]) &#123; book =&gt; complete(props.bookService.updateById(bookId, book)) &#125; &#125; ~ delete &#123; complete(props.bookService.deleteById(bookId).map(id =&gt; Map(&quot;id&quot; -&gt; id))) &#125; &#125; Akka-Http提供了高级routing DSL，可以很自然的定义出树型结构的RESTful风格的API。由代码可见，定义了4个API。分别对应insert、select、update、delete操作，由post、get、put和delete4个指令实现对应操作的HTTP方法。 pathPrefix、pathEnd和path3个路径定义指令的区别在于pathPrefix代表由它定义的路径还并未终结，在它下面还有子路径。而path则代表它已经是最终的路径了，pathEnd是用于在使用了pathPrefix的情况下也可以直接访问由pathPrefix指定的路径。 Segment用于把由path定义的路径抽取成一个参数（bookId）。除了Segment用于抽取一个字符串类型，还有IntNumber和LongNumber用于抽取路径为Int或Long类型。 entity指令用于抽取HTTP请求的body部分，并通过as[T]方法将其自动解析为指定类型。这里使用到了akka提供的Unmarshaller特性。这里通过JsonSupport里定义的json4sUnmarshaller将用户请求提交的JSON字符串映射到Book类型。 1234567891011implicit def json4sUnmarshaller[A: Manifest](implicit mat: Materializer): FromEntityUnmarshaller[A] = Unmarshaller.byteStringUnmarshaller .forContentTypes(MediaTypes.`application/json`) .mapWithCharset &#123; (data, charset) =&gt; val input = if (charset == HttpCharsets.`UTF-8`) data.utf8String else data.decodeString(charset.nioCharset().name) jsonSerialization.read(input) &#125;implicit def json4sMarshaller[A &lt;: AnyRef]: ToEntityMarshaller[A] = Marshaller.StringMarshaller.wrap(ContentType(MediaTypes.`application/json`, HttpCharsets.`UTF-8`))(v =&gt; jsonSerialization.write[A](v)) 自然json4sMarshaller则是把T类型的对象映射为JSON字符串响应给请求方。 BookService 再来看看BookService服务的实现。 1234567891011121314151617181920212223242526272829303132def updateById(bookId: String, book: Book)(implicit ec: ExecutionContext): Future[Book] = Future &#123; if (bookId != book.id) throw MeConflictMessage(s&quot;$&#123;book.id&#125; is invalid，the ID is expected to be $bookId&quot;) val newBooks = BookService.books.filterNot(_.id == bookId) if (newBooks.size == BookService.books.size) throw MeNotFoundMessage(s&quot;$bookId not found&quot;) BookService.books ::= book book &#125; def persist(book: Book)(implicit ec: ExecutionContext): Future[Book] = Future &#123; if (BookService.books.exists(_.id == book.id)) throw MeConflictMessage(s&quot;$&#123;book.id&#125; exsits&quot;) BookService.books ::= book book &#125; def deleteById(bookId: String)(implicit ec: ExecutionContext): Future[String] = Future &#123; val newBooks = BookService.books.filterNot(_.id == bookId) if (newBooks.size == BookService.books.size) throw MeNotFoundMessage(s&quot;$bookId not found&quot;) BookService.books = newBooks bookId &#125; def findOneById(bookId: String)(implicit ec: ExecutionContext): Future[Book] = Future &#123; BookService.books.find(_.id == bookId).getOrElse(throw MeNotFoundMessage(s&quot;$bookId not found&quot;)) &#125; 看到每个方法的返回值都被定义成了Future[T]，akka-http是一个基于akka-actor和akka-stream的异步HTTP工具集，使用Future可以提供整个系统的响应。我们这里直接使用Future来模拟异步访问（数据库操作）。 在每个方法中，我们校验参数是否有效。若校验失败则直接抛出自定义异常。Future函数将捕获异常，由之前定义的customExceptionHandler自定义异常处理器来将自定义异常转换成JSON消息发送给调用方，并设置匹配的HTTP状态码。 测试百闻不如一试，下载代码实际操作下（下载地址在文章开头）。 运行程序： 12.&#x2F;sbtakka-action &gt; runMain me.yangbajing.akkaaction.restapi.App 依次执行docs/scripts/restapi目录下的测试脚本，查看各请求下REST API的返回值（需要系统安装curl）。 ./get-book-aa.sh：正常返回ID为aa的书 ./get-book-bb.sh：查找ID为bb的书返回404 ./post-book.sh：创建一本ID为bb书，返回201 ./get-book-bb.sh：正确返回ID为bb的书 ./put-book.hs：正确更新ID为bb的书 ./put-book-invalid.sh：无效的更新ID为aa的书，返回409 ./delete-book-aa.sh：成功的删除ID为aa的书 ./get-book-aa.sh：再次查找ID为aa的书返回404 ./delete-book-aa.sh：再次删除ID为aa的书时返回404 总结akka-http是一个很有意思的HTTP工具库，它完整的实现了客户端和服务端编程工具，还支持WebScoket。基于akka-actor和akka-stream，提供了高并发的异步编程模型。我们可以很快捷的实现出一个响应式（Reactive）Web Service。其提供的routing DSL可方便的定义出一套树型结构的API，很自然的匹配到RESTful风格的API设计。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"rest","slug":"rest","permalink":"https://yangbajing.github.io/tags/rest/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"micro-service","slug":"micro-service","permalink":"https://yangbajing.github.io/tags/micro-service/"},{"name":"json4s","slug":"json4s","permalink":"https://yangbajing.github.io/tags/json4s/"}]},{"title":"Akka实战：分散、聚合模式","slug":"akka实战：分散与聚合","date":"2015-11-25T11:41:46.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/11/25/akka实战：分散与聚合/","link":"","permalink":"https://yangbajing.github.io/2015/11/25/akka%E5%AE%9E%E6%88%98%EF%BC%9A%E5%88%86%E6%95%A3%E4%B8%8E%E8%81%9A%E5%90%88/","excerpt":"","text":"分散、聚合模式：简单说就是一个任务需要拆分成多个小任务，每个小任务执行完后再把结果聚合在一起返回。 代码 https://github.com/yangbajing/akka-action 实例背景本实例来自一个真实的线上产品，现将其需求简化如下： 传入一个关键词：key，根据key从网上抓取相关新闻 可选传入一个超时参数：duration，设置任务到期时必须反回数据（返回实际已抓取数据） 若超时到返回实际已爬取数据，则任务应继续运行直到所以数据抓取完成，并存库 设计根据需求，一个简化的分散、聚合模式可以使用两个actor来实现。 NewsTask：接收请求，并设置超时时间 SearchPageTask：执行实际的新闻抓取操作（本实例将使用TimeUnit模拟抓取耗时） 实现NewsTask https://github.com/yangbajing/akka-action/blob/master/src/main/scala/me/yangbajing/akkaaction/scattergather/NewsTask.scala 1234567891011121314151617181920212223242526272829override def metricPreStart(): Unit = &#123; context.system.scheduler.scheduleOnce(doneDuration, self, TaskDelay)&#125;override def metricReceive: Receive = &#123; case StartFetchNews =&gt; _receipt = sender() (0 until NewsTask.TASK_SIZE).foreach &#123; i =&gt; context.actorOf(SearchPageTask.props(self), &quot;scatter-&quot; + i) ! SearchPage(key) &#125; case GetNewsItem(newsItem) =&gt; _newses ::= newsItem if (_newses.size == NewsTask.TASK_SIZE) &#123; logger.debug(s&quot;分散任务，$&#123;NewsTask.TASK_SIZE&#125;个已全部完成&quot;) if (_receipt != null) &#123; _receipt ! NewsResult(key, _newses) _receipt = null &#125; self ! PoisonPill &#125; case TaskDelay =&gt; if (_receipt != null) &#123; _receipt ! NewsResult(key, _newses) _receipt = null &#125;&#125; metricPreStart方法中设置定时方法，调用时间为从代码运行开始到doneDuration时间为止。定时被触发时将向当前Actor发送一个TaskDelay消息。 在metricReceive方法中，分别对StartFetchNews、GetNewsItem、TaskDelay三个消息进行操作。 在收到StartFetchNews消息时，actor首先保存发送者actor的引用（结果将返回到此actor）。再根据TASK_SIZE生成相应子任务 GetNewsItem消息的处理中，每收到一个消息就将其添加到_newses列表中。并判断当_newses个数等于TASK_SIZE时（所有子任务已完成）将结果发送给_receipt。 self ! PoisonPill，这句代码停止actor自身。它将把“毒药”发送到NewsTask Actor的接收邮箱队列中。 TaskDelay消息被触发时，将直接返回已完成的新闻_newses。返回数据后并不终止当前还未运行完任务。 SearchPageTask https://github.com/yangbajing/akka-action/blob/master/src/main/scala/me/yangbajing/akkaaction/scattergather/SearchPageTask.scala 123456789101112131415override def metricReceive: Receive = &#123; case SearchPage(key) =&gt; // XXX 模拟抓取新闻时间 TimeUtils.sleep(Random.nextInt(20).seconds) val item = NewsItem( &quot;http://newssite/news/&quot; + self.path.name, &quot;测试新闻&quot; + self.path.name, self.path.name, TimeUtils.now().toString, &quot;内容简介&quot;, &quot;新闻正文&quot;) taskRef ! GetNewsItem(item) context.stop(self)&#125; SearchPageTask的代码逻辑就比较易懂了，这里使用sleep来模拟实际抓取新闻时的耗时。生成结果后返回数据给｀taskRef`，并终止自己。 执行测试12.&#x2F;sbtakka-action &gt; testOnly me.yangbajing.akkaaction.scattergather.ScatterGatherTest 总结这是一个简单的Akka实例，实现了任务分发与结果聚合。提供了一种在指定时间内返回部份有效数据，同时任务继续执行的方式。这种分散、聚合的模式在实际生产中很常用，比如对多种数据源的整合，或某些需要长时间运行同时对返回数据完整性无强制要求的情况等。 MetricActor演示了怎么自定义Actor，并为其提供一些侦测点的方式。以后有时间会写篇详文介绍。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"akka实战","slug":"akka实战","permalink":"https://yangbajing.github.io/tags/akka%E5%AE%9E%E6%88%98/"}]},{"title":"JVM程序员书单","slug":"jvm程序员书单","date":"2015-11-21T12:49:12.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/11/21/jvm程序员书单/","link":"","permalink":"https://yangbajing.github.io/2015/11/21/jvm%E7%A8%8B%E5%BA%8F%E5%91%98%E4%B9%A6%E5%8D%95/","excerpt":"","text":"JVM程序员书单 为什么是JVM程序员书单，因为现在Java已经不再单指Java编程语言了，而是说整个Java生态环境和基于JVM平台的各种虚拟机语言。如：Scala、Clojure、Groovy等。 《软件框架设计的艺术》 这是Netbeans的创始人写的一本很有价值的书，里面的边角细节也很有料。国内市场上没有对这本书给予应给的赞誉。 《Effective Java 第二版》 被称为Java领域的圣经，小中见大。探讨的不仅仅是Java语言，也包括一些形而上的东西，取决于读的人理解多少。我在面试时喜欢考察一些基础的东西，以及背后的想法和初衷，可惜相当多的程序员这本书都没仔细阅读过。 《并发编程实践》 《Java并发编程》 《Java 并发编程设计原则与模式》 《代码的未来》 《Programming in Scala》 中文版是”Scala编程”，对scala程序员来说这本书你不能不读 《Java解惑》 《Java与模式》 十几年前正是模式刚流行的时候，阎宏博士的这本书当时在中文圈里引起了很大反响，这本书算得上一本经典巨著。 《程序设计语言》第三版 《重构》 《Java Rules中文版》 《企业应用架构模式》 《领域驱动设计》 《Java虚拟机规范(Java SE 7版)》 《Java程序员修炼之道》 《HTTP权威指南》 《TCP/IP详解卷1:协议》 《TCP/IP详解卷2：实现》 《构建高性能Web站点》 《JAVASCRIPT语言精髓与编程实践》 《深入剖析Tomcat》 《Maven实战》 《哥德尔、艾舍尔、巴赫:集异璧之大成》 《An Introduction to Functional Programming Through Lambda Calculus》 《分布式系统概念与设计(原书第3版)》 《实用Common Lisp编程》 《面向模式的软件架构 卷1：模式系统》 《面向模式的软件架构 卷2：并发和联网对象模式》 《面向模式的软件架构 卷3：资源管理模式》 《面向模式的软件架构 卷4：分布式计算的模式语言》 《面向模式的软件架构 卷5：模式与模式语言》 《编程语言实现模式》 《架构之美》 《精通正则表达式》 《浪潮之巅》 《多处理器编程的艺术》 《JAVA核心技术 卷II：高级特性》 《Java核心技术 卷I: 基础知识》 《程序员修炼之道——从小工到专家》","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"}]},{"title":"Nginx负载均衡与反向代理","slug":"nginx负载均衡与反向代理","date":"2015-11-20T05:48:49.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/11/20/nginx负载均衡与反向代理/","link":"","permalink":"https://yangbajing.github.io/2015/11/20/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/","excerpt":"","text":"一般在应用部署中都不会直接把Web Server（如：Tomcat、Jetty等）暴露给用户，我们会在Web Server前面再加一个反向代理。这篇文章介绍的就是怎样设置Nginx来做反向代理。 Nginx安装以Ubuntu 14.04为例（其它系统请自行查找安装方法\u0005）。官方安装文档在：http://nginx.org/en/download.html 1234567curl http:&#x2F;&#x2F;nginx.org&#x2F;keys&#x2F;nginx_signing.key | sudo apt-key add -echo &quot;deb http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;mainline&#x2F;ubuntu&#x2F; trusty nginxdeb-src http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;mainline&#x2F;ubuntu&#x2F; trusty nginx&quot; | sudo tee &#x2F;etc&#x2F;apt&#x2F;source.list.d&#x2F;nginx.listsudo apt-get updatesudo apt-get -y install nginx Nginx反向代理常用设置在location段中设置反向代理，必需的设置项是：proxy_pass，它指定将请示转发到的地址。 proxy_pass URL：设置被代理服务的地址或被映射的URI proxy_http_version 1.1：设置HTTP协议 proxy_set_header field value：设置预定义或增加字段到请求header中传到被代理的Server上。\u0005常用设置有： X-Real-IP $remote_addr：代理远端IP X-Forwarded-Proto $scheme：代理远端scheme，一般就是使用的协议，如：http、https、ftp Connection “Keep-Alive”：启用HTTP的Keep-Alive特性，保持HTTP连接。在服务频繁连接使用时可以减少TIME_WAIT状态的发生，有效的提供性能。 proxy_next_upstream value：指定切换请求到下一个被代理Server的机制。默认：error timeout error：发生错误 timeout：超时发生 invalid_header：header头无效 http_500 http_502 http_503 http_504 http_403 http_404 off：禁止传到请求到下一个Server （keepalive 这个词可能是指连接池或者tcp层面的参数，要看上下文。在http里是keep-alive，注意中间有个连字符。） Nginx负载均衡在配置文件http段内定义upstream指令： 1234upstream crawlerApi &#123; server crawler-ali:7100; server crawler-ali:7101;&#125; **server**标识指令定义用于做负载均衡的Server列表。server标识可以定义附加参数，每个参数之间使用空格分隔。crawler-ali和端口改成你自己的。 weight=number：设置当前Server的优先级权重，值越大越高。默认为1 max_fails=number：设置最大重试次数，默认为1 fail_timeout=time：设置重试间隔时间，默认10秒 backup：设置当前Server为备份Server，当其它Server不可以时启用 down：标记当前Server不可用 max_conns=number：设置被代理Server最大活动连接数，默认不限制 在需要配置负载均衡的location里定义代理使用： 1proxy_pass http:&#x2F;&#x2F;crawlerApi; Nginx做负载的键康检查（心跳检测）机制Nginx提供了health_check语句来提供负载（upstream）时的键康检查机制（注意：此语句需要设置在location上下文中）。 支持的参数有： interval=time：设置两次健康检查之间的间隔值，默认为5秒 fails=number：设置将服务器视为不健康的连续检查次数，默认为1次 passes=number：设置一个服务器被视为健康的连续检查次数，默认为1次 uri=uri：定义健康检查的请求URI，默认为”/“ match=name：指定匹配配置块的名字，用记测试响应是否通过健康检测。默认为测试返回状态码为2xx和3xx 一个简单的设置如下，将使用默认值： 1234location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;backend; health_check;&#125; 对就应用，我们可以专门定义一个API用于健康检查：/api/health_check，并只返回HTTP状态码为200。并设置两次检查之间的间隔值为1秒。这样，health_check语句的配置如下： 1health_check uri&#x3D;&quot;&#x2F;api&#x2F;health_check&quot; interval; 对后端某个节点的优雅下线Nginx将请求代理给一个后端节点，这个请求耗时较长，在请求未处理完时后端恰好要做发布。这时在Nginx中先将此节点标记为不可用（在upstream中设置server的down属性）。此时，只要请求连接还保持，Nginx并不会中断当前连接，但之后新的连接将不再使用这个节点。 这样在用Nginx的负载时，后端若需要做发布。只需要将对就节点标记为不可用并留出一定的时间让忆有请求都响应完毕即可。 更严格一些，还应检测到后端节点的网络连接都已释放（那些EST、TIME_WAIT等连接都结束后）。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://yangbajing.github.io/tags/nginx/"},{"name":"反向代理","slug":"反向代理","permalink":"https://yangbajing.github.io/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://yangbajing.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"upstream","slug":"upstream","permalink":"https://yangbajing.github.io/tags/upstream/"},{"name":"proxy","slug":"proxy","permalink":"https://yangbajing.github.io/tags/proxy/"}]},{"title":"Elasticsearch初步使用","slug":"elasticsearch初步使用","date":"2015-11-02T07:40:09.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/11/02/elasticsearch初步使用/","link":"","permalink":"https://yangbajing.github.io/2015/11/02/elasticsearch%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8/","excerpt":"","text":"集群安装安装一个两个结节的简单集群，其中一个Master，一个Slave。两台机器的网络分别是： 12192.168.31.101 sc-007192.168.31.48 scdev-001 Master配置 123456789cluster: name: sc0node: name: sc-007 master: truenetwork: host: 192.168.31.101discovery: zen.ping.unicast.hosts: [&quot;sc-007&quot;] Slave配置 123456789cluster: name: sc0node: name: scdev-001 master: truenetwork: host: 192.168.31.48discovery: zen.ping.unicast.hosts: [&quot;sc-007&quot;] 集群有用的相关命令检查集群健康度： curl -XGET http://127.0.0.1:9200/_cluster/health?pretty 获取集群中节点信息： curl -XGET http://192.168.31.101:9200/_cluster/state/nodes/?pretty 关闭集群中所有节点： curl -XGET http://192.168.31.101:9200/_cluster/state/nodes/_shutdown","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"elasticsearch","slug":"bigdata/elasticsearch","permalink":"https://yangbajing.github.io/categories/bigdata/elasticsearch/"}],"tags":[{"name":"集群","slug":"集群","permalink":"https://yangbajing.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://yangbajing.github.io/tags/elasticsearch/"}]},{"title":"Canssandra开始","slug":"cassandra开始","date":"2015-10-22T13:50:49.000Z","updated":"2015-10-26T13:30:32.000Z","comments":true,"path":"2015/10/22/cassandra开始/","link":"","permalink":"https://yangbajing.github.io/2015/10/22/cassandra%E5%BC%80%E5%A7%8B/","excerpt":"","text":"Install Cassandra1234567sudo mkdir -p &#x2F;usr&#x2F;app&#x2F;cassandrasudo chown -R $(whoami) &#x2F;usr&#x2F;appcd &#x2F;usr&#x2F;app&#x2F;cassandrawget http:&#x2F;&#x2F;apache.fayea.com&#x2F;cassandra&#x2F;2.1.11&#x2F;apache-cassandra-2.1.11-bin.tar.gztar zxf apache-cassandra-2.1.11-bin.tar.gzmv apache-cassandra-2.1.11 cassandra-2.1mkdir data commitlog log saved_caches 启动bin/cassandra -f即可，-f参数的意思是让cassandra服务在前台启动，这样可以各种上日志输出就将直接打印到终端上。 Cassandra集群搭建我们构建一个有3个节点的cassandra集群，IP分别为：192.168.31.101、192.168.31.102、192.168.31.103。 编辑Cassandra配置文件：conf/cassandra.yaml： endpoint_snitch： 1endpoint_snitch: GossipingPropertyFileSnitch 配置Cassandra集群支持机架感知，推荐产品使用。 listen_address： 1listen_address: 192.168.31.101 rpc_address： 1rpc_address: （注意：rpc_address:后面的空格也要删除掉） seeds： 1- seeds: &quot;192.168.31.101,192.168.31.102,192.168.31.103&quot; Store data： 12data_file_directories: - &#x2F;usr&#x2F;app&#x2F;cassandra&#x2F;data Commit log： 1commitlog_directory: &#x2F;usr&#x2F;app&#x2F;cassandra&#x2F;commitlog Saved caches： 1saved_caches_directory: &#x2F;usr&#x2F;app&#x2F;cassandra&#x2F;saved_caches 先配置好一台，再把相同的配置文件和目录复制到其它节点上。在修改相应IP地址即可。之后挨个启动集群，可以看到下面这样的节点连结信息： 123456INFO 12:33:35 Handshaking version with &#x2F;192.168.31.102INFO 12:33:36 No gossip backlog; proceedingINFO 12:33:36 Node &#x2F;192.168.31.102 is now part of the clusterINFO 12:33:36 Netty using native Epoll event loopINFO 12:33:36 InetAddress &#x2F;192.168.31.102 is now UPINFO 12:33:36 Updating topology for &#x2F;192.168.31.102 CQLSH创建keyspace1CREATE KEYSPACE watch_log WITH replication &#x3D; &#123;&#39;class&#39;: &#39;NetworkTopologyStrategy&#39;, &#39;dc1&#39;: 2 &#125;; cqlsh支持查询中文默认的cqlsh是可以正常显示中文的，但当你的查询语句里有中文时，就会报错： 12cqlsh:mykeyspace&gt; select * from users where fname = &#x27;羊&#x27;;&#x27;ascii&#x27; codec can&#x27;t decode byte 0xe7 in position 35: ordinal not in range(128) 因为cqlsh是用Python编写的，所以定位是Python对中文支持的问题。这个问题也很好解决，加入以下两行代码即可： 12reload(sys)sys.setdefaultencoding(&quot;utf-8&quot;) 加入后代码显示如下： 123456789from glob import globfrom StringIO import StringIOfrom uuid import UUIDreload(sys)sys.setdefaultencoding(&quot;utf-8&quot;)description = &quot;CQL Shell for Apache Cassandra&quot;version = &quot;5.0.1&quot; 一些重要的Cassandra配置 cluster_name: 限制只能加入相同名字的集群 num_tokens: 系统优化DataStax 推荐的ulimit设置如下（编辑/etc/security/limits.conf文件，添加）： 1234scdata memlock unlimitedscdata nofile 100000scdata nproc 23768scdata - as unlimited 使用以下命令使设置马上生效： 1$ sudo sysctl -p","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"cassandra","slug":"bigdata/cassandra","permalink":"https://yangbajing.github.io/categories/bigdata/cassandra/"}],"tags":[{"name":"cassandra","slug":"cassandra","permalink":"https://yangbajing.github.io/tags/cassandra/"},{"name":"集群","slug":"集群","permalink":"https://yangbajing.github.io/tags/%E9%9B%86%E7%BE%A4/"}]},{"title":"Spark小试牛刀","slug":"Spark小试牛刀","date":"2015-09-22T16:26:53.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/09/23/Spark小试牛刀/","link":"","permalink":"https://yangbajing.github.io/2015/09/23/Spark%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/","excerpt":"","text":"随着项目的运营，收集了很多的用户数据。最近业务上想做些社交图谱相关的产品，但因为数据很多、很杂，传统的数据库查询已经满足不了业务的需求。试着用Spark来做，权当练练手了。 安装Spark因为有Scala的开发经验，所以就不用官方提供的二进制包了，自编译scala 2.11版本。 下载Spark：http://ftp.cuhk.edu.hk/pub/packages/apache.org/spark/spark-1.5.0/spark-1.5.0.tgz 1234tar zxf spark-1.5.0.tgzcd spark-1.5.0.&#x2F;dev&#x2F;change-scala-version.sh 2.11mvn -Pyarn -Phadoop-2.6 -Dscala-2.11 -DskipTests clean package 以上命令完成Spark基于scala 2.11版本的编译。可以运行自带的一个示例程序来验证安装是否成功。 1.&#x2F;bin&#x2F;run-example SparkPi 编写Standalone application使用sbt来构建一个可提交的简单Spark程序，功能是计算每个用户加入的群组，并把结果保存下来。project/Build.scala配置文件如下： 1234567891011121314151617181920212223242526import _root_.sbt.Keys._import _root_.sbt._import sbtassembly.AssemblyKeys._object Build extends Build &#123; override lazy val settings &#x3D; super.settings :+ &#123; shellPrompt :&#x3D; (s &#x3D;&gt; Project.extract(s).currentProject.id + &quot; &gt; &quot;) &#125; lazy val root &#x3D; Project(&quot;spark-mongodb&quot;, file(&quot;.&quot;)) .settings( scalaVersion :&#x3D; &quot;2.11.7&quot;, assemblyJarName in assembly :&#x3D; &quot;spark-mongodb.jar&quot;, assemblyOption in assembly :&#x3D; (assemblyOption in assembly).value.copy(includeScala &#x3D; false), libraryDependencies ++&#x3D; Seq( &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % verSpark % &quot;scopeProvidedTest, &quot;org.mongodb.mongo-hadoop&quot; % &quot;mongo-hadoop-core&quot; % &quot;1.4.0&quot; excludeAll( ExclusionRule(organization &#x3D; &quot;javax.servlet&quot;), ExclusionRule(organization &#x3D; &quot;commons-beanutils&quot;), ExclusionRule(organization &#x3D; &quot;org.apache.hadoop&quot;))) ) private val scopeProvidedTest &#x3D; &quot;provided,test&quot; private val verSpark &#x3D; &quot;1.5.0&quot;&#125; 数据存储在MongoDB数据库中，所以我们还需要使用mongo-hadoop连接器来访问MongoDB数据库。 示例程序示例程序非常的简单，把数据从数据库里全部读出，使用map来把每条记录里用户ID对应加入的群组ID转换成一个Set，再使用reduceByKey来把相同用户ID的set合并到一起，存入数据库即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import com.mongodb.BasicDBObjectimport com.mongodb.hadoop.&#123;MongoInputFormat, MongoOutputFormat&#125;import org.apache.hadoop.conf.Configurationimport org.apache.spark.&#123;SparkConf, SparkContext&#125;import org.bson.BSONObjectimport scala.collection.JavaConverters._object QQGroup &#123; def main(args: Array[String]): Unit &#x3D; &#123; val sparkConf &#x3D; new SparkConf().setAppName(&quot;QQGroup&quot;) val sc &#x3D; new SparkContext(sparkConf) val inputConfig &#x3D; new Configuration() inputConfig.set(&quot;mongo.input.uri&quot;, &quot;mongodb:&#x2F;&#x2F;192.168.31.121:27017&#x2F;db.userGroup&quot;) inputConfig.set(&quot;mongo.input.fields&quot;, &quot;&quot;&quot;&#123;&quot;userId&quot;:1, &quot;groupId&quot;:1, &quot;_id&quot;:0&#125;&quot;&quot;&quot;) inputConfig.set(&quot;mongo.input.noTimeout&quot;, &quot;true&quot;) val documentRDD &#x3D; sc.newAPIHadoopRDD( inputConfig, classOf[MongoInputFormat], classOf[Object], classOf[BSONObject]) val userRDD &#x3D; documentRDD.map &#123; case (_, doc) &#x3D;&gt; (getValue(doc, &quot;userId&quot;), getValue(doc, &quot;groupId&quot;)) &#125;.reduceByKey(_ ++ _) val resultRDD &#x3D; userRDD.map &#123; case (userId, groupIds) &#x3D;&gt; val o &#x3D; new BasicDBObject() o.put(&quot;groupIds&quot;, groupIds.asJava) userId -&gt; o &#125; val outputConfig &#x3D; new Configuration() outputConfig.set(&quot;mongo.output.uri&quot;, &quot;mongodb:&#x2F;&#x2F;192.168.31.121:27017&#x2F;db_result.userGroup&quot;) resultRDD.saveAsNewAPIHadoopFile( &quot;file:&#x2F;&#x2F;this-is-completely-unused&quot;, classOf[Object], classOf[BSONObject], classOf[MongoOutputFormat[Object, BSONObject]], outputConfig) &#125; def getValue(dbo: BSONObject, key: String) &#x3D; &#123; val value &#x3D; dbo.get(key) if (value eq null) &quot;&quot; else value.asInstanceOf[String] &#125;&#125; MongoDB官方提供了Hadoop连接器，Spark可以使用mongo-hadoop连接器来读、写MongoDB数据库。主要的输入配置荐有： mongo.input.uri: MongoDB的连接URI mongo.input.fields: 指定返回哪些数据，与db.query里的第2个参数功能一样 mongo.input.query: MongoDB的查询参数 相应的MongoDB也提供了一系列的输出参数，如： mongo.output.uri: MongoDB的连接URI sc.newAPIHadoopRDD()方法有4个参数，分别为：配置、输入格式化类、待映射数据主键类型、待映射数据类型。 主要的操作代码： 123456789val userRDD &#x3D; documentRDD.map &#123; case (_, doc) &#x3D;&gt; (getValue(doc, &quot;userId&quot;), Set(getValue(doc, &quot;groupId&quot;)))&#125;.reduceByKey(_ ++ _)val resultRDD &#x3D; userRDD.map &#123; case (userId, groupIds) &#x3D;&gt; val o &#x3D; new BasicDBObject() o.put(&quot;groupIds&quot;, groupIds.asJava) userId -&gt; o&#125; 先使用map方法获取userId和groupId，并把groupId转换为一个Set。 在把数据转换成Tuple2，就是一个KV的形式以后，我们就可以调用一系列的转换方法来对RDD进行操作，这里使用reduceByKey方法来将同一个userId的所以value都合并在一起。这样我们就有了所有用户对应加入的群组的一个RDD集了。 （RDD上有两种类型的操作。一种是“变换”，它只是描述了待进行的操作指令，并不会触发实际的计算；另一种是“动作”，它将触发实际的计算动作，这时候系统才会实际的从数据源读入数据，操作内存，保存数据等） 最后使用resultRDD.saveAsNewAPIHadoopFile()方法来把计算结果存入MongoDB，这里的一个参数：用于指定HDFS的存储位置并不会使用到，因为mongo-hadoop将会使用mongo.output.uri指定的存储URI连接地址来保存数据。","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"spark","slug":"bigdata/spark","permalink":"https://yangbajing.github.io/categories/bigdata/spark/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"spark","slug":"spark","permalink":"https://yangbajing.github.io/tags/spark/"}]},{"title":"Scala实战-通过微信聊天窗口实现应答式点餐 1：连接微信API","slug":"Scala实战-通过微信聊天窗口实现应答式点餐_1：连接微信API","date":"2015-08-15T01:09:46.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/08/15/Scala实战-通过微信聊天窗口实现应答式点餐_1：连接微信API/","link":"","permalink":"https://yangbajing.github.io/2015/08/15/Scala%E5%AE%9E%E6%88%98-%E9%80%9A%E8%BF%87%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E7%AA%97%E5%8F%A3%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%AD%94%E5%BC%8F%E7%82%B9%E9%A4%90_1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%BE%AE%E4%BF%A1API/","excerpt":"","text":"当前代码tag: v0.0.1，https://github.com/yangbajing/wechat-meal/tree/v0.0.1 微信公众号提供了详尽的API文档说明，提供了明文和加密两种接入方式。这里，我们选择加密的接入方式微信公众号接入指南。 本此实战的代码部署到了Heroku，读者也可以下载代码尝试部署到Heroku并连接微信公众号。本章末尾讲讲述Heroku的部署及怎样与微信公众号连接。 微信API现在主要的功能是实现与微信公众号的连接，我们将在微信里实现一个echo功能。就是用户在公众号聊天窗口里输入一段文本，系统原样返回。 连接微信API的代码WeixinCtrl。微信公众号的连接分两个部分： 验证服务器地址有效性这个接口为WeixinCtrl.get方法，用户校验服务器的有效性 依据接口文档实现业务逻辑这个接口为WeixinCtrl.post方法，通过微信公众号聊天窗口发送的各类消息都会发送的这里。 代码WeixinService是所以微信API相关功能实现的入口，现在提供了签名校验、加密消息和解密消息功能。 在WeixinCtrl控制器中，我们将收到的微信公众号消息原样返回给用户： 123456789101112131415161718192021222324252627282930313233def post = Action.async(parse.tolerantText) &#123; request =&gt; def getBody = ...... def responseContent(body: String) = &#123; val node = scala.xml.XML.loadString(body) OrdinaryMessage.msgType(node) match &#123; case MessageTypes.Event =&gt; // event ...... case _ =&gt; // message getContent(node) &#125; &#125; for &#123; body &lt;- getBody resp &lt;- responseContent(body) &#125; yield &#123; Ok(resp).withHeaders(&quot;Content-Type&quot; -&gt; &quot;application/xml; charset=UTF-8&quot;) &#125;&#125;private def getContent(node: Elem, reply: String = &quot;&quot;): Future[String] = &#123; val msg = OrdinaryMessage(node) val newTs = Utils.currentTimeSeconds() val replyContent = if (StringUtils.isEmpty(reply)) &#123; msg.contentOption getOrElse &quot;欢迎关注羊八井花园&quot; &#125; else &#123; reply &#125; val respStr = OrdinaryTextResponse(msg.fromUserName, msg.toUserName, newTs, replyContent).stringify() weixinService.encryptMsg(respStr, newTs, Utils.randomString(8))&#125; Play 2的依赖注入从Play 2.4开始，官方推荐使用依赖注入的方式定义路由和服务了，Play使用了一个Java标准注入方式的实现：Guice。 12345678910111213@Singletonclass WeixinCtrl @Inject()(weixinService: WeixinService) extends Controller with BaseController &#123; def get(signature: String, echostr: String, timestamp: String, nonce: String) = Action.async &#123; request =&gt; logger.debug(request.rawQueryString) weixinService.validateSign(timestamp, nonce).map &#123; case `signature` =&gt; Ok(echostr) case s =&gt; logger.error(s&quot;$s not match $signature&quot;) BadRequest &#125; &#125;...... @singleton注解表示这个控制器将做为单例存在于整个应用生命周期，默认情况是每次调用时都会重新生成一个。 在Play中，注入依赖的方式和Java很不一样，它是在scala类定义的主构造器中注入的，而Java代码中我们一般是在类的私用属性变量上进行注入。@Inject()是一个特殊的语法，用于修饰构造函数，之后的参数实例将由注解框架自动注入。在这里，weixinService这个服务就由系统框架注入了，我们不需要手动管理它的生命周期。 部署代码到Heroku到Heroku官网https://www.heroku.com注册开发者账号。 登陆Heroku的Dashboard，点击屏幕右上方的+号按钮添加新应用。 安装Heroku Toolbelt，支持Mac、Linux和Windows系统。 有3种部署代码到Heroku的方式： 通过Toolbelt用Git方式提交 连接到你的Github代码库 通过Dropbox提交。 这里选择了通过Toolbelt手动提交到Heroku的GIT代码库的方式。 添加新的或已存的项目到GIT版本库 123$ cd wechat-meal/$ git init$ heroku git:remote -a wechat-meal 部署应用 123$ git add .$ git commit -am &quot;make it better&quot;$ git push heroku master 连接微信公众号程序使用“加密连接”的方式，示例代码已经整合了微信提供的Java版加密、解密功能。 在URL(服务器地址)配置好连接微信API的服务地址，这里注意需要使用http协议（必需为80端口）。设置好Token(令牌)和EncodingAESKey(消息加解密密钥)，并选择“安全模式”。 当全部配置都设置好后就可以点击“提交”按钮了。若微信API校验成功，这时你从公众号的聊天窗口输入一段文本，公众号应该会回显你的输入内容。 目录 Scala实战-通过微信聊天窗口实现应答式点餐 0 Scala实战-通过微信聊天窗口实现应答式点餐 1：连接微信API","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"微信开发","slug":"微信开发","permalink":"https://yangbajing.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91/"}]},{"title":"Scala实战-通过微信聊天窗口实现应答式点餐 0","slug":"Scala实战-通过微信聊天窗口实现应答式点餐_0：介绍","date":"2015-08-14T01:08:40.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/08/14/Scala实战-通过微信聊天窗口实现应答式点餐_0：介绍/","link":"","permalink":"https://yangbajing.github.io/2015/08/14/Scala%E5%AE%9E%E6%88%98-%E9%80%9A%E8%BF%87%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E7%AA%97%E5%8F%A3%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%AD%94%E5%BC%8F%E7%82%B9%E9%A4%90_0%EF%BC%9A%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"近来学习Play 2和Akka，想着找一个实战性的项目练练手。正好近来公司提供晚餐，每天看着程序媛拿着手机一个一个的找人点餐，耗时多、且容易点漏、又打断了自身的工作……哥觉得小妹儿工作好累啊。作为一个全栈工程师，为公司小妹儿减轻工作负担义不容辞啊。 就在想，就在想……用什么方法可以简化这个点餐流程呢？把玩着手中的微信，看到同事们在公司群里胡吹海吹，Duang！有了，就做一个基于微信公众号的点餐系统。 技术系统用到的技术有： Scala 2.11.7 sbt 0.13.8 Play 2.4.2 Akka 2.11.12 Slick 3.0.1 PostgreSQL 9.4 Heroku（项目部署在此） Github（项目托管在此：https://github.com/yangbajing/wechat-meal） 系统功能经过深思熟虑的思考，做一个基于WEB的点餐，通过微信打开内置游戏器访问。这个，感觉B格不够高，就是做一个网站了，Low……。我得做一个与微信深度集成的点餐功能，就像一个聊天机器人一下。用户输入指令，系统返回菜单。甚至用户输入语音，系统也返回菜单，哈哈哈！ 在聊天窗口输入指令显示菜单，如： 0：所有指令 1：注册用户 2：今日菜单 3：我的历史（返回连接，直接进入我的历史点餐记录） 选择今日菜单后，系统在聊天窗口返回： 菜品一 菜品二 菜品三 菜品四。。。。。 用户选中一个菜品后系统应返回一个确认提示： 1：确认，2（其它）：取消 用户注册 这个系统只限于公司内部使用，所以不能让随便一个关注了公司号的人都可以进行点餐操作。所以用户注册功能是必需得有的。注册也采用应答的方式，用户在微信聊天窗口输入相关信息，系统验证成功后注册成功。 有注册了，那登录呢？登录？都已经用微信做入口了，就直接登录了吧。 开发Play Play用来做什么？根据微信公众号的开发文档，接入微信公众号需要80端口，并使用HTTP协议。这不是要开发WEB嘛，哥用Scala做开发，那自然就是Play 2了。其实也不当当这个，Scala下可使用的Web框架还是很多的，甚至Spring也可以的嘛。不过我就是想用用Play 2，OK。 用Play其实还有一些网页的开发工作，虽然是通过聊天窗口进行点餐。但还是得有个简单的管理后台的，用于餐品管理、统计等。这些还是做个WEB程序比较方便。 Akka Akka有一个很好的特性，根据actor模型开发，自然而然就是一个树型结构。很适合用来管理每个微信用户的菜单选择状态。 Slick Slick是typesafe开发的一套用于访问数据库的工具库。最新的3.x系列版本实现了一个非阻塞的数据库访问API，底层使用了JDBC驱动。 Slick是一个现代的访问数据库的Scala库，使用编写访问数据库代码和平常编写代码一样，使用类集合操作的方式来访问数据库。同时也提供了以原生SQL语言的方式来读取数据库，并同时保证类型检查。 注册微信号到https://mp.weixin.qq.com官网注册订阅号或服务号。步骤就不详述了。 目录 Scala实战-通过微信聊天窗口实现应答式点餐 0 Scala实战-通过微信聊天窗口实现应答式点餐 1：连接微信API","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"scala实战","slug":"scala/scala实战","permalink":"https://yangbajing.github.io/categories/scala/scala%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"微信开发","slug":"微信开发","permalink":"https://yangbajing.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91/"},{"name":"scala实战","slug":"scala实战","permalink":"https://yangbajing.github.io/tags/scala%E5%AE%9E%E6%88%98/"}]},{"title":"使用Akka Http，ActiveMQ搭建一个邮件发送服务器","slug":"使用Akka Http，ActiveMQ搭建一个邮件发送服务器","date":"2015-08-11T10:11:27.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/08/11/使用Akka Http，ActiveMQ搭建一个邮件发送服务器/","link":"","permalink":"https://yangbajing.github.io/2015/08/11/%E4%BD%BF%E7%94%A8Akka%20Http%EF%BC%8CActiveMQ%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"代码地址：https://github.com/yangbajing/scala-applications/tree/master/email-server 应用功能是实现一个基于队列的邮件发送服务，每个邮件发送者（使用smtp协议）作为一个sender。多个sender可以在同一个组(group)中，每个组中的sender将串行发送邮件。 邮件内容可以通过REST API提交，以可以使用JMS发布到ActiveMQ中，邮件服务器将从中读取邮件内容。 快速开始配置： 推荐在启动时使用-Dapplication.file=/usr/app/etc/emailserver/application.conf指定配置文件 123456789101112131415161718192021222324252627282930313233emailserver &#123; server &#123; interface = &quot;0.0.0.0&quot; port = 9999 &#125; emails &#123; email1 &#123; userName = &quot;email1@email.com&quot; password = &quot;&quot; smtp = &quot;&quot; smtpPort = 0 ssl = true # 同一个组内的邮件会串行发送，此key可忽略 group = &quot;1&quot; &#125; email2 &#123; userName = &quot;email2@email.com&quot; password = &quot;&quot; smtp = &quot;&quot; smtpPort = 0 ssl = true group = &quot;2&quot; &#125; &#125; activemq &#123; url = &quot;tcp://127.0.0.1:61616&quot; emailQueueName = &quot;EmailQueue&quot; &#125;&#125; emails定义邮件发送者（可用于stmp服务进行邮件发送的邮箱信息）。可以定义多个邮件发送者，但每个邮件发送者的key不能相同。比如：email1和email2 activemq定义了ActiveMQ服务的连接参数。 编译与运行： 12345# 编译.&#x2F;sbt assembly# 运行java -Dapplication.file&#x3D;&#x2F;usr&#x2F;app&#x2F;etc&#x2F;emailserver&#x2F;application.conf -jar target&#x2F;scala-2.11&#x2F;email-server.jar 测试REST服务： 1234567# 查询存在的邮箱发送者：curl http:&#x2F;&#x2F;localhost:9999&#x2F;email&#x2F;users# 发送测试邮件curl -v -XPOST -H &quot;Content-Type: application&#x2F;json&quot; \\ -d &#39;&#123;&quot;sender&quot;:&quot;Info@email.cn&quot;, &quot;subject&quot;:&quot;测试邮件&quot;,&quot;to&quot;:[&quot;user1@email.cn&quot;, &quot;user2@email.cn&quot;],&quot;content&quot;:&quot;测试邮件内容咯~&quot;&#125;&#39; \\ http:&#x2F;&#x2F;localhost:9999&#x2F;email&#x2F;send 使用JMS发送邮件： 安装activemq 12345Downloads：http:&#x2F;&#x2F;mirrors.hust.edu.cn&#x2F;apache&#x2F;activemq&#x2F;5.11.1&#x2F;apache-activemq-5.11.1-bin.tar.gztar zxf ~&#x2F;Downloads&#x2F;apache-activemq-5.11.1-bin.tar.gzcd apache-activemq-5.11.1&#x2F;.&#x2F;bin&#x2F;activemq-admin start activemq管理控制台地址：http://localhost:8161/admin/，账号：admin，密码：admin。 JMS TCP地址：tcp://localhost:61616 生产测试邮件 修改EmailProducers.scala的activeMqUrl及mapMessage参数，运行EmailProducers生产一个邮件发送请求。 Akka HttpAkka Http是一个完整的server和client端HTTP开发栈，基于akka-actor他akka-stream。它不是一个WEB框架，而是提供了可以构建Http服务的工具包。 Akka Http有一套很直观的DSL来定义路由，自然的形成了一个树型的路由结构。如Routes： 12345678910111213141516171819202122232425pathPrefix(&quot;email&quot;) &#123; path(&quot;send&quot;) &#123; post &#123; entity(as[JsValue].map(_.as[SendEmail])) &#123; sendEmail =&gt; onComplete(emailService.sendEmail(sendEmail)) &#123; case Success(value) =&gt; value match &#123; case Right(msg) =&gt; complete(msg) case Left(msg) =&gt; complete(StatusCodes.Forbidden, msg) &#125; case Failure(e) =&gt; complete(StatusCodes.InternalServerError, &quot;SendEmail an error occurred: &quot; + e.getMessage) &#125; &#125; &#125; &#125; ~ path(&quot;users&quot;) &#123; get &#123; onComplete(emailService.getEmailSenders) &#123; case Success(emailSenders) =&gt; complete(Json.toJson(emailSenders)) case Failure(e) =&gt; complete(StatusCodes.InternalServerError, &quot;An error occurred: &quot; + e.getMessage) &#125; &#125; &#125;&#125; path -&gt; post -&gt; entity -&gt; complete 式的函数嵌套，很直观的定义出了声明式的树型REST URI结构，层次分明、逻辑清晰。entity函数用于解析Http Body，将其映射成希望的数据类型，可自定义映射方法。 onComplete函数用在返回类型是一个Future[T]时，提供了快捷的方式把一个Future[T]类型的响应转换到complete。 邮件发送邮件的发送采用了串行发送的方式，这个模式刚好契合Actor默认邮箱的FIFO处理形式。把收到的邮件发送请求告诉一个actor，actor再从邮箱里取出，并组装成XXXXEmail（邮件发送使用了commons-email）后发送出去。 首先，程序将收到的邮件发送请求交给EmailMaster，EmailMaster再根据邮件发送者（连接SMTP的邮箱用户名）来决定将这个发送请求交给哪一个具体的EmailGroupActor。 这里，程序对邮件发送者（简称：sender）做了一个分组。因为对于使用相同smtp邮件发送服务提供的sender，程序中最后对此类的sender做串行发送。而对于不同smtp邮件发送服务提供的sender，我们可以并发的发送邮件。这个可以通过在定义配置文件的时候指定特定sender属于的邮件发送组。 123456789101112emails &#123; email1 &#123; userName &#x3D; &quot;email1@email.com&quot; password &#x3D; &quot;&quot; smtp &#x3D; &quot;&quot; smtpPort &#x3D; 0 ssl &#x3D; true # 同一个组内的邮件会串行发送，此key可忽略 group &#x3D; &quot;1&quot; &#125;&#125; 连接ActiveMQ连接ActiveMQ使用了JMS协议，这是一个Java EE标准实现的消息队列。代码在：MQConsumerService。 在JMS里，邮件使用MapMessage消息发送，程序使用case match来匹配期望的消息格式。 123456789101112val listener = new MessageListener &#123; override def onMessage(message: Message): Unit = message match &#123; case msg: MapMessage =&gt; &#123; val subject = msg.getString(&quot;subject&quot;) val sender = msg.getString(&quot;sender&quot;) val content = msg.getString(&quot;content&quot;) val to = msg.getString(&quot;to&quot;).split(&quot;;&quot;) val mimeType = Option(msg.getString(&quot;mimeType&quot;)).map(MimeType.withName).getOrElse(MimeType.Text) val sendEmail = SendEmail(sender, subject, to, content, None, mimeType) emailService.sendEmail(sendEmail).onComplete(result =&gt; logger.debug(result.toString)) &#125; 总结本文简单的演示了Akka Http构建一个REST服务，并支持连接JMS Server来获取发送邮件消息。 演示了文件邮件和HTML格式邮件的发送。 接下来接下来可以添加对邮件附件的支持，这个功能可以留给读者去实现。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"activemq","slug":"activemq","permalink":"https://yangbajing.github.io/tags/activemq/"},{"name":"email","slug":"email","permalink":"https://yangbajing.github.io/tags/email/"}]},{"title":"使用Gatling进行性能测试","slug":"使用Gatling进行性能测试","date":"2015-07-31T10:44:39.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/07/31/使用Gatling进行性能测试/","link":"","permalink":"https://yangbajing.github.io/2015/07/31/%E4%BD%BF%E7%94%A8Gatling%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","excerpt":"","text":"Gatling下载是一款开源的性能测试工具，提供简洁、强大的DSL API编写测试套件，支持插件扩展，且自动生成美观、明了的HTML测试报告。 Gatling现在最新版本是：2.1.7。需要scala 2.11支持。 Gatling有多种执行方式，可以使用官话的bundle包，使用gatling.sh脚本执行，也可以使用使用gatling-sbt下载在Sbt工程里执行，也可以集成到如Jenkins这样的持续集成工具里执行。 使用Gatling在http://gatling.io/#/download下载Gatling bundle 2.1.7，下载后解压，目录如下： 123456789101112131415161718yangjing-mac-air:gatling-charts-highcharts-bundle-2.1.7 $ tree -d -L 3├── bin│ gatling.bat│ gatling.sh│ recorder.bat│ recorder.sh├── conf├── lib│ └── zinc├── results├── target│ └── test-classes│ └── computerdatabase└── user-files ├── bodies ├── data └── simulations └── computerdatabase bin目录的下放了两种启动脚本，分别有Unix Like和Windows环境的脚本 。gatling.sh是执行测试的脚本，它会列出已有的所有测试文件，并选择执行。而recorder.sh是一个图形化的Gatling脚本配置工具，通过很简洁的界面开始编写基础的Gatling测试脚本。 lib目录下是Gatling所依赖的库文件。 用户编写的测试脚本放在user-files/simulations目录下，Gatling已经自带了一个测试样例供参考。user-files/data目录可以放一些测试需要的测试数据，比如用户名和密码等。Gatling提供了对CSV文件的良好支持，可以把一组测试用户数据保存在一个CSV文件里，由Gatling读取。 最终生成的测试报告将会放在results目录。 Gatling自带了几个测试脚本，可以执行./bin/gatling.sh运行。这可以做为一个很好的开始Gatling测试的方式。 在sbt项目中使用Gatling在平常的测试、开发中，每次都把测试脚本放到 user-files/simulations 目录，并通过gatling.sh脚本执行，感觉有些不方便。我们可以使用 Gatling sbt-plugin 把Gatling很方便的集成到sbt工程里。 示例工程地址：https://github.com/yangbajing/gatling-example。 sbt工程配置 project/plugins.sbt 添加gatling插件 1addSbtPlugin(&quot;io.gatling&quot; % &quot;gatling-sbt&quot; % &quot;2.1.7&quot;) project/Build.scala 添加gatling依赖库 12&quot;io.gatling.highcharts&quot; % &quot;gatling-charts-highcharts&quot; % &quot;2.1.7&quot; % &quot;provided,test&quot;&quot;io.gatling&quot; % &quot;gatling-test-framework&quot; % &quot;2.1.7&quot; % &quot;test&quot; Gatling测试脚本的编写 每个gatling测试脚本都需要继承Simulation抽象类，同时还要导入以下包： 12import io.gatling.core.Predef._import io.gatling.http.Predef._ 编写Gatling测试脚本一般gatling脚本的编写分为3部分： 定义 http protocols：定义能用的http header选项，设置要测网址的baseURL。 编写 scenario: 每个剧本定义了一套测试脚本，使用exec执行实际的测试动作。 设置 scenario并执行：使用setUp装载多个scenario，并设置同时多少个用户并发访问，以及访问方式（在一个时间点内同时并发还是在一段时间内渐进并发）等。 http protocol 1234567http .baseURL(&quot;http:&#x2F;&#x2F;localhost:19001&quot;) .acceptHeader(&quot;text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;webp,*&#x2F;*;q&#x3D;0.8&quot;) .doNotTrackHeader(&quot;1&quot;) .acceptLanguageHeader(&quot;zh-CN,zh;q&#x3D;0.8,en;q&#x3D;0.6&quot;) .acceptEncodingHeader(&quot;gzip, deflate&quot;) .userAgentHeader(&quot;Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;44.0.2403.107 Safari&#x2F;537.36&quot;) baseUrl用于设置待测试网址的域名，其它设置是为了模拟浏览器的请求头。 scenario scenario用于定义一组测试脚本，使用exec命令来执行一个HTTP Request。多个HTTP Request可以链式调用。 123val helloscalaSDKApiScenario &#x3D; scenario(&quot;HelloscalaSDKApi&quot;) .feed(externalIds) .exec(createUser, socialSites, userLabels) feed用于导入用户定义数据，可以从文件导入，也可以编程生成。Gatling默认提供了csv、tsv、ssv、jsonFile等多种文件导入方法。feed也支持传入一个Seq[Map[String, T]]类型的用户生成数据。接下来会用编程方式生成一堆测试用户ID。 .exec设置要执行的测试请求，输入类型主要有两类：XXXXBuilder和Expression[Session]。XXXXBuilder用于加入测试请求，Expression[Session]用于设置Gatling的Session状态。定义的几个测试请求动作代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&#x2F;&#x2F; 生成1000个测试externalIdval externalIds &#x3D; (1 to 1000).map(_ &#x3D;&gt; Map(&quot;externalId&quot; -&gt; org.bson.types.ObjectId.get.toString))val createUser &#x3D; resetTimestamp .exec( http(&quot;createUser&quot;) .post(&quot;&#x2F;api&#x2F;external&#x2F;user&quot;) .header(&quot;sc-apikey&quot;, APIKEY) .header(&quot;sc-timestamp&quot;, &quot;$&#123;timestamp&#125;&quot;) .header(&quot;sc-api-token&quot;, session &#x3D;&gt; computeToken(&quot;post&quot;, session(&quot;timestamp&quot;), &quot;&#x2F;api&#x2F;external&#x2F;user&quot;)) .body(StringBody( &quot;&quot;&quot;&#123; | &quot;externalId&quot;:&quot;$&#123;externalId&#125;&quot;, | &quot;name&quot;:&quot;用户1&quot;, | &quot;idCard&quot;:&quot;50038119850000000X&quot;, | &quot;corporation&quot;:&quot;企业1&quot; |&#125;&quot;&quot;&quot;.stripMargin)).asJSON .check(status.is(201)) )val socialSites &#x3D; resetTimestamp .exec( http(&quot;postSocialSites&quot;) .post(&quot;&#x2F;api&#x2F;external&#x2F;user&#x2F;socialSites&quot;) .header(&quot;sc-apikey&quot;, APIKEY) .header(&quot;sc-timestamp&quot;, &quot;$&#123;timestamp&#125;&quot;) .header(&quot;sc-api-token&quot;, session &#x3D;&gt; computeToken(&quot;post&quot;, session(&quot;timestamp&quot;), &quot;&#x2F;api&#x2F;external&#x2F;user&#x2F;socialSites&quot;)) .body(StringBody( &quot;&quot;&quot;&#123; | &quot;externalId&quot;: &quot;$&#123;externalId&#125;&quot;, | &quot;socialSites&quot;:[&#123; | &quot;socialSite&quot;: &quot;QQ&quot;, | &quot;accessToken&quot;: &quot;lskjdflksdjflksdjf&quot;, | &quot;openId&quot;: &quot;24234324&quot;, | &quot;expireIn&quot;: &quot;23423&quot; | &#125;] |&#125;&quot;&quot;&quot;.stripMargin)).asJSON .check(status.is(200)) )val userLabels &#x3D; resetTimestamp .exec( http(&quot;userLables&quot;) .get(&quot;&#x2F;api&#x2F;external&#x2F;user&#x2F;labels&quot;) .header(&quot;sc-apikey&quot;, APIKEY) .header(&quot;sc-timestamp&quot;, &quot;$&#123;timestamp&#125;&quot;) .header(&quot;sc-api-token&quot;, session &#x3D;&gt; computeToken(&quot;get&quot;, session(&quot;timestamp&quot;), &quot;&#x2F;api&#x2F;external&#x2F;user&#x2F;labels&quot;, &quot;externalId&#x3D;&quot; + session(&quot;externalId&quot;).as[String]) ) .queryParam(&quot;externalId&quot;, &quot;$&#123;externalId&#125;&quot;) .check(status.is(200)) ) 先来看看resetTimestamp做了什么工作， 1def resetTimestamp &#x3D; exec(session &#x3D;&gt; session.map(_.set(&quot;timestamp&quot;, System.currentTimeMillis().toString))) 因为是对REST风格的一个API作压力测试，而API接入文档要求每次接入时都需要根据sharedSecret、http method、api path、timestamp、query string做一个Hash，再将生成的token存入http header。 而这段代码的意思就是当前时间戳存到Gatling Session中，这样在每次exec调用前都重置下Session中的timestamp变量，可以更好的模拟真实的API调用环境。 $&#123;timestamp&#125;这样的语法是Gatling提供的EL，见：http://gatling.io/docs/2.1.7/session/expression_el.html。使用字符串插值的方式可以方便的获取到Gatling Session里保存的变量，包括用feed导入的用户数据。 再看userLabels这个方法，这里有特色的一部分是对sc-api-token的设置。对于一个基于REST风格的API，在每次请求时都进行访问校验是一种常用方式，而这个sc-api-token的计算就由computeToken函数来完成。computeToken函数定义如下： 123def computeToken(method: String, timestamp: SessionAttribute, apiPath: String, queryString: String &#x3D; &quot;&quot;) &#x3D; &#123; Utils.hexSha256(method.toLowerCase + SHARED_SECRET + timestamp.as[String] + apiPath + queryString)&#125; 但是在这里，我们不能直接把&quot;$&#123;timestamp&#125;&quot;和&quot;externalId=$&#123;externalId&#125;&quot;当作字符串参数传给computeToken函数，因为computeToken函数的执行并不在Gatling Session的执行上下文中。我们必需在调用computeToken函数之前就获取到Gatling Session中值。 header方法的第二个参数是value: Expression[String]，跟踪代码可以看到，Expression的定义是：type Expression[T] = Session =&gt; Validation[T]。所以之前的一接传入一个字符串其实是由scala的隐式转换功能将其转换成了下人Expression[String]的类型（Scala implicit）。 这里就传入一个Session =&gt; String匿名函数，通过session.apply(key)方法得到一个SessionAttribute，这样就可以获取到Gatling Session里的变量了。而.as[String]方法是获取SessionAttribute变量的值，并取出为String类型。 setUp 使用setUp函数装载写好的测试剧本scenario，并设置请求用户数（并发数）。.protocols设置之前定义的http protocol。 123setUp( helloscalaSDKApiScenario.inject(atOnceUsers(userSize))).protocols(httpConf) 执行测试在sbt控制台里使用test命令执行所有测试脚本，也可以使用testOnly package.Simulation来指定执行某一个脚本。 生成的测试HTML报告将存放在target/galing目录。 ================================================================================ ---- Global Information -------------------------------------------------------- &gt; request count 30 (OK=20 KO=10 ) &gt; min response time 11 (OK=11 KO=12 ) &gt; max response time 61 (OK=61 KO=19 ) &gt; mean response time 20 (OK=23 KO=15 ) &gt; std deviation 12 (OK=14 KO=2 ) &gt; response time 50th percentile 15 (OK=18 KO=14 ) &gt; response time 75th percentile 22 (OK=27 KO=16 ) &gt; mean requests/sec 77.72 (OK=51.813 KO=25.907) ---- Response Time Distribution ------------------------------------------------ &gt; t &lt; 800 ms 20 ( 67%) &gt; 800 ms &lt; t &lt; 1200 ms 0 ( 0%) &gt; t &gt; 1200 ms 0 ( 0%) &gt; failed 10 ( 33%) ---- Errors -------------------------------------------------------------------- &gt; status.find.is(200), but actually found 404 10 (100.0%) ================================================================================ Reports generated in 0s. Please open the following file: /Users/jingyang/workspace/pressure-suite/target/gatling/cloudsimulation-1438759192370/index.html [info] Simulation CloudSimulation successful. [info] Simulation(s) execution ended. [success] Total time: 30 s, completed 2015-8-5 15:19:53 测试结果就不截图了，有兴趣的朋友可以下载源码，并自行修改后运行查看。 总结Gatling是一个强大、易用、可扩展的性能测试利器。现在支持对http、https、jms、sse等多种协议的支持。Gatling使用Async Http Client和Netty提供非阻塞的HTTP。用Akka管理Action（请求、暂停、断言等），以及建模和测试流程。","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"gatling","slug":"gatling","permalink":"https://yangbajing.github.io/tags/gatling/"}]},{"title":"Play2 + ReactiveMongo 实现一个活动报名应用","slug":"Play2 + ReactiveMongo 实现一个活动报名应用","date":"2015-07-29T12:17:26.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/07/29/Play2 + ReactiveMongo 实现一个活动报名应用/","link":"","permalink":"https://yangbajing.github.io/2015/07/29/Play2%20+%20ReactiveMongo%20%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%B4%BB%E5%8A%A8%E6%8A%A5%E5%90%8D%E5%BA%94%E7%94%A8/","excerpt":"","text":"Play 2: https://playframework.com ReactiveMongo: http://reactivemongo.org 代码在： http://git.oschina.net/socialcredits/social-credits-activity-service .pro_name a{color: #4183c4;} .osc_git_title{background-color: #d8e5f1;} .osc_git_box{background-color: #fafafa;} .osc_git_box{border-color: #ddd;} .osc_git_info{color: #666;} .osc_git_main a{color: #4183c4;} 公司要做一些活动，需要一个线上的活动报名应用。想着前几天刚好看了下 ReactiveMongo ，觉得这个小应用正好练练手。 这个活动应用的功能非常简单：用户在线填写表单，提交表单，后台存储数据并向指定的专员发送邮箱通知。 Play 项目整个项目目录结构如下： 1234567891011121314151617181920├── app│ ├── controllers│ │ └── inapi│ ├── utils│ └── views│ └── activity├── conf├── data│ └── src│ └── main├── platform│ └── src│ └── main├── project├── static│ └── src│ └── site└── util └── src ├── main app、conf都是 Play 的标准目录，分别放置代码文件和项目配置文件。app.views 包下的是Play的模板页面文件。 static 是用于放置前端源文件的，包括：js、sass等，使用gulp编译，并输入到 public 目录。 platform 目录放置一些业务代码，比如：Service。 data 目录是数据相关类的存放地，包括model、domain和数据库访问代码，一此数据类相关的隐式转换代码也放置在此。 util 就是工具库了，包括常量定义、配置文件读取、枚举等。 ReactiveMongoconnection mongo collection使用 ReactiveMongo 连接数据库需要先创建一个 MongoDrvier ，并调用 driver.connection 方法创建连接，进而通过 conn.db 方法获取一个数据库访问。 MyDriver.scala 1234567891011class MyDriver private() &#123; val driver = new MongoDriver() def connection = driver.connection(List(Settings.mongo.host)) private def db(implicit ex: ExecutionContext) = connection.db(Settings.mongo.dbName) def collActivity(implicit ex: ExecutionContext) = db.collection[BSONCollection](&quot;activity&quot;) def collActivityRegistration(implicit ex: ExecutionContext) = db.collection[BSONCollection](&quot;activityRegistration&quot;)&#125; case class 与 BSON的转换。使用 Macros.handler 是最简单的实现 case class 与 BSON 转换的方法，它用到了 scala macro。代码如：implicit val __activityHandler = Macros.handler[Activity] BSONImplicits 123456789implicit object LocalDateTimeHandler extends BSONHandler[BSONDateTime, LocalDateTime] &#123; override def read(bson: BSONDateTime): LocalDateTime = LocalDateTime.ofInstant(Instant.ofEpochMilli(bson.value), ZoneOffset.ofHours(8)) override def write(t: LocalDateTime): BSONDateTime = BSONDateTime(t.toInstant(ZoneOffset.ofHours(8)).toEpochMilli)&#125;implicit val __activityHandler = Macros.handler[Activity] 数据库访问查找一个Activity使用 find() 方法获取一个访问数据库游标，再在游标上调用 .one[Activity] 方法即可获取一个 Activity 对象，以 Option[Activity] ActivityRepo 123def findOneById(id: BSONObjectID): Future[Option[Activity]] = &#123; activityColl.find(BSONDocument(&quot;_id&quot; -&gt; id)).one[Activity]&#125; 发送邮件邮箱发送使用了 commons-email ，发送邮件的代码非常简单。 EmailService。 123456789101112131415161718192021222324252627282930313233@Singletonclass EmailService &#123; private val emailSenderActor = Akka.system.actorOf(Props[EmailServiceActor], &quot;email-sender&quot;) def sendEmail(id: String, subject: String, content: String): Unit = &#123; emailSenderActor ! SendEmail(id, subject, content) &#125;&#125;class EmailServiceActor extends Actor with StrictLogging &#123; override def receive: Receive = &#123; case SendEmail(id, subject, content) =&gt; val email = new SimpleEmail() email.setHostName(Settings.email.hostName) email.setSmtpPort(Settings.email.portSsl) email.setSSLOnConnect(true) email.setAuthenticator(new DefaultAuthenticator(Settings.email.username, Settings.email.password)) email.setFrom(Settings.email.from) email.setSubject(subject) email.setMsg(content) email.addTo(Settings.email.to: _*) logger.info( s&quot;&quot;&quot;id: $id |from: $&#123;Settings.email.from&#125; |to: $&#123;Settings.email.to&#125; |$subject |$content&quot;&quot;&quot;.stripMargin) val result = email.send() logger.info( s&quot;&quot;&quot;id: $id |[result] $result&quot;&quot;&quot;.stripMargin) &#125;&#125; 程序中使用了一个 Actor 来对邮件发送动作做队列化处理，感觉有点小题大作。不过 Actor 默认邮箱是FIFO的，这个特性很适合发送邮件的队列操作。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"playframework","slug":"playframework","permalink":"https://yangbajing.github.io/tags/playframework/"},{"name":"reactivemongo","slug":"reactivemongo","permalink":"https://yangbajing.github.io/tags/reactivemongo/"},{"name":"活动报名","slug":"活动报名","permalink":"https://yangbajing.github.io/tags/%E6%B4%BB%E5%8A%A8%E6%8A%A5%E5%90%8D/"}]},{"title":"Learn Spark - 安装","slug":"Learn Spark - 安装","date":"2015-07-27T16:23:23.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/07/28/Learn Spark - 安装/","link":"","permalink":"https://yangbajing.github.io/2015/07/28/Learn%20Spark%20-%20%E5%AE%89%E8%A3%85/","excerpt":"","text":"安装下载 Spark 1.4.1 1wget -c http:&#x2F;&#x2F;www.interior-dsgn.com&#x2F;apache&#x2F;spark&#x2F;spark-1.4.1&#x2F;spark-1.4.1.tgz 编译Spark，使用 scala 2.11 12.&#x2F;dev&#x2F;change-version-to-2.11.shmvn -Dscala-2.11 -DskipTests clean package 运行 spark-shell 12345678910111213141516.&#x2F;bin&#x2F;spark-shell15&#x2F;07&#x2F;23 17:18:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableWelcome to ____ __ &#x2F; __&#x2F;__ ___ _____&#x2F; &#x2F;__ _\\ \\&#x2F; _ \\&#x2F; _ &#96;&#x2F; __&#x2F; &#39;_&#x2F; &#x2F;___&#x2F; .__&#x2F;\\_,_&#x2F;_&#x2F; &#x2F;_&#x2F;\\_\\ version 1.4.1 &#x2F;_&#x2F; Using Scala version 2.11.6 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_40)Type in expressions to have them evaluated.Type :help for more information.Spark context available as sc.SQL context available as sqlContext.scala&gt; 看到以上信息就代表 Spark 已经安装好了。 简单的配置修改 $SPARK_HOME/conf/spark-env.conf 设置如下参数： 123456export JAVA_HOME&#x3D;&quot;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_40.jdk&#x2F;Contents&#x2F;Home&quot;export SPARK_SCALA_VERSION&#x3D;&quot;2.11&quot;export SPARK_MASTER_IP&#x3D;&quot;192.168.1.102&quot;export SPARK_LOCAL_IP&#x3D;&quot;192.168.1.102&quot;export SPARK_WORKER_MEMORY&#x3D;&quot;2G&quot;export SPARK_WORKER_CORE&#x3D;&quot;2&quot; 因为编译的是 scala 2.11 版本，所以应在配置文件里指定 Spark 以scala 2.11进行启动。 接着就可以Standalone模式启动spark了：./sbin/start-all.sh spark-submitSpark 使用 spark-submit 部署执行程序， bin/spark-submit 可以轻松完成 Spark 应用程序在local、Standalone、YARN和Mesos上的快捷部署。我们提交一个最简单的 WorldCount 程序，代码如下： 1234567891011121314151617181920212223package learnspark.introimport org.apache.spark.&#123;SparkContext, SparkConf&#125;object WordCount &#123; def main(args: Array[String]): Unit &#x3D; &#123; println(args.length + &quot; &quot; + args.toList) if (args.length &lt; 2) &#123; println(&quot;run params: inputfile outputfile&quot;) System.exit(1) &#125; val inputFile &#x3D; args(0) val outputFile &#x3D; args(1) val conf &#x3D; new SparkConf().setAppName(&quot;wordCount&quot;) val sc &#x3D; new SparkContext(conf) val input &#x3D; sc.textFile(inputFile) val words &#x3D; input.flatMap(_.split(&#39; &#39;)) val counts &#x3D; words.map((_, 1)).reduceByKey &#123; case (x, y) &#x3D;&gt; x + y &#125; counts.saveAsTextFile(outputFile) &#125;&#125; 使用以下脚本提交程序到 Spark 执行： 123456789#!&#x2F;bin&#x2F;shrm -rf &#x2F;tmp&#x2F;wordcount$SPARK_HOME&#x2F;bin&#x2F;spark-submit \\ --class learnspark.intro.WordCount \\ --master &quot;spark:&#x2F;&#x2F;192.168.1.102:7077&quot; \\ target&#x2F;scala-2.11&#x2F;learn-spark_2.11-0.0.1.jar \\ $SPARK_HOME&#x2F;README.md &#x2F;tmp&#x2F;wordcount –class 指定要运行的class –master 程序要运行的master target/… 程序提交的jar包 inputAttr [outputAttr …] 程序执行参数","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"spark","slug":"bigdata/spark","permalink":"https://yangbajing.github.io/categories/bigdata/spark/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"spark","slug":"spark","permalink":"https://yangbajing.github.io/tags/spark/"}]},{"title":"使用 Jenkins","slug":"使用Jenkins","date":"2015-07-21T02:57:23.000Z","updated":"2022-02-16T02:50:45.195Z","comments":true,"path":"2015/07/21/使用Jenkins/","link":"","permalink":"https://yangbajing.github.io/2015/07/21/%E4%BD%BF%E7%94%A8Jenkins/","excerpt":"","text":"本文简单的记录的 Jenkins 的安装、配置和一些插件的使用。 git: Git Plugin maven: Maven Project Plugin sbt: sbt plugin Install到 https://jenkins-ci.org/ 下载最新版，放到 tomcat/webapp 启动即可。安装非常的简单。 访问 http://localhost:8080/jenkins 目录，对 jenkins 做一些配置后才能更好的使用。 Configuration系统管理 -&gt; 插件管理 -&gt; 可选插件 : 搜索安装 git-plugin 和 sbt-plugin 插件， maven 插件 Jenkins 自带。 系统管理 -&gt; 配置 : 这里我们需要设置的地方有几个： JDK JDK别名: jdk8 JAVA_HOME: /usr/lib/jvm/java-8-oracle GIT Name: git1.9 Path to Git executable: /usr/bin/git （去掉 自动安装 勾选） Maven Maven Name: maven3.3 MAVEN_HOME: /usr/app/maven-3.3 （去掉 自动安装 勾选） Sbt Sbt name: 0.13.8 sbt launch jar: sbt launch jar （去掉 自动安装 勾选） 可选配置 根据自己的邮箱服务器配置可以设置下 Jenkins 的邮件通知功能。 Create Jobmaven项目新建 -&gt; 构建一个自由风格的软件项目 设置下项目的 Item名称 ，确定后就可在首页看见自己的项目列表了。 新建 job 后，需要对 job 本身做一些配置。我们都使用 git 进行源码管理，第一步既是将git代码库导入 job。 源码管理 -&gt; Git Repository URL: https://github.com/yangbajing/play-seed Credentials: 点击 Add 按钮，选择 Kind 为 Username with password，按要求设置用户名和密码 构建触发器 Poll SCM: 日程表: H * * * * （每小时更新 poll 一次代码库） 构建 点击 增加构建步骤，选择 Invoke top-level Maven targets， 在Goals中设置相应的构建目标，如： install 最后点击 应用，保存我们的配置后。 Jenkins 就可以自动进行构建工作了。 sbt项目对于 sbt项目 基本配置和 maven项目 都是一至的，区别在于 增加构建步骤，需要选择 Build using sbt。 Summary简单的 Jenkins 配置， Jenkins 除了对代码进行自动构建外，还可行实现很多其它的功能。 开源免费 跨平台，支持所有的平台 Master/Slave支持分布式的build web形式的可视化的管理页面 安装配置超级简单 tips及时快速的帮助 丰富的插件","categories":[{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://yangbajing.github.io/tags/jenkins/"},{"name":"git","slug":"git","permalink":"https://yangbajing.github.io/tags/git/"},{"name":"maven","slug":"maven","permalink":"https://yangbajing.github.io/tags/maven/"},{"name":"sbt","slug":"sbt","permalink":"https://yangbajing.github.io/tags/sbt/"}]},{"title":"Play 2 示例（种子）项目","slug":"Play2示例（种子）项目","date":"2015-07-17T11:59:30.000Z","updated":"2015-07-18T00:32:51.000Z","comments":true,"path":"2015/07/17/Play2示例（种子）项目/","link":"","permalink":"https://yangbajing.github.io/2015/07/17/Play2%E7%A4%BA%E4%BE%8B%EF%BC%88%E7%A7%8D%E5%AD%90%EF%BC%89%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"项目地址：https://github.com/yangbajing/play-seed play 2 slick 3 slick-pg 0.9 scalatest 2 gulp redis postgresql 9.4 实现了简单的用户认证和session控制功能。采用redis来保存session值。自定义play action和play filter来判断session有效性和重设session。session使用cookie实现。 数据库层，使用slick和slick-pg来连接PostgreSQL。由typesafe config来定义连接参数。ps-util/src/main/resources/reference.conf。 定义play监听端口：PlayKeys.playDefaultPort := 58082。 修改相关配置后，执行如下命令生成数据库实例： 12.&#x2F;sbt[playSeed] $ testOnly me.yangbajing.ps.data.record.SchemasTest 前端代码使用gulp管理，代码放在static目录。编译后的静态文件将保存在public 12npm installnpm run build 访问：http://localhost:58082/account/signup注册账号","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"playframework","slug":"playframework","permalink":"https://yangbajing.github.io/tags/playframework/"}]},{"title":"REST服务下设计AccessToken","slug":"REST服务下设计AccessToken","date":"2015-07-12T02:25:41.000Z","updated":"2015-07-13T09:23:43.000Z","comments":true,"path":"2015/07/12/REST服务下设计AccessToken/","link":"","permalink":"https://yangbajing.github.io/2015/07/12/REST%E6%9C%8D%E5%8A%A1%E4%B8%8B%E8%AE%BE%E8%AE%A1AccessToken/","excerpt":"","text":"REST: https://zh.wikipedia.org/zh/REST Play2: http://playframework.com/ Redis: http://redis.io/ Access Token: https://en.wikipedia.org/wiki/Access_token 最近要设计一套API以提供给接入商使用（以下简称corp），正好可使用Play2对REST天然良好的支持。但是在AccessToken的设计时费了下精力。参考了一些网上的设计，大同小异。最后参考了微信公众号的AccesToken设计方案，方案见：http://mp.weixin.qq.com/wiki/11/0e4b294685f817b95cbed85ba5e82b8f.html。 我的方案 客户端调用/api/token接口，传入client_id, client_secret请求参数以生成Access Token，调用成功将返回JSON，包含两个参数：access_token，expires_in。 每次HTTP请求，客户端都应在请求参数上附加access_token参数 在Play Action中对access_token进行校验 因为使用Play2开发REST服务，对于Access Token的校验自然就想到了使用自定义Action来实现。在自定义Action中，对每次请求参数中的access_token将进行有效性校验，校验失败会返回错误。自定义Action代码如下： 12345678910111213141516171819case class ClientTokenRequest[A](clientToken: ClientAccessTokenInfo, request: Request[A]) extends WrappedRequest[A](request)object ClientAction extends ActionBuilder[ClientTokenRequest] with ActionTransformer[Request, ClientTokenRequest] &#123; override protected def transform[A](request: Request[A]): Future[ClientTokenRequest[A]] = &#123; request.getQueryString(&quot;access_token&quot;) match &#123; case Some(at) =&gt; ApiClientTokenService().getTokenInfoByAccessToken(at) match &#123; case Some(token) =&gt; Future.successful(new ClientTokenRequest(token, request)) case None =&gt; throw FjUnauthorizedException(&quot;access token invalid&quot;) &#125; case None =&gt; throw FjUnauthorizedException(&quot;access token not exists&quot;) &#125; &#125;&#125; 在ApiClientTOkenService().getTokenInfoByAccessToken()方法中，根据在url上的access_token参数在redis中查找相应键值。代码示例如下： 12345678redisClients.withClient &#123; client =&gt; client.get(Commons.API_CLIENT_TOKEN_REDIS_KEY_PREFIX + accessToken).flatMap(s =&gt; s.split(&#x27;\\n&#x27;) match &#123; case Array(corpId, clientId) =&gt; Some(ClientAccessTokenInfo(accessToken, corpId, clientId)) case _ =&gt; None &#125;)&#125; 对于AccessToken超期的设计，可以使用redis提供的EXPIRE功能（http://redis.io/commands/expire）。使用`scala-redis`库，它封装好了在scala下访问redis的各种API。在`set`方法中可以设置键的超时值。 1234567891011def createClientTokenInfo(corp: Corporation) = &#123; val token = ApiClientTokenService.generateToken(corp) redisClients.withClient &#123; client =&gt; client.set( Commons.API_CLIENT_TOKEN_REDIS_KEY_PREFIX + token.accessToken, corp.id + &#x27;\\n&#x27; + corp.client_id, false, Seconds(Settings.server.clientTokenTimeout.getSeconds + 10)) &#125; token&#125; 使用redis来保存Access Token有诸多好处： 简单、快捷，不需要自己设计超期、并发等功能。简化代码 无状态，便于系统横向扩展","categories":[],"tags":[{"name":"rest","slug":"rest","permalink":"https://yangbajing.github.io/tags/rest/"},{"name":"playframework","slug":"playframework","permalink":"https://yangbajing.github.io/tags/playframework/"},{"name":"redis","slug":"redis","permalink":"https://yangbajing.github.io/tags/redis/"},{"name":"accesstoken","slug":"accesstoken","permalink":"https://yangbajing.github.io/tags/accesstoken/"}]},{"title":"Scala技巧","slug":"Scala技巧","date":"2015-04-10T05:46:09.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2015/04/10/Scala技巧/","link":"","permalink":"https://yangbajing.github.io/2015/04/10/Scala%E6%8A%80%E5%B7%A7/","excerpt":"","text":"记录使用Scala开过程中的一些小技巧和陷阱 Future 不要在Future上使用filter方法。","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"}]},{"title":"Mac 10.8 下安装Sphinx并支持生成中文PDF","slug":"Mac 10.8 下安装Sphinx并支持生成中文PDF","date":"2014-12-12T09:33:54.000Z","updated":"2015-04-10T05:46:09.000Z","comments":true,"path":"2014/12/12/Mac 10.8 下安装Sphinx并支持生成中文PDF/","link":"","permalink":"https://yangbajing.github.io/2014/12/12/Mac%2010.8%20%E4%B8%8B%E5%AE%89%E8%A3%85Sphinx%E5%B9%B6%E6%94%AF%E6%8C%81%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87PDF/","excerpt":"","text":"最近一直在用Sphinx撰写文档，但是生成中文PDF时老是失败。今天在网上查了些资料，终于把它弄成功了。现记录如下。 需要用到的软件有： python 2.7 Sphinx 1.2 MacTex 2013 安装Sphinx$ sudo easy_install-2.7 Sphinx 安装MacTex请到 http://www.tug.org/mactex/ 下载，或 点此 下载。安装过程就略了。 让Sphinx latex支持中文首先使用 sphinx-quickstart 生成Sphinx项目。然后修改 conf.py 文件。将如下段： latex_elements = &#123; # The paper size (&#39;letterpaper&#39; or &#39;a4paper&#39;). #&#39;papersize&#39;: &#39;letterpaper&#39;, # The font size (&#39;10pt&#39;, &#39;11pt&#39; or &#39;12pt&#39;). #&#39;pointsize&#39;: &#39;10pt&#39;, # Additional stuff for the LaTeX preamble. #&#39;preamble&#39;: &#39;&#39;, &#125; 替换成： latex_elements = &#123; # The paper size (&#39;letterpaper&#39; or &#39;a4paper&#39;). &#39;papersize&#39;: &#39;a4paper&#39;, # The font size (&#39;10pt&#39;, &#39;11pt&#39; or &#39;12pt&#39;). #&#39;pointsize&#39;: &#39;12pt&#39;, &#39;classoptions&#39;: &#39;,english&#39;, &#39;inputenc&#39;: &#39;&#39;, &#39;utf8extra&#39;: &#39;&#39;, # Additional stuff for the LaTeX preamble. &#39;preamble&#39;: &#39;&#39;&#39; \\usepackage&#123;xeCJK&#125; \\usepackage&#123;indentfirst&#125; \\setlength&#123;\\parindent&#125;&#123;2em&#125; \\setCJKmainfont[BoldFont=SimHei, ItalicFont=STKaiti]&#123;SimSun&#125; \\setCJKmonofont[Scale=0.9]&#123;Consolas&#125; \\setCJKfamilyfont&#123;song&#125;[BoldFont=SimSun]&#123;SimSun&#125; \\setCJKfamilyfont&#123;sf&#125;[BoldFont=SimSun]&#123;SimSun&#125; &#39;&#39;&#39; &#125; 这些配置的具体含意我也不大清楚，不过自已修改下字体还是可行的。你可以使用 fc-list :lang=zh-cn 查看系统所中文字体名字。Mac默认没有此 fc-list 程序，可以使用brew安装。 $ brew install fontconfig 生成PDF首先你需要在Sphinx项目目录执行 make latex 命令生成latex，再使用 xelatex *.tex 生成PDF文件。具体步骤如下： $ make latex $ cd build/latex $ xelatex *.tex $ open *.pdf 结束好了，现在享受Sphinx撰写文档的愉快心情吧！","categories":[{"name":"unix/linux","slug":"unix-linux","permalink":"https://yangbajing.github.io/categories/unix-linux/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://yangbajing.github.io/tags/mac/"},{"name":"sphinx-doc","slug":"sphinx-doc","permalink":"https://yangbajing.github.io/tags/sphinx-doc/"},{"name":"pdf","slug":"pdf","permalink":"https://yangbajing.github.io/tags/pdf/"}]},{"title":"Scala小题目：001","slug":"Scala小题目：001","date":"2013-09-05T10:31:15.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2013/09/05/Scala小题目：001/","link":"","permalink":"https://yangbajing.github.io/2013/09/05/Scala%E5%B0%8F%E9%A2%98%E7%9B%AE%EF%BC%9A001/","excerpt":"","text":"练手题 题目def strtr(src:String, from:String, to:String):String from 和 to是等长的字符串, 要求将src中值为from(i)的字符转换成to(i)例如: strtr(“abcdaf”, “ac”, “AC”) == “AbCdAf” 先来个Java风格版的代码：def java1(src: String, from: String, to: String): String = &#123; val buffer = new StringBuffer() val srcj = src.toVector val fromj = from.toVector val toj = to.toVector var i = 0; while (i &lt; srcj.size) &#123; var c = srcj(i) var j = 0 while (j &lt; fromj.size) &#123; if (srcj(i) == fromj(j)) &#123; c = toj(j) //break &#125; j += 1 &#125; buffer append c i += 1 &#125; buffer.toString &#125; 这段代码的主要意思就是：先把src, from, to三个字符串转换成三个序列，如：Vector。先迭代srcj，再将srcj(i)与from进行迭代比较。再将匹配的字符赋给buffer。 哎，这个风格的代码太繁琐了，我不想再仔细分析下去了，大伙就凑合着看看吧。 Scala风格版(1)def scala1(src: String, from: String, to: String): String = &#123; val mat = from zip to src.map(s =&gt; mat.find(_._1 == s).map(_._2).getOrElse(s)) &#125; 这代码TM的一看就清爽多了，不解释！ Scala风格版(2)def scala2(src: String, from: String, to: String): String = &#123; val mat = (from zip to).toMap src.map(s =&gt; mat.getOrElse(s, s)) &#125; 嗯，这版更清爽。来，说说呗！(from zip to) 这句代码的意思是把from和zip两字符串合并成一个一一对应的IndexSeq，比如：from = “abc”, to = “XYZ”，那mat = IndexSeq((‘a’, ‘X’), (‘b’, ‘Y’), (‘c’, ‘Z’))。这后那个toMap就一目了然了。s =&gt; mat.getOrElse(s, s) 这函数的意思是有一个参数s，类型是Char，在mat中查找key为s的value，若key不存在则返回默认值s（就是getOrElse方法的第二个参数）。src.map(fcuntion)方法的意思就是对src这个字符串进行迭代，并对每次迭代的元素应用function这个函数进行计算并回返计算后的值。 总结好了，一个简单的小问题。发现在使用了scala及函数式编程思维后它的确是一个小问题。但可惜的是在使用java和命令式思维的情况下它不见得会只是一个小问题……","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"}]},{"title":"Mac系统环境变量设置","slug":"Mac系统环境变量设置","date":"2013-05-12T16:41:06.000Z","updated":"2015-04-10T05:46:09.000Z","comments":true,"path":"2013/05/13/Mac系统环境变量设置/","link":"","permalink":"https://yangbajing.github.io/2013/05/13/Mac%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"在Mac系统中，GUI程序并不会像Linux那样继承命令行设置的环境变量。若将在GUI程序中访问自定义环境变量，比如Intellij idea中。需要使用如下命令： $ launchctl setenv XXXXX /tmp/xxx 需要在系统重启和仍然生效，可把设置写入配置文件中/etc/launched.conf： setenv XXXXX /tmp/xxx","categories":[{"name":"unix/linux","slug":"unix-linux","permalink":"https://yangbajing.github.io/categories/unix-linux/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://yangbajing.github.io/tags/mac/"},{"name":"环境变量","slug":"环境变量","permalink":"https://yangbajing.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"}]},{"title":"Option，Either和Try","slug":"Option-Either-Try","date":"2013-02-15T16:49:00.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2013/02/16/Option-Either-Try/","link":"","permalink":"https://yangbajing.github.io/2013/02/16/Option-Either-Try/","excerpt":"","text":"scala数据交互 本文介绍在Scala 2.10中怎样使用一种函数式的方式来处理数据交互，包括入参及返回值。 Option: 解决null（空指针）问题 Either: 解决返回值不确定（返回两个值的其中一个）问题 Try: 解决函数可能会抛出异常问题 OptionAPI：http://www.scala-lang.org/api/2.10.0/index.html#scala.Option 在Java中，当一个操作返回无效值或数据不存在时通常情况下返回返回一个 null 。比如 servlet 中request.getParameter(&quot;id&quot;) ，或id不存在将返回 null 。Map&lt;String, String&gt; 也是，data.get(&quot;dd&quot;) 当Key：dd不存在时也将返回 null 。一句话，在Java的世界，你需要随时小心NullPointerException ！ 现在，我们再来看看Scala中的解决方案：Option。Option实际上有3个类型：Option、Some和None，Some和None都是Option的子类型，Some和None。Option表示可选的值，它的返回类型是 scala.Some或 scala.None 。Some代表返回有效数据，None代表返回空值。最常用的使用方式是把scala.Option当作集合或单子（monad）使用，可以调用它的map、flatMap、filter或foreach方法。这里我们来看看一些例子： scala&gt; val name: Option[String] = Some(&quot; name &quot;) name: Option[String] = Some( name ) scala&gt; val upper = name map &#123; _.trim &#125; filter &#123; _.length != 0 &#125; map &#123; _.toUpperCase &#125; upper: Option[String] = Some(NAME) scala&gt; println(upper getOrElse &quot;-&quot;) NAME scala&gt; upper.get res1: String = NAME 从这个简单的例子可以知道，Option作为变量的类型，而它实际拥有的类型为Some或None。在这里把Some(&quot; name &quot;) 换成 None 再试试： scala&gt; val name: Option[String] = None name: Option[String] = None scala&gt; val upper = name map &#123; _.trim &#125; filter &#123; _.length != 0 &#125; map &#123; _.toUpperCase &#125; upper: Option[String] = None scala&gt; println(upper getOrElse &quot;-&quot;) - scala&gt; upper.get java.util.NoSuchElementException: None.get at scala.None$.get(Option.scala:313) at scala.None$.get(Option.scala:311) 我们可以使用 getOrElse 方法来获取实际的数据，这个方法包含一个参数，当Option为None时将返回传入的参数值。而对于Some，可以直接使用 get 方法获取实际的数据值; None是不可以的。 这里，我们在为Option赋值时显示的使用了Some或None类型，当使用Some时需求我们保证数据有效（不可为null）。其实我们可以使用Option对象来进行赋值： scala&gt; val x: Option[String] = Option(&quot;name&quot;) x: Option[String] = Some(name) scala&gt; val y: Option[String] = Option(null) y: Option[String] = None scala&gt; val x = Option(&quot;name&quot;) x: Option[String] = Some(name) scala&gt; val a = Option(null) a: Option[Null] = None 使用Option的妙处在，使用Servlet时可以如下： val username = Option(request getParameter &quot;username&quot;) val password = Option(request getParameter &quot;password&quot;) val login_? = for ( un &lt;- username; pwd &lt;- password; isLogin &lt;- login(un, pwd)) yield isLogin // login方法登陆验证成功返回true login_? match &#123; case Some(_) =&gt; // 登陆成功 // redirect to ... case None =&gt; // 登陆失败 // 返回错误消息 &#125; 这里，Option.apply 方法在 request.getParameter 返回null时将为 username 赋值为None。因为Option实现了 map, filter, flatMap, foeach及toList 方法，我们可以在for静达式中使用它。 EitherAPI：http://www.scala-lang.org/api/2.10.0/index.html#scala.util.Either 程序设计中经常会有这样的需求，一个函数（或方法）在传入不同参数时会返回不同的值。返回值是两个不相关的类型，分别为： Left 和 Right 。惯例中我们一般认为 Left 包含错误或无效值， Right包含正确或有效值（这个和从小尝到的左、右派分子定义相反啊！） def readfile(): Either[IOException, String] = try &#123; Right(&quot;羊八井好帅 ^_^！&quot;) &#125; catch &#123; case e: IOException =&gt; Left(e) &#125; println(readfile match &#123; case Right(msg) =&gt; msg case Left(e) =&gt; e.getMessage &#125;) 除了使用match case方式来获取数据，我们还可以分别使用 .right.get 和 .left.get 方法，当然你需要使用 .isRight 或 .isLeft 先判断一下。Left或Right类型也有 filter, flatMap, foreach, get, getOrElse, map 方法，它们还有 toOption, toSeq 方法，分别返回一个 Option或 Seq 。 TryAPI：http://www.scala-lang.org/api/2.10.0/index.html#scala.util.Try 在刚才的 readfile 方法里，我们显示使用了 try catch 语法。Scala 2.10提供了 Try 来更优雅的实现这一功能。对于有可能抛出异常的操作。我们可以使用Try来包裹它。 scala&gt; val z: Try[Int] = Try&#123; 27 &#125; z: scala.util.Try[Int] = Success(27) scala&gt; val y: Try[Int] = Try&#123; throw new NullPointerException(&quot;null ...&quot;) &#125; y: scala.util.Try[Int] = Failure(java.lang.NullPointerException: null ...) scala&gt; val x: Try[Int] = Success&#123; 27 &#125; x: scala.util.Try[Int] = Success(27)","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"option","slug":"option","permalink":"https://yangbajing.github.io/tags/option/"},{"name":"either","slug":"either","permalink":"https://yangbajing.github.io/tags/either/"},{"name":"try","slug":"try","permalink":"https://yangbajing.github.io/tags/try/"}]},{"title":"扩展lift CssSelector为使用jQuery CSS Selector形式","slug":"扩展lift CssSelector为使用jQuery CSS Selector 形式","date":"2013-01-06T15:16:58.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2013/01/06/扩展lift CssSelector为使用jQuery CSS Selector 形式/","link":"","permalink":"https://yangbajing.github.io/2013/01/06/%E6%89%A9%E5%B1%95lift%20CssSelector%E4%B8%BA%E4%BD%BF%E7%94%A8jQuery%20CSS%20Selector%20%E5%BD%A2%E5%BC%8F/","excerpt":"","text":"啥也不说了，直接上代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import scala.xml.&#123; Text, NodeSeq &#125;import net.liftweb.http.js.&#123; JsExp, JE &#125;import net.liftweb.util.&#123; CssSel, ComputeTransformRules &#125;import net.liftweb.util.Helpers._object Imports &#123; private val _selRegex = new scala.util.matching.Regex(&quot;&quot;&quot;(\\S)+&quot;&quot;&quot;) private val _selMatch = Set(&#x27;*&#x27;, &#x27;-&#x27;, &#x27;[&#x27;, &#x27;^&#x27;) implicit final class YStringToCssSel(exp: String) &#123; def #&gt;&gt;[T](content: =&gt; T)(implicit computer: ComputeTransformRules[T]): CssSel = &#123; val selects = _selRegex.findAllMatchIn(exp).map(_.matched).toList val (init, last) = if (_selMatch.contains(selects.last.head)) selects.dropRight(2) -&gt; selects.takeRight(2).mkString(&quot; &quot;) else selects.dropRight(1) -&gt; selects.takeRight(1).mkString init.foldRight(last #&gt; content)((s, c) =&gt; s #&gt; c) &#125; &#125; implicit val doubleTransform: ComputeTransformRules[Double] = new ComputeTransformRules[Double] &#123; def computeTransform(str: =&gt; Double, ns: NodeSeq): Seq[NodeSeq] = List(Text(str.toString)) &#125; implicit val shortTransform: ComputeTransformRules[Short] = new ComputeTransformRules[Short] &#123; def computeTransform(str: =&gt; Short, ns: NodeSeq): Seq[NodeSeq] = List(Text(str.toString)) &#125; implicit val byteTransform: ComputeTransformRules[Byte] = new ComputeTransformRules[Byte] &#123; def computeTransform(str: =&gt; Byte, ns: NodeSeq): Seq[NodeSeq] = List(Text(str.toString)) &#125; implicit val charTransform: ComputeTransformRules[Char] = new ComputeTransformRules[Char] &#123; def computeTransform(str: =&gt; Char, ns: NodeSeq): Seq[NodeSeq] = List(Text(str.toString)) &#125; implicit val floatTransform: ComputeTransformRules[Float] = new ComputeTransformRules[Float] &#123; def computeTransform(str: =&gt; Float, ns: NodeSeq): Seq[NodeSeq] = List(Text(str.toString)) &#125;&#125; 还是给个测试吧： (&quot;#id .class span *+&quot; #&gt;&gt; &quot;羊八井！&quot;).apply(&lt;div id=&quot;id&quot;&gt;&lt;a class=&quot;class&quot;&gt;&lt;span&gt;您好，&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;)","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"liftweb","slug":"liftweb","permalink":"https://yangbajing.github.io/tags/liftweb/"},{"name":"jquery","slug":"jquery","permalink":"https://yangbajing.github.io/tags/jquery/"}]},{"title":"在liftweb中扩展一个类似jQuery的方法","slug":"在liftweb 中扩展一个类似 jQuery的方法","date":"2013-01-01T14:10:18.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2013/01/01/在liftweb 中扩展一个类似 jQuery的方法/","link":"","permalink":"https://yangbajing.github.io/2013/01/01/%E5%9C%A8liftweb%20%E4%B8%AD%E6%89%A9%E5%B1%95%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BC%20jQuery%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"","text":"先上代码，文字稍后再补！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344import scala.xml.NodeSeq import net.liftweb.http.js._import net.liftweb.http.js.jquery._ def $(exp: String): jQuery = $(JE.Str(exp)) def $(exp: JsExp): jQuery = jQuery(exp) case class jQuery(exp: JsExp) &#123; val jq = JqJE.Jq(exp) @inline def value(value: JsExp) = (jq ~&gt; JqJE.JqAttr(&quot;value&quot;, value)).cmd @inline def value() = (jq ~&gt; JqJE.JqGetAttr(&quot;value&quot;)).cmd @inline def html(content: NodeSeq) = (jq ~&gt; JqJE.JqHtml(content)).cmd @inline def html() = (jq ~&gt; JqJE.JqHtml()).cmd @inline def remove() = (jq ~&gt; JqJE.JqRemove()).cmd @inline def attr(key: String, value: JsExp) = (jq ~&gt; JqJE.JqAttr(key, value)).cmd @inline def attr(key: String) = (jq ~&gt; JqJE.JqGetAttr(key)).cmd @inline def removeAttr(key: String): JsCmd = (jq ~&gt; JqRemoveAttr(key)).cmd // 更多方法实现 ................................................................ case class JqRemoveAttr(key: String) extends JsExp with JsMember &#123; def toJsCmd = &quot;removeAttr(&quot; + JE.Str(key) + &quot;)&quot; &#125; &#125;","categories":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"}],"tags":[{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"liftweb","slug":"liftweb","permalink":"https://yangbajing.github.io/tags/liftweb/"},{"name":"jquery","slug":"jquery","permalink":"https://yangbajing.github.io/tags/jquery/"}]},{"title":"Qt4中屏蔽粘贴功能","slug":"Qt4中屏蔽粘贴功能","date":"2012-02-06T16:27:00.000Z","updated":"2015-04-10T05:46:09.000Z","comments":true,"path":"2012/02/07/Qt4中屏蔽粘贴功能/","link":"","permalink":"https://yangbajing.github.io/2012/02/07/Qt4%E4%B8%AD%E5%B1%8F%E8%94%BD%E7%B2%98%E8%B4%B4%E5%8A%9F%E8%83%BD/","excerpt":"","text":"在Qt4中实现屏蔽粘贴功能有好几种方法，其中最简单的一种就是把控件属性设为叫读 setReadOnly(true)，但是这样就不能在控件中输入了。我现在想实现的目标是允许用户手动输入文本，但是不允许用户粘贴文本到控件中。 以QLineEdit为例，默认情况下Qt4提供了3种文本粘贴方式： Ctrl+V 鼠标中键 鼠标右键弹出“上下文菜单”，从中选择粘贴功能 其中屏蔽第3种方式最简单，设置控件的上下文菜单策略为Qt::NoContextMenu即可 ui-&gt;lineEdit-&gt;setContextMenuPolicy(Qt::NoContextMenu); 但是这个方式有个问题，设置这个选项后就没有上下文菜单了，包括复制、剪切等都没有，但是我只是想屏蔽“粘贴”功能，其它右键菜单的功能还是应该保留的。其实Qt专门为上下文弹出菜单提供了一个事件处理函数，我们可以继承一个QLineEdit，重写它的contextMenuEvent(QContextMenuEvent *event)函数，来实现屏蔽“粘贴”功能，代码如下： void LineEdit::contextMenuEvent(QContextMenuEvent *event) &#123; QString temp = qApp-&gt;clipboard()-&gt;text(); qApp-&gt;clipboard()-&gt;setText(QString()); if (QMenu *menu = createStandardContextMenu()) &#123; menu-&gt;setAttribute(Qt::WA_DeleteOnClose); menu-&gt;popup(event-&gt;globalPos()); &#125; qApp-&gt;clipboard()-&gt;setText(temp); &#125; 这样，在右键弹出的上下文菜单中，先为系统剪切板里的数据作一个备份后清空它，在这个函数的最后再恢复数据。这样，无论系统剪贴板里是否有数据，粘贴功能都是不可用的。其实我们可以模仿默认的createStandardContextMenu()函数来生成自己的右键上下文菜单。 屏蔽Ctrl+V和鼠标中键最好使用事件过滤器来实现，使用事件过滤器的好处是可以为多个控件使用同一个过滤规则，减少编码工作。先直接贴代码吧：主界面中的事件过滤函数： bool Widget::eventFilter(QObject *target, QEvent *event) &#123; if (target == lineEdit) &#123; if (event-&gt;type() == QEvent::KeyPress) &#123; QKeyEvent *keyEvent = static_cast&lt;QKeyEvent *&gt;(event); if (keyEvent-&gt;matches(QKeySequence::Paste)) &#123; // if (keyEvent-&gt;modifiers() == Qt::ControlModifier// &amp;&amp; keyEvent-&gt;key() == Qt::Key_V) { qDebug() &lt;&lt; “Ctrl + V”; return true; } } if (event-&gt;type() == QEvent::MouseButtonRelease) { QMouseEvent *mouseEvent = static_cast&lt;QMouseEvent *&gt;(event); if (mouseEvent-&gt;button() == Qt::MidButton) { qDebug() &lt;&lt; “Mouse MidButton Release”; return true; } } } return QWidget::eventFilter(target, event); } 屏蔽Ctrl+V有两种方式，使用Qt4内置的QKeySequence和自己判断Qt::ControlModifier和V键按下事件，推荐使用QKeySequence::Paste，因为用户可能会更改系统默认的“粘贴”快捷键。比如在Linux系统下，如果不使用QKeySequence而是自己判断Ctrl+V的话还需要判断Shift+Insert（Qt::ShiftModifier和Qt::Key_Insert）两个键。经过测试鼠标中健的粘贴功能是在鼠标释放时实现的，所有只要在捕获到鼠标中键的MouseButtonRelease事件直接返回true就可以屏蔽掉默认的粘贴功能了。在主界面Widget的构造函数中为ui-&gt;lineEdit加入事件过滤器： lineEdit-&gt;installEventFilter(this); 结尾：相关的QTextEdit等输入控件都可以使用相似的方法来实现屏蔽粘贴功能。","categories":[{"name":"c/c++","slug":"c-c","permalink":"https://yangbajing.github.io/categories/c-c/"}],"tags":[{"name":"c","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"qt","slug":"qt","permalink":"https://yangbajing.github.io/tags/qt/"}]},{"title":"《Unix网络编程（第3版）》代码编译的一些问题","slug":"《Unix网络编程（第3版）》代码编译的一些问题","date":"2012-02-04T09:56:58.000Z","updated":"2015-04-10T05:46:09.000Z","comments":true,"path":"2012/02/04/《Unix网络编程（第3版）》代码编译的一些问题/","link":"","permalink":"https://yangbajing.github.io/2012/02/04/%E3%80%8AUnix%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%EF%BC%88%E7%AC%AC3%E7%89%88%EF%BC%89%E3%80%8B%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","excerpt":"","text":"现在学习《UNIX网络编程（第3版）》一书，书中源代码有一些默认情况下编译不能通过，要经过一些修改都行。这编文档将记录下我遇到的不能正常编译的程序的修改步骤。 28章：traceroute程序： $ make gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o icmpcode_v6.o icmpcode_v6.c icmpcode_v6.c: In function ‘icmpcode_v6’: icmpcode_v6.c:13: error: ‘ICMP6_DST_UNREACH_NOTNEIGHBOR’ undeclared (first use in this function) icmpcode_v6.c:13: error: (Each undeclared identifier is reported only once icmpcode_v6.c:13: error: for each function it appears in.) make: *** [icmpcode_v6.o] Error 1 在网上查了半天都没有找到ICMP6_DST_UNREACH_NOTNEIGHBOR的信息，直接把icmpcode_v6中相关的13~14行注释好了。 $ make gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o main.o main.c gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o icmpcode_v4.o icmpcode_v4.c gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o icmpcode_v6.o icmpcode_v6.c gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o recv_v4.o recv_v4.c recv_v4.c: In function ‘recv_v4’: recv_v4.c:55: error: ‘struct udphdr’ has no member named ‘uh_sport’ recv_v4.c:56: error: ‘struct udphdr’ has no member named ‘uh_dport’ recv_v4.c:72: error: ‘struct udphdr’ has no member named ‘uh_sport’ recv_v4.c:73: error: ‘struct udphdr’ has no member named ‘uh_dport’ make: *** [recv_v4.o] Error 1 提示udphdr结构没有uh_[sd]port成员，解决方法是在trace.h文件中增加#define __FAVOR_BSD声明。注意要加在4个netinet头文件之前，unp.h头文件之后。就像这样： #include &quot;unp.h&quot; #define __FAVOR_BSD #include &lt;netinet/in_systm.h&gt;","categories":[{"name":"unix/linux","slug":"unix-linux","permalink":"https://yangbajing.github.io/categories/unix-linux/"}],"tags":[{"name":"c","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"unix","slug":"unix","permalink":"https://yangbajing.github.io/tags/unix/"},{"name":"network","slug":"network","permalink":"https://yangbajing.github.io/tags/network/"}]},{"title":"Linux下安装Postgresql-9.0.x提示：Cannot read termcap databass","slug":"Linux下安装Postgresql-9.0.x提示：Cannot read termcap database","date":"2011-10-11T16:10:18.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2011/10/12/Linux下安装Postgresql-9.0.x提示：Cannot read termcap database/","link":"","permalink":"https://yangbajing.github.io/2011/10/12/Linux%E4%B8%8B%E5%AE%89%E8%A3%85Postgresql-9.0.x%E6%8F%90%E7%A4%BA%EF%BC%9ACannot%20read%20termcap%20database/","excerpt":"","text":"使用在postgresql.org下载的x86_64二进制版的postgres 9.0.3安装包，解压到了/opt/pgsql。使用initdb命令初始化数据库后向往常一样使用psql命令登陆数据库，提示找不到termcap等一些动态库，把/opt/pgsql/lib目录加入LD_LIBRARY_PATH环境变量就好了。 再次使用psql登陆数据库，却提示如下错误： [yangjing@yangxunjing ~]$ /opt/Netposa/usr/pgsql/9.0/bin/psql -p 5433 -U yangjing -d netposa psql (9.0.3) Type &quot;help&quot; for help. Cannot read termcap database; using dumb terminal settings. Aborted google查找后说是缺少termcap库，但是在/opt/pgsql/lib目录下是有这个库的：libtermcap.so.2，我给它做了个软链接libtermcap.so后再次运行psql命令错误依旧。后来安装了系统自带的compat-libtermcap-2.0.8-49.el6.x86_64软件包后就可以正常运行psql命令登陆数据库了。发现termcap包在/etc目录下生成了一个termcap数据库文件。我把/etc/termcap文件备份后删除compat-libtermcap软件包，再把termcap文件拷贝回/etc目录再次运行psql命令也能正常登陆postgresql数据库。看来我只需要把termcap文件留个备份就好了，以后再次使用官方的二进包安装时将其放到/etc目录就行了。 （注：使用rpm包安装的不需要termcap数据文件，看了下psql的库依赖都没有使用到libtermcap.so。不知道官方的二进制包为什么需要这个库。现在大部份软件都是使用的ncurses了。）","categories":[{"name":"unix/linux","slug":"unix-linux","permalink":"https://yangbajing.github.io/categories/unix-linux/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://yangbajing.github.io/tags/postgresql/"},{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"}]},{"title":"C语言连接MySQL中文字符集问题","slug":"c语言连接mysql中文字符集问题","date":"2011-09-18T12:36:58.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2011/09/18/c语言连接mysql中文字符集问题/","link":"","permalink":"https://yangbajing.github.io/2011/09/18/c%E8%AF%AD%E8%A8%80%E8%BF%9E%E6%8E%A5mysql%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6%E9%9B%86%E9%97%AE%E9%A2%98/","excerpt":"","text":"在学习《Linux程序设计》第8章MySQL数据库8.3节： 使用C语言访问MySQL访问数据库时尝试把SQL数据换成了中文，但是在运行示例程序时终端输出却乱码，MySQL C 语言连接默认字符集是latin1，查了下API找到如下函数可解决中文乱码问题。 1int mysql_set_character_set(MYSQL *mysql, char *csname) 描述: 该函数用于为当前连接设置默认的字符集。字符串csname指定了1个有效的字符集名称。连接校对成为字符集的默认校对。该函数的工作方式与SET NAMES语句类似，但它还能设置mysql-&gt;charset的值，从而影响了由mysql_real_escape_string()设置的字符集。该函数是在MySQL 5.0.7中增加的。返回值0表示成功，非0值表示出现错误。 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &quot;mysql.h&quot;MYSQL my_connection;MYSQL_RES *res_ptr;MYSQL_ROW sqlrow;void display_row();int main(int argc, char *argv[])&#123; int res; mysql_init(&amp;my_connection); if (mysql_real_connect(&amp;my_connection, &quot;localhost&quot;, &quot;rick&quot;, &quot;secret&quot;, &quot;foo&quot;, 0, NULL, 0)) &#123; &#x2F;* 设置数据库默认字符集 *&#x2F; if (mysql_set_character_set(&amp;my_connection, &quot;utf8&quot;)) &#123; fprintf(stderr, &quot;错误, %s\\n&quot;, mysql_error(&amp;my_connection)); &#125; res &#x3D; mysql_query(&amp;my_connection, &quot;SELECT childno, fname, age FROM children WHERE age &gt; 5&quot;); if (res) &#123; fprintf(stderr, &quot;SELECT error: %s\\n&quot;, mysql_error(&amp;my_connection)); &#125; else &#123; res_ptr &#x3D; mysql_use_result(&amp;my_connection); if (res_ptr) &#123; while ((sqlrow &#x3D; mysql_fetch_row(res_ptr))) &#123; display_row(); &#125; if (mysql_errno(&amp;my_connection)) &#123; fprintf(stderr, &quot;Retrive error: %s\\n&quot;, mysql_error(&amp;my_connection)); &#125; mysql_free_result(res_ptr); &#125; &#125; mysql_close(&amp;my_connection); &#125; else &#123; fprintf(stderr, &quot;Connection failed\\n&quot;); if (mysql_errno(&amp;my_connection)) &#123; fprintf(stderr, &quot;Connection error %d: %s\\n&quot;, mysql_errno(&amp;my_connection), mysql_error(&amp;my_connection)); &#125; &#125; return EXIT_SUCCESS;&#125;void display_row()&#123; unsigned int field_count; field_count &#x3D; 0; while (field_count &lt; mysql_field_count(&amp;my_connection)) &#123; if (sqlrow[field_count]) printf(&quot;%s &quot;, sqlrow[field_count]); else printf(&quot;NULL&quot;); field_count++; &#125; printf(&quot;\\n&quot;);&#125;","categories":[{"name":"c/c++","slug":"c-c","permalink":"https://yangbajing.github.io/categories/c-c/"}],"tags":[{"name":"c","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"mysql","slug":"mysql","permalink":"https://yangbajing.github.io/tags/mysql/"},{"name":"中文字符集","slug":"中文字符集","permalink":"https://yangbajing.github.io/tags/%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6%E9%9B%86/"}]},{"title":"解决Eclipse Access restriction：问题","slug":"解决eclipse-access-restriction：问题","date":"2010-10-29T10:50:18.000Z","updated":"2022-02-16T02:50:45.194Z","comments":true,"path":"2010/10/29/解决eclipse-access-restriction：问题/","link":"","permalink":"https://yangbajing.github.io/2010/10/29/%E8%A7%A3%E5%86%B3eclipse-access-restriction%EF%BC%9A%E9%97%AE%E9%A2%98/","excerpt":"","text":"今天在Linux下用eclipse 3.5开发Jpcap相关的程序，先试试官方的UdpSend.java能否跑起来。結果eclipse给出了如下错误提示： 12 Access restriction: The type JpcapCaptor is not accessible due to restriction on required library &#x2F;media&#x2F;sda7&#x2F;opt&#x2F;jdk1.6.0_16&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;jpcap.jar 其实要解决它也很容易，在Window - Java - Compiler - Errors/Warnings界面的Deprecated and restricted API下。把Forbidden reference (access rules): 的规则由默认的Error改为Warning即可。","categories":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"eclipse","slug":"eclipse","permalink":"https://yangbajing.github.io/tags/eclipse/"}]}],"categories":[{"name":"essay","slug":"essay","permalink":"https://yangbajing.github.io/categories/essay/"},{"name":"bigdata","slug":"bigdata","permalink":"https://yangbajing.github.io/categories/bigdata/"},{"name":"pulsar","slug":"bigdata/pulsar","permalink":"https://yangbajing.github.io/categories/bigdata/pulsar/"},{"name":"work","slug":"work","permalink":"https://yangbajing.github.io/categories/work/"},{"name":"greenplum","slug":"bigdata/greenplum","permalink":"https://yangbajing.github.io/categories/bigdata/greenplum/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/categories/java/"},{"name":"flink","slug":"bigdata/flink","permalink":"https://yangbajing.github.io/categories/bigdata/flink/"},{"name":"作品","slug":"作品","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/"},{"name":"nacos-sdk-scala","slug":"作品/nacos-sdk-scala","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/nacos-sdk-scala/"},{"name":"akka-http-chinese","slug":"作品/akka-http-chinese","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/akka-http-chinese/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/categories/scala/"},{"name":"akka","slug":"scala/akka","permalink":"https://yangbajing.github.io/categories/scala/akka/"},{"name":"lecture","slug":"作品/lecture","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/lecture/"},{"name":"akka-cookbook","slug":"作品/akka-cookbook","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/akka-cookbook/"},{"name":"scala实战","slug":"scala/scala实战","permalink":"https://yangbajing.github.io/categories/scala/scala%E5%AE%9E%E6%88%98/"},{"name":"postgresql","slug":"bigdata/postgresql","permalink":"https://yangbajing.github.io/categories/bigdata/postgresql/"},{"name":"scala-web-development","slug":"作品/scala-web-development","permalink":"https://yangbajing.github.io/categories/%E4%BD%9C%E5%93%81/scala-web-development/"},{"name":"ambari/hdp","slug":"bigdata/ambari-hdp","permalink":"https://yangbajing.github.io/categories/bigdata/ambari-hdp/"},{"name":"unix/linux","slug":"unix-linux","permalink":"https://yangbajing.github.io/categories/unix-linux/"},{"name":"elasticsearch","slug":"bigdata/elasticsearch","permalink":"https://yangbajing.github.io/categories/bigdata/elasticsearch/"},{"name":"learning scala","slug":"scala/learning-scala","permalink":"https://yangbajing.github.io/categories/scala/learning-scala/"},{"name":"cassandra","slug":"bigdata/cassandra","permalink":"https://yangbajing.github.io/categories/bigdata/cassandra/"},{"name":"data","slug":"data","permalink":"https://yangbajing.github.io/categories/data/"},{"name":"spark","slug":"bigdata/spark","permalink":"https://yangbajing.github.io/categories/bigdata/spark/"},{"name":"c/c++","slug":"c-c","permalink":"https://yangbajing.github.io/categories/c-c/"}],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://yangbajing.github.io/tags/micro-service/"},{"name":"DDD","slug":"DDD","permalink":"https://yangbajing.github.io/tags/DDD/"},{"name":"mysql","slug":"mysql","permalink":"https://yangbajing.github.io/tags/mysql/"},{"name":"pulsar","slug":"pulsar","permalink":"https://yangbajing.github.io/tags/pulsar/"},{"name":"cdc","slug":"cdc","permalink":"https://yangbajing.github.io/tags/cdc/"},{"name":"functions","slug":"functions","permalink":"https://yangbajing.github.io/tags/functions/"},{"name":"debezium","slug":"debezium","permalink":"https://yangbajing.github.io/tags/debezium/"},{"name":"grpc","slug":"grpc","permalink":"https://yangbajing.github.io/tags/grpc/"},{"name":"api-design","slug":"api-design","permalink":"https://yangbajing.github.io/tags/api-design/"},{"name":"api","slug":"api","permalink":"https://yangbajing.github.io/tags/api/"},{"name":"protobuf","slug":"protobuf","permalink":"https://yangbajing.github.io/tags/protobuf/"},{"name":"postgres","slug":"postgres","permalink":"https://yangbajing.github.io/tags/postgres/"},{"name":"greenplum","slug":"greenplum","permalink":"https://yangbajing.github.io/tags/greenplum/"},{"name":"centos","slug":"centos","permalink":"https://yangbajing.github.io/tags/centos/"},{"name":"scheduler","slug":"scheduler","permalink":"https://yangbajing.github.io/tags/scheduler/"},{"name":"kafka","slug":"kafka","permalink":"https://yangbajing.github.io/tags/kafka/"},{"name":"etl","slug":"etl","permalink":"https://yangbajing.github.io/tags/etl/"},{"name":"flink","slug":"flink","permalink":"https://yangbajing.github.io/tags/flink/"},{"name":"realtime-etl","slug":"realtime-etl","permalink":"https://yangbajing.github.io/tags/realtime-etl/"},{"name":"r2dbc","slug":"r2dbc","permalink":"https://yangbajing.github.io/tags/r2dbc/"},{"name":"postgresql","slug":"postgresql","permalink":"https://yangbajing.github.io/tags/postgresql/"},{"name":"jdbc","slug":"jdbc","permalink":"https://yangbajing.github.io/tags/jdbc/"},{"name":"jackson","slug":"jackson","permalink":"https://yangbajing.github.io/tags/jackson/"},{"name":"enum","slug":"enum","permalink":"https://yangbajing.github.io/tags/enum/"},{"name":"mybatis-plus","slug":"mybatis-plus","permalink":"https://yangbajing.github.io/tags/mybatis-plus/"},{"name":"mybatis","slug":"mybatis","permalink":"https://yangbajing.github.io/tags/mybatis/"},{"name":"java","slug":"java","permalink":"https://yangbajing.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://yangbajing.github.io/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://yangbajing.github.io/tags/spring-boot/"},{"name":"scala","slug":"scala","permalink":"https://yangbajing.github.io/tags/scala/"},{"name":"json","slug":"json","permalink":"https://yangbajing.github.io/tags/json/"},{"name":"jackson-module-scala","slug":"jackson-module-scala","permalink":"https://yangbajing.github.io/tags/jackson-module-scala/"},{"name":"batch-insert","slug":"batch-insert","permalink":"https://yangbajing.github.io/tags/batch-insert/"},{"name":"exactly-once","slug":"exactly-once","permalink":"https://yangbajing.github.io/tags/exactly-once/"},{"name":"akka","slug":"akka","permalink":"https://yangbajing.github.io/tags/akka/"},{"name":"docker","slug":"docker","permalink":"https://yangbajing.github.io/tags/docker/"},{"name":"nacos","slug":"nacos","permalink":"https://yangbajing.github.io/tags/nacos/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://yangbajing.github.io/tags/spring-cloud/"},{"name":"play","slug":"play","permalink":"https://yangbajing.github.io/tags/play/"},{"name":"akka-http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"akka-http-chinese","slug":"akka-http-chinese","permalink":"https://yangbajing.github.io/tags/akka-http-chinese/"},{"name":"at-least-once-delivery","slug":"at-least-once-delivery","permalink":"https://yangbajing.github.io/tags/at-least-once-delivery/"},{"name":"akka-grpc","slug":"akka-grpc","permalink":"https://yangbajing.github.io/tags/akka-grpc/"},{"name":"scala-logging","slug":"scala-logging","permalink":"https://yangbajing.github.io/tags/scala-logging/"},{"name":"akka-log","slug":"akka-log","permalink":"https://yangbajing.github.io/tags/akka-log/"},{"name":"slf4j","slug":"slf4j","permalink":"https://yangbajing.github.io/tags/slf4j/"},{"name":"spring-log","slug":"spring-log","permalink":"https://yangbajing.github.io/tags/spring-log/"},{"name":"fusion-log","slug":"fusion-log","permalink":"https://yangbajing.github.io/tags/fusion-log/"},{"name":"coordinated-shutdown","slug":"coordinated-shutdown","permalink":"https://yangbajing.github.io/tags/coordinated-shutdown/"},{"name":"akka-streams","slug":"akka-streams","permalink":"https://yangbajing.github.io/tags/akka-streams/"},{"name":"top-k","slug":"top-k","permalink":"https://yangbajing.github.io/tags/top-k/"},{"name":"akka-cluster","slug":"akka-cluster","permalink":"https://yangbajing.github.io/tags/akka-cluster/"},{"name":"akka-persistence","slug":"akka-persistence","permalink":"https://yangbajing.github.io/tags/akka-persistence/"},{"name":"oauth-2","slug":"oauth-2","permalink":"https://yangbajing.github.io/tags/oauth-2/"},{"name":"oauth2","slug":"oauth2","permalink":"https://yangbajing.github.io/tags/oauth2/"},{"name":"access_token","slug":"access-token","permalink":"https://yangbajing.github.io/tags/access-token/"},{"name":"akka-cluster-sharding","slug":"akka-cluster-sharding","permalink":"https://yangbajing.github.io/tags/akka-cluster-sharding/"},{"name":"cqrs","slug":"cqrs","permalink":"https://yangbajing.github.io/tags/cqrs/"},{"name":"event-sourced","slug":"event-sourced","permalink":"https://yangbajing.github.io/tags/event-sourced/"},{"name":"cluster-sharding","slug":"cluster-sharding","permalink":"https://yangbajing.github.io/tags/cluster-sharding/"},{"name":"cluster-distributedata","slug":"cluster-distributedata","permalink":"https://yangbajing.github.io/tags/cluster-distributedata/"},{"name":"cluster-singleton","slug":"cluster-singleton","permalink":"https://yangbajing.github.io/tags/cluster-singleton/"},{"name":"akka-typed","slug":"akka-typed","permalink":"https://yangbajing.github.io/tags/akka-typed/"},{"name":"book","slug":"book","permalink":"https://yangbajing.github.io/tags/book/"},{"name":"akka-cookbook","slug":"akka-cookbook","permalink":"https://yangbajing.github.io/tags/akka-cookbook/"},{"name":"design-pattern","slug":"design-pattern","permalink":"https://yangbajing.github.io/tags/design-pattern/"},{"name":"akka-2.6","slug":"akka-2-6","permalink":"https://yangbajing.github.io/tags/akka-2-6/"},{"name":"reactive","slug":"reactive","permalink":"https://yangbajing.github.io/tags/reactive/"},{"name":"策服务","slug":"策服务","permalink":"https://yangbajing.github.io/tags/%E7%AD%96%E6%9C%8D%E5%8A%A1/"},{"name":"config","slug":"config","permalink":"https://yangbajing.github.io/tags/config/"},{"name":"配置","slug":"配置","permalink":"https://yangbajing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"akka-stream","slug":"akka-stream","permalink":"https://yangbajing.github.io/tags/akka-stream/"},{"name":"集群","slug":"集群","permalink":"https://yangbajing.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"cluster","slug":"cluster","permalink":"https://yangbajing.github.io/tags/cluster/"},{"name":"逻辑复制","slug":"逻辑复制","permalink":"https://yangbajing.github.io/tags/%E9%80%BB%E8%BE%91%E5%A4%8D%E5%88%B6/"},{"name":"logical replication","slug":"logical-replication","permalink":"https://yangbajing.github.io/tags/logical-replication/"},{"name":"replication","slug":"replication","permalink":"https://yangbajing.github.io/tags/replication/"},{"name":"wal","slug":"wal","permalink":"https://yangbajing.github.io/tags/wal/"},{"name":"ssl","slug":"ssl","permalink":"https://yangbajing.github.io/tags/ssl/"},{"name":"https","slug":"https","permalink":"https://yangbajing.github.io/tags/https/"},{"name":"http-2","slug":"http-2","permalink":"https://yangbajing.github.io/tags/http-2/"},{"name":"ssl-config","slug":"ssl-config","permalink":"https://yangbajing.github.io/tags/ssl-config/"},{"name":"linux","slug":"linux","permalink":"https://yangbajing.github.io/tags/linux/"},{"name":"firewall","slug":"firewall","permalink":"https://yangbajing.github.io/tags/firewall/"},{"name":"outofmemory","slug":"outofmemory","permalink":"https://yangbajing.github.io/tags/outofmemory/"},{"name":"vm.overcommit_memory","slug":"vm-overcommit-memory","permalink":"https://yangbajing.github.io/tags/vm-overcommit-memory/"},{"name":"reactor","slug":"reactor","permalink":"https://yangbajing.github.io/tags/reactor/"},{"name":"webflux","slug":"webflux","permalink":"https://yangbajing.github.io/tags/webflux/"},{"name":"functional","slug":"functional","permalink":"https://yangbajing.github.io/tags/functional/"},{"name":"script","slug":"script","permalink":"https://yangbajing.github.io/tags/script/"},{"name":"scala-script","slug":"scala-script","permalink":"https://yangbajing.github.io/tags/scala-script/"},{"name":"jenkins","slug":"jenkins","permalink":"https://yangbajing.github.io/tags/jenkins/"},{"name":"devops","slug":"devops","permalink":"https://yangbajing.github.io/tags/devops/"},{"name":"gitlab","slug":"gitlab","permalink":"https://yangbajing.github.io/tags/gitlab/"},{"name":"jenkins-pipeline","slug":"jenkins-pipeline","permalink":"https://yangbajing.github.io/tags/jenkins-pipeline/"},{"name":"jenkinsfile","slug":"jenkinsfile","permalink":"https://yangbajing.github.io/tags/jenkinsfile/"},{"name":"alpakka-kafka","slug":"alpakka-kafka","permalink":"https://yangbajing.github.io/tags/alpakka-kafka/"},{"name":"alpakka","slug":"alpakka","permalink":"https://yangbajing.github.io/tags/alpakka/"},{"name":"akka http","slug":"akka-http","permalink":"https://yangbajing.github.io/tags/akka-http/"},{"name":"html5","slug":"html5","permalink":"https://yangbajing.github.io/tags/html5/"},{"name":"断点上传","slug":"断点上传","permalink":"https://yangbajing.github.io/tags/%E6%96%AD%E7%82%B9%E4%B8%8A%E4%BC%A0/"},{"name":"断点下载","slug":"断点下载","permalink":"https://yangbajing.github.io/tags/%E6%96%AD%E7%82%B9%E4%B8%8B%E8%BD%BD/"},{"name":"scala-web","slug":"scala-web","permalink":"https://yangbajing.github.io/tags/scala-web/"},{"name":"slick","slug":"slick","permalink":"https://yangbajing.github.io/tags/slick/"},{"name":"slick-pg","slug":"slick-pg","permalink":"https://yangbajing.github.io/tags/slick-pg/"},{"name":"4a","slug":"4a","permalink":"https://yangbajing.github.io/tags/4a/"},{"name":"user-system","slug":"user-system","permalink":"https://yangbajing.github.io/tags/user-system/"},{"name":"scalatest","slug":"scalatest","permalink":"https://yangbajing.github.io/tags/scalatest/"},{"name":"akka-http-testkit","slug":"akka-http-testkit","permalink":"https://yangbajing.github.io/tags/akka-http-testkit/"},{"name":"route","slug":"route","permalink":"https://yangbajing.github.io/tags/route/"},{"name":"test","slug":"test","permalink":"https://yangbajing.github.io/tags/test/"},{"name":"nginx","slug":"nginx","permalink":"https://yangbajing.github.io/tags/nginx/"},{"name":"tengine","slug":"tengine","permalink":"https://yangbajing.github.io/tags/tengine/"},{"name":"elt","slug":"elt","permalink":"https://yangbajing.github.io/tags/elt/"},{"name":"reactivestream","slug":"reactivestream","permalink":"https://yangbajing.github.io/tags/reactivestream/"},{"name":"mass-data","slug":"mass-data","permalink":"https://yangbajing.github.io/tags/mass-data/"},{"name":"mass-rdi","slug":"mass-rdi","permalink":"https://yangbajing.github.io/tags/mass-rdi/"},{"name":"ambari","slug":"ambari","permalink":"https://yangbajing.github.io/tags/ambari/"},{"name":"hdp","slug":"hdp","permalink":"https://yangbajing.github.io/tags/hdp/"},{"name":"centos7","slug":"centos7","permalink":"https://yangbajing.github.io/tags/centos7/"},{"name":"shell","slug":"shell","permalink":"https://yangbajing.github.io/tags/shell/"},{"name":"vim","slug":"vim","permalink":"https://yangbajing.github.io/tags/vim/"},{"name":"bash","slug":"bash","permalink":"https://yangbajing.github.io/tags/bash/"},{"name":"postgresql 10","slug":"postgresql-10","permalink":"https://yangbajing.github.io/tags/postgresql-10/"},{"name":"sbt","slug":"sbt","permalink":"https://yangbajing.github.io/tags/sbt/"},{"name":"idea","slug":"idea","permalink":"https://yangbajing.github.io/tags/idea/"},{"name":"Sphinx 撰写 电子文档","slug":"Sphinx-撰写-电子文档","permalink":"https://yangbajing.github.io/tags/Sphinx-%E6%92%B0%E5%86%99-%E7%94%B5%E5%AD%90%E6%96%87%E6%A1%A3/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://yangbajing.github.io/tags/elasticsearch/"},{"name":"hanlp","slug":"hanlp","permalink":"https://yangbajing.github.io/tags/hanlp/"},{"name":"cassandra","slug":"cassandra","permalink":"https://yangbajing.github.io/tags/cassandra/"},{"name":"oracle","slug":"oracle","permalink":"https://yangbajing.github.io/tags/oracle/"},{"name":"neokylin","slug":"neokylin","permalink":"https://yangbajing.github.io/tags/neokylin/"},{"name":"互操作","slug":"互操作","permalink":"https://yangbajing.github.io/tags/%E4%BA%92%E6%93%8D%E4%BD%9C/"},{"name":"gradle","slug":"gradle","permalink":"https://yangbajing.github.io/tags/gradle/"},{"name":"about","slug":"about","permalink":"https://yangbajing.github.io/tags/about/"},{"name":"collection","slug":"collection","permalink":"https://yangbajing.github.io/tags/collection/"},{"name":"入门","slug":"入门","permalink":"https://yangbajing.github.io/tags/%E5%85%A5%E9%97%A8/"},{"name":"scala, akka, actor","slug":"scala-akka-actor","permalink":"https://yangbajing.github.io/tags/scala-akka-actor/"},{"name":"工作","slug":"工作","permalink":"https://yangbajing.github.io/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"技术架构","slug":"技术架构","permalink":"https://yangbajing.github.io/tags/%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/"},{"name":"技术选型","slug":"技术选型","permalink":"https://yangbajing.github.io/tags/%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/"},{"name":"Scala","slug":"Scala","permalink":"https://yangbajing.github.io/tags/Scala/"},{"name":"Java","slug":"Java","permalink":"https://yangbajing.github.io/tags/Java/"},{"name":"Node","slug":"Node","permalink":"https://yangbajing.github.io/tags/Node/"},{"name":"Go","slug":"Go","permalink":"https://yangbajing.github.io/tags/Go/"},{"name":"Python","slug":"Python","permalink":"https://yangbajing.github.io/tags/Python/"},{"name":"spark","slug":"spark","permalink":"https://yangbajing.github.io/tags/spark/"},{"name":"hadoop","slug":"hadoop","permalink":"https://yangbajing.github.io/tags/hadoop/"},{"name":"hive","slug":"hive","permalink":"https://yangbajing.github.io/tags/hive/"},{"name":"spark sql","slug":"spark-sql","permalink":"https://yangbajing.github.io/tags/spark-sql/"},{"name":"upgrading","slug":"upgrading","permalink":"https://yangbajing.github.io/tags/upgrading/"},{"name":"maven","slug":"maven","permalink":"https://yangbajing.github.io/tags/maven/"},{"name":"system-manager","slug":"system-manager","permalink":"https://yangbajing.github.io/tags/system-manager/"},{"name":"mongodb","slug":"mongodb","permalink":"https://yangbajing.github.io/tags/mongodb/"},{"name":"log","slug":"log","permalink":"https://yangbajing.github.io/tags/log/"},{"name":"logrotate","slug":"logrotate","permalink":"https://yangbajing.github.io/tags/logrotate/"},{"name":"生活","slug":"生活","permalink":"https://yangbajing.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"crawler","slug":"crawler","permalink":"https://yangbajing.github.io/tags/crawler/"},{"name":"python","slug":"python","permalink":"https://yangbajing.github.io/tags/python/"},{"name":"并发","slug":"并发","permalink":"https://yangbajing.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"scala实战","slug":"scala实战","permalink":"https://yangbajing.github.io/tags/scala%E5%AE%9E%E6%88%98/"},{"name":"future","slug":"future","permalink":"https://yangbajing.github.io/tags/future/"},{"name":"promise","slug":"promise","permalink":"https://yangbajing.github.io/tags/promise/"},{"name":"rest","slug":"rest","permalink":"https://yangbajing.github.io/tags/rest/"},{"name":"json4s","slug":"json4s","permalink":"https://yangbajing.github.io/tags/json4s/"},{"name":"akka实战","slug":"akka实战","permalink":"https://yangbajing.github.io/tags/akka%E5%AE%9E%E6%88%98/"},{"name":"反向代理","slug":"反向代理","permalink":"https://yangbajing.github.io/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://yangbajing.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"upstream","slug":"upstream","permalink":"https://yangbajing.github.io/tags/upstream/"},{"name":"proxy","slug":"proxy","permalink":"https://yangbajing.github.io/tags/proxy/"},{"name":"微信开发","slug":"微信开发","permalink":"https://yangbajing.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91/"},{"name":"activemq","slug":"activemq","permalink":"https://yangbajing.github.io/tags/activemq/"},{"name":"email","slug":"email","permalink":"https://yangbajing.github.io/tags/email/"},{"name":"gatling","slug":"gatling","permalink":"https://yangbajing.github.io/tags/gatling/"},{"name":"playframework","slug":"playframework","permalink":"https://yangbajing.github.io/tags/playframework/"},{"name":"reactivemongo","slug":"reactivemongo","permalink":"https://yangbajing.github.io/tags/reactivemongo/"},{"name":"活动报名","slug":"活动报名","permalink":"https://yangbajing.github.io/tags/%E6%B4%BB%E5%8A%A8%E6%8A%A5%E5%90%8D/"},{"name":"git","slug":"git","permalink":"https://yangbajing.github.io/tags/git/"},{"name":"redis","slug":"redis","permalink":"https://yangbajing.github.io/tags/redis/"},{"name":"accesstoken","slug":"accesstoken","permalink":"https://yangbajing.github.io/tags/accesstoken/"},{"name":"mac","slug":"mac","permalink":"https://yangbajing.github.io/tags/mac/"},{"name":"sphinx-doc","slug":"sphinx-doc","permalink":"https://yangbajing.github.io/tags/sphinx-doc/"},{"name":"pdf","slug":"pdf","permalink":"https://yangbajing.github.io/tags/pdf/"},{"name":"环境变量","slug":"环境变量","permalink":"https://yangbajing.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"name":"option","slug":"option","permalink":"https://yangbajing.github.io/tags/option/"},{"name":"either","slug":"either","permalink":"https://yangbajing.github.io/tags/either/"},{"name":"try","slug":"try","permalink":"https://yangbajing.github.io/tags/try/"},{"name":"liftweb","slug":"liftweb","permalink":"https://yangbajing.github.io/tags/liftweb/"},{"name":"jquery","slug":"jquery","permalink":"https://yangbajing.github.io/tags/jquery/"},{"name":"c","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"https://yangbajing.github.io/tags/c/"},{"name":"qt","slug":"qt","permalink":"https://yangbajing.github.io/tags/qt/"},{"name":"unix","slug":"unix","permalink":"https://yangbajing.github.io/tags/unix/"},{"name":"network","slug":"network","permalink":"https://yangbajing.github.io/tags/network/"},{"name":"中文字符集","slug":"中文字符集","permalink":"https://yangbajing.github.io/tags/%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6%E9%9B%86/"},{"name":"eclipse","slug":"eclipse","permalink":"https://yangbajing.github.io/tags/eclipse/"}]}